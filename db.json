{"meta":{"version":1,"warehouse":"1.0.2"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1},{"_id":"source/upload/java-at-alibaba.pptx","path":"upload/java-at-alibaba.pptx","modified":1},{"_id":"source/images/wpid-nio-oio.jpg","path":"images/wpid-nio-oio.jpg","modified":1},{"_id":"source/images/wpid-Netty-thread-model3.png","path":"images/wpid-Netty-thread-model3.png","modified":1},{"_id":"source/images/wpid-Netty-ChannelPipeline-.png","path":"images/wpid-Netty-ChannelPipeline-.png","modified":1},{"_id":"source/images/wpid-Multi-reactors3.png","path":"images/wpid-Multi-reactors3.png","modified":1},{"_id":"source/images/wpid-EventLoopAndEventExecutor3.jpg","path":"images/wpid-EventLoopAndEventExecutor3.jpg","modified":1},{"_id":"source/images/wpid-Channel.png","path":"images/wpid-Channel.png","modified":1},{"_id":"source/images/solr-DocSet.png","path":"images/solr-DocSet.png","modified":1},{"_id":"source/images/reactors-in-threads.png","path":"images/reactors-in-threads.png","modified":1},{"_id":"source/images/reactors-in-threads-thread-pool.png","path":"images/reactors-in-threads-thread-pool.png","modified":1},{"_id":"source/images/reactor-thread-pool.png","path":"images/reactor-thread-pool.png","modified":1},{"_id":"source/images/reactor-single-thread.png","path":"images/reactor-single-thread.png","modified":1},{"_id":"source/images/ranksystem-in-social-network.png","path":"images/ranksystem-in-social-network.png","modified":1},{"_id":"source/images/facet-1.png","path":"images/facet-1.png","modified":1},{"_id":"source/images/bytebuf-priciple.png","path":"images/bytebuf-priciple.png","modified":1},{"_id":"source/images/bytebuf-diagram.jpg","path":"images/bytebuf-diagram.jpg","modified":1},{"_id":"source/images/bytebuf-combine-slice-buffer.png","path":"images/bytebuf-combine-slice-buffer.png","modified":1},{"_id":"source/favicon.png","path":"favicon.png","modified":1},{"_id":"themes/next/source/vendors/velocity/velocity.ui.min.js","path":"vendors/velocity/velocity.ui.min.js","modified":1},{"_id":"themes/next/source/vendors/velocity/velocity.ui.js","path":"vendors/velocity/velocity.ui.js","modified":1},{"_id":"themes/next/source/vendors/velocity/velocity.min.js","path":"vendors/velocity/velocity.min.js","modified":1},{"_id":"themes/next/source/vendors/velocity/velocity.js","path":"vendors/velocity/velocity.js","modified":1},{"_id":"themes/next/source/vendors/velocity/bower.json","path":"vendors/velocity/bower.json","modified":1},{"_id":"themes/next/source/vendors/jquery/index.js","path":"vendors/jquery/index.js","modified":1},{"_id":"themes/next/source/vendors/fastclick/lib/fastclick.min.js","path":"vendors/fastclick/lib/fastclick.min.js","modified":1},{"_id":"themes/next/source/vendors/fastclick/lib/fastclick.js","path":"vendors/fastclick/lib/fastclick.js","modified":1},{"_id":"themes/next/source/vendors/fastclick/bower.json","path":"vendors/fastclick/bower.json","modified":1},{"_id":"themes/next/source/vendors/fastclick/README.md","path":"vendors/fastclick/README.md","modified":1},{"_id":"themes/next/source/vendors/fastclick/LICENSE","path":"vendors/fastclick/LICENSE","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.pack.js","path":"vendors/fancybox/source/jquery.fancybox.pack.js","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.js","path":"vendors/fancybox/source/jquery.fancybox.js","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.css","path":"vendors/fancybox/source/jquery.fancybox.css","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-media.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-media.js","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/helpers/fancybox_buttons.png","path":"vendors/fancybox/source/helpers/fancybox_buttons.png","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite@2x.png","path":"vendors/fancybox/source/fancybox_sprite@2x.png","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite.png","path":"vendors/fancybox/source/fancybox_sprite.png","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_overlay.png","path":"vendors/fancybox/source/fancybox_overlay.png","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading@2x.gif","path":"vendors/fancybox/source/fancybox_loading@2x.gif","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading.gif","path":"vendors/fancybox/source/fancybox_loading.gif","modified":1},{"_id":"themes/next/source/vendors/fancybox/source/blank.gif","path":"vendors/fancybox/source/blank.gif","modified":1},{"_id":"themes/next/source/js/ua-parser.min.js","path":"js/ua-parser.min.js","modified":1},{"_id":"themes/next/source/js/nav-toggle.js","path":"js/nav-toggle.js","modified":1},{"_id":"themes/next/source/js/motion_global.js","path":"js/motion_global.js","modified":1},{"_id":"themes/next/source/js/motion_fallback.js","path":"js/motion_fallback.js","modified":1},{"_id":"themes/next/source/js/lazyload.js","path":"js/lazyload.js","modified":1},{"_id":"themes/next/source/js/hook-duoshuo.js","path":"js/hook-duoshuo.js","modified":1},{"_id":"themes/next/source/js/helpers.js","path":"js/helpers.js","modified":1},{"_id":"themes/next/source/js/fancy-box.js","path":"js/fancy-box.js","modified":1},{"_id":"themes/next/source/js/bootstrap.scrollspy.js","path":"js/bootstrap.scrollspy.js","modified":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1},{"_id":"themes/next/source/images/hongweiyi.jpg","path":"images/hongweiyi.jpg","modified":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1},{"_id":"themes/next/source/images/bkdefault_avatar.jpg","path":"images/bkdefault_avatar.jpg","modified":1},{"_id":"themes/next/source/fonts/icon-linecons/selection.json","path":"fonts/icon-linecons/selection.json","modified":1},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.woff","path":"fonts/icon-linecons/icomoon.woff","modified":1},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.ttf","path":"fonts/icon-linecons/icomoon.ttf","modified":1},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.svg","path":"fonts/icon-linecons/icomoon.svg","modified":1},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.eot","path":"fonts/icon-linecons/icomoon.eot","modified":1},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.woff","path":"fonts/icon-icomoon/icomoon.woff","modified":1},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.ttf","path":"fonts/icon-icomoon/icomoon.ttf","modified":1},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.svg","path":"fonts/icon-icomoon/icomoon.svg","modified":1},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.eot","path":"fonts/icon-icomoon/icomoon.eot","modified":1},{"_id":"themes/next/source/fonts/icon-fifty-shades/selection.json","path":"fonts/icon-fifty-shades/selection.json","modified":1},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.woff","path":"fonts/icon-fifty-shades/icomoon.woff","modified":1},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.ttf","path":"fonts/icon-fifty-shades/icomoon.ttf","modified":1},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.svg","path":"fonts/icon-fifty-shades/icomoon.svg","modified":1},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.eot","path":"fonts/icon-fifty-shades/icomoon.eot","modified":1},{"_id":"themes/next/source/fonts/icon-feather/selection.json","path":"fonts/icon-feather/selection.json","modified":1},{"_id":"themes/next/source/fonts/icon-feather/icomoon.woff","path":"fonts/icon-feather/icomoon.woff","modified":1},{"_id":"themes/next/source/fonts/icon-feather/icomoon.ttf","path":"fonts/icon-feather/icomoon.ttf","modified":1},{"_id":"themes/next/source/fonts/icon-feather/icomoon.svg","path":"fonts/icon-feather/icomoon.svg","modified":1},{"_id":"themes/next/source/fonts/icon-feather/icomoon.eot","path":"fonts/icon-feather/icomoon.eot","modified":1},{"_id":"themes/next/source/fonts/icon-default/selection.json","path":"fonts/icon-default/selection.json","modified":1},{"_id":"themes/next/source/fonts/icon-default/icomoon.woff","path":"fonts/icon-default/icomoon.woff","modified":1},{"_id":"themes/next/source/fonts/icon-default/icomoon.ttf","path":"fonts/icon-default/icomoon.ttf","modified":1},{"_id":"themes/next/source/fonts/icon-default/icomoon.svg","path":"fonts/icon-default/icomoon.svg","modified":1},{"_id":"themes/next/source/fonts/icon-default/icomoon.eot","path":"fonts/icon-default/icomoon.eot","modified":1},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1}],"Cache":[{"_id":"source/CNAME","shasum":"0ac7ddcf1b989fbcc91f6ca144101324ffac8de4","modified":1451395815000},{"_id":"source/_posts/2013-learning-plan.md","shasum":"fb8c1db1948c8e5c8317405015f1b97d58cb8d76","modified":1451395863000},{"_id":"source/_posts/README.md","shasum":"ed7b6e8cb12f4361f78ddf68b5f4cda552ae0ef8","modified":1451395815000},{"_id":"source/_posts/algorithm-dynammic-programming.md","shasum":"771657ed51abfae51b5b0da1c22cb33ae008cda1","modified":1451395863000},{"_id":"source/_posts/algorithm-probability.md","shasum":"7935348a676fa92cd24964f13eda672c1326523b","modified":1451395863000},{"_id":"source/_posts/algorithm-search.md","shasum":"2f8cbfbb1f6f9590d157692394169861bb735526","modified":1451395863000},{"_id":"source/_posts/android-ui.md","shasum":"39cf2fb69270ec0d84dea24dba55e2f6c8d27223","modified":1451395863000},{"_id":"source/_posts/apache-hadoop-yarn-background-and-an-overview.md","shasum":"7bbcc8c84f1b141aa5bc9fec95940e48e613c5e5","modified":1451395863000},{"_id":"source/_posts/apache-solr-data-structrue-part-1.md","shasum":"019a367be39c204664ce59b7118f727e197578be","modified":1451395815000},{"_id":"source/_posts/apache-solr-data-structrue-part-2.md","shasum":"4c0477b4a51aedfd98c4363d1f778cd9c81bf81b","modified":1451395815000},{"_id":"source/_posts/apache-solr-distributed-search.md","shasum":"585bbeb4d8acbdbd18252c9b3cd0fcb599111700","modified":1451395815000},{"_id":"source/_posts/apache-solr-facet-introduction.md","shasum":"504e22b7d7a847db4560a00f0a4ccadb4cecdb62","modified":1451395815000},{"_id":"source/_posts/apache-solr-facet-pivot-implementation-tranplant.md","shasum":"39dba09d46ab464c725f1317de2b410745e9e187","modified":1451395815000},{"_id":"source/_posts/buying-laptop.md","shasum":"c4dd155780d97cf9d72f011fd5f6845023422b08","modified":1451395863000},{"_id":"source/_posts/configurate-solr-src-in-eclipse.md","shasum":"12b0ea559874ef8ea45e2ddbf08981dd71b73a7b","modified":1451395863000},{"_id":"source/_posts/css-practice.md","shasum":"4c66d9c02f21b6404006cf85bf18276a65e31387","modified":1451395815000},{"_id":"source/_posts/data-structure-bitmap.md","shasum":"811675c96fea2172b72d6599bc2675e5384fbc42","modified":1451395863000},{"_id":"source/_posts/data-structure-disjoint-set.md","shasum":"b5677c206c681284df3cff984f8f19ea4c4464b7","modified":1451395863000},{"_id":"source/_posts/data-structure-skiplists.md","shasum":"d9a94045c9f7a81e956cd907e18c2ecc9293df9f","modified":1451395863000},{"_id":"source/_posts/design-pattern-adapter.md","shasum":"4b8f9acdeaf3902530acf9f1a0708214e3817b49","modified":1451395863000},{"_id":"source/_posts/design-pattern-additional.md","shasum":"52d1912dd690af12eadd183fdda60b0b03f94344","modified":1451395863000},{"_id":"source/_posts/design-pattern-cor.md","shasum":"8826645d3c47b9a7dd8c7f299e0b3a702b836ece","modified":1451395863000},{"_id":"source/_posts/design-pattern-decorate.md","shasum":"f52230d154aa5c08b84f7e9ec22ca07d178f689c","modified":1451395863000},{"_id":"source/_posts/design-pattern-facade.md","shasum":"2aeba82664c17356617051a5b7a1ed6d557c0e85","modified":1451395863000},{"_id":"source/_posts/design-pattern-factory-abs.md","shasum":"5a318d6a76e46e3eab27b5cccbc4b46705da48e7","modified":1451395863000},{"_id":"source/_posts/design-pattern-factory.md","shasum":"4d4bef90157e5f868d4ff4c11cd4f51638fc20dc","modified":1451395863000},{"_id":"source/_posts/design-pattern-observer.md","shasum":"8314b2d6f4a35a4e5fbe24d585bdd4681d3f3ac6","modified":1451395863000},{"_id":"source/_posts/design-pattern-proxy.md","shasum":"b5e42a3284e8a40173ee78a1ea5f00d759c8a3c6","modified":1451395863000},{"_id":"source/_posts/design-pattern-singleton.md","shasum":"0ae22916bf2adbfe8a21991621e91ef3d597db04","modified":1451395863000},{"_id":"source/_posts/dist-filesystem-metadata-server.md","shasum":"cfed853d5855661e4821b413694a0b2cc830f470","modified":1451395863000},{"_id":"source/_posts/ditital-screen.md","shasum":"be9f5a9518785f2761a7522b94fe22fee100add0","modified":1451395863000},{"_id":"source/_posts/docker-compose-pratice.md","shasum":"81d723d410f9fb2fa4cc0796a182272ddbd292ef","modified":1451395815000},{"_id":"source/_posts/docker-volume-plugin.md","shasum":"3967ae1a2d2c17241c312defdd7292f33915f2b8","modified":1451395815000},{"_id":"source/_posts/eclipse-plugin-unintall.md","shasum":"a7a62b7d1be9b5f31d712cf94bb9e412a4321b31","modified":1451395863000},{"_id":"source/_posts/english-punctuate.md","shasum":"742db7c728a94aa1108ce69f6b1d908fa9aef47b","modified":1451395863000},{"_id":"source/_posts/forget-your-lusts-1.md","shasum":"c2549c0150e9a91a760a5d49f3544632e73a0e24","modified":1451395863000},{"_id":"source/_posts/forget-your-lusts.md","shasum":"fd8cb51f74651eaf568218e3d45093804f123ff6","modified":1451395815000},{"_id":"source/_posts/git-practice.md","shasum":"9d2244c9fd42c307cff874ed500d22c83e6c2f06","modified":1451396758000},{"_id":"source/_posts/google-doodle-for-turing.md","shasum":"2444ec07c8d88ef75307937a6ed157057abe11bf","modified":1451395863000},{"_id":"source/_posts/hadoop-bug-in-text.md","shasum":"a7a0c6b30777856ead1128d5be39ceb49afd9d78","modified":1451395863000},{"_id":"source/_posts/hadoop-default-conf.md","shasum":"af763ca33a80bd0a3572f852d85bb35152e7f0ea","modified":1451395863000},{"_id":"source/_posts/hadoop-ipc-client.md","shasum":"3a8e412eab6a23ca9bf30e35b95369819f6d67da","modified":1451395863000},{"_id":"source/_posts/hadoop-ipc-rpc.md","shasum":"e944a7d9d7c70e6389019697aede4967e07655a8","modified":1451395863000},{"_id":"source/_posts/hadoop-ipc-server.md","shasum":"9fbf8215395d4506d9c58e50964a53f912b04b6c","modified":1451395863000},{"_id":"source/_posts/hadoop-pipes-src.md","shasum":"94dfb25ff9944cc4a9e8ffde94ee5f95ec1e5f64","modified":1451395863000},{"_id":"source/_posts/hadoop-related.md","shasum":"7eb58b27d96673d85ce90c0ab28eb2c53f983c3e","modified":1451395863000},{"_id":"source/_posts/hadoop-pipes.md","shasum":"df6bc3d8f38d624d02f9869082b52281800ccd3e","modified":1451395863000},{"_id":"source/_posts/hello-sae.md","shasum":"4cb7e6036fdc4f3e0ea0dc9c0ea7e9a6a8e67842","modified":1451395863000},{"_id":"source/_posts/i-need-an-answer-now-from-remote.md","shasum":"20d5379d0d60448a66f9ece49d5d9b21a588046d","modified":1451395815000},{"_id":"source/_posts/iterative-mapred-distcache.md","shasum":"a4a882b9756fb34a985820262da87c8d8a13d3db","modified":1451395863000},{"_id":"source/_posts/iterative-mapred-summary-haloop.md","shasum":"ac6d73ea1ee127cbc5eae36a401271a8653672e4","modified":1451395863000},{"_id":"source/_posts/iterative-mapred.md","shasum":"751f369ed02ed5c78c0b682aa9d1a9da78d852ba","modified":1451395863000},{"_id":"source/_posts/java-boxing.md","shasum":"accc97d3d06692e9e0de8e8de2fa5969e9c4beff","modified":1451395863000},{"_id":"source/_posts/java-practice.md","shasum":"7d255690325ed7063c0d07bced981eaf75cec93a","modified":1451395815000},{"_id":"source/_posts/java-probability.md","shasum":"e3d4f226674fc618035edd0226455fb6ae46d8f5","modified":1451395863000},{"_id":"source/_posts/java-source-code-practice.md","shasum":"e35e352d2d089d63fd1be1bee46675ba56f8533e","modified":1451395815000},{"_id":"source/_posts/jvm-structure.md","shasum":"f48a27d76501c04754e8e5c7e2e08eb7cde5bfa6","modified":1451395863000},{"_id":"source/_posts/les-miserables-lrc.md","shasum":"9efeaa71f0d0f0c558f5912426cc1e8e73b6a4cf","modified":1451395863000},{"_id":"source/_posts/linux-file-directory-shell.md","shasum":"ac4115abe6d9743c2bc82df4a807cf8aece1a000","modified":1451395863000},{"_id":"source/_posts/linux-process-shell.md","shasum":"c74c929d0e79d6177b627988fa008dbe56eeaf4f","modified":1451395863000},{"_id":"source/_posts/linux-shell-term-tuning.md","shasum":"bee86db5dc3bc83d1f39852d7e9d08a0034529a0","modified":1451395863000},{"_id":"source/_posts/linux-text-shell.md","shasum":"79cbb889e042081ae703322d9e6a6f74910ebd4e","modified":1451395863000},{"_id":"source/_posts/mapred-optimize-writable.md","shasum":"6a7e2c3ed152376727807e0886ccd016873910ab","modified":1451395863000},{"_id":"source/_posts/mapred-optimize.md","shasum":"6cde0c6828565d89e43fc9d8b8f6641ee38988c7","modified":1451395863000},{"_id":"source/_posts/mapreduce-task-src-analysis.md","shasum":"09e02be775df155e8462c38f7f6dec2b28b64a24","modified":1451395863000},{"_id":"source/_posts/maven-coordinates-dependencies.md","shasum":"9235207c574a76659697cf1bbec8aee04c14af71","modified":1451395863000},{"_id":"source/_posts/maven-repositories.md","shasum":"818821e775e5f56246a0b4e2df26793691f5f5ad","modified":1451395863000},{"_id":"source/_posts/multi-columns-group-by.md","shasum":"b9996094cb2f72f9acfff6bb610412ca5f8c4166","modified":1451395863000},{"_id":"source/_posts/my-macbook.md","shasum":"e4d02b2b7834be96c933f670b4a8c42cb94c43e7","modified":1451395863000},{"_id":"source/_posts/my-motive.md","shasum":"6c85bdc13f75c920f07ea73b11ed11076cbf13d9","modified":1451395863000},{"_id":"source/_posts/netty-4-x-bytebuf.md","shasum":"cf5be6da4996618547c4ebb96abcbd4dd435bb77","modified":1451395815000},{"_id":"source/_posts/netty-4-x-channel-pipeline.md","shasum":"dc4638a1e3046b17fe979c28995208d7f4489780","modified":1451395815000},{"_id":"source/_posts/netty-4-x-thread-model.md","shasum":"6e902100ff218758cb15c5c1200f82e3fa95fb1b","modified":1451395815000},{"_id":"source/_posts/netty-mina-in-depth-1.md","shasum":"4bdaa9ac00fe395b951fdc0a3285d0948da84d6f","modified":1451395815000},{"_id":"source/_posts/netty-mina-in-depth-2.md","shasum":"959f1dc0d5a16b48aa38a6a8bd67ab6402146fc4","modified":1451395815000},{"_id":"source/_posts/nlp-repost-segmentation.md","shasum":"2feec3242e7acb0f290764d723b4c9a1fa08cc6b","modified":1451395863000},{"_id":"source/_posts/nlp-repost-semantic.md","shasum":"5a59a7555d3650aba717bf37f53f17e7edc85e2d","modified":1451395863000},{"_id":"source/_posts/nlp-say-hi.md","shasum":"c460b5a20c41ae1a8b74dc585643a301b028c705","modified":1451395863000},{"_id":"source/_posts/once-java-profiling.md","shasum":"918496494a06bf64d913d2aa6e29dc0a3216d119","modified":1451395863000},{"_id":"source/_posts/oom-killer-1.md","shasum":"b48bac6ad708228f6647c738c244894f9a62714f","modified":1451396619000},{"_id":"source/_posts/photometry.md","shasum":"49ac1158e08f699c49eb6b378ea3f893fb31e1bf","modified":1451396618000},{"_id":"source/_posts/python-chat.md","shasum":"2bf804091032dd5098973fa395b39a3226369ddc","modified":1451395863000},{"_id":"source/_posts/python-traverse-dir.md","shasum":"ea03eec7160a3347b20b98d2d105796795470174","modified":1451395863000},{"_id":"source/_posts/ranksystem-in-social-network.md","shasum":"3013bc1811e81068798da2d2d6c8b7ffa7e48dd9","modified":1451396289000},{"_id":"source/_posts/re-equip-my-little-black.md","shasum":"57ec881b6cbf0672431e5ef355ddebfd8bb1d0eb","modified":1451395863000},{"_id":"source/_posts/redis-data-strutrue.md","shasum":"2c258874644a23551780c681d3c95e2f7127cba6","modified":1451395863000},{"_id":"source/_posts/relax-schrodinger-cat.md","shasum":"9785917918539f203013b2a515668fd38f94dbef","modified":1451395863000},{"_id":"source/_posts/remoting-practice.md","shasum":"cacdab9eb0883789117224138b0327116a64fdae","modified":1451395815000},{"_id":"source/_posts/rework-digest.md","shasum":"fcdaed2747fcb5dce72f13aea51de39719eb60d6","modified":1451395815000},{"_id":"source/_posts/single-lens-paraxonic.md","shasum":"d75e64e7d9f1d1c901fbcc8394f49d22f95603bd","modified":1451395863000},{"_id":"source/_posts/solr-switch-query-parser.md","shasum":"df8a14ed2566ceb82e4297cd2ea2da724e72678c","modified":1451395863000},{"_id":"source/_posts/study-school-sociey.md","shasum":"25f4b26fd1a1c10fbf29043af2873d05fee7a812","modified":1451395863000},{"_id":"source/_posts/system-architecture-stuffs.md","shasum":"7c7b46a88922fbe8060455205a5b1fe897912567","modified":1451395863000},{"_id":"source/_posts/truth-in-rumor.md","shasum":"b57775270a5e5a479766b3b5d4978a0891ef1eba","modified":1451395863000},{"_id":"source/_posts/the-nosql-ecosystem.md","shasum":"04db00b083abe34841a01b15a6d5ff0d94bef386","modified":1451395863000},{"_id":"source/_posts/wanting-qu.md","shasum":"89ef8685a5cfeaafdabc46a081af248bae59ab26","modified":1451395863000},{"_id":"source/_posts/weibo-analysis.md","shasum":"34c30e16d4857ba28cd413263adc5291f9180cb1","modified":1451395863000},{"_id":"source/_posts/what-i-think-about-1111.md","shasum":"6e032ac22fd68daf5b0f7f3c9170ba089aaebc80","modified":1451395863000},{"_id":"source/_posts/zookeeper-ephemeral-nodes-experience.md","shasum":"5e8c047abc28c32acefb32fbfac6b4951f65d386","modified":1451395863000},{"_id":"source/favicon.png","shasum":"6cdd78df2d91e397f08a981df6e5bb58896f1f80","modified":1451395815000},{"_id":"source/images/bytebuf-diagram.jpg","shasum":"81f2c3c1b19f01d6af05b2de19124c93ea3cad23","modified":1451395815000},{"_id":"source/images/bytebuf-priciple.png","shasum":"f2abcaa081d341f8b6aaa1c7c19e7c562329475b","modified":1451395815000},{"_id":"source/images/facet-1.png","shasum":"938bd19a87b24de5485960176c817bdac85b6093","modified":1451395815000},{"_id":"source/images/reactor-single-thread.png","shasum":"799dbea22e802bf51877500c9d7a80621baadc44","modified":1451395815000},{"_id":"source/tags/index.md","shasum":"6c8fe74182de9061c3a10e994aaccab990e58f1a","modified":1451395815000},{"_id":"source/images/bytebuf-combine-slice-buffer.png","shasum":"a073deecce1516d12e2270f373ccfa8bc57b87fd","modified":1451395815000},{"_id":"source/images/reactor-thread-pool.png","shasum":"2698dc114f10fdddef468dd49f23338f743c319e","modified":1451395815000},{"_id":"source/images/wpid-EventLoopAndEventExecutor3.jpg","shasum":"2fa9ffd6acb767bf9c8f23da2271354dba8bee63","modified":1451395815000},{"_id":"source/images/wpid-nio-oio.jpg","shasum":"ac7df496f41f1b549b41a4a4404a437ea18460c9","modified":1451395815000},{"_id":"source/images/reactors-in-threads-thread-pool.png","shasum":"cf1805741cd76ae36b85f51e3b5c455c418fa910","modified":1451395815000},{"_id":"source/images/reactors-in-threads.png","shasum":"31e20bc84b78d60af27998c0a154014babfb09dd","modified":1451395815000},{"_id":"source/images/wpid-Channel.png","shasum":"06acf8025d55d644ecb8d153a62c438ce6f07b8f","modified":1451395815000},{"_id":"source/images/solr-DocSet.png","shasum":"08891f7f7c7f3ee40161f9b8a01012249e5d9151","modified":1451395815000},{"_id":"source/images/wpid-Netty-ChannelPipeline-.png","shasum":"3b02ee73f26fcc6a782a8cb6b3af22b6e7d2be7d","modified":1451395815000},{"_id":"source/images/wpid-Multi-reactors3.png","shasum":"c18acca0c970ff38beb9605f03819eae331a0d1b","modified":1451395815000},{"_id":"source/images/wpid-Netty-thread-model3.png","shasum":"c55d7b5776528103b4e6e207d8d44aa09d7faf79","modified":1451395815000},{"_id":"source/images/ranksystem-in-social-network.png","shasum":"6250cb26042719803f5c641cc14ef10401c8675e","modified":1451396159000},{"_id":"source/upload/java-at-alibaba.pptx","shasum":"bd213366da7aeac6bb98721ed84972ac62070298","modified":1451395815000},{"_id":"themes/next/source/css/_common/_page/home.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1451395815000},{"_id":"themes/next/source/css/_mixins/Mist.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1451395815000},{"_id":"themes/next/source/css/_mixins/custom.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1451395815000},{"_id":"themes/next/source/css/_mixins/default.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1451395815000},{"_id":"themes/next/source/css/_variables/custom.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1451395815000},{"_id":"themes/next/source/css/_variables/default.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1451395815000},{"_id":"themes/next/README.en.md","shasum":"565ba52b3825b85a9f05b41183caca7f18b741d4","modified":1451395815000},{"_id":"themes/next/README.md","shasum":"3319de8565699fc9642f76c41ee96b50f2234b6a","modified":1451395815000},{"_id":"themes/next/_config.yml","shasum":"d54512d01a4f7aa029b02b12e3c8ee6439e0d708","modified":1451395815000},{"_id":"themes/next/bower.json","shasum":"1bdb0641bdcb9b5b154d2e379c57fe5675f06b9c","modified":1451395815000},{"_id":"themes/next/diff.md","shasum":"d52974f90b9ac8f7d770b426dad0d1bf8acb05ca","modified":1451395815000},{"_id":"themes/next/languages/de.yml","shasum":"7a8de0e5665c52a1bf168c1e7dd222c8a74fb0ab","modified":1451395815000},{"_id":"themes/next/languages/default.yml","shasum":"7e65ef918f16d0189055deb5f1616b9dedcb1920","modified":1451395815000},{"_id":"themes/next/languages/en.yml","shasum":"7e65ef918f16d0189055deb5f1616b9dedcb1920","modified":1451395815000},{"_id":"themes/next/languages/fr-FR.yml","shasum":"6d097445342a9fb5235afea35d65bf5271b772f0","modified":1451395815000},{"_id":"themes/next/languages/ru.yml","shasum":"b4a827b9ddac9d5f6dca096fe513aeafb46a3e93","modified":1451395815000},{"_id":"themes/next/languages/zh-Hans.yml","shasum":"8af76df5557561050a950bdd7091d3bb3939c5c0","modified":1451395815000},{"_id":"themes/next/languages/zh-hk.yml","shasum":"3fc38103c9efa6f6c37149adbddb014ff85ec849","modified":1451395815000},{"_id":"themes/next/languages/zh-tw.yml","shasum":"8897a06e521b36c7a1226c72057c8357611eded8","modified":1451395815000},{"_id":"themes/next/layout/_layout.swig","shasum":"07fd733b050577e90fa69c50faa4f630c1cc0dba","modified":1451395815000},{"_id":"themes/next/layout/_macro/post-collapse.swig","shasum":"42927bdde998cefd3cf4f19b0476d69bd9e5116a","modified":1451395815000},{"_id":"themes/next/layout/_macro/post.swig","shasum":"598b3085b6b74f4664eb66e6ae8737920e07d7a9","modified":1451395815000},{"_id":"themes/next/layout/_macro/sidebar.swig","shasum":"b0c467b42073270db7db41907ce8881f64bf3793","modified":1451395815000},{"_id":"themes/next/layout/_partials/footer.swig","shasum":"44d513401032362655c40cae66e579dba8dd3d85","modified":1451395815000},{"_id":"themes/next/layout/_partials/head.swig","shasum":"fc9ab6752cbdd13f563b3969d039ef7cf05ab046","modified":1451395815000},{"_id":"themes/next/layout/_partials/header.swig","shasum":"eefb48589ed5b0894ac46883608618ac8a4dba3c","modified":1451395815000},{"_id":"themes/next/layout/_partials/old-browsers.swig","shasum":"dbbfea810bf3a2ed9c83b9a6683037175aacfc67","modified":1451395815000},{"_id":"themes/next/layout/_partials/pagination.swig","shasum":"d6c7f04eee4388d8f133eb5526b7c0875c321a30","modified":1451395815000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","shasum":"00c2b49f6289198b0b2b4e157e4ee783277f32a7","modified":1451395815000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","shasum":"2f92046e0b50ebd65abb7045b1cbbfc50abbb034","modified":1451395815000},{"_id":"themes/next/layout/_partials/search.swig","shasum":"64f14da26792a17bc27836c4e9d83190175f36e6","modified":1451395815000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","shasum":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1451395815000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","shasum":"63315fcf210799f894208c9f512737096df84962","modified":1451395815000},{"_id":"themes/next/layout/_scripts/analytics/baidu-analytics.swig","shasum":"7c43d66da93cde65b473a7d6db2a86f9a42647d6","modified":1451395815000},{"_id":"themes/next/layout/_scripts/analytics/google-analytics.swig","shasum":"30a23fa7e816496fdec0e932aa42e2d13098a9c2","modified":1451395815000},{"_id":"themes/next/layout/_scripts/analytics.swig","shasum":"0ebbf76c2317faa8ba31365adba59331c2e0262c","modified":1451395815000},{"_id":"themes/next/layout/_scripts/baidushare.swig","shasum":"d726361945437cf6e48067b3dd041b7e36e98d85","modified":1451395815000},{"_id":"themes/next/layout/_scripts/bootstrap.scrollspy.swig","shasum":"85295f126836b95f0837d03e58228bb3cf8c4490","modified":1451395815000},{"_id":"themes/next/layout/_scripts/comments/disqus.swig","shasum":"3491d3cebabc8a28857200db28a1be65aad6adc2","modified":1451395815000},{"_id":"themes/next/layout/_scripts/comments/duoshuo.swig","shasum":"3351ea62225933f8045d036a79654e19e84d19a7","modified":1451395815000},{"_id":"themes/next/layout/_scripts/fancy-box.swig","shasum":"41b4ff1446060c88c33bf666a32277dcf12129f0","modified":1451395815000},{"_id":"themes/next/layout/_scripts/helpers.swig","shasum":"4d2cbfca0aaf546a2b5813288073e824c1498fdf","modified":1451395815000},{"_id":"themes/next/layout/_scripts/mathjax.swig","shasum":"abc52fefb276c52cbb19de5c214521dfcf2a10fd","modified":1451395815000},{"_id":"themes/next/layout/_scripts/motion.swig","shasum":"817705bfd1a1282cb6bf59094afe507e11455aa0","modified":1451395815000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","shasum":"b63ef233886538f30ced60344ac15d25e5f3e0af","modified":1451395815000},{"_id":"themes/next/layout/archive.swig","shasum":"0c3ce594759f347ea90a4ce592a7a18e2ae4cc5c","modified":1451395815000},{"_id":"themes/next/layout/category.swig","shasum":"d6b3e1dc5e0b8deade9a084c463126e70188ee9b","modified":1451395815000},{"_id":"themes/next/layout/index.swig","shasum":"fdc801f0da71a2eb205ce9c0b12f156b219fdc9c","modified":1451395815000},{"_id":"themes/next/layout/page.swig","shasum":"8019d02232a6dd1a665b6a4d2daef8e5dd2f0049","modified":1451395815000},{"_id":"themes/next/layout/post.swig","shasum":"a84457e8ced46e63bc7a8a9e0541a6ba53122a92","modified":1451395815000},{"_id":"themes/next/layout/tag.swig","shasum":"aab44af54fcbc66fea4ad12b2767ffca3eadd451","modified":1451395815000},{"_id":"themes/next/scripts/merge-configs.js","shasum":"dfd147d1317e56d283f5e779f00608e913603b51","modified":1451395815000},{"_id":"themes/next/scripts/tags/center-quote.js","shasum":"37274f743c2054244dcbbde56fba9ff353414281","modified":1451395815000},{"_id":"themes/next/source/css/_common/_component/back-to-top.styl","shasum":"88cd66910260006aa8e9e795df4948d4b67bfa11","modified":1451395815000},{"_id":"themes/next/scripts/tags/full-image.js","shasum":"0d69739d1bad5861a4a6ff2db511c3669783e438","modified":1451395815000},{"_id":"themes/next/source/css/_common/_component/buttons.styl","shasum":"81063e0979f04a0f9af37f321d7321dda9abf593","modified":1451395815000},{"_id":"themes/next/source/css/_common/_component/comments.styl","shasum":"54e73681ba6f57ef961138f94d2ee8ac845990c3","modified":1451395815000},{"_id":"themes/next/source/css/_common/_component/duoshuo.styl","shasum":"c307f1e4827d7cb82816a5f9de109ae14ed4199c","modified":1451395815000},{"_id":"themes/next/source/css/_common/_component/gallery.styl","shasum":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1451395815000},{"_id":"themes/next/source/css/_common/_component/jiathis.styl","shasum":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1451395815000},{"_id":"themes/next/source/css/_common/_component/pagination.styl","shasum":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1451395815000},{"_id":"themes/next/source/css/_common/_component/posts-collapse.styl","shasum":"8f9e8f5f65956ccf1d52ff8526392803dff579d3","modified":1451395815000},{"_id":"themes/next/source/css/_common/_component/posts-expand.styl","shasum":"4b82dbbb6e536e6e8ee3cec6e62c2fd4bea60a09","modified":1451395815000},{"_id":"themes/next/source/css/_common/_component/posts-type.styl","shasum":"40b593134bf96d1d6095b3439d47820659d7f10b","modified":1451395815000},{"_id":"themes/next/source/css/_common/_component/tag-cloud.styl","shasum":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1451395815000},{"_id":"themes/next/source/css/_common/_core/base.styl","shasum":"e79a08484b191dca14ccfc005053eb95786dafae","modified":1451395815000},{"_id":"themes/next/source/css/_common/_core/helpers.styl","shasum":"41a31d651b60b4f458fc56a1d191dfbbdcb6d794","modified":1451395815000},{"_id":"themes/next/source/css/_common/_core/normalize.styl","shasum":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1451395815000},{"_id":"themes/next/source/css/_common/_core/scaffolding.styl","shasum":"cbd7f1d5c72e3024b5d70dafb6ca93e2723652ab","modified":1451395815000},{"_id":"themes/next/source/css/_common/_core/tables.styl","shasum":"f142a185fda68bc579e89ead9a31bc8fa0f3ca8c","modified":1451395815000},{"_id":"themes/next/source/css/_common/_fonts/icon-default.styl","shasum":"8b809aef383bebaeb3f282b47675f3a364ce3569","modified":1451395815000},{"_id":"themes/next/source/css/_common/_fonts/icon-feather.styl","shasum":"80413afacfa656322100ce1900fed1ebcd8f8f44","modified":1451395815000},{"_id":"themes/next/source/css/_common/_fonts/icon-fifty-shades.styl","shasum":"249f75bafa26b99d272352c0646e7497ea680b39","modified":1451395815000},{"_id":"themes/next/source/css/_common/_fonts/icon-font.styl","shasum":"ec3f86739bede393cafcd3e31052c01115ae20d6","modified":1451395815000},{"_id":"themes/next/source/css/_common/_fonts/icon-linecons.styl","shasum":"9cdbedb3627ac941cfb063b152abe5a75c3c699a","modified":1451395815000},{"_id":"themes/next/source/css/_common/_page/archive.styl","shasum":"dff879f55ca65fa79c07e9098719e53eeea7ac88","modified":1451395815000},{"_id":"themes/next/source/css/_common/_page/categories.styl","shasum":"4f696a2eaeee2f214adcf273eab25c62a398077a","modified":1451395815000},{"_id":"themes/next/source/css/_common/_page/post-detail.styl","shasum":"73796f6f13caa7151a2ee8e55755627e0d189f55","modified":1451395815000},{"_id":"themes/next/source/css/_common/_section/body.styl","shasum":"ca1a4766cbe25baac757c6b47a4858d221afdc40","modified":1451395815000},{"_id":"themes/next/source/css/_common/_section/footer.styl","shasum":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1451395815000},{"_id":"themes/next/source/css/_common/_section/header.styl","shasum":"ba501332fb111bd72dc0777f2e1c8a29ad538ff9","modified":1451395815000},{"_id":"themes/next/source/css/_common/_section/layout.styl","shasum":"4daaadd156ece64ae05908ad6bb0159c8a27c071","modified":1451395815000},{"_id":"themes/next/source/css/_common/_section/media.styl","shasum":"fa9809d2ecc753cf32f70803c1d0821c405211f4","modified":1451395815000},{"_id":"themes/next/source/css/_common/_section/sidebar.styl","shasum":"d57e1769ebd2c472d2b27d17a706d3f564f94033","modified":1451395815000},{"_id":"themes/next/source/css/_common/_vendor/highlight/highlight.styl","shasum":"f3529b7da284c4b859429573c9b1004d32937e40","modified":1451395815000},{"_id":"themes/next/source/css/_common/_vendor/highlight/theme.styl","shasum":"ae19721ceee5ba460e131cb2427dae3c1ff39d6f","modified":1451395815000},{"_id":"themes/next/source/css/_custom/custom.styl","shasum":"68b6859fb48fe8358e567fc324f218cecfc3a533","modified":1451395815000},{"_id":"themes/next/source/css/_mixins/base.styl","shasum":"66985fe77bd323f7f8f634908e17166f51e96e95","modified":1451395815000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","shasum":"f3f4fac628d0b588cb40795d498110d33b11ce26","modified":1451395815000},{"_id":"themes/next/source/css/_schemes/default/_menu.styl","shasum":"4bba29cece65ffc5122f4e052063dea4439fe4ae","modified":1451395815000},{"_id":"themes/next/source/css/_schemes/default/_search.styl","shasum":"c524bccdc554349106d1c8be9c3f275d4c0d4281","modified":1451395815000},{"_id":"themes/next/source/css/_schemes/default/index.styl","shasum":"2588e55132e10d82c0608f03c2c72a2bace8fa4e","modified":1451395815000},{"_id":"themes/next/source/css/_variables/Mist.styl","shasum":"f5dda1ca48c1b73a0bd34e08413de57699f24083","modified":1451395815000},{"_id":"themes/next/source/css/_variables/base.styl","shasum":"9d5c6ffbef443ec0db66f418eefac17024ff6780","modified":1451395815000},{"_id":"themes/next/source/css/main.styl","shasum":"b05c342e94ded24a5f2b203cedf77d3faa817fd5","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-default/icomoon.eot","shasum":"90763e97be18be78e65749075225cceeddc6fa8a","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-default/icomoon.svg","shasum":"f92ad8cddc250f0bb5ca466fca95d321987e127e","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-default/icomoon.ttf","shasum":"c093408e6030221cafc1f79d897f1fb5283c1178","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-default/icomoon.woff","shasum":"dbe0368f2a65d87b13234cfea29d9783892fc7a8","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-default/selection.json","shasum":"dc07c29f687315f9458f6b251c214768af865fb2","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-feather/icomoon.eot","shasum":"11554b9e9d5b9f535ba96cbb27d45d8c8f1689fd","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-feather/icomoon.svg","shasum":"d5eb756eefda9b454dcb23c2b1cefd4051d18d41","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-feather/icomoon.ttf","shasum":"b2bbae4b613403cf61ad25037913378da1c07b8f","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-feather/icomoon.woff","shasum":"2ea1c59c17422798e64ee6f4e9ce1f7aff1a06a5","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-feather/selection.json","shasum":"06ea91e3f98ebe1080087acad4356802bc5b6ebf","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.eot","shasum":"da86ba5df72d1288de9e9633e5f528062dd427d5","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.svg","shasum":"1a4afd739e1f8eb8d430dbdd29e36a9999802e8d","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.ttf","shasum":"72fe82e1f3db52414eed706952d385af241cb196","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.woff","shasum":"4de6a74f523dee33d95dde61caae5809f9a5d448","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-fifty-shades/selection.json","shasum":"fdd09098d1c3688e2c88cf33fd51e76b383b6d7f","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.eot","shasum":"301fcf00c24750dddf1c529f944ca62c7f1a217d","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.svg","shasum":"e316347805eb93425faa678611c5e42a7152da8f","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.ttf","shasum":"f399713d1c9400d4d3373e38991a7e362a754a94","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.woff","shasum":"05f1ec0bd307da5e731a86eb4961589a6042aebb","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.eot","shasum":"e2d7f040428a632f3c50bfa94083b759936effc2","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.svg","shasum":"808eaf7d61f7e67c76976265c885e79c36920f0b","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.ttf","shasum":"078068206684e4f185b0187ad3cee16f54a287d7","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.woff","shasum":"0b07ee6ceda3b1bceb40c1e7379b3aa48dcc15a8","modified":1451395815000},{"_id":"themes/next/source/fonts/icon-linecons/selection.json","shasum":"db4ce25d31449ecc6685b32e145252103967bb5c","modified":1451395815000},{"_id":"themes/next/source/images/bkdefault_avatar.jpg","shasum":"b687bb4bfbe35a32b592c24d652ba80cfdc770fc","modified":1451395815000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","shasum":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1451395815000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","shasum":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1451395815000},{"_id":"themes/next/source/images/cc-by-nc.svg","shasum":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1451395815000},{"_id":"themes/next/source/images/cc-by-nd.svg","shasum":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1451395815000},{"_id":"themes/next/source/images/cc-by-sa.svg","shasum":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1451395815000},{"_id":"themes/next/source/images/cc-by.svg","shasum":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1451395815000},{"_id":"themes/next/source/images/cc-zero.svg","shasum":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1451395815000},{"_id":"themes/next/source/images/loading.gif","shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1451395815000},{"_id":"themes/next/source/images/hongweiyi.jpg","shasum":"032b54ac39b0ba0bcd4e2f7497b0599d3f931ca8","modified":1451395815000},{"_id":"themes/next/source/images/placeholder.gif","shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1451395815000},{"_id":"themes/next/source/images/searchicon.png","shasum":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1451395815000},{"_id":"themes/next/source/js/bootstrap.scrollspy.js","shasum":"ae7bdce88b515aade4eea8bf7407eec458bcd625","modified":1451395815000},{"_id":"themes/next/source/js/fancy-box.js","shasum":"116cafc741e048497287121a508d7a54c050c70c","modified":1451395815000},{"_id":"themes/next/source/js/helpers.js","shasum":"c2117b0ec653df4c45dd9d9575b190cbe1035335","modified":1451395815000},{"_id":"themes/next/source/js/hook-duoshuo.js","shasum":"a34b872747db57bf2577155c3169e552916090b5","modified":1451395815000},{"_id":"themes/next/source/js/lazyload.js","shasum":"b92e9acdc7afc15468314c03f4a643b0c93944cf","modified":1451395815000},{"_id":"themes/next/source/js/motion_fallback.js","shasum":"a767d522c65a8b2fbad49135c9332135c6785c3e","modified":1451395815000},{"_id":"themes/next/source/js/motion_global.js","shasum":"367e329b2cc19c6b7634ea2917a218c84a22ec17","modified":1451395815000},{"_id":"themes/next/source/js/nav-toggle.js","shasum":"78b59f1beb12adea0d7f9bcf4377cb699963f220","modified":1451395815000},{"_id":"themes/next/source/js/ua-parser.min.js","shasum":"acf0ee6a47ffb7231472b56e43996e3f947c258a","modified":1451395815000},{"_id":"themes/next/source/vendors/fancybox/source/blank.gif","shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1451395815000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading.gif","shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1451395815000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading@2x.gif","shasum":"273b123496a42ba45c3416adb027cd99745058b0","modified":1451395815000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_overlay.png","shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1451395815000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite.png","shasum":"17df19f97628e77be09c352bf27425faea248251","modified":1451395815000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite@2x.png","shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1451395815000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/fancybox_buttons.png","shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1451395815000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","shasum":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1451395815000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","shasum":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1451395815000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-media.js","shasum":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1451395815000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","shasum":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1451395815000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","shasum":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1451395815000},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.css","shasum":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1451395815000},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.js","shasum":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1451395815000},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.pack.js","shasum":"53360764b429c212f424399384417ccc233bb3be","modified":1451395815000},{"_id":"themes/next/source/vendors/fastclick/LICENSE","shasum":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1451395815000},{"_id":"themes/next/source/vendors/fastclick/README.md","shasum":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1451395815000},{"_id":"themes/next/source/vendors/fastclick/bower.json","shasum":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1451395815000},{"_id":"themes/next/source/vendors/fastclick/lib/fastclick.js","shasum":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1451395815000},{"_id":"themes/next/source/vendors/fastclick/lib/fastclick.min.js","shasum":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1451395815000},{"_id":"themes/next/source/vendors/velocity/bower.json","shasum":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1451395815000},{"_id":"themes/next/source/vendors/velocity/velocity.min.js","shasum":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1451395815000},{"_id":"themes/next/source/vendors/velocity/velocity.ui.js","shasum":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1451395815000},{"_id":"themes/next/source/vendors/velocity/velocity.ui.min.js","shasum":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1451395815000},{"_id":"themes/next/test/helpers.js","shasum":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1451395815000},{"_id":"themes/next/test/intern.js","shasum":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1451395815000},{"_id":"themes/next/source/vendors/jquery/index.js","shasum":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1451395815000},{"_id":"themes/next/source/vendors/velocity/velocity.js","shasum":"e63dc7cea055ca60a95d286f32349d88b10c5a4d","modified":1451395815000},{"_id":"public/CNAME","modified":1451396781467,"shasum":"0ac7ddcf1b989fbcc91f6ca144101324ffac8de4"},{"_id":"public/upload/java-at-alibaba.pptx","modified":1451396781471,"shasum":"bd213366da7aeac6bb98721ed84972ac62070298"},{"_id":"public/images/wpid-nio-oio.jpg","modified":1451396781474,"shasum":"ac7df496f41f1b549b41a4a4404a437ea18460c9"},{"_id":"public/images/wpid-Netty-thread-model3.png","modified":1451396781476,"shasum":"c55d7b5776528103b4e6e207d8d44aa09d7faf79"},{"_id":"public/images/wpid-Netty-ChannelPipeline-.png","modified":1451396781478,"shasum":"3b02ee73f26fcc6a782a8cb6b3af22b6e7d2be7d"},{"_id":"public/images/wpid-Multi-reactors3.png","modified":1451396781480,"shasum":"c18acca0c970ff38beb9605f03819eae331a0d1b"},{"_id":"public/images/wpid-EventLoopAndEventExecutor3.jpg","modified":1451396781482,"shasum":"2fa9ffd6acb767bf9c8f23da2271354dba8bee63"},{"_id":"public/images/wpid-Channel.png","modified":1451396781484,"shasum":"06acf8025d55d644ecb8d153a62c438ce6f07b8f"},{"_id":"public/images/solr-DocSet.png","modified":1451396781486,"shasum":"08891f7f7c7f3ee40161f9b8a01012249e5d9151"},{"_id":"public/images/reactors-in-threads.png","modified":1451396781489,"shasum":"31e20bc84b78d60af27998c0a154014babfb09dd"},{"_id":"public/images/reactors-in-threads-thread-pool.png","modified":1451396781491,"shasum":"cf1805741cd76ae36b85f51e3b5c455c418fa910"},{"_id":"public/images/reactor-thread-pool.png","modified":1451396781493,"shasum":"2698dc114f10fdddef468dd49f23338f743c319e"},{"_id":"public/images/reactor-single-thread.png","modified":1451396781496,"shasum":"799dbea22e802bf51877500c9d7a80621baadc44"},{"_id":"public/images/ranksystem-in-social-network.png","modified":1451396781498,"shasum":"6250cb26042719803f5c641cc14ef10401c8675e"},{"_id":"public/images/facet-1.png","modified":1451396781501,"shasum":"938bd19a87b24de5485960176c817bdac85b6093"},{"_id":"public/images/bytebuf-priciple.png","modified":1451396781502,"shasum":"f2abcaa081d341f8b6aaa1c7c19e7c562329475b"},{"_id":"public/images/bytebuf-diagram.jpg","modified":1451396781504,"shasum":"81f2c3c1b19f01d6af05b2de19124c93ea3cad23"},{"_id":"public/images/bytebuf-combine-slice-buffer.png","modified":1451396781507,"shasum":"a073deecce1516d12e2270f373ccfa8bc57b87fd"},{"_id":"public/favicon.png","modified":1451396781509,"shasum":"6cdd78df2d91e397f08a981df6e5bb58896f1f80"},{"_id":"public/vendors/velocity/velocity.ui.min.js","modified":1451396781511,"shasum":"ed5e534cd680a25d8d14429af824f38a2c7d9908"},{"_id":"public/vendors/velocity/velocity.ui.js","modified":1451396781513,"shasum":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df"},{"_id":"public/vendors/velocity/velocity.min.js","modified":1451396781514,"shasum":"2f1afadc12e4cf59ef3b405308d21baa97e739c6"},{"_id":"public/vendors/velocity/velocity.js","modified":1451396781517,"shasum":"9f08181baea0cc0e906703b7e5df9111b9ef3373"},{"_id":"public/vendors/velocity/bower.json","modified":1451396781519,"shasum":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409"},{"_id":"public/vendors/jquery/index.js","modified":1451396781520,"shasum":"41b4bfbaa96be6d1440db6e78004ade1c134e276"},{"_id":"public/vendors/fastclick/lib/fastclick.min.js","modified":1451396781521,"shasum":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18"},{"_id":"public/vendors/fastclick/lib/fastclick.js","modified":1451396781522,"shasum":"06cef196733a710e77ad7e386ced6963f092dc55"},{"_id":"public/vendors/fastclick/bower.json","modified":1451396781523,"shasum":"4dcecf83afddba148464d5339c93f6d0aa9f42e9"},{"_id":"public/vendors/fastclick/README.html","modified":1451396781529,"shasum":"4a6074903daa9004301ef30a6fb96556ba3eab60"},{"_id":"public/vendors/fastclick/LICENSE","modified":1451396781545,"shasum":"dcd5b6b43095d9e90353a28b09cb269de8d4838e"},{"_id":"public/vendors/fancybox/source/jquery.fancybox.pack.js","modified":1451396781546,"shasum":"53360764b429c212f424399384417ccc233bb3be"},{"_id":"public/vendors/fancybox/source/jquery.fancybox.js","modified":1451396781548,"shasum":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4"},{"_id":"public/vendors/fancybox/source/jquery.fancybox.css","modified":1451396781548,"shasum":"5f163444617b6cf267342f06ac166a237bb62df9"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1451396781549,"shasum":"53e194f4a72e649c04fb586dd57762b8c022800b"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1451396781550,"shasum":"4ac329c16a5277592fc12a37cca3d72ca4ec292f"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-media.js","modified":1451396781551,"shasum":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1451396781551,"shasum":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1451396781552,"shasum":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8"},{"_id":"public/vendors/fancybox/source/helpers/fancybox_buttons.png","modified":1451396781553,"shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3"},{"_id":"public/vendors/fancybox/source/fancybox_sprite@2x.png","modified":1451396781553,"shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8"},{"_id":"public/vendors/fancybox/source/fancybox_sprite.png","modified":1451396781554,"shasum":"17df19f97628e77be09c352bf27425faea248251"},{"_id":"public/vendors/fancybox/source/fancybox_overlay.png","modified":1451396781555,"shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0"},{"_id":"public/vendors/fancybox/source/fancybox_loading@2x.gif","modified":1451396781556,"shasum":"273b123496a42ba45c3416adb027cd99745058b0"},{"_id":"public/vendors/fancybox/source/fancybox_loading.gif","modified":1451396781557,"shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c"},{"_id":"public/vendors/fancybox/source/blank.gif","modified":1451396781558,"shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a"},{"_id":"public/js/ua-parser.min.js","modified":1451396781559,"shasum":"acf0ee6a47ffb7231472b56e43996e3f947c258a"},{"_id":"public/js/nav-toggle.js","modified":1451396781560,"shasum":"78b59f1beb12adea0d7f9bcf4377cb699963f220"},{"_id":"public/js/motion_global.js","modified":1451396781562,"shasum":"367e329b2cc19c6b7634ea2917a218c84a22ec17"},{"_id":"public/js/motion_fallback.js","modified":1451396781562,"shasum":"a767d522c65a8b2fbad49135c9332135c6785c3e"},{"_id":"public/js/lazyload.js","modified":1451396781563,"shasum":"b92e9acdc7afc15468314c03f4a643b0c93944cf"},{"_id":"public/js/hook-duoshuo.js","modified":1451396781564,"shasum":"9881b19132ad90dffd82c53947e4c356e30353e7"},{"_id":"public/js/helpers.js","modified":1451396781565,"shasum":"c2117b0ec653df4c45dd9d9575b190cbe1035335"},{"_id":"public/js/fancy-box.js","modified":1451396781566,"shasum":"116cafc741e048497287121a508d7a54c050c70c"},{"_id":"public/js/bootstrap.scrollspy.js","modified":1451396781566,"shasum":"ae7bdce88b515aade4eea8bf7407eec458bcd625"},{"_id":"public/images/searchicon.png","modified":1451396781568,"shasum":"67727a6a969be0b2659b908518fa6706eed307b8"},{"_id":"public/images/placeholder.gif","modified":1451396781569,"shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b"},{"_id":"public/images/loading.gif","modified":1451396781570,"shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b"},{"_id":"public/images/hongweiyi.jpg","modified":1451396781571,"shasum":"032b54ac39b0ba0bcd4e2f7497b0599d3f931ca8"},{"_id":"public/images/cc-zero.svg","modified":1451396781572,"shasum":"87669bf8ac268a91d027a0a4802c92a1473e9030"},{"_id":"public/images/cc-by.svg","modified":1451396781573,"shasum":"28a0a4fe355a974a5e42f68031652b76798d4f7e"},{"_id":"public/images/cc-by-sa.svg","modified":1451396781576,"shasum":"aa4742d733c8af8d38d4c183b8adbdcab045872e"},{"_id":"public/images/cc-by-nd.svg","modified":1451396781577,"shasum":"c563508ce9ced1e66948024ba1153400ac0e0621"},{"_id":"public/images/cc-by-nc.svg","modified":1451396781578,"shasum":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7"},{"_id":"public/images/cc-by-nc-sa.svg","modified":1451396781580,"shasum":"3031be41e8753c70508aa88e84ed8f4f653f157e"},{"_id":"public/images/cc-by-nc-nd.svg","modified":1451396781581,"shasum":"c6524ece3f8039a5f612feaf865d21ec8a794564"},{"_id":"public/images/bkdefault_avatar.jpg","modified":1451396781581,"shasum":"b687bb4bfbe35a32b592c24d652ba80cfdc770fc"},{"_id":"public/fonts/icon-linecons/selection.json","modified":1451396781583,"shasum":"68da6ea1b3ab9355d42694bf5745071cdefa4a65"},{"_id":"public/fonts/icon-linecons/icomoon.woff","modified":1451396781584,"shasum":"0b07ee6ceda3b1bceb40c1e7379b3aa48dcc15a8"},{"_id":"public/fonts/icon-linecons/icomoon.ttf","modified":1451396781585,"shasum":"078068206684e4f185b0187ad3cee16f54a287d7"},{"_id":"public/fonts/icon-linecons/icomoon.svg","modified":1451396781587,"shasum":"808eaf7d61f7e67c76976265c885e79c36920f0b"},{"_id":"public/fonts/icon-linecons/icomoon.eot","modified":1451396781588,"shasum":"e2d7f040428a632f3c50bfa94083b759936effc2"},{"_id":"public/fonts/icon-icomoon/icomoon.woff","modified":1451396781589,"shasum":"05f1ec0bd307da5e731a86eb4961589a6042aebb"},{"_id":"public/fonts/icon-icomoon/icomoon.ttf","modified":1451396781590,"shasum":"f399713d1c9400d4d3373e38991a7e362a754a94"},{"_id":"public/fonts/icon-icomoon/icomoon.svg","modified":1451396781591,"shasum":"e316347805eb93425faa678611c5e42a7152da8f"},{"_id":"public/fonts/icon-icomoon/icomoon.eot","modified":1451396781592,"shasum":"301fcf00c24750dddf1c529f944ca62c7f1a217d"},{"_id":"public/fonts/icon-fifty-shades/selection.json","modified":1451396781594,"shasum":"e5a5042e8e516b1d30fa3b1206d2c74921cec72b"},{"_id":"public/fonts/icon-fifty-shades/icomoon.woff","modified":1451396781596,"shasum":"4de6a74f523dee33d95dde61caae5809f9a5d448"},{"_id":"public/fonts/icon-fifty-shades/icomoon.ttf","modified":1451396781597,"shasum":"72fe82e1f3db52414eed706952d385af241cb196"},{"_id":"public/fonts/icon-fifty-shades/icomoon.svg","modified":1451396781598,"shasum":"1a4afd739e1f8eb8d430dbdd29e36a9999802e8d"},{"_id":"public/fonts/icon-fifty-shades/icomoon.eot","modified":1451396781598,"shasum":"da86ba5df72d1288de9e9633e5f528062dd427d5"},{"_id":"public/fonts/icon-feather/selection.json","modified":1451396781600,"shasum":"d95a90b0d541e48b049902090c0d008ad92b4115"},{"_id":"public/fonts/icon-feather/icomoon.woff","modified":1451396781601,"shasum":"2ea1c59c17422798e64ee6f4e9ce1f7aff1a06a5"},{"_id":"public/fonts/icon-feather/icomoon.ttf","modified":1451396781602,"shasum":"b2bbae4b613403cf61ad25037913378da1c07b8f"},{"_id":"public/fonts/icon-feather/icomoon.svg","modified":1451396781603,"shasum":"d5eb756eefda9b454dcb23c2b1cefd4051d18d41"},{"_id":"public/fonts/icon-feather/icomoon.eot","modified":1451396781604,"shasum":"11554b9e9d5b9f535ba96cbb27d45d8c8f1689fd"},{"_id":"public/fonts/icon-default/selection.json","modified":1451396781605,"shasum":"ff1b9b78eced4d0368d14cc192ac67a0dd498593"},{"_id":"public/fonts/icon-default/icomoon.woff","modified":1451396781607,"shasum":"dbe0368f2a65d87b13234cfea29d9783892fc7a8"},{"_id":"public/fonts/icon-default/icomoon.ttf","modified":1451396781607,"shasum":"c093408e6030221cafc1f79d897f1fb5283c1178"},{"_id":"public/fonts/icon-default/icomoon.svg","modified":1451396781608,"shasum":"f92ad8cddc250f0bb5ca466fca95d321987e127e"},{"_id":"public/fonts/icon-default/icomoon.eot","modified":1451396781609,"shasum":"90763e97be18be78e65749075225cceeddc6fa8a"},{"_id":"public/css/main.css","modified":1451396781829,"shasum":"9063148b07ae99e4f62bc45265fc27c3dd44b67f"},{"_id":"public/tags/index.html","modified":1451396781983,"shasum":"97b73c68d0c28d2be8a3c0e25faf57bd46f3c29d"},{"_id":"public/2015/12/remoting-practice/index.html","modified":1451396782031,"shasum":"821cca54b902fe8a40f72fce79ab4d385888370d"},{"_id":"public/2015/10/docker-volume-plugin/index.html","modified":1451396782076,"shasum":"4090b7517c4cb868ac99b3332317a6aafe5c797c"},{"_id":"public/2015/10/docker-compose-pratice/index.html","modified":1451396782117,"shasum":"17c40a110d9d0e45eee4c2e0b161daa468dbeaad"},{"_id":"public/2015/09/java-source-code-practice/index.html","modified":1451396782150,"shasum":"72b80f85266ec1cd291e0013a464b0adee33b0d7"},{"_id":"public/2015/08/css-practice/index.html","modified":1451396782192,"shasum":"57c311af941255f25833012593ef6759cb389278"},{"_id":"public/2015/08/git-practice/index.html","modified":1451396782226,"shasum":"86c2a2503ab76fee508b17beb4fa69677fa65d8d"},{"_id":"public/2015/08/java-practice/index.html","modified":1451396782282,"shasum":"3b947b9742de6941d75eae4e92b943a62dc87939"},{"_id":"public/2015/08/README/index.html","modified":1451396782329,"shasum":"0c9298771ecf40e6fddb82c5f68c2c6437664cc5"},{"_id":"public/2015/03/oom-killer-1/index.html","modified":1451396782397,"shasum":"1ce1b1736753ecb8a7f00d81ba409947635a9082"},{"_id":"public/2014/10/i-need-an-answer-now-from-remote/index.html","modified":1451396782448,"shasum":"99809e0b4d78f2ebd0a58aa8777dc35344ed49a7"},{"_id":"public/2014/05/netty-mina-in-depth-2/index.html","modified":1451396782496,"shasum":"e007d8347231290765ddacad18d78fd23d00ba9b"},{"_id":"public/2014/05/netty-mina-in-depth-1/index.html","modified":1451396782552,"shasum":"34a72558b8f865d506339b11aef0892d16c048f7"},{"_id":"public/2014/04/rework-digest/index.html","modified":1451396782610,"shasum":"08585df0283220216eca723c4adb00a24d69e258"},{"_id":"public/2014/04/forget-your-lusts-1/index.html","modified":1451396782677,"shasum":"1b6161e63fe555bbbc98d872573bde36bb4e33df"},{"_id":"public/2014/04/forget-your-lusts/index.html","modified":1451396782708,"shasum":"b05964d6ca6be55fa19842f68faaa1fd9cf53585"},{"_id":"public/2014/01/netty-4-x-thread-model/index.html","modified":1451396782754,"shasum":"16f1405fd2c17527ef91d691889ea53eea7ebe20"},{"_id":"public/2014/01/netty-4-x-channel-pipeline/index.html","modified":1451396782789,"shasum":"c02aee0f99d4197cac37e639465a21f07551f0ec"},{"_id":"public/2014/01/netty-4-x-bytebuf/index.html","modified":1451396782833,"shasum":"bf294ca9ae22783b77e558b1717708962f267c78"},{"_id":"public/2013/11/what-i-think-about-1111/index.html","modified":1451396782869,"shasum":"d142c370d3f4d43f0c594c220dff08031c298213"},{"_id":"public/2013/11/my-macbook/index.html","modified":1451396782916,"shasum":"bb3e54789a8cae1f33acf2cce9162f093adee185"},{"_id":"public/2013/10/once-java-profiling/index.html","modified":1451396782951,"shasum":"75f4c6d411929409580b79cf44d638b550e6d532"},{"_id":"public/2013/08/solr-switch-query-parser/index.html","modified":1451396782997,"shasum":"ccd97b1c558242c087946953ceccd77f42f03cd2"},{"_id":"public/2013/05/multi-columns-group-by/index.html","modified":1451396783041,"shasum":"11b130e14f589afb82ea233c213e48cd9c539d04"},{"_id":"public/2013/04/apache-solr-data-structrue-part-1/index.html","modified":1451396783081,"shasum":"0953c9f53bf570126b1a1b676e7647cbc2786001"},{"_id":"public/2013/04/apache-solr-data-structrue-part-2/index.html","modified":1451396783114,"shasum":"e407cd1364db9e51bd6cba97206c62acc9fd5f30"},{"_id":"public/2013/04/apache-solr-distributed-search/index.html","modified":1451396783157,"shasum":"4639fdd03f81fc15441550e38e0f54072384fa0b"},{"_id":"public/2013/03/apache-solr-facet-pivot-implementation-tranplant/index.html","modified":1451396783207,"shasum":"81951677c9e65ddc8854b825056eee027abd084d"},{"_id":"public/2013/03/apache-solr-facet-introduction/index.html","modified":1451396783247,"shasum":"df35467571c7995cf2fdf8c627399a49f901740a"},{"_id":"public/2013/03/re-equip-my-little-black/index.html","modified":1451396783284,"shasum":"d164eb0942525910eb0dac2bec3f3770892edaf0"},{"_id":"public/2013/03/configurate-solr-src-in-eclipse/index.html","modified":1451396783316,"shasum":"b76aa9abdcfe85e85289ba49809e64371c191c9e"},{"_id":"public/2013/03/maven-repositories/index.html","modified":1451396783368,"shasum":"783b48500e966ff2a8cb7e7a534d4a645047eb1d"},{"_id":"public/2013/03/maven-coordinates-dependencies/index.html","modified":1451396783424,"shasum":"d2e757e31bfc93f91936786d9b8ebc5b038d4a12"},{"_id":"public/2013/03/system-architecture-stuffs/index.html","modified":1451396783482,"shasum":"4b545494002cd4ea2764ef2697418be42bf8c638"},{"_id":"public/2013/03/les-miserables-lrc/index.html","modified":1451396783533,"shasum":"832c78d6727d1080b2e28cee64ced7bb5d6d947d"},{"_id":"public/2013/01/linux-process-shell/index.html","modified":1451396783580,"shasum":"8e6b19099652cd371ae6975382df55c20be4b479"},{"_id":"public/2013/01/linux-text-shell/index.html","modified":1451396783631,"shasum":"ea5f2a18e7a959953bd4345a8bddb932eaa88561"},{"_id":"public/2013/01/linux-file-directory-shell/index.html","modified":1451396783683,"shasum":"a54c80e2c54910a171b40ccc350fdd841056d250"},{"_id":"public/2013/01/linux-shell-term-tuning/index.html","modified":1451396783754,"shasum":"66c3166b73e53e611bbc845fd6d58d7f9c81806a"},{"_id":"public/2013/01/2013-learning-plan/index.html","modified":1451396783785,"shasum":"e67745f4028f818ef99e143c53a88a6d4b47750d"},{"_id":"public/2012/11/zookeeper-ephemeral-nodes-experience/index.html","modified":1451396783820,"shasum":"7ffe4abbd0b935e909de394971ebbc3efcc53164"},{"_id":"public/2012/10/mapreduce-task-src-analysis/index.html","modified":1451396783859,"shasum":"12e06459e880cab825c21e5fd648dd2e126c8cdb"},{"_id":"public/2012/09/mapred-optimize-writable/index.html","modified":1451396783899,"shasum":"5d41768c0c72ba7e533b8f25b4484521c1c7858b"},{"_id":"public/2012/09/hadoop-bug-in-text/index.html","modified":1451396783932,"shasum":"297746e8f70ca27f41e2217d222ef0d9a8ef083f"},{"_id":"public/2012/09/apache-hadoop-yarn-background-and-an-overview/index.html","modified":1451396783972,"shasum":"6dfefdf7f440e1526983b27ed53104f7882eee20"},{"_id":"public/2012/07/the-nosql-ecosystem/index.html","modified":1451396784010,"shasum":"112d2ca07fe14dcac8babd493eb4440c89055fcc"},{"_id":"public/2012/06/google-doodle-for-turing/index.html","modified":1451396784046,"shasum":"c824f79f1978881e8395c006dab3d33c6ea251a4"},{"_id":"public/2012/05/hadoop-pipes-src/index.html","modified":1451396784079,"shasum":"570dcfc14cf5c323982e034f22db39d41ef17093"},{"_id":"public/2012/05/hadoop-pipes/index.html","modified":1451396784121,"shasum":"f9013cf634bef55a2d9d57877cd67191fc69de40"},{"_id":"public/2012/04/relax-schrodinger-cat/index.html","modified":1451396784154,"shasum":"60734d8ba7a798aba36d0671d8879cecb2ed36de"},{"_id":"public/2012/04/hadoop-default-conf/index.html","modified":1451396784193,"shasum":"0974ff4cfee98098287914813a4d4261054c5ccc"},{"_id":"public/2012/04/nlp-say-hi/index.html","modified":1451396784230,"shasum":"86dccae0b460be543e082514b512a891c4e7a078"},{"_id":"public/2012/04/nlp-repost-semantic/index.html","modified":1451396784263,"shasum":"d22d429e3cd379791039335e650f55a36184d23c"},{"_id":"public/2012/04/nlp-repost-segmentation/index.html","modified":1451396784300,"shasum":"55773b177e54594288fd676bc09852ba86e38da8"},{"_id":"public/2012/03/weibo-analysis/index.html","modified":1451396784332,"shasum":"1c8367f68ad3c428dc5bf5a335f0a140e5be23c9"},{"_id":"public/2012/03/data-structure-disjoint-set/index.html","modified":1451396784369,"shasum":"5354e5e8241052900eabc98fca13255dff1e06b7"},{"_id":"public/2012/03/data-structure-skiplists/index.html","modified":1451396784404,"shasum":"eec44ba9364a88f7f9cfae0b14f45128fa989976"},{"_id":"public/2012/03/redis-data-strutrue/index.html","modified":1451396784456,"shasum":"78dace2644933d4c364a50b1ab4704288b169b7b"},{"_id":"public/2012/03/data-structure-bitmap/index.html","modified":1451396784501,"shasum":"f06f49ace3c2f48fb171387530bda1e913001e40"},{"_id":"public/2012/03/hadoop-related/index.html","modified":1451396784559,"shasum":"93c79b294d8d9f6ff9e3ab7e0dd965ff6346cace"},{"_id":"public/2012/03/java-boxing/index.html","modified":1451396784600,"shasum":"f63e2d9f11c5a41abb589aa97bf7ce1127c5ed7e"},{"_id":"public/2012/02/iterative-mapred-summary-haloop/index.html","modified":1451396784650,"shasum":"3b087f0c2b5ae24cb90a13e4dee1188e29a1b42b"},{"_id":"public/2012/02/hadoop-ipc-server/index.html","modified":1451396784713,"shasum":"ce2195ec1eab66291d34ca34c28166698fc6ecfd"},{"_id":"public/2012/02/hadoop-ipc-client/index.html","modified":1451396784762,"shasum":"37c13e3e58e27c40640d6b41950a5d224a762dd5"},{"_id":"public/2012/02/hadoop-ipc-rpc/index.html","modified":1451396784840,"shasum":"cab088adf18e7df6ffb7a0638c988bf863e21bb5"},{"_id":"public/2012/02/iterative-mapred-distcache/index.html","modified":1451396784874,"shasum":"da96c6f3e4fed81836c2f6c4a25f97ab270d1362"},{"_id":"public/2012/02/algorithm-search/index.html","modified":1451396784909,"shasum":"2d59a72798e8896b25397449ba4eddfef735b260"},{"_id":"public/2012/02/algorithm-probability/index.html","modified":1451396784947,"shasum":"216ef412117122085b0bcd9bdbbd4b7d3f62ede0"},{"_id":"public/2012/02/algorithm-dynammic-programming/index.html","modified":1451396784987,"shasum":"9a141e703d4db9aa5c85f1222812caea7e6c4fd2"},{"_id":"public/2012/02/jvm-structure/index.html","modified":1451396785021,"shasum":"7b26bea1677b519b534e92c5155f67730ac87a23"},{"_id":"public/2012/02/mapred-optimize/index.html","modified":1451396785058,"shasum":"d1d28492e02ad50d68019dfd0c4079f5d18e6195"},{"_id":"public/2012/02/iterative-mapred/index.html","modified":1451396785091,"shasum":"5a887aca8dc33c29b49ad005c8d644a852fc7515"},{"_id":"public/2012/01/python-chat/index.html","modified":1451396785130,"shasum":"d13a6eb8cc0897c58c577304513c485d66859467"},{"_id":"public/2011/12/design-pattern-adapter/index.html","modified":1451396785164,"shasum":"26e8ec2acb1376482d7de3aff0645f3e01e43e28"},{"_id":"public/2011/12/design-pattern-facade/index.html","modified":1451396785201,"shasum":"1b3fefdd65748ca260bac11c88be0279bfcf486b"},{"_id":"public/2011/12/design-pattern-decorate/index.html","modified":1451396785234,"shasum":"7c5c6eafa46ff3871a7bcb6178def083dea80c57"},{"_id":"public/2011/12/design-pattern-proxy/index.html","modified":1451396785274,"shasum":"854235050c7a8464a64dca38e7186ec431547b7b"},{"_id":"public/2011/12/design-pattern-additional/index.html","modified":1451396785308,"shasum":"679f3bc2436284e60d07c186de9fee3041128467"},{"_id":"public/2011/12/design-pattern-cor/index.html","modified":1451396785349,"shasum":"efc84ef48c41d4d96d87a16c71ecd479d6f5a0f1"},{"_id":"public/2011/12/python-traverse-dir/index.html","modified":1451396785388,"shasum":"030c6ed42edd7f815977f0ea94033812f1e23573"},{"_id":"public/2011/12/design-pattern-observer/index.html","modified":1451396785422,"shasum":"fd64433497279f4e5ff0d2f231431e8e1eee783b"},{"_id":"public/2011/12/design-pattern-singleton/index.html","modified":1451396785461,"shasum":"93c9a1777bcb782e31f38a05416b50b12df6356a"},{"_id":"public/2011/12/design-pattern-factory-abs/index.html","modified":1451396785500,"shasum":"0fee019b03ab9746786d9d1ddd46b70213dcc87e"},{"_id":"public/2011/12/design-pattern-factory/index.html","modified":1451396785557,"shasum":"65dfd83280f3f19a1484e1d5cdc965e5b3d263b1"},{"_id":"public/2011/11/hello-sae/index.html","modified":1451396785606,"shasum":"685e8d32dce16aa8215ef994c8f17031d5b91645"},{"_id":"public/2011/10/dist-filesystem-metadata-server/index.html","modified":1451396785662,"shasum":"b8ef888b62361d0cb2d160a00930c6f24432ebb9"},{"_id":"public/2011/09/single-lens-paraxonic/index.html","modified":1451396785713,"shasum":"6d18c327dc6d14763ec53c632e96c15b33ad5a27"},{"_id":"public/2011/09/photometry/index.html","modified":1451396785758,"shasum":"dbcb683c6e4410e736d6a89601955e37d85930fc"},{"_id":"public/2011/07/android-ui/index.html","modified":1451396785808,"shasum":"147d1a1fbd17f20bbd9003bb1a010761a62d34e0"},{"_id":"public/2011/06/ditital-screen/index.html","modified":1451396785855,"shasum":"fa4be66257106dd4f81dcb4fb48572777f200042"},{"_id":"public/2011/05/eclipse-plugin-unintall/index.html","modified":1451396785909,"shasum":"59ed19bf28c648e69e918c4e1e56af2bca0761fd"},{"_id":"public/2011/04/wanting-qu/index.html","modified":1451396785960,"shasum":"94ae1610be6360000c6b418c032feb804439b0b1"},{"_id":"public/2011/03/java-probability/index.html","modified":1451396785993,"shasum":"3ed01a3a95b9ca0623873af1df82a765d1ee8680"},{"_id":"public/2011/03/study-school-sociey/index.html","modified":1451396786030,"shasum":"e89b3efc05d45684ebe6a5a5bdabe6eddae97a28"},{"_id":"public/2011/03/english-punctuate/index.html","modified":1451396786064,"shasum":"095cd4797524d0a55ea546516b3cacc08bbe4981"},{"_id":"public/2011/03/ranksystem-in-social-network/index.html","modified":1451396786101,"shasum":"b806972f051ba516e8b98f8689cf13a367aa2e28"},{"_id":"public/2011/02/my-motive/index.html","modified":1451396786133,"shasum":"e594e2a7483ddfa23bb8e089d3255834c89eb1f6"},{"_id":"public/2011/02/buying-laptop/index.html","modified":1451396786170,"shasum":"4175f3c2cc7f63382dc44101b16ad8b511ffb3cc"},{"_id":"public/2011/02/truth-in-rumor/index.html","modified":1451396786203,"shasum":"44888c4d17102f88d5d2749a84d68e760bb1891f"},{"_id":"public/archives/index.html","modified":1451396786248,"shasum":"7501e8639edf6733c8797f7d862c2d1d4cf3574f"},{"_id":"public/archives/page/2/index.html","modified":1451396786289,"shasum":"0a8a45fee69ee3c62f62a2be5160ac4c972423a0"},{"_id":"public/archives/page/3/index.html","modified":1451396786324,"shasum":"988c447e4c20d70ab1f4c7b68604700d6d862ebf"},{"_id":"public/archives/page/4/index.html","modified":1451396786366,"shasum":"be01b1633335ca72b2f1d2b843a37497dc523630"},{"_id":"public/archives/page/5/index.html","modified":1451396786408,"shasum":"d76adc3dde24c0dfd55c4bc5aa610b1f015b26ac"},{"_id":"public/archives/page/6/index.html","modified":1451396786442,"shasum":"9b3bb05a891f0b8d27eedc51df2e8a3a7d950302"},{"_id":"public/archives/page/7/index.html","modified":1451396786481,"shasum":"0b90474cccc7519724f5a8b5ec1728154554c484"},{"_id":"public/archives/page/8/index.html","modified":1451396786520,"shasum":"0ffddfa2d09b4b3820ea56937a28d7c56aaee378"},{"_id":"public/archives/page/9/index.html","modified":1451396786555,"shasum":"cf82d738a6abb7e07be7e72837dbf00124ff78de"},{"_id":"public/archives/page/10/index.html","modified":1451396786611,"shasum":"97a897cb6404f7da5f42175b5240e2242e4e055b"},{"_id":"public/archives/page/11/index.html","modified":1451396786669,"shasum":"08dd49b15fd1a3ff8ec2511e2a0860bf2efa40ed"},{"_id":"public/archives/page/12/index.html","modified":1451396786720,"shasum":"8e626a819fa4d3fda13e3ece6b9bf2e3c02fc8f8"},{"_id":"public/archives/page/13/index.html","modified":1451396786773,"shasum":"adf8a0ac46be60f2788592844957a0d2d112ad1e"},{"_id":"public/archives/page/14/index.html","modified":1451396786830,"shasum":"2af473fb1d45fcbd637a98d6a467bf958c14def6"},{"_id":"public/archives/2011/index.html","modified":1451396786882,"shasum":"26f0f480cce6597d0c66ea7314525e6df1d0cd64"},{"_id":"public/archives/2011/page/2/index.html","modified":1451396786954,"shasum":"3bd700768b4202194f5ff7cd335add19cc880c53"},{"_id":"public/archives/2011/page/3/index.html","modified":1451396786990,"shasum":"817fefdbb968089ebee2c0cf0b91d6e1a72bd5d8"},{"_id":"public/archives/2011/page/4/index.html","modified":1451396787028,"shasum":"0c2c52c5eca91b6de5e52668025be057a9f2b755"},{"_id":"public/archives/2011/02/index.html","modified":1451396787054,"shasum":"3040f53b2142cf6a7c2ceaa50295b4bfef795502"},{"_id":"public/archives/2011/03/index.html","modified":1451396787088,"shasum":"e7d5f7d905a5851efa48ceceff30fdda87b1d37c"},{"_id":"public/archives/2011/04/index.html","modified":1451396787111,"shasum":"cf00e7d363c6386a48ec86c1e28809aa26ab91e0"},{"_id":"public/archives/2011/05/index.html","modified":1451396787135,"shasum":"b921e0dc5a4de9df4e4d2596bad48f97151c063a"},{"_id":"public/archives/2011/06/index.html","modified":1451396787165,"shasum":"7ea0a30daef17e8547cf4512a748f485a40f75e6"},{"_id":"public/archives/2011/07/index.html","modified":1451396787190,"shasum":"a80eea926c156e11fd77bc9d4de8a8cf1d16005d"},{"_id":"public/archives/2011/09/index.html","modified":1451396787222,"shasum":"1c6938ecba3b2b9290ae6677777d17bf7e169198"},{"_id":"public/archives/2011/10/index.html","modified":1451396787246,"shasum":"f8741ffb527e8c5b75454cc3e995f31371592608"},{"_id":"public/archives/2011/11/index.html","modified":1451396787275,"shasum":"c4dc2d3c5dcacf9c81ac1ef3460a329be23b1771"},{"_id":"public/archives/2011/12/index.html","modified":1451396787309,"shasum":"82a759a7394bb69be18b700e9447db11f5615be3"},{"_id":"public/archives/2011/12/page/2/index.html","modified":1451396787344,"shasum":"c12ded3944a04b729b5cc7adb8c575a5c0d0a816"},{"_id":"public/archives/2012/index.html","modified":1451396787380,"shasum":"4ec0fde419aac53e35f3fa85024656d2aac86961"},{"_id":"public/archives/2012/page/2/index.html","modified":1451396787421,"shasum":"bd4cc22dfb5b9f21712173f08196ef6142c903cd"},{"_id":"public/archives/2012/page/3/index.html","modified":1451396787463,"shasum":"62fb085a269c68533a6734ce7258acbb9c65c98e"},{"_id":"public/archives/2012/page/4/index.html","modified":1451396787496,"shasum":"597593bcb7030255495b8c0bb14f1580ab1a14e0"},{"_id":"public/archives/2012/page/5/index.html","modified":1451396787549,"shasum":"456b42fc6f31f3ea01cc49703e2c02d531a28e79"},{"_id":"public/archives/2012/01/index.html","modified":1451396787581,"shasum":"a70d8ebfc253f84e9651142e510ea73c79494189"},{"_id":"public/archives/2012/02/index.html","modified":1451396787635,"shasum":"9c53daed147add04239ec063f169d15095c06c89"},{"_id":"public/archives/2012/02/page/2/index.html","modified":1451396787676,"shasum":"424429760ac5a65c85ae137b6aef9107c728e507"},{"_id":"public/archives/2012/03/index.html","modified":1451396787722,"shasum":"2d5068c3e072e46ec7cae833527583e0a59715fa"},{"_id":"public/archives/2012/04/index.html","modified":1451396787766,"shasum":"95e9ae13ebcb2d0d0083a3fa892f9dc0a2f1b905"},{"_id":"public/archives/2012/05/index.html","modified":1451396787803,"shasum":"485b16dffb34a2e6259ca9bf98fa523974f8317a"},{"_id":"public/archives/2012/06/index.html","modified":1451396787843,"shasum":"db892930b403534a2853fb6afdc4cde257147c9d"},{"_id":"public/archives/2012/07/index.html","modified":1451396787886,"shasum":"4bc002177489a144f86e68461ddb95c7057dd8a9"},{"_id":"public/archives/2012/09/index.html","modified":1451396787917,"shasum":"d8bca45f8363820cfd76928cd6ee3a42ed0ee069"},{"_id":"public/archives/2012/10/index.html","modified":1451396787939,"shasum":"efb1d727837a8383cb5b9c528f625ac0825d2472"},{"_id":"public/archives/2012/11/index.html","modified":1451396787971,"shasum":"da4190ac180f79f7a163560927b1de0a461d026a"},{"_id":"public/archives/2013/index.html","modified":1451396788014,"shasum":"cfbb159d2be82fb0c63f4b3894ca98c85798d1d5"},{"_id":"public/archives/2013/page/2/index.html","modified":1451396788051,"shasum":"3c04244c97c589e65bddf4d186f8054f10b05fc3"},{"_id":"public/archives/2013/page/3/index.html","modified":1451396788091,"shasum":"bb078b994b0af851ecdb1b68daec88abf329616b"},{"_id":"public/archives/2013/01/index.html","modified":1451396788119,"shasum":"6c280e43df538f835273b1e5e6fbbc772152c071"},{"_id":"public/archives/2013/03/index.html","modified":1451396788159,"shasum":"d5f4cd3c8b251c8189e835b065366c6f166c039f"},{"_id":"public/archives/2013/03/page/2/index.html","modified":1451396788188,"shasum":"0fa1d92e1289dfaffad87a1e5655ffc44a570141"},{"_id":"public/archives/2013/04/index.html","modified":1451396788217,"shasum":"37c1c3ba0da93594fd96c22c37354d42c60dbf7d"},{"_id":"public/archives/2013/05/index.html","modified":1451396788240,"shasum":"a61af734b00d712cc062bbba7c80e2ec6c53fb2c"},{"_id":"public/archives/2013/08/index.html","modified":1451396788273,"shasum":"edbe1e6d6ce256fe1aac3708d2867d4d0baa9ee2"},{"_id":"public/archives/2013/10/index.html","modified":1451396788295,"shasum":"a5be09b2040e41b7216ba3e3caca6800e5c40d2d"},{"_id":"public/archives/2013/11/index.html","modified":1451396788327,"shasum":"e1dc1ec2f67f96f4f590b77c41658c3fc5319033"},{"_id":"public/archives/2014/index.html","modified":1451396788359,"shasum":"244b8002ae8a91910f24ed9661cb2b04d1174698"},{"_id":"public/archives/2014/page/2/index.html","modified":1451396788391,"shasum":"85f57191222e8b52f440da399fe720234d76b3c1"},{"_id":"public/archives/2014/01/index.html","modified":1451396788419,"shasum":"464caf29f490cc88ef232262651624ccc42becaf"},{"_id":"public/archives/2014/04/index.html","modified":1451396788462,"shasum":"95fc21dced3f18f93cf05ee4b49b2cd4dad43f5a"},{"_id":"public/archives/2014/05/index.html","modified":1451396788498,"shasum":"90850c153da1ee0999ef0db62e625de9a9e38b8f"},{"_id":"public/archives/2014/10/index.html","modified":1451396788542,"shasum":"4670bf344defae181d3a2eca1c99ee5245da79bb"},{"_id":"public/archives/2015/index.html","modified":1451396788590,"shasum":"839dc9834da0b33c12a82a47a896e87bcddc6117"},{"_id":"public/archives/2015/page/2/index.html","modified":1451396788628,"shasum":"cc2b161969a1388b97723d7f35832c12a989c298"},{"_id":"public/archives/2015/03/index.html","modified":1451396788661,"shasum":"4be58c8ac7f1520e549e5af3ce247e5a8417fbee"},{"_id":"public/archives/2015/08/index.html","modified":1451396788706,"shasum":"e424f9a9d1b35ea48318fd7461ae8d0a389b92e6"},{"_id":"public/archives/2015/09/index.html","modified":1451396788739,"shasum":"ac37eaa9f9b3c861c29a7ead4fda5910e5806e1e"},{"_id":"public/archives/2015/10/index.html","modified":1451396788785,"shasum":"982d9370b0582e7674450f4019e5907bef41f5bd"},{"_id":"public/archives/2015/12/index.html","modified":1451396788828,"shasum":"c5009011aae5a8a3eb3460bd3d664bf61f0a73fd"},{"_id":"public/categories/技术分享/index.html","modified":1451396788855,"shasum":"aa0ff6ac10fdb57fb04378585eadca96f9918836"},{"_id":"public/categories/技术分享/page/2/index.html","modified":1451396788884,"shasum":"ee811154d52883aa28e35e99383372434791a9ff"},{"_id":"public/categories/技术分享/page/3/index.html","modified":1451396788918,"shasum":"e019fbaa6b5d816ef95882f0158c88c0a91ba52e"},{"_id":"public/categories/技术分享/page/4/index.html","modified":1451396788945,"shasum":"7eafd721c7e62ab918df04bb0602766c995e9203"},{"_id":"public/categories/技术分享/page/5/index.html","modified":1451396788978,"shasum":"49f2f38748790e4c661f6facab8f05ccf3383170"},{"_id":"public/categories/技术分享/page/6/index.html","modified":1451396789005,"shasum":"b0759f6221cc3016a28797152f645515a51f4546"},{"_id":"public/categories/技术分享/page/7/index.html","modified":1451396789037,"shasum":"da29a1eb5ad1c2d77cbcd955f0f60bff621f0aa1"},{"_id":"public/categories/技术分享/page/8/index.html","modified":1451396789064,"shasum":"14eb3fe046d70d74859fa17f3a1037e178d3e8e4"},{"_id":"public/categories/技术分享/page/9/index.html","modified":1451396789095,"shasum":"b03fa9a7ea61e5204ffe86349d79db968c020c70"},{"_id":"public/categories/技术分享/page/10/index.html","modified":1451396789124,"shasum":"ac8899e13f85415e01ab241d22a85231076feb40"},{"_id":"public/categories/生活分享/index.html","modified":1451396789156,"shasum":"2b3c60ee02d1c8b863adbc592621f8bfde0fa07e"},{"_id":"public/categories/生活分享/page/2/index.html","modified":1451396789184,"shasum":"84eeb8c3e900078ed0bff17052d5e72b5b9bcef8"},{"_id":"public/categories/生活分享/page/3/index.html","modified":1451396789212,"shasum":"9c681feb593787b350389a9b5dd98424ae940042"},{"_id":"public/categories/生活点滴/index.html","modified":1451396789236,"shasum":"972b1403e0a8919a21a80bc8d81c83d4882559b9"},{"_id":"public/categories/最佳实践/index.html","modified":1451396789268,"shasum":"b0ed1d2c71a63b01e95081ed84caa768dd2e6293"},{"_id":"public/categories/自学资料/index.html","modified":1451396789290,"shasum":"1118b4a225fcb8301dde3d847689587a07b70c03"},{"_id":"public/categories/技术分享/生活分享/index.html","modified":1451396789313,"shasum":"9ee5ba38b99930da48c3a2f075e817c7c09b0f24"},{"_id":"public/index.html","modified":1451396789361,"shasum":"798e79f9047bfb189e56e69fffe15b79a08c7ac8"},{"_id":"public/page/2/index.html","modified":1451396789426,"shasum":"78b54715258cc10febc0ccb0a62a666ecaebf567"},{"_id":"public/page/3/index.html","modified":1451396789493,"shasum":"ed7d69271bd7f6ca8a3264e8d0c9b12beb8c2bda"},{"_id":"public/page/4/index.html","modified":1451396789555,"shasum":"c4f7e8e7a85cd276200596ed4fac2c1adb1b4bba"},{"_id":"public/page/5/index.html","modified":1451396789609,"shasum":"d90e94f1976fc612bda4bd83a8e6e94c38786741"},{"_id":"public/page/6/index.html","modified":1451396789674,"shasum":"bddcfc777ccfdb9909df19c91a64c1d607163eec"},{"_id":"public/page/7/index.html","modified":1451396789751,"shasum":"53b708ebeb432627a2aec8eb12f3c38693abac06"},{"_id":"public/page/8/index.html","modified":1451396789796,"shasum":"dcd1397e753563968d6bfee170487cca49bb4791"},{"_id":"public/page/9/index.html","modified":1451396789840,"shasum":"685141dffafd9d70423b3fd90b35145111cf9df8"},{"_id":"public/page/10/index.html","modified":1451396789885,"shasum":"f6d0b9468c6d6ee21b8d2e0ae4377e49e3e6fc9c"},{"_id":"public/page/11/index.html","modified":1451396789929,"shasum":"21318aebbb7b5bc0a704901bd3903d752a273506"},{"_id":"public/page/12/index.html","modified":1451396789969,"shasum":"66339707e55e76a1e3f2f97e29c86a20e2fbfd92"},{"_id":"public/page/13/index.html","modified":1451396790018,"shasum":"c9efbd7ed73a4eb86cc362c9b1a5102a27fbe3dd"},{"_id":"public/page/14/index.html","modified":1451396790064,"shasum":"12b38dbfef25b25d9ca8bcf2327604b6b3f00024"},{"_id":"public/tags/ZooKeeper/index.html","modified":1451396790086,"shasum":"1d17c7b38fb311410f2431ced0a0a92d7218a9d0"},{"_id":"public/tags/双11/index.html","modified":1451396790113,"shasum":"e024e4fe78c79fa116c114728e599af78c36233c"},{"_id":"public/tags/微博/index.html","modified":1451396790134,"shasum":"ec52b115710ccdbcf24095635cac3981475747ab"},{"_id":"public/tags/数据分析/index.html","modified":1451396790161,"shasum":"2514ac3ca67f03570e988ed6b2297c244e005a8f"},{"_id":"public/tags/歌词/index.html","modified":1451396790184,"shasum":"6e1fa2d88fba6e8e0931d9735bcebae23d9df0a1"},{"_id":"public/tags/音乐/index.html","modified":1451396790206,"shasum":"7aa308d59eb96ab1058094871f65378b3cc19980"},{"_id":"public/tags/生活/index.html","modified":1451396790237,"shasum":"8dc498b7a43dc3fadd06e64d98f50b045eadcf22"},{"_id":"public/tags/NoSQL/index.html","modified":1451396790260,"shasum":"7212e0f3d11f7889c7d43c11d668272251d663ef"},{"_id":"public/tags/系统架构/index.html","modified":1451396790281,"shasum":"2fec423a16b11e826d06326b1910afb07c201480"},{"_id":"public/tags/价值观/index.html","modified":1451396790322,"shasum":"595efea3d220bd401af04e22bbfbc1b544ebbb79"},{"_id":"public/tags/Solr/index.html","modified":1451396790359,"shasum":"2d2c29547b5dfaf2f3a27018e11faa2aee8b1d65"},{"_id":"public/tags/摄影/index.html","modified":1451396790403,"shasum":"1b76808184c46bfc8ecea4660c21b46bdd8dcdce"},{"_id":"public/tags/数码/index.html","modified":1451396790435,"shasum":"37a94df78805a5e386f18cbcf39673f34087759a"},{"_id":"public/tags/REWORK-37signals-书摘-生活/index.html","modified":1451396790468,"shasum":"3dee5904da56ecfaca51df3861af5a8fdfb70f77"},{"_id":"public/tags/Java/index.html","modified":1451396790501,"shasum":"70efe33ca58cad358f2e21be8d048ab2504a31c6"},{"_id":"public/tags/Network/index.html","modified":1451396790529,"shasum":"9c41b422baa6e5e225878c894867c34ec0340d42"},{"_id":"public/tags/果壳网/index.html","modified":1451396790562,"shasum":"9f75b9efa7a13dfa2225929511af5f8dbd6cb6af"},{"_id":"public/tags/Redis/index.html","modified":1451396790593,"shasum":"f3c3adba8c5697f9c98e9afa48d6e577522f8ae3"},{"_id":"public/tags/数据结构/index.html","modified":1451396790629,"shasum":"e1e3621c763d0308f749aba9591ba8ec2614d23c"},{"_id":"public/tags/SSD/index.html","modified":1451396790679,"shasum":"a26eadc8c8b64a8002791e3e22db9bbe2f45b8ea"},{"_id":"public/tags/电影/index.html","modified":1451396790700,"shasum":"5cd736215ff0f1606e34bddea0109259546500d8"},{"_id":"public/tags/算法/index.html","modified":1451396790727,"shasum":"ee3b000ce8eda127fe846a6dc9d5d9b690f52d3d"},{"_id":"public/tags/Python/index.html","modified":1451396790754,"shasum":"adc3185bbaa7df49461411633f7aac5e456be140"},{"_id":"public/tags/JVM/index.html","modified":1451396790777,"shasum":"27bfb3ae5184f5bdd73c4e2ea17336a3640f0585"},{"_id":"public/tags/OOM-Killer/index.html","modified":1451396790807,"shasum":"f274dcdc570e60b5a6cac6f71cadfd7ddc2c3bb8"},{"_id":"public/tags/java/index.html","modified":1451396790832,"shasum":"612e0b4f46cee4807e15a9cd038ed36daa730615"},{"_id":"public/tags/自然语言处理/index.html","modified":1451396790857,"shasum":"3c81aca003e1ae853da0fec6d8a9f885798256f5"},{"_id":"public/tags/语义/index.html","modified":1451396790885,"shasum":"e4bc630e06f20b4aefec31ea97bae7593fbc1c87"},{"_id":"public/tags/Mina/index.html","modified":1451396790907,"shasum":"4dc81f794bc13cabd69da9129ed1b19490760c35"},{"_id":"public/tags/Netty/index.html","modified":1451396790940,"shasum":"210b31596a6b87d799d849f54f7dd2d1740e103b"},{"_id":"public/tags/线程模型/index.html","modified":1451396790964,"shasum":"46e1bf7ec5b86951973f1d6454cc8e7e8d33763c"},{"_id":"public/tags/Apple/index.html","modified":1451396790987,"shasum":"57364add705826ebb094430cee6aa070e5682fd8"},{"_id":"public/tags/Macbook/index.html","modified":1451396791015,"shasum":"fa31f34060e8f5eb6665bd7bad0fd4edaf01a0f5"},{"_id":"public/tags/RBMP/index.html","modified":1451396791036,"shasum":"c4cc3175833c807cef27165af99a1d67d592cdf3"},{"_id":"public/tags/group-by/index.html","modified":1451396791057,"shasum":"0f8b4d7e9e05aa3ac37c940e6b5e9c13b2a23ecd"},{"_id":"public/tags/SQL/index.html","modified":1451396791085,"shasum":"99a6760857a6826dd2055389cd7db7d9b577587d"},{"_id":"public/tags/Maven/index.html","modified":1451396791110,"shasum":"0a7f434f3277a871ba5dac8af9e696902dad0b55"},{"_id":"public/tags/Hadoop/index.html","modified":1451396791142,"shasum":"68b7012134c721fc09dc225bb0439b81c705f620"},{"_id":"public/tags/Hadoop/page/2/index.html","modified":1451396791168,"shasum":"85002a19fbc8863536e7d6e2df6dd0dc3a736321"},{"_id":"public/tags/Hadoop/page/3/index.html","modified":1451396791195,"shasum":"d31b8c642a2bb600ce8a690a7d8f20313f48fb85"},{"_id":"public/tags/MapReduce/index.html","modified":1451396791221,"shasum":"c87842e414ddfb27609660fcaba2acf477f07808"},{"_id":"public/tags/MapReduce/page/2/index.html","modified":1451396791243,"shasum":"0465ad11eb0adac4f52efb934fdf2c70a2e1fa8a"},{"_id":"public/tags/Linux/index.html","modified":1451396791275,"shasum":"d02c46b8c05f38a9e9b4de662ed357566b43c738"},{"_id":"public/tags/Shell/index.html","modified":1451396791300,"shasum":"f05c1a0ffc588492cf8dd2aa94afd0ec737fc9ba"},{"_id":"public/tags/Java-源码/index.html","modified":1451396791334,"shasum":"f9a7244966b200905087ba70a4ff7fcaead5533c"},{"_id":"public/tags/Haloop/index.html","modified":1451396791364,"shasum":"50c9fb2aed649a547b7130a57bfb37d2b968713c"},{"_id":"public/tags/Remote-书摘-生活/index.html","modified":1451396791393,"shasum":"d5276c664a8bc475c5d01ff650968372cf738815"},{"_id":"public/tags/SAE/index.html","modified":1451396791430,"shasum":"6f81f40c949ceff58110eff56006579820651bbe"},{"_id":"public/tags/Hadoop-Pipes/index.html","modified":1451396791463,"shasum":"b0fcfce55a2cb908f736e35342e52a8b154231ea"},{"_id":"public/tags/RPC/index.html","modified":1451396791496,"shasum":"916b05300beb25f6009538a4848621f1f86bfbbf"},{"_id":"public/tags/Google/index.html","modified":1451396791535,"shasum":"c911b4b252ee60f472a51400f441019c41179173"},{"_id":"public/tags/GIT/index.html","modified":1451396791571,"shasum":"332cd03baf9e15b2158321ec710e819f107add27"},{"_id":"public/tags/价值观-生活/index.html","modified":1451396791622,"shasum":"1d10601e491898b90d4874be1f427142652e3bb5"},{"_id":"public/tags/英语/index.html","modified":1451396791664,"shasum":"29501a8bed04174615266780e36f579b26f9eb9f"},{"_id":"public/tags/Eclipse/index.html","modified":1451396791697,"shasum":"ee3c7549fa22a85886da40c5c11686a74f3fd878"},{"_id":"public/tags/Docker/index.html","modified":1451396791757,"shasum":"487b760b7883823d7aa40abca15c9c16c35f821f"},{"_id":"public/tags/Docker-plugins/index.html","modified":1451396791780,"shasum":"721eb5261e76ab3eceb843d123c9fe9808af4d72"},{"_id":"public/tags/Docker-volume/index.html","modified":1451396791802,"shasum":"4a171cd71c88ed07b10068e10574bd8051c352c2"},{"_id":"public/tags/Docker-Compose/index.html","modified":1451396791826,"shasum":"70da27d8a58220a69297d663d45b32a66ae8ab5b"},{"_id":"public/tags/分布式/index.html","modified":1451396791854,"shasum":"98bd06c1205231f051c0a59b3f9f4d881dad1d81"},{"_id":"public/tags/设计模式/index.html","modified":1451396791882,"shasum":"e870c58cda486660892bbcc7440d513ec9b4c16f"},{"_id":"public/tags/设计模式/page/2/index.html","modified":1451396791912,"shasum":"1277296c0e6afe97ae31e1980ae7f1c044ba88a5"},{"_id":"public/tags/CSS/index.html","modified":1451396791937,"shasum":"66fc8a281c1aafccfd53210f976cfc376b7fa69c"},{"_id":"public/tags/Frontend/index.html","modified":1451396791971,"shasum":"3fa6b46d1f8e384ef57bad6293eab56578042df0"},{"_id":"public/tags/Solr-数据结构/index.html","modified":1451396792001,"shasum":"d69e435c516c6d0fbe95f521be91ce2499ba73f3"},{"_id":"public/tags/YARN/index.html","modified":1451396792023,"shasum":"413810ba99638d5ba5b039ee670bd674c0e6e95c"},{"_id":"public/tags/Android/index.html","modified":1451396792043,"shasum":"588cdcf81356b586036a7e03cdd719664d4791de"}],"Category":[{"name":"技术分享","_id":"ciirg620g0002sb8fbby8sg93"},{"name":"生活分享","_id":"ciirg620m000bsb8fkm4sf9k6"},{"name":"生活点滴","_id":"ciirg6212001esb8fp344f5y9"},{"name":"最佳实践","_id":"ciirg6214001jsb8fgfjd266m"},{"name":"自学资料","_id":"ciirg6243008isb8fq4wzlvb6"},{"name":"生活分享","parent":"ciirg620g0002sb8fbby8sg93","_id":"ciirg6249008wsb8f0ydfqs54"}],"Data":[],"Page":[{"title":"All tags","date":"2015-08-28T14:35:52.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"title: All tags \ndate: 2015-08-28 22:35:52\ntype: \"tags\"\ncomments: false\n---\n","updated":"2015-12-29T13:30:15.000Z","path":"tags/index.html","layout":"page","_id":"ciirg61zy0000sb8fvbd7aypi"}],"Post":[{"title":"Zookeeper Ephemeral结点使用心得","id":"619","date":"2012-11-05T12:33:28.000Z","_content":"\n公司里面在拿Zookeeper做命名服务，通过使用ZK，前端只需要根据指定的ZK地址获得相应的资源或服务的后端服务器地址即可，而后端服务器需要做的仅仅是将自己的地址注册到ZK上作为一个Ephemeral结点即可。（虽然是挺方便后端扩容，但是我个人不太建议直接上ZK，否则开发成本会增加）\n<!--more-->  > **P.S.:**Ephemeral结点在Apache Zookeeper中是一个临时结点，这些结点只要创建它的结点session不挂，它就一直存在，当session中止了，结点也就删除了。  \n\n**问题：**\n\n在开发的时候遇到了一个奇怪的问题，当某个后端快速重启之后，该后端的结点信息过一段时间后会被删除，这样就导致了后端服务永远无法被前端访问到。\n\n**原因：**\n\n查了资料后得知，如果在你的session中，ephemeral结点不是由你创建的，你的session就不会拥有该结点，所以当拥有该结点的session终止（expire）了，该结点也就销毁了。那么，如果不是你显式的删除该结点的话，就只能由ZK帮你终止它，在会话超时之后ZK就自动删除结点。如果在会话还未超时的过程中（一般是30s），你重启后端服务器的话，就会导致我所说的情况。\n\n**解决方案：**\n\nApache提供了几个patch，也有人提供了一些解决方案，均是显式的终止session。但是后端服务器挂了，显式终止一般是没用的。找到的这个方法是比较靠谱的，那就是在创建结点前，先删除之前的结点：   <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\" width=\"637\"><tbody>       <tr>         <td valign=\"top\" width=\"635\">           <p> 1\\. try {\n\n 2.&#160;&#160; zk.delete(path)\n\n 3\\. } catch {\n\n 4.&#160;&#160; e: NoNodeException =&gt; // do nothing\n\n 5\\. }\n\n 6\\. zk.create(path, data, CreateMode.EPHEMERAL)\n         </td>       </tr>     </tbody></table> </p>  > **参考资料：**\n> \n> [A Gotcha When Using ZooKeeper Ephemeral Nodes](http://developers.blog.box.com/2012/04/10/a-gotcha-when-using-zookeeper-ephemeral-nodes/)\n> \n> [ephemerals handling after restart](http://zookeeper-user.578899.n2.nabble.com/ephemerals-handling-after-restart-td1084715.html)","source":"_posts/zookeeper-ephemeral-nodes-experience.md","raw":"title: Zookeeper Ephemeral结点使用心得\ntags:\n  - ZooKeeper\nid: 619\ncategories:\n  - 技术分享\ndate: 2012-11-05 20:33:28\n---\n\n公司里面在拿Zookeeper做命名服务，通过使用ZK，前端只需要根据指定的ZK地址获得相应的资源或服务的后端服务器地址即可，而后端服务器需要做的仅仅是将自己的地址注册到ZK上作为一个Ephemeral结点即可。（虽然是挺方便后端扩容，但是我个人不太建议直接上ZK，否则开发成本会增加）\n<!--more-->  > **P.S.:**Ephemeral结点在Apache Zookeeper中是一个临时结点，这些结点只要创建它的结点session不挂，它就一直存在，当session中止了，结点也就删除了。  \n\n**问题：**\n\n在开发的时候遇到了一个奇怪的问题，当某个后端快速重启之后，该后端的结点信息过一段时间后会被删除，这样就导致了后端服务永远无法被前端访问到。\n\n**原因：**\n\n查了资料后得知，如果在你的session中，ephemeral结点不是由你创建的，你的session就不会拥有该结点，所以当拥有该结点的session终止（expire）了，该结点也就销毁了。那么，如果不是你显式的删除该结点的话，就只能由ZK帮你终止它，在会话超时之后ZK就自动删除结点。如果在会话还未超时的过程中（一般是30s），你重启后端服务器的话，就会导致我所说的情况。\n\n**解决方案：**\n\nApache提供了几个patch，也有人提供了一些解决方案，均是显式的终止session。但是后端服务器挂了，显式终止一般是没用的。找到的这个方法是比较靠谱的，那就是在创建结点前，先删除之前的结点：   <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\" width=\"637\"><tbody>       <tr>         <td valign=\"top\" width=\"635\">           <p> 1\\. try {\n\n 2.&#160;&#160; zk.delete(path)\n\n 3\\. } catch {\n\n 4.&#160;&#160; e: NoNodeException =&gt; // do nothing\n\n 5\\. }\n\n 6\\. zk.create(path, data, CreateMode.EPHEMERAL)\n         </td>       </tr>     </tbody></table> </p>  > **参考资料：**\n> \n> [A Gotcha When Using ZooKeeper Ephemeral Nodes](http://developers.blog.box.com/2012/04/10/a-gotcha-when-using-zookeeper-ephemeral-nodes/)\n> \n> [ephemerals handling after restart](http://zookeeper-user.578899.n2.nabble.com/ephemerals-handling-after-restart-td1084715.html)","slug":"zookeeper-ephemeral-nodes-experience","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg620d0001sb8fc9nebivq"},{"title":"小菜看双11大促","id":"875","date":"2013-11-17T15:49:49.000Z","_content":"\n**1、前言**\n\n本人小菜在支付宝数据平台实习半年，主要业务均是离线场景，原以为今年是刷不上双11了，但幸运的是，运营支撑部门准备开发一套线上场景的应用，需要用到数据平台这边的系统，更幸运的是，我负责了部分数据平台这边的部分数据出口系统。该套应用双11当天也需要使用，所以呢，我也算是凑了凑双11开发的热闹。\n<!--more-->  \n\n在这过程虽然对于双11相关的开发事宜了解不是很多，但是或多或少有所耳闻，在这里将我的一些心得体会记录下来。\n\n&#160;\n\n**2、内部机制**\n\n我面向的这个应用的开发流程和普通的应用开发流程基本一致，提前2-3个月开发完毕，开发周期约1个半月。\n\n开发需要做的**第一件事**：需要与各个关联应用的owner沟通协商，沟通内容大概就是需求是否能够满足；平均TPS/峰值TPS大约多少；如果需要开发周期多长，我负责的主要数据相关的接口，结果是需求暂时无法满足，得重新开发新接口；TPS似乎有点高，得压测后评估新的服务器容量；半个人月开发一周测试。这个结果也还算okay，基本就是时间的问题，与他们协商好新接口以及联调的时间即可自行开发了。\n\n开发需要做的**第二件事**：具体开发过程大同小异了，开发完毕后需要进行联调以及测试，同时要对新的接口进行压测，压测完毕后才是重点——服务器容量水位评估，用以评估在当前的水平下，需要多少台机器才能够撑得住预估TPS。具体的评估方法在这里就不细说了，阿里技术嘉年华中有篇PPT，就讲了容量水位的评估，《[如何利用应用自己的数据来保证系统的稳定](http://club.alibabatech.org/resource_detail.htm?topicId=81)》，和我用的类似但不完全相同。\n\n开发需要做的**第三件事**：联调完毕，压测完毕，机器扩容也完毕。在我这个小菜看来，我的系统就可以发布了，后经运维再三提醒与要求，给接口加上了服务开发，方便在各个活动中进行服务的升降级。公司内部有自己的分布式资源管理组件，可很方便的实现应用开关，基本的实现思路可以看一下这篇博客：《[java分布式系统开关功能设计](http://iamzhongyong.iteye.com/blog/1897694)》\n\n由于接的这个项目并非支付宝关键链路上的系统，所以系统优先级会比较低，我上层的应用做的限流机制也比较轻便。业务方会评估我系统的应用容量，配置报警机制，在超过容量阈值的时候报警，同时人工干预进行系统限流。具体的限流实现也较为简单，分布式资源管理系统推送限流概率，比如说0.9，业务则会通过Random过滤掉约为10%的请求，直接抛弃掉，好像也很弱的样子。当然，这是属于应用级的限流，也有系统级的限流，比如淘宝那边的TMD，支付宝这边的SLA，都没有深入了解，如TMD是nginx的一个组件，应该是在接入层做的限流，如限流控制在500TPS，那么第501个请求则直接抛弃。运维方面，在双11前几天也会提前查看机器状态信息，如负载、请求量、日志情况，针对不同的情况作出不同的调整，比如动态给数据库集群增添机器、修改报警阈值等。\n\n&#160;\n\n**3、后记**\n\n以上便是我这个双11相关工作周边游荡的编外人员所接触到的双11内部机制，无论是理解还是实践都比较肤浅，不过还有机会深入双11核心工作滴，木哈哈哈！\n\n&#160;\n  > 双11前两天我那系统的请求量还是挺可观的，比平常翻了十翻，但是双11当天请求量却掉回解放前。应该是被限流了，不是关键链路上的就是悲惨啊！！！","source":"_posts/what-i-think-about-1111.md","raw":"title: 小菜看双11大促\ntags:\n  - 双11\nid: 875\ncategories:\n  - 技术分享\ndate: 2013-11-17 23:49:49\n---\n\n**1、前言**\n\n本人小菜在支付宝数据平台实习半年，主要业务均是离线场景，原以为今年是刷不上双11了，但幸运的是，运营支撑部门准备开发一套线上场景的应用，需要用到数据平台这边的系统，更幸运的是，我负责了部分数据平台这边的部分数据出口系统。该套应用双11当天也需要使用，所以呢，我也算是凑了凑双11开发的热闹。\n<!--more-->  \n\n在这过程虽然对于双11相关的开发事宜了解不是很多，但是或多或少有所耳闻，在这里将我的一些心得体会记录下来。\n\n&#160;\n\n**2、内部机制**\n\n我面向的这个应用的开发流程和普通的应用开发流程基本一致，提前2-3个月开发完毕，开发周期约1个半月。\n\n开发需要做的**第一件事**：需要与各个关联应用的owner沟通协商，沟通内容大概就是需求是否能够满足；平均TPS/峰值TPS大约多少；如果需要开发周期多长，我负责的主要数据相关的接口，结果是需求暂时无法满足，得重新开发新接口；TPS似乎有点高，得压测后评估新的服务器容量；半个人月开发一周测试。这个结果也还算okay，基本就是时间的问题，与他们协商好新接口以及联调的时间即可自行开发了。\n\n开发需要做的**第二件事**：具体开发过程大同小异了，开发完毕后需要进行联调以及测试，同时要对新的接口进行压测，压测完毕后才是重点——服务器容量水位评估，用以评估在当前的水平下，需要多少台机器才能够撑得住预估TPS。具体的评估方法在这里就不细说了，阿里技术嘉年华中有篇PPT，就讲了容量水位的评估，《[如何利用应用自己的数据来保证系统的稳定](http://club.alibabatech.org/resource_detail.htm?topicId=81)》，和我用的类似但不完全相同。\n\n开发需要做的**第三件事**：联调完毕，压测完毕，机器扩容也完毕。在我这个小菜看来，我的系统就可以发布了，后经运维再三提醒与要求，给接口加上了服务开发，方便在各个活动中进行服务的升降级。公司内部有自己的分布式资源管理组件，可很方便的实现应用开关，基本的实现思路可以看一下这篇博客：《[java分布式系统开关功能设计](http://iamzhongyong.iteye.com/blog/1897694)》\n\n由于接的这个项目并非支付宝关键链路上的系统，所以系统优先级会比较低，我上层的应用做的限流机制也比较轻便。业务方会评估我系统的应用容量，配置报警机制，在超过容量阈值的时候报警，同时人工干预进行系统限流。具体的限流实现也较为简单，分布式资源管理系统推送限流概率，比如说0.9，业务则会通过Random过滤掉约为10%的请求，直接抛弃掉，好像也很弱的样子。当然，这是属于应用级的限流，也有系统级的限流，比如淘宝那边的TMD，支付宝这边的SLA，都没有深入了解，如TMD是nginx的一个组件，应该是在接入层做的限流，如限流控制在500TPS，那么第501个请求则直接抛弃。运维方面，在双11前几天也会提前查看机器状态信息，如负载、请求量、日志情况，针对不同的情况作出不同的调整，比如动态给数据库集群增添机器、修改报警阈值等。\n\n&#160;\n\n**3、后记**\n\n以上便是我这个双11相关工作周边游荡的编外人员所接触到的双11内部机制，无论是理解还是实践都比较肤浅，不过还有机会深入双11核心工作滴，木哈哈哈！\n\n&#160;\n  > 双11前两天我那系统的请求量还是挺可观的，比平常翻了十翻，但是双11当天请求量却掉回解放前。应该是被限流了，不是关键链路上的就是悲惨啊！！！","slug":"what-i-think-about-1111","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg620i0006sb8fu116ik6u"},{"title":"@小e_鸿伟的微博粗分析","id":"492","date":"2012-03-26T15:20:04.000Z","_content":"\n**1****、杂侃**\n\n最近状态着实不太好，也有点闲。大部分时间都在看书，coding也不太多，琢磨着写一两个小程序，也没找到好玩的。昨晚无聊刷微博的时候，灵机一动，干脆分析分析自己的微博吧。所以也就有了这篇文章。\n\n<!--more-->\n\n**2****、数据准备**\n\n要分析，就得有数据，数据也还好弄，到了微博的[开放平台](http://open.weibo.com/)，下了一个Java SDK，开始拉数据……\n\n微博的sdk比人人的易用一些，先登录获得access_token，再创建一个Weibo对象，将请求的json地址填进去就可以了。 \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span>User user = um.showUserById(uid);&#160;&#160; </span></span>2.  <span></span><span class=\"comment\">// get the count of your weibos </span><span>&#160; </span></span>3.  <span></span><span class=\"comment\">// prepared for iteration </span><span>&#160; </span></span>4.  <span></span><span class=\"keyword\">int</span><span> count = user.getStatusesCount();&#160;&#160; </span></span>5.  <span></span><span class=\"keyword\">int</span><span> page_count = </span><span class=\"number\">30</span><span>;&#160;&#160; </span></span>6.  <span>String json = </span><span class=\"string\">&quot;https://api.weibo.com/2/statuses/user_timeline.json?count=&quot;</span><span>&#160; </span></span>7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; + page_count + </span><span class=\"string\">&quot;&amp;page=&quot;</span><span>;&#160;&#160; </span></span>8.  <span></span><span class=\"keyword\">int</span><span> page = </span><span class=\"number\">1</span><span>;&#160;&#160; </span></span>9.  <span>FileWriter writer;&#160;&#160; </span>10.  <span>Response response = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>11.  <span></span><span class=\"keyword\">do</span><span> {&#160;&#160; </span></span>12.  <span>&#160;&#160;&#160; writer = </span><span class=\"keyword\">new</span><span> FileWriter(</span><span class=\"keyword\">new</span><span> File(</span><span class=\"string\">&quot;txt&quot;</span><span>+page+</span><span class=\"string\">&quot;.txt&quot;</span><span>), </span><span class=\"keyword\">true</span><span>);&#160;&#160; </span></span>13.  <span>&#160;&#160;&#160; response = weibo.client.get(json + page);&#160;&#160; </span>14.  <span>&#160;&#160;&#160; writer.write(response.getResponseAsString());&#160;&#160; </span>15.  <span>} </span><span class=\"keyword\">while</span><span> (page++ * page_count &lt; count);&#160;&#160; </span></span> </div>    \n\n上面这段代码也就将我的微博就扒拉下来了。\n\n**3****、数据解析**\n\n扒拉下来的数据是标准的json格式。但是我一直用不习惯json包，找同学要了一个org.json的，不喜欢用。GSON又要将所有字段都写成实体类，嫌麻烦。所以最后的解析就直接用正则表达式了，简单、暴力、直接。\n\n主要解析了created_at（发布时间）、source（发布客户端）两个字段。获得直接就是用的python的re对象，需要注意的是时间格式为“Tue May 31 17:46:55 +0800 2011”，在Java中需要创建一个格式化对象，格式化代码如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>SimpleDateFormat **formater** = **new** SimpleDateFormat(\n\n&quot;EEE MMM d HH:mm:ss Z yyyy&quot;, Locale._ENGLISH_);\n         </td>       </tr>     </tbody></table> </p>  \n\n格式化之后，最好将Date对象转换成Calender对象，因为Date中的年份不太好用，怎么不好用，自己可以体会一下。\n\n**4****、生成图表**\n\n有了数据，就直接复制到Excel中，生成图表。图表如下：\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb6.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image6.png) \n\n我是有多爱转发啊……\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb7.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image7.png) \n\n网页版新浪微博稳居第一，因为我大部分时间还是花在pc上的。买了pad后，在iPad客户端上的发布数应该会上升很多。\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb8.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image8.png) \n\n一周中，每天发的微博数差不多，也是，我对周几一般来说是没概念的。\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb9.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image9.png) \n\n一天中，发布的大部分时间都集中在了中午和午夜，夜晚倒能理解，中午为啥也那么高呢？\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb10.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image10.png) \n\n去年三月份创建的微博帐户，之后发布的微博数急速上升，到了五月到了顶峰，之后就回落。去年十月份之后就比较忙了，一直到了开学，微博又有上升的趋势了。\n\n**5、小结**\n\n以上仅是在无聊中无聊的作品，仅仅是一些字段的孤立的统计，没有任何技术内涵可言，但是还是可以说明一些问题的。不过改天得仔细分析分析我发的微博内容，嗯，是的……","source":"_posts/weibo-analysis.md","raw":"title: '@小e_鸿伟的微博粗分析'\ntags:\n  - 微博\n  - 数据分析\nid: 492\ncategories:\n  - 生活分享\ndate: 2012-03-26 23:20:04\n---\n\n**1****、杂侃**\n\n最近状态着实不太好，也有点闲。大部分时间都在看书，coding也不太多，琢磨着写一两个小程序，也没找到好玩的。昨晚无聊刷微博的时候，灵机一动，干脆分析分析自己的微博吧。所以也就有了这篇文章。\n\n<!--more-->\n\n**2****、数据准备**\n\n要分析，就得有数据，数据也还好弄，到了微博的[开放平台](http://open.weibo.com/)，下了一个Java SDK，开始拉数据……\n\n微博的sdk比人人的易用一些，先登录获得access_token，再创建一个Weibo对象，将请求的json地址填进去就可以了。 \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span>User user = um.showUserById(uid);&#160;&#160; </span></span>2.  <span></span><span class=\"comment\">// get the count of your weibos </span><span>&#160; </span></span>3.  <span></span><span class=\"comment\">// prepared for iteration </span><span>&#160; </span></span>4.  <span></span><span class=\"keyword\">int</span><span> count = user.getStatusesCount();&#160;&#160; </span></span>5.  <span></span><span class=\"keyword\">int</span><span> page_count = </span><span class=\"number\">30</span><span>;&#160;&#160; </span></span>6.  <span>String json = </span><span class=\"string\">&quot;https://api.weibo.com/2/statuses/user_timeline.json?count=&quot;</span><span>&#160; </span></span>7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; + page_count + </span><span class=\"string\">&quot;&amp;page=&quot;</span><span>;&#160;&#160; </span></span>8.  <span></span><span class=\"keyword\">int</span><span> page = </span><span class=\"number\">1</span><span>;&#160;&#160; </span></span>9.  <span>FileWriter writer;&#160;&#160; </span>10.  <span>Response response = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>11.  <span></span><span class=\"keyword\">do</span><span> {&#160;&#160; </span></span>12.  <span>&#160;&#160;&#160; writer = </span><span class=\"keyword\">new</span><span> FileWriter(</span><span class=\"keyword\">new</span><span> File(</span><span class=\"string\">&quot;txt&quot;</span><span>+page+</span><span class=\"string\">&quot;.txt&quot;</span><span>), </span><span class=\"keyword\">true</span><span>);&#160;&#160; </span></span>13.  <span>&#160;&#160;&#160; response = weibo.client.get(json + page);&#160;&#160; </span>14.  <span>&#160;&#160;&#160; writer.write(response.getResponseAsString());&#160;&#160; </span>15.  <span>} </span><span class=\"keyword\">while</span><span> (page++ * page_count &lt; count);&#160;&#160; </span></span> </div>    \n\n上面这段代码也就将我的微博就扒拉下来了。\n\n**3****、数据解析**\n\n扒拉下来的数据是标准的json格式。但是我一直用不习惯json包，找同学要了一个org.json的，不喜欢用。GSON又要将所有字段都写成实体类，嫌麻烦。所以最后的解析就直接用正则表达式了，简单、暴力、直接。\n\n主要解析了created_at（发布时间）、source（发布客户端）两个字段。获得直接就是用的python的re对象，需要注意的是时间格式为“Tue May 31 17:46:55 +0800 2011”，在Java中需要创建一个格式化对象，格式化代码如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>SimpleDateFormat **formater** = **new** SimpleDateFormat(\n\n&quot;EEE MMM d HH:mm:ss Z yyyy&quot;, Locale._ENGLISH_);\n         </td>       </tr>     </tbody></table> </p>  \n\n格式化之后，最好将Date对象转换成Calender对象，因为Date中的年份不太好用，怎么不好用，自己可以体会一下。\n\n**4****、生成图表**\n\n有了数据，就直接复制到Excel中，生成图表。图表如下：\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb6.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image6.png) \n\n我是有多爱转发啊……\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb7.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image7.png) \n\n网页版新浪微博稳居第一，因为我大部分时间还是花在pc上的。买了pad后，在iPad客户端上的发布数应该会上升很多。\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb8.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image8.png) \n\n一周中，每天发的微博数差不多，也是，我对周几一般来说是没概念的。\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb9.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image9.png) \n\n一天中，发布的大部分时间都集中在了中午和午夜，夜晚倒能理解，中午为啥也那么高呢？\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb10.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image10.png) \n\n去年三月份创建的微博帐户，之后发布的微博数急速上升，到了五月到了顶峰，之后就回落。去年十月份之后就比较忙了，一直到了开学，微博又有上升的趋势了。\n\n**5、小结**\n\n以上仅是在无聊中无聊的作品，仅仅是一些字段的孤立的统计，没有任何技术内涵可言，但是还是可以说明一些问题的。不过改天得仔细分析分析我发的微博内容，嗯，是的……","slug":"weibo-analysis","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg620l000asb8fofw0pm2c"},{"title":"我的歌声里","id":"135","date":"2011-04-05T02:34:36.000Z","_content":"\n没有一点点防备，也没有一丝顾虑\n\n你就这样出现在我的世界里，带给我惊喜，情不自已\n\n可是你偏又这样，在我不知不觉中\n\n悄悄的消失，从我的世界里，没有音讯，剩下的只是回忆\n\n&nbsp;\n\n你存在，我深深的脑海里，我的梦里，我的心里，我的歌声里\n\n你存在，我深深的脑海里，我的梦里，我的心里，我的歌声里\n\n&nbsp;\n\n还记得我们曾经，肩并肩一起走过，那段繁华巷口\n\n尽管你我是陌生人，是过路人，但彼此还是感觉到了对方的\n\n一个眼神，一个心跳....\n\n一种意想不到的快乐，好像是\n\n一场梦境，命中注定\n\n&nbsp;\n\n你存在，我深深的脑海里，我的梦里，我的心里，我的歌声里\n\n你存在，我深深的脑海里，我的梦里，我的心里，我的歌声里\n\n&nbsp;\n\n世界之大为何我们相遇\n\n难道是缘分\n\n难道是天意...\n\n&nbsp;\n\n你存在，我深深的脑海里，我的梦里，我的心里，我的歌声里\n\n你存在，我深深的脑海里，我的梦里，我的心里，我的歌声里\n\n你存在，我深深的脑海里，我的梦里，我的心里，我的歌声里\n\n<object classid=\"clsid:d27cdb6e-ae6d-11cf-96b8-444553540000\" width=\"100\" height=\"50\" codebase=\"http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0\"><param name=\"src\" value=\"http://www.directcurrentmusic.com/storage/mp3s-12/Wanting%20-%20You%20Exist%20In%20My%20Song.mp3\" /><embed type=\"application/x-shockwave-flash\" width=\"100\" height=\"50\" src=\"http://www.directcurrentmusic.com/storage/mp3s-12/Wanting%20-%20You%20Exist%20In%20My%20Song.mp3\"></embed></object>","source":"_posts/wanting-qu.md","raw":"title: 我的歌声里\ntags:\n  - 歌词\n  - 音乐\nid: 135\ncategories:\n  - 生活分享\ndate: 2011-04-05 10:34:36\n---\n\n没有一点点防备，也没有一丝顾虑\n\n你就这样出现在我的世界里，带给我惊喜，情不自已\n\n可是你偏又这样，在我不知不觉中\n\n悄悄的消失，从我的世界里，没有音讯，剩下的只是回忆\n\n&nbsp;\n\n你存在，我深深的脑海里，我的梦里，我的心里，我的歌声里\n\n你存在，我深深的脑海里，我的梦里，我的心里，我的歌声里\n\n&nbsp;\n\n还记得我们曾经，肩并肩一起走过，那段繁华巷口\n\n尽管你我是陌生人，是过路人，但彼此还是感觉到了对方的\n\n一个眼神，一个心跳....\n\n一种意想不到的快乐，好像是\n\n一场梦境，命中注定\n\n&nbsp;\n\n你存在，我深深的脑海里，我的梦里，我的心里，我的歌声里\n\n你存在，我深深的脑海里，我的梦里，我的心里，我的歌声里\n\n&nbsp;\n\n世界之大为何我们相遇\n\n难道是缘分\n\n难道是天意...\n\n&nbsp;\n\n你存在，我深深的脑海里，我的梦里，我的心里，我的歌声里\n\n你存在，我深深的脑海里，我的梦里，我的心里，我的歌声里\n\n你存在，我深深的脑海里，我的梦里，我的心里，我的歌声里\n\n<object classid=\"clsid:d27cdb6e-ae6d-11cf-96b8-444553540000\" width=\"100\" height=\"50\" codebase=\"http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0\"><param name=\"src\" value=\"http://www.directcurrentmusic.com/storage/mp3s-12/Wanting%20-%20You%20Exist%20In%20My%20Song.mp3\" /><embed type=\"application/x-shockwave-flash\" width=\"100\" height=\"50\" src=\"http://www.directcurrentmusic.com/storage/mp3s-12/Wanting%20-%20You%20Exist%20In%20My%20Song.mp3\"></embed></object>","slug":"wanting-qu","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg620o000hsb8fdkgqpsgk"},{"title":"谣言的“是”","id":"61","date":"2011-02-11T05:14:39.000Z","_content":"\n很多朋友都喜欢讨论星座、“伪”科学、恶搞生活等等关于评论个人性格的东东，似乎也还是有那么点靠谱了。\n\n“以自我感受、不怕旁人眼光的骄傲的狮子。”这是昨天一朋友发给我的。前天LL同学也说过差不多这样的话：“骄傲的狮子，除了自己啥都不会信。”还是比较准确的。骄傲的我，不相信任何非“权威”人士、书籍或者自己验证过的事情。\n\n有朋友说我这是批判主义，有进步意义。在我看来，部分意义上进步吧，我也明白，对于生活，这样的“主义”会缺少很多很多的乐趣。理性（抑或是固执）固然好，但是缺少感性却是那么的无力。突然好想发现我偏题了，此处省略230个字……\n\n<!--more-->回到主题，最近喜欢看一个网站——[**果壳网（Guokr.com）**](http://www.guokr.com)，它的主题是：科技、志趣、生活。很理性的一个网站，都是实验党人士。[**果壳**](http://www.guokr.com)有很多很多个主题站，我喜欢里面的[**谣言粉碎机**](http://www.guokr.com/site/fact/)。站如其名，它会将网上一个个谣言从科学实验、理论的角度一一粉碎。但是，他粉碎的谣言多半都是我也深信不疑的，不深信也半信了。例举几个：\n> [**毛发会越剃越浓，越硬，越黑吗？**](http://www.guokr.com/article/598/) 不会！\r> \n> \n> [**洗脸+仙人掌，防电脑辐射？**](http://www.guokr.com/article/598/) 不会！\r> \n> \n> **[唤醒梦游者会至呆傻？](http://www.guokr.com/article/701/) **不会！\r> \n> \n> [**可乐会杀精？**](http://www.guokr.com/article/1079/) 无理论支持！\n很多我平常看似正确的，科学验证起来就错误了。其实，多了以上的“错误”，生活上人们会有更多更多的谈资，更多更多的关心，更多更多的温暖。尽管知道了是假的，还是先将错就错，让我更为感性吧……","source":"_posts/truth-in-rumor.md","raw":"title: 谣言的“是”\ntags:\n  - 生活\nid: 61\ncategories:\n  - 生活分享\ndate: 2011-02-11 13:14:39\n---\n\n很多朋友都喜欢讨论星座、“伪”科学、恶搞生活等等关于评论个人性格的东东，似乎也还是有那么点靠谱了。\n\n“以自我感受、不怕旁人眼光的骄傲的狮子。”这是昨天一朋友发给我的。前天LL同学也说过差不多这样的话：“骄傲的狮子，除了自己啥都不会信。”还是比较准确的。骄傲的我，不相信任何非“权威”人士、书籍或者自己验证过的事情。\n\n有朋友说我这是批判主义，有进步意义。在我看来，部分意义上进步吧，我也明白，对于生活，这样的“主义”会缺少很多很多的乐趣。理性（抑或是固执）固然好，但是缺少感性却是那么的无力。突然好想发现我偏题了，此处省略230个字……\n\n<!--more-->回到主题，最近喜欢看一个网站——[**果壳网（Guokr.com）**](http://www.guokr.com)，它的主题是：科技、志趣、生活。很理性的一个网站，都是实验党人士。[**果壳**](http://www.guokr.com)有很多很多个主题站，我喜欢里面的[**谣言粉碎机**](http://www.guokr.com/site/fact/)。站如其名，它会将网上一个个谣言从科学实验、理论的角度一一粉碎。但是，他粉碎的谣言多半都是我也深信不疑的，不深信也半信了。例举几个：\n> [**毛发会越剃越浓，越硬，越黑吗？**](http://www.guokr.com/article/598/) 不会！\r> \n> \n> [**洗脸+仙人掌，防电脑辐射？**](http://www.guokr.com/article/598/) 不会！\r> \n> \n> **[唤醒梦游者会至呆傻？](http://www.guokr.com/article/701/) **不会！\r> \n> \n> [**可乐会杀精？**](http://www.guokr.com/article/1079/) 无理论支持！\n很多我平常看似正确的，科学验证起来就错误了。其实，多了以上的“错误”，生活上人们会有更多更多的谈资，更多更多的关心，更多更多的温暖。尽管知道了是假的，还是先将错就错，让我更为感性吧……","slug":"truth-in-rumor","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg620q000nsb8fup05cm9a"},{"title":"转 - NoSQL生态系统","id":"571","date":"2012-07-25T14:33:49.000Z","_content":"\n躺在床上看到这篇文章就有一种“垂死病中惊坐起”的感觉。忍不住就给转过来了，顺带附上HTML、PDF以及原版。转载自[**NoSQLFan**](http://blog.nosqlfan.com)，这网站最贱的一句话就是“**据**说看到好文章不转的人，服务器容易宕机！”，不过虽然贱，但是我喜欢……\n\n［[**HTML****版**](https://docs.google.com/document/pub?id=1NO__9thOb8V1mM3iQID3IUmwGh9wtra7xkpmvCZIvoU)］［**[PDF版](http://blog.nosqlfan.com/wp-content/uploads/2011/nosql_ecosystem.pdf)**］[ [**原版**](http://www.aosabook.org/en/nosql.html) ] [ [**转载处**](http://blog.nosqlfan.com/html/2171.html) ]\n\n<!--more-->\n\n**-----------------------------------****华丽丽分割线**-------------------------------------\n\n与本书中提到的其它主题不同，NoSQL不是一个工具，而是由一些具有互补性和竞争性的工具组成的一个概念，是一个生态圈。这些被称作NoSQL的工具，在存储数据的方式上，提供了一种与基于SQL语言的关系型数据截然不同的思路。要想了解NoSQL，我们必须先了解现有的这些工具，去理解那些让他们开拓出新的存储领域的设计思路。\n\n如果你正在考虑使用NoSQL，你应该会马上发现你有很多种选择。NoSQL系统舍弃了许了传统关系型数据库的方便之处，而把一些通常由关系型数据库本身来完成的任务交给了应用层来完成。这需要开发人员更深入的去了解存储系统的架构和具体实现。 \n\n**13.1 NoSQL****其名**\n\n在给NoSQL下定义之前，我们先来试着从它的名字上做一下解读，顾名思义，NoSQL系统的数据操作接口应该是非SQL类型的。但在NoSQL社区，NoSQL被赋予了更具有包容性的含义，其意为Not Only SQL，即NoSQL提供了一种与传统关系型数据库不太一样的存储模式，这为开发者提供了在关系型数据库之外的另一种选择。有时候你可能会完全用NoSQL数据库代替关系型数据加，但你也可以同时使用关系型和非关系型存储来解决具体的问题。\n\n在进入NoSQL的大门之前，我们先来看看哪些场景下使用关系型数据库更合适，哪些使用NoSQL更合适。\n\n**13.1.1 SQL****及其关联型结构**\n\nSQL是一种任务描述性的查询语言，所谓任务描述性的查询语言，就是说它只描述他需要系统做什么，而不告诉系统如何去做。例如：查出39号员工的信息，查出员工的名字和电话，只查找做会计工作的员工信息，计算出每个部门的员工总数，或者是对员工表和经理表做一个联合查询。\n\n简单的说，SQL让我们可以直接向数据库提出上述问题而不必考虑数据是如何在磁盘上存储的，使用哪些索引来查询数据，或者说用哪种算法来处理数据。在关系型数据库中有一个重要的组件，叫做查询优化器，正是它来推算用哪种操作方式能够更快的完成操作。查询优化器通常比一般的数据库用户更聪明，但是有时候由于没有充足的信息或者系统模型过于简单，也会导致查询优化器不能得出最有效的操作方式。\n\n作为目前应用最广的数据库系统，关系型数据库系统以其关联型的数据模型而命名。在关联型的数据模型中，在现实世界中的不同类型的个体被存储在不同的表里。比如有一个专门存员工的员工表，有一个专门存部门的部门表。每一行数据又包含多个列，比如员工表里可能包含了员工号，员工工资，生日以及姓名等，这些信息项被存在员工表中的某一列中。\n\n关联型的模型与SQL是紧密想连的。简单的查询操作，比如查询符合某个条件的所有行（例：employeeid = 3, 或者 salary &gt; $20000）。更复杂一些的任务会让数据库做一些额外的工作，比如跨表的联合查询（例：查出3号员的部门名称是什么）。一些复杂的查询，比如统计操作（例：算出所有员工的平均工资），甚至可能会导致全表扫描。\n\n关联型的数据模型定义了高度结构化的数据结构，以及对这些结构之间关系的严格定义。在这样的数据模型上执行的查询操作会比较局限，而且可能会导致复杂的数据遍历操作。数据结构的复杂性及查询的复杂性，会导致系统产生如下的一些限制：\n\n*   复杂导致不确定性。使用SQL的一个问题就是计算某个查询的代价或者产生的负载几乎是不可能的。使用简单的查询语言可能会导致应用层的逻辑更复杂，但是这样可以将存储系统的工作简单化，让它只需要响应一些简单的请求。*   对一个问题建模有很多种方式。其中关联型的数据模型是非常严格的一种：表结构的定义规定了表中每一行数据的存储内容。如果你的数据结构化并没有那么强，或者对每一行数据的要求比较灵活，那可能关联型的数据模型就太过严格了。类似的，应用层的开发人员可能对关联型的数据结构并不满意。比如很多应用程序是用面向对象的语言写的，数据在这些语言中通常是以列表、队列或集合的形式组织的，程序员们当然希望他们的数据存储层也能和应用层的数据模型一致。*   当数据量增长到一台机器已经不能容纳，我们需要将不同的数据表分布到不同的机器。而为了避免在不同机器上的数据表在进行联合查询时需要跨网络进行。我们必须进行反范式的数据库设计，这种设计方式要求我们把需要一次性查询到的数据存储在一起。这样做使得我们的系统变得就像一个主键查询系统一样，于是我们开始思考，是否有其它更适合我们数据的数据模型。  \n\n通常来说，舍弃多年以来的设计思路是不明智的。当你要把数据存到数据库，当考虑到SQL与关联型的数据模型，这些都是数十年的研究的开发成果，提供丰富的数据模型，提供复杂操作的保证。而当你的问题涉及到大数据量，高负载或者说你的数据结构在SQL与关联型数据模型下很难得到优化，NoSQL可能是更好的选择。\n\n**13.1.2 NoSQL****的启示**\n\nNoSQL运动受到了很多相关研究论文的启示，这所有论文中，最核心的有两个。\n\nGoogle的BigTable[[CDG+06](http://www.aosabook.org/en/bibliography.html#bib:bigtable)]提出了一种很有趣的数据模型，它将各列数据进行排序存储。数据值按范围分布在多台机器，数据更新操作有严格的一致性保证。\n\nAmazon的Dynamo[[DHJ+07](http://www.aosabook.org/en/bibliography.html#bib:amazon:dynamo)]使用的是另外一种分布式模型。Dynamo的模型更简单，它将数据按key进行hash存储。其数据分片模型有比较强的容灾性，因此它实现的是相对松散的弱一致性：最终一致性。\n\n接下来我们会深入介绍这些设计思想，而实际上在现实中这些思想经常是混搭使用的。比如像HBase及其它一些NoSQL系统他们在设计上更接受BigTable的模型，而像Voldemort 系统它就和Dynamo更像。同时还有像Cassandra这种两种特性都具备的实现（它的数据模型和BigTable类似，分片策略和一致性机制和Dynamo类似）。\n\n**13.1.3 ****特性概述**\n\nNoSQL系统舍弃了一些SQL标准中的功能，取而代之的是提供了一些简单灵活的功能。NoSQL 的构建思想就是尽量简化数据操作，尽量让执行操作的效率可预知。在很多NoSQL系统里，复杂的操作都是留给应用层来做的，这样的结果就是我们对数据层进行的操作得到简化，让操作效率可预知。\n\nNoSQL系统不仅舍弃了很多关系数据库中的操作。它还可能不具备关系数据库以下的一些特性：比如通常银行系统中要求的事务保证，一致性保证以及数据可靠性的保证等。事务机制提供了在执行多个命令时的all-or-nothing保证。一致性保证了如果一个数据更新后，那么在其之后的操作中都能看到这个更新。可靠性保证如果一个数据被更新，它就会被写到持久化的存储设备上（比如说磁盘），并且保证在数据库崩溃后数据可恢复。\n\n通过放宽对上述几点特性的要求，NoSQL系统可以为一些非银行类的业务提供以性能换稳定的策略。而同时，对这几点要求的放宽，又使得NoSQL系统能够轻松的实现分片策略，将远远超出单机容量的大量数据分布在多台机器上的。\n\n由于NoSQL系统还处在萌芽阶段，本章中提到的很多NoSQL架构都是用于满足各种不同用户的需求的。对这些架构进行总结不太可能，因为它们总在变化。所以希望你能记住的一点是，不同的NoSQL系统的特点是不同的，通过本章的内容，希望你能该根据自己的业务情况来选择合适的NoSQL系统，而本章内容不可能给你直接的答案。\n\n当你去考查一个NoSQL系统的时候，下面的的几点是值得注意的：\n\n*   数据模型及操作模型：你的应用层数据模型是行、对象还是文档型的呢？这个系统是否能支持你进行一些统计工作呢？*   可靠性：当你更新数据时，新的数据是否立刻写到持久化存储中去了？新的数据是否同步到多台机器上了？*   扩展性：你的数据量有多大，单机是否能容下？你的读写量求单机是否能支持？*   分区策略：考虑到你对扩展性，可用性或者持久性的要求，你是否需要一份数据被存在多台机器上？你是否需要知道数据在哪台机器上，以及你能否知道。*   一致性：你的数据是否被复制到了多台机器上，这些分布在不同点的数据如何保证一致性？*   事务机制：你的业务是否需要ACID的事务机制？*   单机性能：如果你打算持久化的将数据存在磁盘上，哪种数据结构能满足你的需求（你的需求是读多还是写多）？写操作是否会成为磁盘瓶颈？*   负载可评估：对于一个读多写少的应用，诸如响应用户请求的web应用，我们总会花很多精力来关注负载情况。你可能需要进行数据规模的监控，对多个用户的数据进行汇总统计。你的应用场景是否需要这样的功能呢？  \n\n尽管后三点在本章没有独立的小节进行描述，但它们和其它几点一样重要，下面就让我们对以上的几点进行阐述。\n\n**13.2 NoSQL****数据模型及操作模型**\n\n数据库的数据模型指的是数据在数据库中的组织方式，数据库的操作模型指的是存取这些数据的方式。通常数据模型包括关系模型、键值模型以及各种图结构模型。的操作语言可能包括SQL、键值查询及MapReduce等。NoSQL通常结合了多种数据模型和操作模型，提供了不一样的架构方式。\n\n**13.2.1 ****基于key值存储的NoSQL数据模型**\n\n在键值型系统中，复杂的联合操作以及满足多个条件的取数据操作就不那么容易了，需要我们创造性的建立和使用键名。如果一个程序员既想通过员工号查到员工信息，又想通过部门号查到员工信息，那么他必须建立两种类型的键值对。例如 emplyee:30 这个键用于指向员工号为30的员工信息。employee_departments:20 可能用到指向一个包含在20号部门工作的所有员工工号的列表。这样数据库中的联合操作就被转换成业务层的逻辑了：要获取部门号为20的所有员工的信息，应用层可以先获取employee_departments:20 这个列表，然后再循环地拿这个列表中的ID通过获取employee:ID得到所有员工的信息。\n\n键值查找的一个好处是，对数据库的操作模式是固定的，这些操作所产生的负载也是相对固定且可预知的。这样像分析整个应用中的性能瓶颈这种事，就变得简单多了。因为复杂的逻辑操作并不是放在数据库里面黑箱操作了。不过这样做之后，业务逻辑和数据逻辑可能就没那么容易分清了。\n\n下面我们快速地把各种键值模型的数据结构简单描述一下。看看不同的NoSQL系统的在这方面的不同实现方式。\n\n**Key-Value ****存储**\n\nKey-Value存储可以说是最简单的NoSQL存储。每个key值对应一个任意的数据值。对NoSQL 系统来说，这个任意的数据值是什么，它并不关心。比如在员工信念数据库里，exployee:30 这个key对应的可能就是一段包含员工所有信息的二进制数据。这个二进制的格式可能是[Protocol Buffer](http://code.google.com/p/protobuf/)、[Thrift](http://thrift.apache.org/)或者[Avro](http://avro.apache.org/)都无所谓。\n\n如果你使用上面说的Key-Value存储来保存你的结构化数据，那么你就得在应用层来处理具体的数据结构：单纯的Key-Value存储是不提供针对数据中特定的某个属性值来进行操作。通常它只提供像set、get和delete这样的操作。以Dynamo为原型的Voldemort数据库，就只提供了分布式的Key-Value存储功能。BDB 是一个提供Key-Value操作的持久化数据存储引擎。\n\n**Key ****– 结构化数据 存储**\n\nKey对应结构化数据存储，其典型代表是Redis，Redis将Key-Value存储的Value变成了结构化的数据类型。Value的类型包括数字、字符串、列表、集合以及有序集合。除了set/get/delete 操作以为，Redis还提供了很多针对以上数据类型的特殊操作，比如针对数字可以执行增、减操作，对list可以执行 push/pop 操作，而这些对特定数据类型的特定操作并没有对性能造成多大的影响。通过提供这种针对单个Value进行的特定类型的操作，Redis可以说实现了功能与性能的平衡。\n\n**Key ****– 文档 存储**\n\nKey – 文档存储的代表有CouchDB、MongoDB和Riak。这种存储方式下Key-Value的Value是结构化的文档，通常这些文档是被转换成JSON或者类似于JSON的结构进行存储。文档可以存储列表，键值对以及层次结构复杂的文档。\n\nMongoDB 将Key按业务分到各个collection里，这样以collection作为命名空间，员工信息和部门信息的Key就被隔开了。CouchDB和Riak把类型跟踪这种事留给了开发者去完成。文档型存储的灵活性和复杂性是一把双刃剑：一方面，开发者可以任意组织文档的结构，另一方面，应用层的查询需求会变得比较复杂。\n\n**BigTable ****的列簇式存储**\n\nHBase和Cassandra的数据模型都借鉴自Google 的BigTable。这种数据模型的特点是列式存储，每一行数据的各项被存储在不同的列中（这些列的集合称作列簇）。而每一列中每一个数据都包含一个时间戳属性，这样列中的同一个数据项的多个版本都能保存下来。\n\n列式存储可以理解成这样，将行ID、列簇号，列号以及时间戳一起，组成一个Key，然后将Value按Key的顺序进行存储。Key值的结构化使这种数据结构能够实现一些特别的功能。最常用的就是将一个数据的多个版本存成时间戳不同的几个值，这样就能很方便的保存历史数据。这种结构也能天然地进行高效的松散列数据（在很多行中并没有某列的数据）存储。当然，另一方面，对于那些很少有某一行有NULL值的列，由于每一个数据必须包含列标识，这又会造成空间的浪费。\n\n这些NoSQL系统对BigTable数据模型的实现多少有些差别，这其中以Cassandra进行的变更最为显著。Cassandra引入了超级列（supercolumn）的概念，通过将列组织到相应的超级列中，可以在更高层级上进行数据的组织，索引等。这一做法也取代了locality groups的概念（这一概念的实现可以让相关的几个行的数据存储在一起，以提高存取性能）。\n\n**13.2.2 ****图结构存储**\n\n图结构存储是NoSQL的另一种存储实现。图结构存储的一个指导思想是：数据并非对等的，关系型的存储或者键值对的存储，可能都不是最好的存储方式。图结构是计算机科学的基础结构之一，Neo4j和HyperGraphDB是当前最流行的图结构数据库。图结构的存储与我们之前讨论过的几种存储方式很不同，这种不同几乎体现在每一个方面，包括：数据模型、数据查询方式、数据在磁盘上的组织方式、在多个结点上的分布方式，甚至包括对事务机制的实现等等。由于篇幅的限制，对这些方面我们暂时不做深入的讨论，这里需要你了解的是，某些数据结构使用图结构的数据库进行存储可能会更好。\n\n**13.2.3 ****复杂查询**\n\n在NoSQL存储系统中，有很多比键值查找更复杂的操作。比如MongoDB可以在任意数据行上建立索引，可以使用Javascript语法设定复杂的查询条件。BigTable型的系统通常支持对单独某一行的数据进行遍历，允许对单列的数据进行按特定条件地筛选。CouchDB允许你创建同一份数据的多个视图，通过运行MapReduce任务来实现一些更为复杂的查询或者更新操作。很多NoSQL系统都支持与Hadoop或者其它一些MapReduce框架结合来进行一些大规模数据分析工作。\n\n**13.2.4 ****事务机制**\n\n传统的关系型数据库在功能支持上通常很宽泛，从简单的键值查询，到复杂的多表联合查询再到事务机制的支持。而与之不同的是，NoSQL系统通常注重性能和扩展性，而非事务机制。\n\n传统的SQL数据库的事务通常都是支持ACID的强事务机制。A代表原子性，即在事务中执行多个操作是原子性的，要么事务中的操作全部执行，要么一个都不执行;C代表一致性，即保证进行事务的过程中整个数据加的状态是一致的，不会出现数据花掉的情况;I代表隔离性，即两个事务不会相互影响，覆盖彼此数据等;D表示持久化，即事务一量完成，那么数据应该是被写到安全的，持久化存储的设备上（比如磁盘）。\n\nACID的支持使得应用者能够很清楚他们当前的数据状态。即使如对于多个事务同时执行的情况下也能够保证数据状态的正常性。但是如果要保证数据的一致性，通常多个事务是不可能交叉执行的，这样就导致了可能一个很简单的操作需要等等一个复杂操作完成才能进行的情况。\n\n对很多NoSQL系统来说，对性能的考虑远在ACID的保证之上。通常NoSQL系统仅提供对行级别的原子性保证，也就是说同时对同一个Key下的数据进行的两个操作，在实际执行的时候是会串行的执行，保证了每一个Key-Value对不会被破坏。对绝大多数应用场景来说，这样的保证并不会引起多大的问题，但其换来的执行效率却是非常可观的。当然，使用这样的系统可能需要我们在应用层的设计上多做容错性和修正机制的考虑。\n\n在NoSQL中，Redis在事务支持这方面上不太一样，它提供了一个MULTI命令用来将多个命令进行组合式的操作，通过一个WATCH命令提供操作隔离性。这和其它一些提供test-and-set这样的低层级的隔离机制类似。\n\n**13.2.5 Schema-free****的存储**\n\n还有一个很多NoSQL都有的共同点，就是它通常并没有强制的数据结构约束。即使是在文档型存储或者列式存储上，也不会要求某一个数据列在每一行数据上都必须存在。这在非结构化数据的存储上更方便，同时也省去了修改表结构的代价。而这一机制对应用层的容错性要求可能会更高。比如程序可能得确定如果某一个员工的信息里缺少lastname这一项，是否算是错误。或者说某个表结构的变更是否对所有数据行起了作用。还有一个问题，就是数据库的表结构可能会因为项目的多次迭代而变得混乱不堪。\n\n**13.3 ****数据可靠性**\n\n最理想状态是，数据库会把所有写操作立刻写到持久化存储的设备，同时复制多个副本到不同地理位置的不同节点上以防止数据丢失。但是这种对数据安全性的要求对性能是有影响的，所以不同的NoSQL系统在自身性能的考虑下，在数据安全上采取了不太一样的策略。\n\n一种典型的出错情况是重启机器或者机器断电了，这时候需要让数据从内存转存到磁盘才能保证数据的安全性，因为磁盘数据不会因断电而丢失。而要避免磁盘损坏这种故障，就需要将数据冗余的存在其它磁盘上，比如使用RAID来做镜像，或者将数据同步到不同机器。但是有些时候针对同一个数据中心来说，是不可能做到完全的数据安全的，比如一旦发生飓风地震这种天灾，整个机房机器可能都会损坏，所以，在这种情况下要保证数据的安全性，就必须将数据备份存储到其它地理位置上比较远的数据中心。所以，具体各个NoSQL系统在数据安全性和性能上的权衡策略也不太一样。\n\n**13.3.1 ****单机可靠性**\n\n单机可靠性理解起来非常简单，它的定义是写操作不会由于机器重启或者断电而丢失。通常单机可靠性的保证是通过把数据写到磁盘来完成的，而这通常会造成磁盘IO成为整个系统的瓶颈。而事实上，即使你的程序每次都把数据写到了磁盘，实际上由于操作系统buffer层的存在，数据还是不会立刻被写到物理磁盘上，只有当你调用fsync这个系统调用的时候，操作系统才会尽可能的把数据写到磁盘。\n\n一般的磁盘大概能进行每秒100-200次的随机访问，每秒30-100MB的顺序写入速度。而内存在这两方面的性能都有数量级上的提升。通过尽量减少随机写，取而代之的对每个磁盘设备进行顺序写，这样能够减少单机可靠性保证的代价。也就是说我们需要减少在两次fsync调用之间的写操作次数，而增加顺序写操作的数量。下面我们说一下一些在单机可靠性的保证下提高性能的方法。\n\n**控制fsync的调用频率**\n\nMemcached是一个纯内存的存储，由于其不进行磁盘上的持久化存储，从而换来了很高的性能。当然，在我们进行服务器重启或者服务器意外断电后，这些数据就全丢了。因此Memcached 是一个非常不错的缓存，但是做不了持久化存储。\n\nRedis则提供了几种对fsync调用频率的控制方法。应用开发者可以配置Redis在每次更新操作后都执行一次fsync，这样会比较安全，当然也就比较慢。Redis也可以设置成N秒种调用一次fsync，这样性能会更好一点。但这样的后果就是一旦出现故障，最多可能导致N秒内的数据丢失。而对一些可靠性要求不太高的场合（比如仅仅把Redis当Cache用的时候），应用开发者甚至可以直接关掉fsync的调用：让操作系统来决定什么时候需要把数据flush到磁盘。   \n（译者：这只是Redis append only file的机制，Redis是可以关闭aof日志的，另外请注意：Redis 本身支持将内存中数据dump成rdb文件的机制，和上面说的不是一回事。）\n\n**使用日志型的数据结构**\n\n像B+ 树这样的一些数据结构，使得NoSQL系统能够快速的定位到磁盘上的数据，但是通常这些数据结构的更新操作是随机写操作，如果你在每次操作后再调用一次fsync，那就会造成频繁的磁盘随机访问了。为了避免产生这样的问题，像Cassandra、HBase、Redis和Riak都会把写操作顺序的写入到一个日志文件中。相对于存储系统中的其它数据结构，上面说到的日志文件可以频繁的进行fsync操作。这个日志文件记录了操作行为，可以用于在出现故障后恢复丢失那段时间的数据，这样就把随机写变成顺序写了。\n\n虽然有的NoSQL系统，比如MongoDB，是直接在原数据上进行更新操作的，但也有许多NoSQL系统是采用了上面说到的日志策略。Cassandra和HBase借鉴了BigTable的做法，在数据结构上实现了一个日志型的查找树。Riak也使用了类似的方法实现了一个日志型的hash表（译者：也就是Riak的[BitCask](http://downloads.basho.com/papers/bitcask-intro.pdf)模型）。CouchDB对传统的B+树结构进行了修改，使得对树的更新可以使用顺序的追加写操作来实现（译者：这种B+树被称作[append-only B-Tree](http://jchrisa.net/drl/nosql-oakland/btree-nosql-oak.pdf)）。这些方法的使用，使得存储系统的写操作承载力更高，但同时为了防止数据异构后膨胀得过大，需要定时进行一些合并操作。\n\n**通过合并写操作提高吞吐性能**\n\nCassandra有一个机制，它会把一小段时间内的几个并发的写操作放在一起进行一次fsync调用。这种做法叫group commit，它导致的一个结果就是更新操作的返回时间可能会变长，因为一个更新操作需要等就近的几个更新操作一起进行提交。这样做的好处是能够提高写操作承载力。作为HBase底层数据支持的Hadoop 分布式文件系统HDFS，它最近的一些补丁也在实现一些顺序写和group commit的机制。\n\n**13.3.2 ****多机可靠性**\n\n由于硬件层面有时候会造成无法恢复的损坏，单机可靠性的保证在这方面就鞭长莫及了。对于一些重要数据，跨机器做备份保存是必备的安全措施。一些NoSQL系统提供了多机可靠性的支持。\n\nRedis采用了传统的主从数据同步的方式。所有在master上执行的操作，都会通过类似于操作日志的结构顺序地传递给slave上再执行一遍。如果master发生宕机等事故，slave可以继续执行完master传来的操作日志并且成为新的master。可能这中间会导致一些数据丢失，因为master同步操作到slave是非阻塞的，master并不知道操作是否已经同步线slave了。CouchDB 实现了一个类似的指向性的同步功能，它使得一个写操作可以同步到其它节点上。\n\nMongoDB提供了一个叫Replica Sets的架构方制，这个架构策略使得每一个文档都会保存在组成Replica Sets的所有机器上。MongoDB提供了一些选项，让开发者可以确定一个写操作是否已经同步到了所有节点上，也可以在节点数据并不是最新的情况下执行一些操作。很多其它的分布式NoSQL存储都提供了类似的多机可靠性支持。由于HBase的底层存储是HDFS，它也就自然的获得了HDFS提供的多机可靠性保证。HDFS的多机可靠性保证是通过把每个写操作都同步到两个以上的节点来实现的。\n\nRiak、Cassandra和Voldemort提供了一些更灵活的可配置策略。这三个系统提供一个可配置的参数N，代表每一个数据会被备份的份数，然后还可以配置一个参数W，代表每个写操作需要同步到多少能机器上才返回成功。当然W是小于N的。\n\n为了应对整个数据中心出现故障的情况，需要实现跨数据中心的多机备份功能。Cassandra、HBase和Voldemort都实现了一个机架位置可知的配置，这种配置方式使得整个分布式系统可以了解各个节点的地理位置分布情况。如果一个操作需要等待另外的数据中心的同步操作成功才返回给用户，那时间就太长了，所以通常跨数据中心的同步备份操作都是异步进行的。用户并不需要等待另一个数据中心同步的同步操作执行成功。\n\n**13.4 ****横向扩展带来性能提升**\n\n上面我们讨论了对出错情况的处理，下面我们讨论另一种情况：成功！如果数据存储操作成功执行了，那么你的系统就要负责对这些数据进行处理。就要承担数据带来的负载。一个比较粗暴的解决方法是通过升级你的机器来提升单机性能：通过加大内存和添加硬盘来应对越来越大的负载。但是随着数据量的增大，投入在升级机器上的钱将将不会产生原来那么大的效果。这时候你就必须考虑把数据同步到不同的机器上，利用横向扩展来分担访问压力。\n\n横向扩展的目标是达到线性的效果，即如果你增加一倍的机器，那么负载能力应该也能相应的增加一倍。其主要需要解决的问题是如何让数据在多台机器间分布。数据分片技术实际上就是将对数据和读写请求在多个机器节点上进行分配的技术，分片技术在很多NoSQL系统中都有实现，比如Cassandra、HBase、Voldemort和Riak等等，最近MongoDB和Redis也在做相应的实现。而有的项目并不提供内置的分片支持，比如CouchDB更加注重单机性能的提升。对于这些项目，通常我们可以借助一些其它的技术在上层来进行负载分配。\n\n下面让我们来整理一些通用的概念。对于数据分片和分区，我们可以做同样的理解。对机器，服务器或者节点，我们可以统一的理解成物理上的存储数据的机器。最后，集群或者机器环都可以理解成为是组成你存储系统的集合。\n\n分片的意思是，没有任何一台机器可以处理所有写请求，也没有任何一台机器可以处理对所有数据的读请求。很多NoSQL系统都是基于键值模型的，因此其查询条件也基本上是基于键值的查询，基本不会有对整个数据进行查询的时候。由于基本上所有的查询操作都是基本键值形式的，因此分片通常也基于数据的键来做：键的一些属性会决定这个键值对存储在哪台机器上。下面我们将会对hash分片和范围分片两种分片方式进行描述。\n\n**13.4.1 ****如非必要，请勿分片**\n\n分片会导致系统复杂程序大增，所以，如果没有必要，请不要使用分片。下面我们先讲两种不用分片就能让系统具有扩展性的方法。\n\n**读写分离**\n\n大多数应用场景都是读多写少的场景。所以在这种情况下，可以用一个简单的方法来分担负载，就是把数据同步到多台机器上。这时候写请求还是由master机器处理，而读请求则可以分担给那些同步到数据的机器了。而同步数据的操作，通常是不会对master带来多大的压力的。\n\n如果你已经使用了主从配置，将数据同步到多台机器以提供高可靠性了，那么你的slave机器应该能够为master分担不少压力了。对有些实时性要求不是非常高的查询请求，比如一些统计操作，你完全可以放到slave上来执行。通常来说，你的应用对实时性要求越低，你的slave机器就能承担越多的任务。\n\n**使用缓存**\n\n将一些经常访问的数据放到缓存层中，通常会带来很好的效果。Memcached 主要的作用就是将数据层的数据进行分布式的缓存。Memcached 通过客户端的算法（译者： 常见的一致性hash算法）来实现横向扩展，这样当你想增大你缓存池的大小时，只需要添加一台新的缓存机器即可。\n\n由于Memcached仅仅是一个缓存存储，它并不具备一些持久存储的复杂特性。当你在考虑使用复杂的扩展方案时，希望你先考虑一下使用缓存来解决你的负载问题。注意，缓存并不是临时的处理方案：Facebook 就部署了总容量达到几十TB的Memcahced内存池。\n\n通过读写分离和构建有效的缓存层，通常可以大大分担系统的读负载，但是当你的写请求越来越频繁的时候，你的master机器还是会承受越来越大的压力。对于这种情况，我们可能就要用到下面说到的数据分片技术了。\n\n**13.4.2 ****通过协调器进行数据分片**\n\n由于CouchDB专注于单机性能，没有提供类似的横向扩展方案，于是出现了两个项目：Lounge 和 BigCouch，他们通过提供一个proxy层来对CouchDB中的数据进行分片。在这种架构中，proxy作为CouchDB集群的前端机器，接受和分配请求到后端的多台CouchDB上。后端的CouchDB 之间并没有交互。协调器会将按操作的key值将请求分配到下层的具体某台机器。\n\nTwitter 自己实现了一个叫Gizzard的协调器，可以实现数据分片和备份功能。Gizzard不关心数据类型，它使用树结构来存储数据范围标识，你可以用它来对SQL或者NoSQL系统进行封装。通过对 Gizzard 进行配置，可以实现将特定范围内的数据进行冗余存储，以提高系统的容灾能力。\n\n**13.4.3 ****一致性hash环算法**\n\n好的hash算法可以使数据保持比较均匀的分布。这使得我们可以按这种分布将数据保存布多台机器上。一致性hash是一种被广泛应用的技术，其最早在一个叫distributed hash tables (DHTs)的系统中进行使用。那些类Dynamo的应用，比如Cassandra、Voldemort和Riak，基本上都使用了一致性hash算法。\n\n**Hash****环图**\n\n[![A-Distributed-Hash-Table-Ring](http://www.hongweiyi.com/wp-content/uploads/2012/07/ADistributedHashTableRing_thumb.png \"A-Distributed-Hash-Table-Ring\")](http://www.hongweiyi.com/wp-content/uploads/2012/07/ADistributedHashTableRing.png) \n\n一致性hash算法的工作原理如下：首先我们有一个hash函数H，可以通过数据的key值计算出一个数字型的hash值。然后我们将整个hash环的范围定义为［1，L］这个区间，我们将刚才算出的hash值对L进行取余，就能算出一个key值在这个环上的位置。而每一台真实服务器结点就会负责［1-L］之间的某个区间的数据。如上图，就是一个五个结点的hash环。\n\n上面hash环的L值为1000，然后我们对ABCDE 5个点分别进行hash运算，H(A) mod L = 7, H(B) mod L = 234, H(C) mod L = 447, H(D) mod L = 660, and H(E) mod L = 875 ，这样，hash值在7-233之间的所有数据，我们都让它保存在A节点上。在实际动作中，我们对数据进行hash，算出其应该在哪个节点存储即可，例：H(‘employee30′) mod L = 899 那么它应该在E节点上，H(‘employee31′) mod L = 234 那么这个数据应该在B节点上。\n\n**备份数据**\n\n一致性hash下的数据备份通常采用下面的方法：将数据冗余的存在其归属的节点的顺序往下的节点，例如你的冗余系数为3（即数据会在不同节点中保存三份），那么如果通过hash计算你的数据在A区间［7，233］，你的数据会被同时保存在A，B，C三个节点上。这样如果A节点出现故障，那么B，C节点就能处理这部分数据的请求了。而某些设计会使E节点将自己的范围扩大到A233，以接受对出故障的A节点的请求。\n\n**优化的数据分配策略**\n\n虽然hash算法能够产生相对均匀的hash值。而且通常是节点数量越多，hash算法会越平均的分配key值。然而通常在项目初期不会有太多的数据，当然也不需要那么多的机器节点，这时候就会造成数据分配不平均的问题。比如上面的5个节点，其中A节点需要负责的hash区间范围大小为227，而E节点负责的区间范围为132。同时在这种情况下，出故障后数据请求转移到相邻节点的策略也可能不好实施了。\n\n为了解决由于节点比较少导致数据分配不均的问题，很多DHT系统都实现了一种叫做虚拟节点的技术。例如4个虚拟节点的系统中，A节点可能被虚拟化成A_1，A_2，A_3，A_4这四个虚拟节点，然后对这四个虚拟节点再进行hash运算，A节点负责的key值区间就比较分散了。Voldemort 使用了与上面类似的策略，它允许对虚拟节点数进行配置，通常这个节点数会大于真实节点数，这样每个真实节点实际上是负责了N个虚拟节点上的数据。\n\nCassandra 并没有使用虚拟节点到真实节点映射的方法。这导致它的数据分配是不均匀的。为了解决这种不平衡，Cassandra 利用一个异步的进程根据各节点的历史负载情况来调节数据的分布。\n\n**13.4.4 ****连续范围分区**\n\n使用连续范围分区的方法进行数据分片，需要我们保存一份映射关系表，标明哪一段key值对应存在哪台机器上。和一致性hash类似，连续范围分区会把key值按连续的范围分段，每段数据会被指定保存在某个节点上，然后会被冗余备份到其它的节点。和一致性hash不同的是，连续范围分区使得key值上相邻的两个数据在存储上也基本上是在同一个数据段。这样数据路由表只需记录某段数据的开始和结束点［start，end］就可以了。\n\n通过动态调整数据段到机器结点的映射关系，可以更精确的平衡各节点机器负载。如果某个区段的数据负载比较大，那么负载控制器就可以通过缩短其所在节点负责的数据段，或者直接减少其负责的数据分片数目。通过添加这样一个监控和路由模块，使我们能够更好的对数据节点进行负载均衡。\n\n**BigTable****的处理方式**\n\nGoogle BigTable 论文中描述了一种范围分区方式，它将数据切分成一个个的tablet数据块。每个tablet保存一定数量的键值对。然后每个Tablet 服务器会存储多个tablet块，具体每个Tablet服务器保存的tablet数据块数，则是由服务器压力来决定的。\n\n每个tablet大概100-200MB大。如果tablet的尺寸变小，那么两个tablet可能会合并成一个tablet，同样的如果一个tablet过大，它也会被分裂成两个tablet，以保持每个tablet的大小在一定范围内。在整个系统中有一个master机器，会根据tablet的大小、负载情况以及机器的负载能力等因素动态地调整tablet在各个机器上的分布。\n\n[![BigTable-based-Range-Partitioning](http://www.hongweiyi.com/wp-content/uploads/2012/07/BigTablebasedRangePartitioning_thumb.png \"BigTable-based-Range-Partitioning\")](http://www.hongweiyi.com/wp-content/uploads/2012/07/BigTablebasedRangePartitioning.png)     \nmaster服务器会把 tablet 的归属关系存在元数据表里。当数据量非常大时，这个元数据表实际也会变得非常大，所以归属关系表实际上也是被切分成一个个的tablet保存在tablet服务器中的。这样整个数据存储就被分成了如上图的三层模型。\n\n下面我们解释一下上面图中的例子。当某个客户端要从BigTable系统中获取key值为900的数据时，首先他会到第一级元数据服务器A（METADATA0）去查询，第一级元数据服务器查询自己的元数据表，500-1500这个区间中的所有元数据都存在B服务器中，于是会返回客户端说去B服务器查询，客户端再到B服务器中进行查询，B服务器判断到850-950这个区间中的数据都存在tablet服务器C中，于是会告知客户端到具体的tablet服务器C去查询。然后客户端再发起一次向C服务器的请求，就能获取到900对应的数据了。然后，客户端会把这个查询结果进行缓存，以避免对元数据服务器的频繁请求。在这样的三层架构下，只需要128MB的元数据存储，就能定位234 个tablet数据块了（按128MB一个数据块算，是261bytes的数据）。\n\n**故障处理**\n\n在BigTable中，master机器是一个故障单点，不过系统可以容忍短时间的master故障。另一方面，如果tablet 服务器故障，那么master可以把对其上tablet的所有请求分配到其它机器节点。\n\n为了监测和处理节点故障，BigTable实现了一个叫Chubby的模块，Chubby是一个分布式的锁系统，用于管理集群成员及检测各成员是否存活。ZooKeeper是Chubby的一个开源实现，有很多基于 Hadoop 的项目都使用它来进行二级master和tablet节点的调度。\n\n**基于范围分区的NoSQL项目**\n\nHBase 借鉴了BigTable的分层理论来实现范围分区策略。tablet相关的数据存在HDFS里。HDFS 会处理数据的冗余备份，并负责保证各备份的一致性。而像处理数据请求，修改存储结构或者执行tablet的分裂和合并这种事，是具体的tablet服务器来负责的。\n\nMongoDB也用了类似于BigTable的方案来实现范围分区。他用几台配置机器组成集群来管理数据在节点上的分布。这几台机器保存着一样的配置信息，他们采用 two-phase commit 协议来保证数据的一致性。这些配置节点实际上同时扮演了BigTable中的master的路由角色，及Chubby 的高可用性调度器的角色。而MongoDB具体的数据存储节点是通过其Replica Sets方案来实现数据冗余备份的。\n\nCassandra 提供了一个有序的分区表，使你可以快速对数据进行范围查询。Cassandra也使用了一致性hash算法进行数据分配，但是不同的是，它不是直接按单条数据进行hash，而是对一段范围内的数据进行hash，也就是说20号数据和21号数据基本上会被分配在同一台机器节点上。\n\nTwitter的Gizzard框架也是通过使用范围分区来管理数据在多个节点间的备份与分配。路由服务器可以部署成多层，任何一层只负责对key值进行按范围的分配到下层的不同节点。也就是说路由服务器的下层既可以是真实的数据存储节点，也可能是下层的路由节点。Gizzard的数据备份机制是通过将写操作在多台机器上执行多次来实现的。Gizzard的路由节点处理失败的写操作的方式和其它NoSQL不太一样，他要求所有更新都是幂等的（意思是可以重复执行而不会出错）。于是当一个节点故障后，其上层的路由节点会把当前的写操作cache起来并且重复地让这个节点执行，直到其恢复正常。\n\n**13.4.5 ****选择哪种分区策略**\n\n上面我们说到了Hash分区和范围分区两种策略，哪种更好呢？这要看情况了，如果你需要经常做范围查询，需要按顺序对key值进行操作，那么你选择范围分区会比较好。因为如果选择hash分区的话，要查询一个范围的数据可能就需要跨好几个节点来进行了。\n\n那如果我不会进行范围查询或者顺序查询呢？这时候hash分区相对来说可能更方便一点，而且hash分区时可能通过虚拟结点的设置来解决hash不均的问题。在hash分区中，基本上只要在客户端执行相应的hash函数就能知道对应的数据存在哪个节点上了。而如果考虑到节点故障后的数据转移情况，可能获取到数据存放节点就会麻烦一些了。\n\n范围分区要求在查询数据前对配置节点还要进行一次查询，如果没有特别好的高可用容灾方案，配置节点将会是一个危险的故障单点。当然，你可以把配置节点再进行一层负载均衡来减轻负载。而范围分区时如果某个节点故障了，它上面的数据可以被分配到多个节点上，而不像在一致性hash时，只能迁移到其顺序的后一个节点，造成下一个节点的负载飙升。\n\n**13.5 ****一致性**\n\n上面我们讲到了通过将数据冗余存储到不同的节点来保证数据安全和减轻负载，下面我们来看看这样做引发的一个问题：保证数据在多个节点间的一致性是非常困难的。在实际应用中我们会遇到很多困难，同步节点可能会故障，甚至会无法恢复，网络可能会有延迟或者丢包，网络原因导致集群中的机器被分隔成两个不能互通的子域等等。在NoSQL中，通常有两个层次的一致性：第一种是强一致性，既集群中的所有机器状态同步保持一致。第二种是最终一致性，既可以允许短暂的数据不一致，但数据最终会保持一致。我们先来讲一下，在分布式集群中，为什么最终一致性通常是更合理的选择，然后再来讨论两种一致性的具体实现结节。\n\n**13.5.1 ****关于CAP理论**\n\n为什么我们会考虑削弱数据的一致性呢？其实这背后有一个关于分布式系统的理论依据。这个理论最早被 Eric Brewer 提出，称为CAP理论，尔后Gilbert 和 Lynch 对CAP进行了理论证明。这一理论首先把分布式系统中的三个特性进行了如下归纳：\n\n*   一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。*   可用性（A）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。*   分区容忍性（P）：集群中的某些节点在无法联系后，集群整体是否还能继续进行服务。  \n\n而CAP理论就是说在分布式存储系统中，最多只能实现上面的两点。而由于当前的网络硬件肯定会出现延迟丢包等问题，所以分区容忍性是我们必须需要实现的。所以我们只能在一致性和可用性之间进行权衡，没有NoSQL系统能同时保证这三点。\n\n要保证数据一致性，最简单的方法是令写操作在所有数据节点上都执行成功才能返回成功。而这时如果某个结点出现故障，那么写操作就成功不了了，需要一直等到这个节点恢复。也就是说，如果要保证强一致性，那么就无法提供7×24的高可用性。\n\n而要保证可用性的话，就意味着节点在响应请求时，不用完全考虑整个集群中的数据是否一致。只需要以自己当前的状态进行请求响应。由于并不保证写操作在所有节点都写成功，这可能会导致各个节点的数据状态不一致。\n\nCAP理论导致了最终一致性和强一致性两种选择。当然，事实上还有其它的选择，比如在Yahoo! 的PNUTS中，采用的就是松散的一致性和弱可用性结合的方法。但是我们讨论的NoSQL系统没有类似的实现，所以我们在后续不会对其进行讨论。\n\n**13.5.2 ****强一致性**\n\n强一致性的保证，要求所有数据节点对同一个key值在同一时刻有同样的value值。虽然实际上可能某些节点存储的值是不一样的，但是作为一个整体，当客户端发起对某个key的数据请求时，整个集群对这个key对应的数据会达成一致。下面就举例说明这种一致性是如何实现的。\n\n假设在我们的集群中，一个数据会被备份到N个结点。这N个节点中的某一个可能会扮演协调器的作用。它会保证每一个数据写操作会在成功同步到W个节点后才向客户端返回成功。而当客户端读取数据时，需要至少R个节点返回同样的数据才能返回读操作成功。而NWR之间必须要满足下面关系：R＋W&gt;N\n\n下面举个实在的例子。比如我们设定N＝3（数据会备份到A、B、C三个结点）。比如值 employee30:salary 当前的值是20000，我们想将其修改为30000。我们设定W＝2，下面我们会对A、B、C三个节点发起写操作（employee30:salary, 30000），当A、B两个节点返回写成功后，协调器就会返回给客户端说写成功了。至于节点C，我们可以假设它从来没有收到这个写请求，他保存的依然是20000那个值。之后，当一个协调器执行一个对employee30:salary的读操作时，他还是会发三个请求给A、B、C三个节点：\n\n*   如果设定R＝1，那么当C节点先返回了20000这个值时，那我们客户端实际得到了一个错误的值。*   如果设定R＝2，则当协调器收到20000和30000两个值时，它会发现数据不太正确，并且会在收到第三个节点的30000的值后判断20000这个值是错误的。  \n\n所以如果要保证强一致性，在上面的应用场景中，我们需要设定R＝2，W＝2\n\n如果写操作不能收到W个节点的成功返回，或者写操作不能得到R个一致的结果。那么协调器可能会在某个设定的过期时间之后向客户端返回操作失败，或者是等到系统慢慢调整到一致。这可能就导致系统暂时处于不可用状态。\n\n对于R和W的不同设定，会导致系统在进行不同操作时需要不同数量的机器节点可用。比如你设定在所有备份节点上都写入才算写成功，既W＝N，那么只要有一个备份节点故障，写操作就失败了。一般设定是R＋W = N+1，这是保证强一致性的最小设定了。一些强一致性的系统设定W＝N，R＝1，这样就根本不用考虑各个节点数据可能不一致的情况了。\n\nHBase是借助其底层的HDFS来实现其数据冗余备份的。HDFS采用的就是强一致性保证。在数据没有完全同步到N个节点前，写操作是不会返回成功的。也就是说它的W＝N，而读操作只需要读到一个值即可，也就是说它R＝1。为了不至于让写操作太慢，对多个节点的写操作是并发异步进行的。在直到所有的节点都收到了新的数据后，会自动执行一个swap操作将新数据写入。这个操作是原子性和一致性的。保证了数据在所有节点有一致的值。\n\n**13.5.3 ****最终一致性**\n\n像Voldemort，Cassandra和Riak这些类Dynamo的系统，通常都允许用户按需要设置N，R，W三个值，即使是设置成W＋R&lt;= N也是可以的。也就是说他允许用户在强一致性和最终一致性之间自由选择。而在用户选择了最终一致性，或者是W&lt;N的强一致性时，则总会出现一段各个节点数据不同步导致系统处理不一致的时间。为了提供最终一致性的支持，这些系统会提供一些工具来使数据更新被最终同步到所有相关节点。\n\n下面我们会先讲一讲如何判断数据是最新的还是陈旧的，然后我们再讨论一下如何进行数据同步，最后我们再列举一些Dynamo里使用的加速同步过程的巧妙方法。\n\n**版本控制与冲突**\n\n由于同一份数据在不同的节点可能存在不同值，对数据的版本控制和冲突监测就变得尤为重要。类Dynamo的系统通常都使用了一种叫vector clock（向量时钟）的版本控制机制。一个vector clock可以理解成是一个向量，它包含了这个值在每一个备份节点中修改的次数。比如说有的数据会备份到A，B，C三个节点，那么这些值的vector clock值就是类似（NA，NB，NC），而其初始值为（0，0，0）。\n\n每次一个key的值被修改，其vector clock相应的值就会加1。比如有一个key值当前的vector clock值为（39，1，5），然后他在B节点被修改了一次，那么它的cector clock值就会相应的变成（39，2，5）。而当另一个节点C在收到B节点的同步请求时，他会先用自己保存的vector clock值与B传来的vector clock值进行对比，如果自己的vector clock值的每一项都小于等于B传来的这个值，那么说明这次的修改值是在自已保存的值上的修改，不会有冲突，直接进行相应的修改，并把自己的vector clock值更新。但是如果C发现自己的vector clock有些项比B大，而某些项比B小，比如B的是（39，2，5）C的是（39，1，6），那么这时候说明B的这次修改并不是在C的基础上改的，数据出现冲突了。\n\n**冲突解决**\n\n不同的系统有不同的冲突解决策略。Dynamo选择把冲突留给应用层来解决。如果是两个节点保存的购物车信息冲突了，可以选择简单的通过把两个数据合并进行解决。但如果是对同一份文档进行的修改冲突了，可能就需要人工来解决冲突了（译者：像我们在SVN中做的一样）。Voldemort就是采用的后者，它在发现冲突后，会把有冲突的几份数据一起返回给应用层，把冲突解决留给应用层来做。\n\nCassandra通过为每一个操作保存一个时间戳的方法来解决冲突，在冲突的几个版本里，最后修改的一个会获胜成为新的值。相对于上面的方式，它减少了通过应用层解决冲突时需要的网络访问，同时也简化了客户端的操作API。但这种策略并不适合用来处理一些需要合并冲突的场合，比如上面的购物车的例子，或者是分布式的计数器这样的应用。而Riak把Voldemort和 Cassandra 的策略都实现了。CouchDB会把冲突的key进行标识，以便应用层可以主动进行人工修复，在修复完成前，客户端的请求是无法得到确定值的。\n\n**读时修复**\n\n在数据读取时，如果有R个节点返回了一致的数据，那么协调器就可以认为这个值是正确的并返回给客户端了。但是在总共返回的N个值中，如果协调器发现有的数据不是最新的。那么它可以通过读时修复机制来对这些节点进行处理。这种方式在Dynamo中有描述，在Voldemort 、 Cassandra和Riak中都得到了实现。当协调器发现有的节点数据不是最新时，它会在数据不一致的节点间启动一个冲突解决过程。这样主动的修复策略并不会有多大的工作量。因为读取操作时，各个节点都已经把数据返回给协调器了，所以解决冲突越快，实际上可能造成的后续的不一致的可能性也就越小。\n\n**Hinted Handoff**\n\nCassandra、Riak和Voldemort都实现了一种叫Hinted Handoff的技术，用来保证在有节点故障后系统的写操作不受太大影响。它的过程是如果负责某个key值的某个节点宕机了，另一个节点会被选择作为其临时切换点，以临时保存在故障节点上面的写操作。这些写操作被单独保存起来，直到故障节点恢复正常，临时节点会把这些写操作重新迁移给刚刚恢复的节点。Dynamo 论文中提到一种叫“sloppy quorum”的方法，它会把通过 Hinted Handoff 写成功的临时节点也计算在成功写入数中。但是Cassandra和Voldemort并不会将临时节点也算在写入成功节点数内，如果写入操作并没有成功写在W个正式节点中，它们会返回写入失败。当然，Hinted Handoff 策略在这些系统中也有使用，不过只是用在加速节点恢复上。\n\n**Anti-Entropy**\n\n如果一个节点故障时间太长，或者是其 Hinted Handoff 临时替代节点也故障了，那么新恢复的节点就需要从其它节点中同步数据了。（译者：实际上就是要找出经过这段时间造成的数据差异，并将差异部分同步过来）。这种情况下Cassandra和Riak都实现了在Dynamo文档中提到的一种方法，叫做anti-entropy。在anti-entropy过程中，节点间通过交换Merkle Tree来找出那些不一致的部分。Merkle Tree是一个分层的hash校验机制：如果包含某个key值范围的hash值在两个数据集中不相同，那么不同点就在这个key值范围，同理，如果顶层的hash值相同，那么其负责的所有key值范围内的值都认为是相同的。这种方法的好处是，在节点恢复时，不用把所有的值都传一遍来检查哪些值是有变化的。只需要传几个hash值就能找到不一致的数据，重传这个数据即可。\n\n**Gossip**\n\n当一个分布式系统越来越大，就很难搞清集群中的每个节点的状态了。上面说到的类Dynamo 应用都采用了Dynamo文档中说到的一种古老的方法：Gossip。通过这个方法，节点间能够互相保持联系并能够检测到故障节点。其具体做法是，每隔一段时间（比如一秒），一个节点就会随便找一个曾经有过通信的节点与其交换一下其它节点的健康状态。通过这种方式，节点能够比较快速的了解到集群中哪些节点故障了，从而把这些节点负责的数据分配到其它节点去。（译者：Gossip其实是仿生学的设计，Gossip意思为流言，节点传播其它节点的健康信息，就像一个小村镇里的无聊妇人们互相说别人的闲话一样，基本上谁家谁人出什么事了，都能比较快地被所有人知道）。\n\n**13.6 ****写在最后的话**\n\n目前NoSQL系统来处在它的萌芽期，我们上面讨论到的很多NoSQL系统，他们的架构、设计和接口可能都会改变。本章的目的，不在于让你了解这些NoSQL系统目前是如何工作的，而在于让你理解这些系统之所以这样实现的原因。NoSQL系统把更多的设计工作留给了应用开发工作者来做。理解上面这些组件的架构，不仅能让您写出下一个NoSQL系统，更让您对现有系统应用得更好。\n\n**13.7 ****致谢**\n\n非常感谢Jackie Carter, Mihir Kedia，以及所有对本章进行校对并且提出宝贵意见的人。没有这些年来NoSQL社区的专注工作，也不会有这一章内容的诞生。各位加油。\n  > **相关信息**\n> \n> 原文: [http://www.aosabook.org/en/nosql.html](http://www.aosabook.org/en/nosql.html)\n> \n> 原作者：[Adam Marcus](http://www.aosabook.org/en/intro.html#marcus-adam)\n> \n> 译者：[iammutex](http://lgone.com/)\n> \n> 组织：[NoSQLFan](http://nosqlfan.com/)\n> \n> 翻译时间：2011年6月","source":"_posts/the-nosql-ecosystem.md","raw":"title: 转 - NoSQL生态系统\ntags:\n  - NoSQL\nid: 571\ncategories:\n  - 技术分享\ndate: 2012-07-25 22:33:49\n---\n\n躺在床上看到这篇文章就有一种“垂死病中惊坐起”的感觉。忍不住就给转过来了，顺带附上HTML、PDF以及原版。转载自[**NoSQLFan**](http://blog.nosqlfan.com)，这网站最贱的一句话就是“**据**说看到好文章不转的人，服务器容易宕机！”，不过虽然贱，但是我喜欢……\n\n［[**HTML****版**](https://docs.google.com/document/pub?id=1NO__9thOb8V1mM3iQID3IUmwGh9wtra7xkpmvCZIvoU)］［**[PDF版](http://blog.nosqlfan.com/wp-content/uploads/2011/nosql_ecosystem.pdf)**］[ [**原版**](http://www.aosabook.org/en/nosql.html) ] [ [**转载处**](http://blog.nosqlfan.com/html/2171.html) ]\n\n<!--more-->\n\n**-----------------------------------****华丽丽分割线**-------------------------------------\n\n与本书中提到的其它主题不同，NoSQL不是一个工具，而是由一些具有互补性和竞争性的工具组成的一个概念，是一个生态圈。这些被称作NoSQL的工具，在存储数据的方式上，提供了一种与基于SQL语言的关系型数据截然不同的思路。要想了解NoSQL，我们必须先了解现有的这些工具，去理解那些让他们开拓出新的存储领域的设计思路。\n\n如果你正在考虑使用NoSQL，你应该会马上发现你有很多种选择。NoSQL系统舍弃了许了传统关系型数据库的方便之处，而把一些通常由关系型数据库本身来完成的任务交给了应用层来完成。这需要开发人员更深入的去了解存储系统的架构和具体实现。 \n\n**13.1 NoSQL****其名**\n\n在给NoSQL下定义之前，我们先来试着从它的名字上做一下解读，顾名思义，NoSQL系统的数据操作接口应该是非SQL类型的。但在NoSQL社区，NoSQL被赋予了更具有包容性的含义，其意为Not Only SQL，即NoSQL提供了一种与传统关系型数据库不太一样的存储模式，这为开发者提供了在关系型数据库之外的另一种选择。有时候你可能会完全用NoSQL数据库代替关系型数据加，但你也可以同时使用关系型和非关系型存储来解决具体的问题。\n\n在进入NoSQL的大门之前，我们先来看看哪些场景下使用关系型数据库更合适，哪些使用NoSQL更合适。\n\n**13.1.1 SQL****及其关联型结构**\n\nSQL是一种任务描述性的查询语言，所谓任务描述性的查询语言，就是说它只描述他需要系统做什么，而不告诉系统如何去做。例如：查出39号员工的信息，查出员工的名字和电话，只查找做会计工作的员工信息，计算出每个部门的员工总数，或者是对员工表和经理表做一个联合查询。\n\n简单的说，SQL让我们可以直接向数据库提出上述问题而不必考虑数据是如何在磁盘上存储的，使用哪些索引来查询数据，或者说用哪种算法来处理数据。在关系型数据库中有一个重要的组件，叫做查询优化器，正是它来推算用哪种操作方式能够更快的完成操作。查询优化器通常比一般的数据库用户更聪明，但是有时候由于没有充足的信息或者系统模型过于简单，也会导致查询优化器不能得出最有效的操作方式。\n\n作为目前应用最广的数据库系统，关系型数据库系统以其关联型的数据模型而命名。在关联型的数据模型中，在现实世界中的不同类型的个体被存储在不同的表里。比如有一个专门存员工的员工表，有一个专门存部门的部门表。每一行数据又包含多个列，比如员工表里可能包含了员工号，员工工资，生日以及姓名等，这些信息项被存在员工表中的某一列中。\n\n关联型的模型与SQL是紧密想连的。简单的查询操作，比如查询符合某个条件的所有行（例：employeeid = 3, 或者 salary &gt; $20000）。更复杂一些的任务会让数据库做一些额外的工作，比如跨表的联合查询（例：查出3号员的部门名称是什么）。一些复杂的查询，比如统计操作（例：算出所有员工的平均工资），甚至可能会导致全表扫描。\n\n关联型的数据模型定义了高度结构化的数据结构，以及对这些结构之间关系的严格定义。在这样的数据模型上执行的查询操作会比较局限，而且可能会导致复杂的数据遍历操作。数据结构的复杂性及查询的复杂性，会导致系统产生如下的一些限制：\n\n*   复杂导致不确定性。使用SQL的一个问题就是计算某个查询的代价或者产生的负载几乎是不可能的。使用简单的查询语言可能会导致应用层的逻辑更复杂，但是这样可以将存储系统的工作简单化，让它只需要响应一些简单的请求。*   对一个问题建模有很多种方式。其中关联型的数据模型是非常严格的一种：表结构的定义规定了表中每一行数据的存储内容。如果你的数据结构化并没有那么强，或者对每一行数据的要求比较灵活，那可能关联型的数据模型就太过严格了。类似的，应用层的开发人员可能对关联型的数据结构并不满意。比如很多应用程序是用面向对象的语言写的，数据在这些语言中通常是以列表、队列或集合的形式组织的，程序员们当然希望他们的数据存储层也能和应用层的数据模型一致。*   当数据量增长到一台机器已经不能容纳，我们需要将不同的数据表分布到不同的机器。而为了避免在不同机器上的数据表在进行联合查询时需要跨网络进行。我们必须进行反范式的数据库设计，这种设计方式要求我们把需要一次性查询到的数据存储在一起。这样做使得我们的系统变得就像一个主键查询系统一样，于是我们开始思考，是否有其它更适合我们数据的数据模型。  \n\n通常来说，舍弃多年以来的设计思路是不明智的。当你要把数据存到数据库，当考虑到SQL与关联型的数据模型，这些都是数十年的研究的开发成果，提供丰富的数据模型，提供复杂操作的保证。而当你的问题涉及到大数据量，高负载或者说你的数据结构在SQL与关联型数据模型下很难得到优化，NoSQL可能是更好的选择。\n\n**13.1.2 NoSQL****的启示**\n\nNoSQL运动受到了很多相关研究论文的启示，这所有论文中，最核心的有两个。\n\nGoogle的BigTable[[CDG+06](http://www.aosabook.org/en/bibliography.html#bib:bigtable)]提出了一种很有趣的数据模型，它将各列数据进行排序存储。数据值按范围分布在多台机器，数据更新操作有严格的一致性保证。\n\nAmazon的Dynamo[[DHJ+07](http://www.aosabook.org/en/bibliography.html#bib:amazon:dynamo)]使用的是另外一种分布式模型。Dynamo的模型更简单，它将数据按key进行hash存储。其数据分片模型有比较强的容灾性，因此它实现的是相对松散的弱一致性：最终一致性。\n\n接下来我们会深入介绍这些设计思想，而实际上在现实中这些思想经常是混搭使用的。比如像HBase及其它一些NoSQL系统他们在设计上更接受BigTable的模型，而像Voldemort 系统它就和Dynamo更像。同时还有像Cassandra这种两种特性都具备的实现（它的数据模型和BigTable类似，分片策略和一致性机制和Dynamo类似）。\n\n**13.1.3 ****特性概述**\n\nNoSQL系统舍弃了一些SQL标准中的功能，取而代之的是提供了一些简单灵活的功能。NoSQL 的构建思想就是尽量简化数据操作，尽量让执行操作的效率可预知。在很多NoSQL系统里，复杂的操作都是留给应用层来做的，这样的结果就是我们对数据层进行的操作得到简化，让操作效率可预知。\n\nNoSQL系统不仅舍弃了很多关系数据库中的操作。它还可能不具备关系数据库以下的一些特性：比如通常银行系统中要求的事务保证，一致性保证以及数据可靠性的保证等。事务机制提供了在执行多个命令时的all-or-nothing保证。一致性保证了如果一个数据更新后，那么在其之后的操作中都能看到这个更新。可靠性保证如果一个数据被更新，它就会被写到持久化的存储设备上（比如说磁盘），并且保证在数据库崩溃后数据可恢复。\n\n通过放宽对上述几点特性的要求，NoSQL系统可以为一些非银行类的业务提供以性能换稳定的策略。而同时，对这几点要求的放宽，又使得NoSQL系统能够轻松的实现分片策略，将远远超出单机容量的大量数据分布在多台机器上的。\n\n由于NoSQL系统还处在萌芽阶段，本章中提到的很多NoSQL架构都是用于满足各种不同用户的需求的。对这些架构进行总结不太可能，因为它们总在变化。所以希望你能记住的一点是，不同的NoSQL系统的特点是不同的，通过本章的内容，希望你能该根据自己的业务情况来选择合适的NoSQL系统，而本章内容不可能给你直接的答案。\n\n当你去考查一个NoSQL系统的时候，下面的的几点是值得注意的：\n\n*   数据模型及操作模型：你的应用层数据模型是行、对象还是文档型的呢？这个系统是否能支持你进行一些统计工作呢？*   可靠性：当你更新数据时，新的数据是否立刻写到持久化存储中去了？新的数据是否同步到多台机器上了？*   扩展性：你的数据量有多大，单机是否能容下？你的读写量求单机是否能支持？*   分区策略：考虑到你对扩展性，可用性或者持久性的要求，你是否需要一份数据被存在多台机器上？你是否需要知道数据在哪台机器上，以及你能否知道。*   一致性：你的数据是否被复制到了多台机器上，这些分布在不同点的数据如何保证一致性？*   事务机制：你的业务是否需要ACID的事务机制？*   单机性能：如果你打算持久化的将数据存在磁盘上，哪种数据结构能满足你的需求（你的需求是读多还是写多）？写操作是否会成为磁盘瓶颈？*   负载可评估：对于一个读多写少的应用，诸如响应用户请求的web应用，我们总会花很多精力来关注负载情况。你可能需要进行数据规模的监控，对多个用户的数据进行汇总统计。你的应用场景是否需要这样的功能呢？  \n\n尽管后三点在本章没有独立的小节进行描述，但它们和其它几点一样重要，下面就让我们对以上的几点进行阐述。\n\n**13.2 NoSQL****数据模型及操作模型**\n\n数据库的数据模型指的是数据在数据库中的组织方式，数据库的操作模型指的是存取这些数据的方式。通常数据模型包括关系模型、键值模型以及各种图结构模型。的操作语言可能包括SQL、键值查询及MapReduce等。NoSQL通常结合了多种数据模型和操作模型，提供了不一样的架构方式。\n\n**13.2.1 ****基于key值存储的NoSQL数据模型**\n\n在键值型系统中，复杂的联合操作以及满足多个条件的取数据操作就不那么容易了，需要我们创造性的建立和使用键名。如果一个程序员既想通过员工号查到员工信息，又想通过部门号查到员工信息，那么他必须建立两种类型的键值对。例如 emplyee:30 这个键用于指向员工号为30的员工信息。employee_departments:20 可能用到指向一个包含在20号部门工作的所有员工工号的列表。这样数据库中的联合操作就被转换成业务层的逻辑了：要获取部门号为20的所有员工的信息，应用层可以先获取employee_departments:20 这个列表，然后再循环地拿这个列表中的ID通过获取employee:ID得到所有员工的信息。\n\n键值查找的一个好处是，对数据库的操作模式是固定的，这些操作所产生的负载也是相对固定且可预知的。这样像分析整个应用中的性能瓶颈这种事，就变得简单多了。因为复杂的逻辑操作并不是放在数据库里面黑箱操作了。不过这样做之后，业务逻辑和数据逻辑可能就没那么容易分清了。\n\n下面我们快速地把各种键值模型的数据结构简单描述一下。看看不同的NoSQL系统的在这方面的不同实现方式。\n\n**Key-Value ****存储**\n\nKey-Value存储可以说是最简单的NoSQL存储。每个key值对应一个任意的数据值。对NoSQL 系统来说，这个任意的数据值是什么，它并不关心。比如在员工信念数据库里，exployee:30 这个key对应的可能就是一段包含员工所有信息的二进制数据。这个二进制的格式可能是[Protocol Buffer](http://code.google.com/p/protobuf/)、[Thrift](http://thrift.apache.org/)或者[Avro](http://avro.apache.org/)都无所谓。\n\n如果你使用上面说的Key-Value存储来保存你的结构化数据，那么你就得在应用层来处理具体的数据结构：单纯的Key-Value存储是不提供针对数据中特定的某个属性值来进行操作。通常它只提供像set、get和delete这样的操作。以Dynamo为原型的Voldemort数据库，就只提供了分布式的Key-Value存储功能。BDB 是一个提供Key-Value操作的持久化数据存储引擎。\n\n**Key ****– 结构化数据 存储**\n\nKey对应结构化数据存储，其典型代表是Redis，Redis将Key-Value存储的Value变成了结构化的数据类型。Value的类型包括数字、字符串、列表、集合以及有序集合。除了set/get/delete 操作以为，Redis还提供了很多针对以上数据类型的特殊操作，比如针对数字可以执行增、减操作，对list可以执行 push/pop 操作，而这些对特定数据类型的特定操作并没有对性能造成多大的影响。通过提供这种针对单个Value进行的特定类型的操作，Redis可以说实现了功能与性能的平衡。\n\n**Key ****– 文档 存储**\n\nKey – 文档存储的代表有CouchDB、MongoDB和Riak。这种存储方式下Key-Value的Value是结构化的文档，通常这些文档是被转换成JSON或者类似于JSON的结构进行存储。文档可以存储列表，键值对以及层次结构复杂的文档。\n\nMongoDB 将Key按业务分到各个collection里，这样以collection作为命名空间，员工信息和部门信息的Key就被隔开了。CouchDB和Riak把类型跟踪这种事留给了开发者去完成。文档型存储的灵活性和复杂性是一把双刃剑：一方面，开发者可以任意组织文档的结构，另一方面，应用层的查询需求会变得比较复杂。\n\n**BigTable ****的列簇式存储**\n\nHBase和Cassandra的数据模型都借鉴自Google 的BigTable。这种数据模型的特点是列式存储，每一行数据的各项被存储在不同的列中（这些列的集合称作列簇）。而每一列中每一个数据都包含一个时间戳属性，这样列中的同一个数据项的多个版本都能保存下来。\n\n列式存储可以理解成这样，将行ID、列簇号，列号以及时间戳一起，组成一个Key，然后将Value按Key的顺序进行存储。Key值的结构化使这种数据结构能够实现一些特别的功能。最常用的就是将一个数据的多个版本存成时间戳不同的几个值，这样就能很方便的保存历史数据。这种结构也能天然地进行高效的松散列数据（在很多行中并没有某列的数据）存储。当然，另一方面，对于那些很少有某一行有NULL值的列，由于每一个数据必须包含列标识，这又会造成空间的浪费。\n\n这些NoSQL系统对BigTable数据模型的实现多少有些差别，这其中以Cassandra进行的变更最为显著。Cassandra引入了超级列（supercolumn）的概念，通过将列组织到相应的超级列中，可以在更高层级上进行数据的组织，索引等。这一做法也取代了locality groups的概念（这一概念的实现可以让相关的几个行的数据存储在一起，以提高存取性能）。\n\n**13.2.2 ****图结构存储**\n\n图结构存储是NoSQL的另一种存储实现。图结构存储的一个指导思想是：数据并非对等的，关系型的存储或者键值对的存储，可能都不是最好的存储方式。图结构是计算机科学的基础结构之一，Neo4j和HyperGraphDB是当前最流行的图结构数据库。图结构的存储与我们之前讨论过的几种存储方式很不同，这种不同几乎体现在每一个方面，包括：数据模型、数据查询方式、数据在磁盘上的组织方式、在多个结点上的分布方式，甚至包括对事务机制的实现等等。由于篇幅的限制，对这些方面我们暂时不做深入的讨论，这里需要你了解的是，某些数据结构使用图结构的数据库进行存储可能会更好。\n\n**13.2.3 ****复杂查询**\n\n在NoSQL存储系统中，有很多比键值查找更复杂的操作。比如MongoDB可以在任意数据行上建立索引，可以使用Javascript语法设定复杂的查询条件。BigTable型的系统通常支持对单独某一行的数据进行遍历，允许对单列的数据进行按特定条件地筛选。CouchDB允许你创建同一份数据的多个视图，通过运行MapReduce任务来实现一些更为复杂的查询或者更新操作。很多NoSQL系统都支持与Hadoop或者其它一些MapReduce框架结合来进行一些大规模数据分析工作。\n\n**13.2.4 ****事务机制**\n\n传统的关系型数据库在功能支持上通常很宽泛，从简单的键值查询，到复杂的多表联合查询再到事务机制的支持。而与之不同的是，NoSQL系统通常注重性能和扩展性，而非事务机制。\n\n传统的SQL数据库的事务通常都是支持ACID的强事务机制。A代表原子性，即在事务中执行多个操作是原子性的，要么事务中的操作全部执行，要么一个都不执行;C代表一致性，即保证进行事务的过程中整个数据加的状态是一致的，不会出现数据花掉的情况;I代表隔离性，即两个事务不会相互影响，覆盖彼此数据等;D表示持久化，即事务一量完成，那么数据应该是被写到安全的，持久化存储的设备上（比如磁盘）。\n\nACID的支持使得应用者能够很清楚他们当前的数据状态。即使如对于多个事务同时执行的情况下也能够保证数据状态的正常性。但是如果要保证数据的一致性，通常多个事务是不可能交叉执行的，这样就导致了可能一个很简单的操作需要等等一个复杂操作完成才能进行的情况。\n\n对很多NoSQL系统来说，对性能的考虑远在ACID的保证之上。通常NoSQL系统仅提供对行级别的原子性保证，也就是说同时对同一个Key下的数据进行的两个操作，在实际执行的时候是会串行的执行，保证了每一个Key-Value对不会被破坏。对绝大多数应用场景来说，这样的保证并不会引起多大的问题，但其换来的执行效率却是非常可观的。当然，使用这样的系统可能需要我们在应用层的设计上多做容错性和修正机制的考虑。\n\n在NoSQL中，Redis在事务支持这方面上不太一样，它提供了一个MULTI命令用来将多个命令进行组合式的操作，通过一个WATCH命令提供操作隔离性。这和其它一些提供test-and-set这样的低层级的隔离机制类似。\n\n**13.2.5 Schema-free****的存储**\n\n还有一个很多NoSQL都有的共同点，就是它通常并没有强制的数据结构约束。即使是在文档型存储或者列式存储上，也不会要求某一个数据列在每一行数据上都必须存在。这在非结构化数据的存储上更方便，同时也省去了修改表结构的代价。而这一机制对应用层的容错性要求可能会更高。比如程序可能得确定如果某一个员工的信息里缺少lastname这一项，是否算是错误。或者说某个表结构的变更是否对所有数据行起了作用。还有一个问题，就是数据库的表结构可能会因为项目的多次迭代而变得混乱不堪。\n\n**13.3 ****数据可靠性**\n\n最理想状态是，数据库会把所有写操作立刻写到持久化存储的设备，同时复制多个副本到不同地理位置的不同节点上以防止数据丢失。但是这种对数据安全性的要求对性能是有影响的，所以不同的NoSQL系统在自身性能的考虑下，在数据安全上采取了不太一样的策略。\n\n一种典型的出错情况是重启机器或者机器断电了，这时候需要让数据从内存转存到磁盘才能保证数据的安全性，因为磁盘数据不会因断电而丢失。而要避免磁盘损坏这种故障，就需要将数据冗余的存在其它磁盘上，比如使用RAID来做镜像，或者将数据同步到不同机器。但是有些时候针对同一个数据中心来说，是不可能做到完全的数据安全的，比如一旦发生飓风地震这种天灾，整个机房机器可能都会损坏，所以，在这种情况下要保证数据的安全性，就必须将数据备份存储到其它地理位置上比较远的数据中心。所以，具体各个NoSQL系统在数据安全性和性能上的权衡策略也不太一样。\n\n**13.3.1 ****单机可靠性**\n\n单机可靠性理解起来非常简单，它的定义是写操作不会由于机器重启或者断电而丢失。通常单机可靠性的保证是通过把数据写到磁盘来完成的，而这通常会造成磁盘IO成为整个系统的瓶颈。而事实上，即使你的程序每次都把数据写到了磁盘，实际上由于操作系统buffer层的存在，数据还是不会立刻被写到物理磁盘上，只有当你调用fsync这个系统调用的时候，操作系统才会尽可能的把数据写到磁盘。\n\n一般的磁盘大概能进行每秒100-200次的随机访问，每秒30-100MB的顺序写入速度。而内存在这两方面的性能都有数量级上的提升。通过尽量减少随机写，取而代之的对每个磁盘设备进行顺序写，这样能够减少单机可靠性保证的代价。也就是说我们需要减少在两次fsync调用之间的写操作次数，而增加顺序写操作的数量。下面我们说一下一些在单机可靠性的保证下提高性能的方法。\n\n**控制fsync的调用频率**\n\nMemcached是一个纯内存的存储，由于其不进行磁盘上的持久化存储，从而换来了很高的性能。当然，在我们进行服务器重启或者服务器意外断电后，这些数据就全丢了。因此Memcached 是一个非常不错的缓存，但是做不了持久化存储。\n\nRedis则提供了几种对fsync调用频率的控制方法。应用开发者可以配置Redis在每次更新操作后都执行一次fsync，这样会比较安全，当然也就比较慢。Redis也可以设置成N秒种调用一次fsync，这样性能会更好一点。但这样的后果就是一旦出现故障，最多可能导致N秒内的数据丢失。而对一些可靠性要求不太高的场合（比如仅仅把Redis当Cache用的时候），应用开发者甚至可以直接关掉fsync的调用：让操作系统来决定什么时候需要把数据flush到磁盘。   \n（译者：这只是Redis append only file的机制，Redis是可以关闭aof日志的，另外请注意：Redis 本身支持将内存中数据dump成rdb文件的机制，和上面说的不是一回事。）\n\n**使用日志型的数据结构**\n\n像B+ 树这样的一些数据结构，使得NoSQL系统能够快速的定位到磁盘上的数据，但是通常这些数据结构的更新操作是随机写操作，如果你在每次操作后再调用一次fsync，那就会造成频繁的磁盘随机访问了。为了避免产生这样的问题，像Cassandra、HBase、Redis和Riak都会把写操作顺序的写入到一个日志文件中。相对于存储系统中的其它数据结构，上面说到的日志文件可以频繁的进行fsync操作。这个日志文件记录了操作行为，可以用于在出现故障后恢复丢失那段时间的数据，这样就把随机写变成顺序写了。\n\n虽然有的NoSQL系统，比如MongoDB，是直接在原数据上进行更新操作的，但也有许多NoSQL系统是采用了上面说到的日志策略。Cassandra和HBase借鉴了BigTable的做法，在数据结构上实现了一个日志型的查找树。Riak也使用了类似的方法实现了一个日志型的hash表（译者：也就是Riak的[BitCask](http://downloads.basho.com/papers/bitcask-intro.pdf)模型）。CouchDB对传统的B+树结构进行了修改，使得对树的更新可以使用顺序的追加写操作来实现（译者：这种B+树被称作[append-only B-Tree](http://jchrisa.net/drl/nosql-oakland/btree-nosql-oak.pdf)）。这些方法的使用，使得存储系统的写操作承载力更高，但同时为了防止数据异构后膨胀得过大，需要定时进行一些合并操作。\n\n**通过合并写操作提高吞吐性能**\n\nCassandra有一个机制，它会把一小段时间内的几个并发的写操作放在一起进行一次fsync调用。这种做法叫group commit，它导致的一个结果就是更新操作的返回时间可能会变长，因为一个更新操作需要等就近的几个更新操作一起进行提交。这样做的好处是能够提高写操作承载力。作为HBase底层数据支持的Hadoop 分布式文件系统HDFS，它最近的一些补丁也在实现一些顺序写和group commit的机制。\n\n**13.3.2 ****多机可靠性**\n\n由于硬件层面有时候会造成无法恢复的损坏，单机可靠性的保证在这方面就鞭长莫及了。对于一些重要数据，跨机器做备份保存是必备的安全措施。一些NoSQL系统提供了多机可靠性的支持。\n\nRedis采用了传统的主从数据同步的方式。所有在master上执行的操作，都会通过类似于操作日志的结构顺序地传递给slave上再执行一遍。如果master发生宕机等事故，slave可以继续执行完master传来的操作日志并且成为新的master。可能这中间会导致一些数据丢失，因为master同步操作到slave是非阻塞的，master并不知道操作是否已经同步线slave了。CouchDB 实现了一个类似的指向性的同步功能，它使得一个写操作可以同步到其它节点上。\n\nMongoDB提供了一个叫Replica Sets的架构方制，这个架构策略使得每一个文档都会保存在组成Replica Sets的所有机器上。MongoDB提供了一些选项，让开发者可以确定一个写操作是否已经同步到了所有节点上，也可以在节点数据并不是最新的情况下执行一些操作。很多其它的分布式NoSQL存储都提供了类似的多机可靠性支持。由于HBase的底层存储是HDFS，它也就自然的获得了HDFS提供的多机可靠性保证。HDFS的多机可靠性保证是通过把每个写操作都同步到两个以上的节点来实现的。\n\nRiak、Cassandra和Voldemort提供了一些更灵活的可配置策略。这三个系统提供一个可配置的参数N，代表每一个数据会被备份的份数，然后还可以配置一个参数W，代表每个写操作需要同步到多少能机器上才返回成功。当然W是小于N的。\n\n为了应对整个数据中心出现故障的情况，需要实现跨数据中心的多机备份功能。Cassandra、HBase和Voldemort都实现了一个机架位置可知的配置，这种配置方式使得整个分布式系统可以了解各个节点的地理位置分布情况。如果一个操作需要等待另外的数据中心的同步操作成功才返回给用户，那时间就太长了，所以通常跨数据中心的同步备份操作都是异步进行的。用户并不需要等待另一个数据中心同步的同步操作执行成功。\n\n**13.4 ****横向扩展带来性能提升**\n\n上面我们讨论了对出错情况的处理，下面我们讨论另一种情况：成功！如果数据存储操作成功执行了，那么你的系统就要负责对这些数据进行处理。就要承担数据带来的负载。一个比较粗暴的解决方法是通过升级你的机器来提升单机性能：通过加大内存和添加硬盘来应对越来越大的负载。但是随着数据量的增大，投入在升级机器上的钱将将不会产生原来那么大的效果。这时候你就必须考虑把数据同步到不同的机器上，利用横向扩展来分担访问压力。\n\n横向扩展的目标是达到线性的效果，即如果你增加一倍的机器，那么负载能力应该也能相应的增加一倍。其主要需要解决的问题是如何让数据在多台机器间分布。数据分片技术实际上就是将对数据和读写请求在多个机器节点上进行分配的技术，分片技术在很多NoSQL系统中都有实现，比如Cassandra、HBase、Voldemort和Riak等等，最近MongoDB和Redis也在做相应的实现。而有的项目并不提供内置的分片支持，比如CouchDB更加注重单机性能的提升。对于这些项目，通常我们可以借助一些其它的技术在上层来进行负载分配。\n\n下面让我们来整理一些通用的概念。对于数据分片和分区，我们可以做同样的理解。对机器，服务器或者节点，我们可以统一的理解成物理上的存储数据的机器。最后，集群或者机器环都可以理解成为是组成你存储系统的集合。\n\n分片的意思是，没有任何一台机器可以处理所有写请求，也没有任何一台机器可以处理对所有数据的读请求。很多NoSQL系统都是基于键值模型的，因此其查询条件也基本上是基于键值的查询，基本不会有对整个数据进行查询的时候。由于基本上所有的查询操作都是基本键值形式的，因此分片通常也基于数据的键来做：键的一些属性会决定这个键值对存储在哪台机器上。下面我们将会对hash分片和范围分片两种分片方式进行描述。\n\n**13.4.1 ****如非必要，请勿分片**\n\n分片会导致系统复杂程序大增，所以，如果没有必要，请不要使用分片。下面我们先讲两种不用分片就能让系统具有扩展性的方法。\n\n**读写分离**\n\n大多数应用场景都是读多写少的场景。所以在这种情况下，可以用一个简单的方法来分担负载，就是把数据同步到多台机器上。这时候写请求还是由master机器处理，而读请求则可以分担给那些同步到数据的机器了。而同步数据的操作，通常是不会对master带来多大的压力的。\n\n如果你已经使用了主从配置，将数据同步到多台机器以提供高可靠性了，那么你的slave机器应该能够为master分担不少压力了。对有些实时性要求不是非常高的查询请求，比如一些统计操作，你完全可以放到slave上来执行。通常来说，你的应用对实时性要求越低，你的slave机器就能承担越多的任务。\n\n**使用缓存**\n\n将一些经常访问的数据放到缓存层中，通常会带来很好的效果。Memcached 主要的作用就是将数据层的数据进行分布式的缓存。Memcached 通过客户端的算法（译者： 常见的一致性hash算法）来实现横向扩展，这样当你想增大你缓存池的大小时，只需要添加一台新的缓存机器即可。\n\n由于Memcached仅仅是一个缓存存储，它并不具备一些持久存储的复杂特性。当你在考虑使用复杂的扩展方案时，希望你先考虑一下使用缓存来解决你的负载问题。注意，缓存并不是临时的处理方案：Facebook 就部署了总容量达到几十TB的Memcahced内存池。\n\n通过读写分离和构建有效的缓存层，通常可以大大分担系统的读负载，但是当你的写请求越来越频繁的时候，你的master机器还是会承受越来越大的压力。对于这种情况，我们可能就要用到下面说到的数据分片技术了。\n\n**13.4.2 ****通过协调器进行数据分片**\n\n由于CouchDB专注于单机性能，没有提供类似的横向扩展方案，于是出现了两个项目：Lounge 和 BigCouch，他们通过提供一个proxy层来对CouchDB中的数据进行分片。在这种架构中，proxy作为CouchDB集群的前端机器，接受和分配请求到后端的多台CouchDB上。后端的CouchDB 之间并没有交互。协调器会将按操作的key值将请求分配到下层的具体某台机器。\n\nTwitter 自己实现了一个叫Gizzard的协调器，可以实现数据分片和备份功能。Gizzard不关心数据类型，它使用树结构来存储数据范围标识，你可以用它来对SQL或者NoSQL系统进行封装。通过对 Gizzard 进行配置，可以实现将特定范围内的数据进行冗余存储，以提高系统的容灾能力。\n\n**13.4.3 ****一致性hash环算法**\n\n好的hash算法可以使数据保持比较均匀的分布。这使得我们可以按这种分布将数据保存布多台机器上。一致性hash是一种被广泛应用的技术，其最早在一个叫distributed hash tables (DHTs)的系统中进行使用。那些类Dynamo的应用，比如Cassandra、Voldemort和Riak，基本上都使用了一致性hash算法。\n\n**Hash****环图**\n\n[![A-Distributed-Hash-Table-Ring](http://www.hongweiyi.com/wp-content/uploads/2012/07/ADistributedHashTableRing_thumb.png \"A-Distributed-Hash-Table-Ring\")](http://www.hongweiyi.com/wp-content/uploads/2012/07/ADistributedHashTableRing.png) \n\n一致性hash算法的工作原理如下：首先我们有一个hash函数H，可以通过数据的key值计算出一个数字型的hash值。然后我们将整个hash环的范围定义为［1，L］这个区间，我们将刚才算出的hash值对L进行取余，就能算出一个key值在这个环上的位置。而每一台真实服务器结点就会负责［1-L］之间的某个区间的数据。如上图，就是一个五个结点的hash环。\n\n上面hash环的L值为1000，然后我们对ABCDE 5个点分别进行hash运算，H(A) mod L = 7, H(B) mod L = 234, H(C) mod L = 447, H(D) mod L = 660, and H(E) mod L = 875 ，这样，hash值在7-233之间的所有数据，我们都让它保存在A节点上。在实际动作中，我们对数据进行hash，算出其应该在哪个节点存储即可，例：H(‘employee30′) mod L = 899 那么它应该在E节点上，H(‘employee31′) mod L = 234 那么这个数据应该在B节点上。\n\n**备份数据**\n\n一致性hash下的数据备份通常采用下面的方法：将数据冗余的存在其归属的节点的顺序往下的节点，例如你的冗余系数为3（即数据会在不同节点中保存三份），那么如果通过hash计算你的数据在A区间［7，233］，你的数据会被同时保存在A，B，C三个节点上。这样如果A节点出现故障，那么B，C节点就能处理这部分数据的请求了。而某些设计会使E节点将自己的范围扩大到A233，以接受对出故障的A节点的请求。\n\n**优化的数据分配策略**\n\n虽然hash算法能够产生相对均匀的hash值。而且通常是节点数量越多，hash算法会越平均的分配key值。然而通常在项目初期不会有太多的数据，当然也不需要那么多的机器节点，这时候就会造成数据分配不平均的问题。比如上面的5个节点，其中A节点需要负责的hash区间范围大小为227，而E节点负责的区间范围为132。同时在这种情况下，出故障后数据请求转移到相邻节点的策略也可能不好实施了。\n\n为了解决由于节点比较少导致数据分配不均的问题，很多DHT系统都实现了一种叫做虚拟节点的技术。例如4个虚拟节点的系统中，A节点可能被虚拟化成A_1，A_2，A_3，A_4这四个虚拟节点，然后对这四个虚拟节点再进行hash运算，A节点负责的key值区间就比较分散了。Voldemort 使用了与上面类似的策略，它允许对虚拟节点数进行配置，通常这个节点数会大于真实节点数，这样每个真实节点实际上是负责了N个虚拟节点上的数据。\n\nCassandra 并没有使用虚拟节点到真实节点映射的方法。这导致它的数据分配是不均匀的。为了解决这种不平衡，Cassandra 利用一个异步的进程根据各节点的历史负载情况来调节数据的分布。\n\n**13.4.4 ****连续范围分区**\n\n使用连续范围分区的方法进行数据分片，需要我们保存一份映射关系表，标明哪一段key值对应存在哪台机器上。和一致性hash类似，连续范围分区会把key值按连续的范围分段，每段数据会被指定保存在某个节点上，然后会被冗余备份到其它的节点。和一致性hash不同的是，连续范围分区使得key值上相邻的两个数据在存储上也基本上是在同一个数据段。这样数据路由表只需记录某段数据的开始和结束点［start，end］就可以了。\n\n通过动态调整数据段到机器结点的映射关系，可以更精确的平衡各节点机器负载。如果某个区段的数据负载比较大，那么负载控制器就可以通过缩短其所在节点负责的数据段，或者直接减少其负责的数据分片数目。通过添加这样一个监控和路由模块，使我们能够更好的对数据节点进行负载均衡。\n\n**BigTable****的处理方式**\n\nGoogle BigTable 论文中描述了一种范围分区方式，它将数据切分成一个个的tablet数据块。每个tablet保存一定数量的键值对。然后每个Tablet 服务器会存储多个tablet块，具体每个Tablet服务器保存的tablet数据块数，则是由服务器压力来决定的。\n\n每个tablet大概100-200MB大。如果tablet的尺寸变小，那么两个tablet可能会合并成一个tablet，同样的如果一个tablet过大，它也会被分裂成两个tablet，以保持每个tablet的大小在一定范围内。在整个系统中有一个master机器，会根据tablet的大小、负载情况以及机器的负载能力等因素动态地调整tablet在各个机器上的分布。\n\n[![BigTable-based-Range-Partitioning](http://www.hongweiyi.com/wp-content/uploads/2012/07/BigTablebasedRangePartitioning_thumb.png \"BigTable-based-Range-Partitioning\")](http://www.hongweiyi.com/wp-content/uploads/2012/07/BigTablebasedRangePartitioning.png)     \nmaster服务器会把 tablet 的归属关系存在元数据表里。当数据量非常大时，这个元数据表实际也会变得非常大，所以归属关系表实际上也是被切分成一个个的tablet保存在tablet服务器中的。这样整个数据存储就被分成了如上图的三层模型。\n\n下面我们解释一下上面图中的例子。当某个客户端要从BigTable系统中获取key值为900的数据时，首先他会到第一级元数据服务器A（METADATA0）去查询，第一级元数据服务器查询自己的元数据表，500-1500这个区间中的所有元数据都存在B服务器中，于是会返回客户端说去B服务器查询，客户端再到B服务器中进行查询，B服务器判断到850-950这个区间中的数据都存在tablet服务器C中，于是会告知客户端到具体的tablet服务器C去查询。然后客户端再发起一次向C服务器的请求，就能获取到900对应的数据了。然后，客户端会把这个查询结果进行缓存，以避免对元数据服务器的频繁请求。在这样的三层架构下，只需要128MB的元数据存储，就能定位234 个tablet数据块了（按128MB一个数据块算，是261bytes的数据）。\n\n**故障处理**\n\n在BigTable中，master机器是一个故障单点，不过系统可以容忍短时间的master故障。另一方面，如果tablet 服务器故障，那么master可以把对其上tablet的所有请求分配到其它机器节点。\n\n为了监测和处理节点故障，BigTable实现了一个叫Chubby的模块，Chubby是一个分布式的锁系统，用于管理集群成员及检测各成员是否存活。ZooKeeper是Chubby的一个开源实现，有很多基于 Hadoop 的项目都使用它来进行二级master和tablet节点的调度。\n\n**基于范围分区的NoSQL项目**\n\nHBase 借鉴了BigTable的分层理论来实现范围分区策略。tablet相关的数据存在HDFS里。HDFS 会处理数据的冗余备份，并负责保证各备份的一致性。而像处理数据请求，修改存储结构或者执行tablet的分裂和合并这种事，是具体的tablet服务器来负责的。\n\nMongoDB也用了类似于BigTable的方案来实现范围分区。他用几台配置机器组成集群来管理数据在节点上的分布。这几台机器保存着一样的配置信息，他们采用 two-phase commit 协议来保证数据的一致性。这些配置节点实际上同时扮演了BigTable中的master的路由角色，及Chubby 的高可用性调度器的角色。而MongoDB具体的数据存储节点是通过其Replica Sets方案来实现数据冗余备份的。\n\nCassandra 提供了一个有序的分区表，使你可以快速对数据进行范围查询。Cassandra也使用了一致性hash算法进行数据分配，但是不同的是，它不是直接按单条数据进行hash，而是对一段范围内的数据进行hash，也就是说20号数据和21号数据基本上会被分配在同一台机器节点上。\n\nTwitter的Gizzard框架也是通过使用范围分区来管理数据在多个节点间的备份与分配。路由服务器可以部署成多层，任何一层只负责对key值进行按范围的分配到下层的不同节点。也就是说路由服务器的下层既可以是真实的数据存储节点，也可能是下层的路由节点。Gizzard的数据备份机制是通过将写操作在多台机器上执行多次来实现的。Gizzard的路由节点处理失败的写操作的方式和其它NoSQL不太一样，他要求所有更新都是幂等的（意思是可以重复执行而不会出错）。于是当一个节点故障后，其上层的路由节点会把当前的写操作cache起来并且重复地让这个节点执行，直到其恢复正常。\n\n**13.4.5 ****选择哪种分区策略**\n\n上面我们说到了Hash分区和范围分区两种策略，哪种更好呢？这要看情况了，如果你需要经常做范围查询，需要按顺序对key值进行操作，那么你选择范围分区会比较好。因为如果选择hash分区的话，要查询一个范围的数据可能就需要跨好几个节点来进行了。\n\n那如果我不会进行范围查询或者顺序查询呢？这时候hash分区相对来说可能更方便一点，而且hash分区时可能通过虚拟结点的设置来解决hash不均的问题。在hash分区中，基本上只要在客户端执行相应的hash函数就能知道对应的数据存在哪个节点上了。而如果考虑到节点故障后的数据转移情况，可能获取到数据存放节点就会麻烦一些了。\n\n范围分区要求在查询数据前对配置节点还要进行一次查询，如果没有特别好的高可用容灾方案，配置节点将会是一个危险的故障单点。当然，你可以把配置节点再进行一层负载均衡来减轻负载。而范围分区时如果某个节点故障了，它上面的数据可以被分配到多个节点上，而不像在一致性hash时，只能迁移到其顺序的后一个节点，造成下一个节点的负载飙升。\n\n**13.5 ****一致性**\n\n上面我们讲到了通过将数据冗余存储到不同的节点来保证数据安全和减轻负载，下面我们来看看这样做引发的一个问题：保证数据在多个节点间的一致性是非常困难的。在实际应用中我们会遇到很多困难，同步节点可能会故障，甚至会无法恢复，网络可能会有延迟或者丢包，网络原因导致集群中的机器被分隔成两个不能互通的子域等等。在NoSQL中，通常有两个层次的一致性：第一种是强一致性，既集群中的所有机器状态同步保持一致。第二种是最终一致性，既可以允许短暂的数据不一致，但数据最终会保持一致。我们先来讲一下，在分布式集群中，为什么最终一致性通常是更合理的选择，然后再来讨论两种一致性的具体实现结节。\n\n**13.5.1 ****关于CAP理论**\n\n为什么我们会考虑削弱数据的一致性呢？其实这背后有一个关于分布式系统的理论依据。这个理论最早被 Eric Brewer 提出，称为CAP理论，尔后Gilbert 和 Lynch 对CAP进行了理论证明。这一理论首先把分布式系统中的三个特性进行了如下归纳：\n\n*   一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。*   可用性（A）：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。*   分区容忍性（P）：集群中的某些节点在无法联系后，集群整体是否还能继续进行服务。  \n\n而CAP理论就是说在分布式存储系统中，最多只能实现上面的两点。而由于当前的网络硬件肯定会出现延迟丢包等问题，所以分区容忍性是我们必须需要实现的。所以我们只能在一致性和可用性之间进行权衡，没有NoSQL系统能同时保证这三点。\n\n要保证数据一致性，最简单的方法是令写操作在所有数据节点上都执行成功才能返回成功。而这时如果某个结点出现故障，那么写操作就成功不了了，需要一直等到这个节点恢复。也就是说，如果要保证强一致性，那么就无法提供7×24的高可用性。\n\n而要保证可用性的话，就意味着节点在响应请求时，不用完全考虑整个集群中的数据是否一致。只需要以自己当前的状态进行请求响应。由于并不保证写操作在所有节点都写成功，这可能会导致各个节点的数据状态不一致。\n\nCAP理论导致了最终一致性和强一致性两种选择。当然，事实上还有其它的选择，比如在Yahoo! 的PNUTS中，采用的就是松散的一致性和弱可用性结合的方法。但是我们讨论的NoSQL系统没有类似的实现，所以我们在后续不会对其进行讨论。\n\n**13.5.2 ****强一致性**\n\n强一致性的保证，要求所有数据节点对同一个key值在同一时刻有同样的value值。虽然实际上可能某些节点存储的值是不一样的，但是作为一个整体，当客户端发起对某个key的数据请求时，整个集群对这个key对应的数据会达成一致。下面就举例说明这种一致性是如何实现的。\n\n假设在我们的集群中，一个数据会被备份到N个结点。这N个节点中的某一个可能会扮演协调器的作用。它会保证每一个数据写操作会在成功同步到W个节点后才向客户端返回成功。而当客户端读取数据时，需要至少R个节点返回同样的数据才能返回读操作成功。而NWR之间必须要满足下面关系：R＋W&gt;N\n\n下面举个实在的例子。比如我们设定N＝3（数据会备份到A、B、C三个结点）。比如值 employee30:salary 当前的值是20000，我们想将其修改为30000。我们设定W＝2，下面我们会对A、B、C三个节点发起写操作（employee30:salary, 30000），当A、B两个节点返回写成功后，协调器就会返回给客户端说写成功了。至于节点C，我们可以假设它从来没有收到这个写请求，他保存的依然是20000那个值。之后，当一个协调器执行一个对employee30:salary的读操作时，他还是会发三个请求给A、B、C三个节点：\n\n*   如果设定R＝1，那么当C节点先返回了20000这个值时，那我们客户端实际得到了一个错误的值。*   如果设定R＝2，则当协调器收到20000和30000两个值时，它会发现数据不太正确，并且会在收到第三个节点的30000的值后判断20000这个值是错误的。  \n\n所以如果要保证强一致性，在上面的应用场景中，我们需要设定R＝2，W＝2\n\n如果写操作不能收到W个节点的成功返回，或者写操作不能得到R个一致的结果。那么协调器可能会在某个设定的过期时间之后向客户端返回操作失败，或者是等到系统慢慢调整到一致。这可能就导致系统暂时处于不可用状态。\n\n对于R和W的不同设定，会导致系统在进行不同操作时需要不同数量的机器节点可用。比如你设定在所有备份节点上都写入才算写成功，既W＝N，那么只要有一个备份节点故障，写操作就失败了。一般设定是R＋W = N+1，这是保证强一致性的最小设定了。一些强一致性的系统设定W＝N，R＝1，这样就根本不用考虑各个节点数据可能不一致的情况了。\n\nHBase是借助其底层的HDFS来实现其数据冗余备份的。HDFS采用的就是强一致性保证。在数据没有完全同步到N个节点前，写操作是不会返回成功的。也就是说它的W＝N，而读操作只需要读到一个值即可，也就是说它R＝1。为了不至于让写操作太慢，对多个节点的写操作是并发异步进行的。在直到所有的节点都收到了新的数据后，会自动执行一个swap操作将新数据写入。这个操作是原子性和一致性的。保证了数据在所有节点有一致的值。\n\n**13.5.3 ****最终一致性**\n\n像Voldemort，Cassandra和Riak这些类Dynamo的系统，通常都允许用户按需要设置N，R，W三个值，即使是设置成W＋R&lt;= N也是可以的。也就是说他允许用户在强一致性和最终一致性之间自由选择。而在用户选择了最终一致性，或者是W&lt;N的强一致性时，则总会出现一段各个节点数据不同步导致系统处理不一致的时间。为了提供最终一致性的支持，这些系统会提供一些工具来使数据更新被最终同步到所有相关节点。\n\n下面我们会先讲一讲如何判断数据是最新的还是陈旧的，然后我们再讨论一下如何进行数据同步，最后我们再列举一些Dynamo里使用的加速同步过程的巧妙方法。\n\n**版本控制与冲突**\n\n由于同一份数据在不同的节点可能存在不同值，对数据的版本控制和冲突监测就变得尤为重要。类Dynamo的系统通常都使用了一种叫vector clock（向量时钟）的版本控制机制。一个vector clock可以理解成是一个向量，它包含了这个值在每一个备份节点中修改的次数。比如说有的数据会备份到A，B，C三个节点，那么这些值的vector clock值就是类似（NA，NB，NC），而其初始值为（0，0，0）。\n\n每次一个key的值被修改，其vector clock相应的值就会加1。比如有一个key值当前的vector clock值为（39，1，5），然后他在B节点被修改了一次，那么它的cector clock值就会相应的变成（39，2，5）。而当另一个节点C在收到B节点的同步请求时，他会先用自己保存的vector clock值与B传来的vector clock值进行对比，如果自己的vector clock值的每一项都小于等于B传来的这个值，那么说明这次的修改值是在自已保存的值上的修改，不会有冲突，直接进行相应的修改，并把自己的vector clock值更新。但是如果C发现自己的vector clock有些项比B大，而某些项比B小，比如B的是（39，2，5）C的是（39，1，6），那么这时候说明B的这次修改并不是在C的基础上改的，数据出现冲突了。\n\n**冲突解决**\n\n不同的系统有不同的冲突解决策略。Dynamo选择把冲突留给应用层来解决。如果是两个节点保存的购物车信息冲突了，可以选择简单的通过把两个数据合并进行解决。但如果是对同一份文档进行的修改冲突了，可能就需要人工来解决冲突了（译者：像我们在SVN中做的一样）。Voldemort就是采用的后者，它在发现冲突后，会把有冲突的几份数据一起返回给应用层，把冲突解决留给应用层来做。\n\nCassandra通过为每一个操作保存一个时间戳的方法来解决冲突，在冲突的几个版本里，最后修改的一个会获胜成为新的值。相对于上面的方式，它减少了通过应用层解决冲突时需要的网络访问，同时也简化了客户端的操作API。但这种策略并不适合用来处理一些需要合并冲突的场合，比如上面的购物车的例子，或者是分布式的计数器这样的应用。而Riak把Voldemort和 Cassandra 的策略都实现了。CouchDB会把冲突的key进行标识，以便应用层可以主动进行人工修复，在修复完成前，客户端的请求是无法得到确定值的。\n\n**读时修复**\n\n在数据读取时，如果有R个节点返回了一致的数据，那么协调器就可以认为这个值是正确的并返回给客户端了。但是在总共返回的N个值中，如果协调器发现有的数据不是最新的。那么它可以通过读时修复机制来对这些节点进行处理。这种方式在Dynamo中有描述，在Voldemort 、 Cassandra和Riak中都得到了实现。当协调器发现有的节点数据不是最新时，它会在数据不一致的节点间启动一个冲突解决过程。这样主动的修复策略并不会有多大的工作量。因为读取操作时，各个节点都已经把数据返回给协调器了，所以解决冲突越快，实际上可能造成的后续的不一致的可能性也就越小。\n\n**Hinted Handoff**\n\nCassandra、Riak和Voldemort都实现了一种叫Hinted Handoff的技术，用来保证在有节点故障后系统的写操作不受太大影响。它的过程是如果负责某个key值的某个节点宕机了，另一个节点会被选择作为其临时切换点，以临时保存在故障节点上面的写操作。这些写操作被单独保存起来，直到故障节点恢复正常，临时节点会把这些写操作重新迁移给刚刚恢复的节点。Dynamo 论文中提到一种叫“sloppy quorum”的方法，它会把通过 Hinted Handoff 写成功的临时节点也计算在成功写入数中。但是Cassandra和Voldemort并不会将临时节点也算在写入成功节点数内，如果写入操作并没有成功写在W个正式节点中，它们会返回写入失败。当然，Hinted Handoff 策略在这些系统中也有使用，不过只是用在加速节点恢复上。\n\n**Anti-Entropy**\n\n如果一个节点故障时间太长，或者是其 Hinted Handoff 临时替代节点也故障了，那么新恢复的节点就需要从其它节点中同步数据了。（译者：实际上就是要找出经过这段时间造成的数据差异，并将差异部分同步过来）。这种情况下Cassandra和Riak都实现了在Dynamo文档中提到的一种方法，叫做anti-entropy。在anti-entropy过程中，节点间通过交换Merkle Tree来找出那些不一致的部分。Merkle Tree是一个分层的hash校验机制：如果包含某个key值范围的hash值在两个数据集中不相同，那么不同点就在这个key值范围，同理，如果顶层的hash值相同，那么其负责的所有key值范围内的值都认为是相同的。这种方法的好处是，在节点恢复时，不用把所有的值都传一遍来检查哪些值是有变化的。只需要传几个hash值就能找到不一致的数据，重传这个数据即可。\n\n**Gossip**\n\n当一个分布式系统越来越大，就很难搞清集群中的每个节点的状态了。上面说到的类Dynamo 应用都采用了Dynamo文档中说到的一种古老的方法：Gossip。通过这个方法，节点间能够互相保持联系并能够检测到故障节点。其具体做法是，每隔一段时间（比如一秒），一个节点就会随便找一个曾经有过通信的节点与其交换一下其它节点的健康状态。通过这种方式，节点能够比较快速的了解到集群中哪些节点故障了，从而把这些节点负责的数据分配到其它节点去。（译者：Gossip其实是仿生学的设计，Gossip意思为流言，节点传播其它节点的健康信息，就像一个小村镇里的无聊妇人们互相说别人的闲话一样，基本上谁家谁人出什么事了，都能比较快地被所有人知道）。\n\n**13.6 ****写在最后的话**\n\n目前NoSQL系统来处在它的萌芽期，我们上面讨论到的很多NoSQL系统，他们的架构、设计和接口可能都会改变。本章的目的，不在于让你了解这些NoSQL系统目前是如何工作的，而在于让你理解这些系统之所以这样实现的原因。NoSQL系统把更多的设计工作留给了应用开发工作者来做。理解上面这些组件的架构，不仅能让您写出下一个NoSQL系统，更让您对现有系统应用得更好。\n\n**13.7 ****致谢**\n\n非常感谢Jackie Carter, Mihir Kedia，以及所有对本章进行校对并且提出宝贵意见的人。没有这些年来NoSQL社区的专注工作，也不会有这一章内容的诞生。各位加油。\n  > **相关信息**\n> \n> 原文: [http://www.aosabook.org/en/nosql.html](http://www.aosabook.org/en/nosql.html)\n> \n> 原作者：[Adam Marcus](http://www.aosabook.org/en/intro.html#marcus-adam)\n> \n> 译者：[iammutex](http://lgone.com/)\n> \n> 组织：[NoSQLFan](http://nosqlfan.com/)\n> \n> 翻译时间：2011年6月","slug":"the-nosql-ecosystem","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg620t000rsb8f0ulnpyru"},{"title":"转 - 系统架构领域的一些学习材料","id":"702","date":"2013-03-15T16:00:14.000Z","_content":"\n系统架构是一个工程和研究相结合的领域，既注重实践又依赖理论指导，入门容易但精通很难，有时候还要讲点悟性，很具有“伪科学”的特征。要在此领域进阶，除了要不断设计并搭建实际系统，也要注意方法论和设计理念的学习和提炼。\n\n对于工程师来说，到一定阶段后往往会遇到成长瓶颈。要突破此瓶颈，需要在所属技术领域更深入学习，了解本领域的问题本质、方法论与设计理念、发展历史等。以下提供一些架构相关领域的学习材料，附上简单点评，供有兴趣的工程师参考。希望大家能通过对这些领域的了解和学习，掌握更多system design principles，在自己的工作中得心应手，步入自由王国。\n<!--more-->\n\n&#160;\n\n**1\\. Operating Systems**\n\n**Mach** [Intro: [http://www-2.cs.cmu.edu/afs/cs/project/mach/public/www/mach.html](http://www-2.cs.cmu.edu/afs/cs/project/mach/public/www/mach.html),Paper: [http://www-2.cs.cmu.edu/afs/cs/project/mach/public/www/doc/publications.html](http://www-2.cs.cmu.edu/afs/cs/project/mach/public/www/doc/publications.html)]\n\n传统的kernel实现中，对中断的响应是在一个“大函数”里实现的。称为大函数的原因是从中断的入口到出口都是同一个控制流，当有中断重入发生的时候，实现逻辑将变得非常复杂。大多数的OS，如UNIX，都采用这种monolithic kernel architecture。\n\n1985年开始的Mach项目，提出了一种全新的microkernel结构，使得由于70年代UNIX的发展到了极致而觉得后续无枝可依的学术界顿时找到了兴奋点，也开始了沸沸扬扬的monokernel与microkernel的争论。\n\n插播一个花絮：Mach的主导者Richard Rashid，彼时是CMU的教授，受BillGates之托去游说JimGray加盟MS。结果把自己也被绕了进来，组建了Microsoft Research。他到中国来做过几次21Century Computing的keynotes。\n\n**Exokernel** [Intro:[http://pdos.csail.mit.edu/exo/](http://pdos.csail.mit.edu/exo/)，Paper:[http://pdos.csail.mit.edu/PDOS-papers.html#Exokernels](http://pdos.csail.mit.edu/PDOS-papers.html#Exokernels)]\n\n虽然microkernel的结构很好，但实际中并没有广泛应用，因为performance太差，而且大家逐渐发现OS的问题并不在于实现的复杂性，而更多在于如何提高application使用资源的灵活性。这也就是在kernel extension（例如loadable module in Linux）出现后，有关OS kernel architecture的争论就慢慢淡出人们视线的原因。\n\nExokernel正是在这样的背景中出现的，它并不提供传统OS的abstraction（process,virtual memory等），而是专注于资源隔离与复用（resource isolation and multiplexing），由MIT提出。在exokernel之上，提供了一套库，著名的libOS，用于实现各种OS的interface。这样的结构为application提供了最大的灵活度，使不同的application可以或专注于调度公平性或响应实时性，或专注于提高资源使用效率以优化性能。以今天的眼光来看，exokernel更像是一个virtual machine monitor。\n\n**Singularity** [Intro:[http://research.microsoft.com/os/Singularity/](http://research.microsoft.com/os/Singularity/),Paper: [http://www.     \nresearch.microsoft.com/os/singularity/publications/HotOS2005_BroadNewResearch.pdf](http://www.research.microsoft.com/os/singularity/publications/HotOS2005_BroadNewResearch.pdf)]\n\nSingularity出现在virus，spyware取之不尽、杀之不绝的21世纪初期，由Microsoft Research提出。学术界和工业界都在讨论如何提供一个trust-worthy computing环境，如何使计算机系统更具有manage-ability。Singularity认为要解决这些问题，底层系统必须提供hardisolation，而以前人们都依赖的硬件virtual memory机制并无法提供高灵活性和良好性能。在.Net和Java等runtime出现之后，一个软件级的解决方案成为可能。\n\nSingularity在microkernel的基础上，通过.Net构建了一套type-safed assembly作为ABI，同时规定了数据交换的message passing机制，从根本上防止了修改隔离数据的可能。再加上对application的安全性检查，从而提供一个可控、可管理的操作系统。由于.NetCLR的持续优化以及硬件的发展，加了这些检查后的Singularity在性能上的损失相对于它提供的这些良好特性，仍是可以接受的。\n\n这种设计目前还处于实验室阶段，是否能最终胜出，还需要有当年UNIX的机遇。\n\n&#160;\n\n**2\\. Virtual Machines**\n\n**VMWare** [&quot;[MemoryResource Management in VMware ESX Server](http://www.usenix.org/events/osdi02/tech/waldspurger/waldspurger.pdf)&quot;，OSDI’02,Best paper award]\n\n耳熟能详的vmware，无需多说。\n\n**XEN** [“[Xen and the Art of Virtualization](http://www.cl.cam.ac.uk/research/srg/netos/papers/2003-xensosp.pdf)”, OSDI’04]\n\n性能极好的VMM，来自Cambridge。\n\n**Denali** [“[Scaleand Performance in the Denali Isolation Kernel](http://denali.cs.washington.edu/pubs/distpubs/papers/denali_osdi.pdf)”, OSDI’02, UW]\n\n为internetservices而设计的application level virtual machine，在普通机器上可运行数千个VMs。其VMM基于isolation kernel，提供隔离，但并不要求资源分配绝对公平，以此减少性能消耗。\n\n**Entropia** [“[The Entropia VirtualMachine for Desktop Grids](http://www-csag.ucsd.edu/papers/Entropia-VM.pdf)”, VEE’05]\n\n要统一利用公司内桌面机器资源来进行计算，需要对计算任务进行良好的包装，以保证不影响机器正常使用并与用户数据隔离。Entropia就提供了这样的一个计算环境，基于windows实现了一个application level virtual machine。其基本做法就是对计算任务所调用的syscall进行重定向以保证隔离。类似的工作还有FVM：“[AFeather-weight Virtual Machine for Windows Applications](http://www.usenix.org/events/vee06/full_papers/p24-yu.pdf)”。\n\n&#160;\n\n**3\\. Design Revisited**\n\n “[Are Virtual Machine Monitors Microkernels Done Right?](http://www.usenix.org/event/hotos05/final_papers/full_papers/hand/hand.pdf)”，HotOS’05\n\n这个题目乍听起来，十分费解，其意思是VMMs其实就是Microkernel的正确实现方法。里面详细讨论了VMM和Microkernel，是了解这两个概念的极好参考。\n\n“[Thirty Years Is Long Enough: Getting Beyond C](http://www.usenix.org/events/hotos05/final_papers/full_papers/brewer/brewer.pdf)”, HotOS’05\n\nC可能是这个世界上最成功的编程语言，但其缺点也十分明显。比如不支持thread，在今天高度并行的硬件结构中显得有点力不从心，而这方面则是functional programming language的长处，如何结合二者的优点，是一个很promising的领域。\n\n&#160;\n\n**4\\. Programming Model**\n\n“[Why Threads Are a Bad Idea](http://www.stanford.edu/class/cs240/readings/threads-bad-usenix96.pdf)”\n\n单使用thread结构的server是很难真正做到高性能的，原因在于内存使用、切换开销、同步开销和保证锁正确性带来的编程复杂度等。\n\n“[SEDA: An Architecture for Well-Conditioned, Scalable Internet Services](http://www.eecs.harvard.edu/~mdw/papers/seda-sosp01.pdf)”，OSDI’01\n\nThread不好，但event也没法解决所有问题，于是我们寻找一个结合的方法。SEDA将应用拆分为多个stage，不同stage通过queue相连接，同一个stage内可以启动多个thread来执行queue中的event，并且可通过反馈来自动调整thread数量。\n\n**Software Transactional Memory**\n\n如果内存可以提供transaction语义，那么我们面对的世界将完全两样，language, compiler, OS, runtime都将发生根本变化。虽然intel现在正在做hardware transactional memory，但估计可预见的将来不会商用，所以人们转而寻求软件解决方案。可想而知，这个方案无法base在native assembly上，目前有C#,haskell等语言的实现版本。资料比较多，参见[Wikipedia](http://en.wikipedia.org/wiki/Software_transactional_memory)。\n\n&#160;\n\n**5\\. Distributed Algorithms**\n\n**Logical clock**, [“[Time,clocks, and the ordering of events in a distributed system](http://portal.acm.org/ft_gateway.cfm?id=359563&amp;type=pdf&amp;coll=GUIDE&amp;dl=GUIDE&amp;CFID=12744388&amp;CFTOKEN=15273596)”, Leslie Lamport, 1978]\n\n这是一篇关于Logic clock, time stamp, distributed synchronization的经典paper。\n\n**Byzantine** [“[The ByzantineGenerals Problem](http://research.microsoft.com/users/lamport/pubs/byz.pdf)”, Leslie Lamport, 1982]\n\n分布式系统中的错误各种各样，有出错就能停机的，有出错了拖后腿的，更严重的是出错了会做出恶意行为的。最后的这种malicious behavior，就好像出征将军的叛变，将会对系统造成严重影响。对于这类问题，Lamport提出了Byzantine failure model，对于一个由3f+1个replica组成的statemachine，只要叛变的replica数量小于等于f，整个state machine还能正常工作。\n\n**Paxos** [“[The part-time parliament](http://portal.acm.org/ft_gateway.cfm?id=279229&amp;type=pdf&amp;coll=GUIDE&amp;dl=GUIDE&amp;CFID=12744388&amp;CFTOKEN=15273596)”, Leslie Lamport, 1998]\n\n如何在一个异步的分布式环境中达成consensus，这是分布式算法研究的最根本问题。Paxos是这类算法的顶峰。不过这篇paper太难了，据说全世界就3.5人能看懂，所以Lamport后来又写了一篇普及版paper：“[Paxos Made Simple](http://research.microsoft.com/users/lamport/pubs/paxos-simple.pdf)” ，不过还是很难懂。另外，也可参看Butler Lampson写的“[The ABCD’s of Paxos](http://portal.acm.org/citation.cfm?id=383962.383969&amp;coll=GUIDE&amp;dl=GUIDE&amp;CFID=12744978&amp;CFTOKEN=60475496)”（PODC’01），其中关于replicated state machine的描述会严重启发你对并行世界本质的认识，图灵奖的实力可不是盖的。\n\n这上面反复出现了一个名字：[Leslie Lamport](http://research.microsoft.com/users/lamport/)，他在distributed computing这个领域挖坑不辍，终成一代宗师。关于他，也有几则轶事。记得以前他在MSR的主页是这么写的，“当我在研究logicalclock的时候，BillGates还穿着开裆裤(in diaper)…”（大意如此，原文现在找不到了）。另外，他在写paper的时候，很喜欢把其他牛人的名字变换一下编排进去。这可能也是他还没拿到图灵奖的原因。\n\n关于Lamport的其他成就，还可以参见这篇向他60岁生日献礼的paper：“[Lamport on mutual exclusion: 27 years of planting seeds](http://portal.acm.org/ft_gateway.cfm?id=383967&amp;type=pdf&amp;coll=GUIDE&amp;dl=GUIDE&amp;CFID=12744388&amp;CFTOKEN=15273596)”, PODC’01。\n\n&#160;\n\n**6\\. Overlay Networking, and P2P DHT**\n\n**RON** [“[Resilient Overlay Networks](http://nms.lcs.mit.edu/papers/ron-sosp2001.html)”, SOSP’01]\n\nRON描述了如何在应用层搭建一个overlay，以提供秒级广域网网络层故障恢复速度，而现有的通过路由协议来恢复通信的时间至少在几十分钟。这种快速恢复特性和灵活性使得overlay networking现在被广泛应用。\n\n**Application Level Multicast**\n\n“[End System Multicast](http://www.cs.cmu.edu/~hzhang/papers/sigmetrics-2000.ps.gz)”, SigMetrics’00\n\n“[Scalable Application Layer Multicast](http://pages.cs.wisc.edu/~suman/pubs/sigcomm02.pdf)”, SigComm’02\n\n关于ALM的paper很多，基本上都是描述如何搭建一个mesh network用以鲁棒的传输控制信息，另外再搭建一个multicast tree用以高效传输数据，然后再根据多媒体数据的特点做一些layered delivery。前几年出现的coolstream, pplive等系统都是这类系统的商业化产品。\n\n**P2P**\n\nP2P的出现改变了网络。按照各种P2P网络的结构，可以分为三种。\n\n1.&#160;&#160;&#160; Napster式，集中式目录服务，数据传输Peer to peer。\n\n2.&#160;&#160;&#160; Gnutella式，通过在邻居间gossip来查询，也被称为unstructured P2P。\n\n3.&#160;&#160;&#160; DHT，与unstructured P2P不同的是，DHT进行的查询有保证，如果数据存在，可在一定的hop数内返回。这个hop数通常为logN，N为系统节点数。\n\n典型的DHT有[CAN](http://berkeley.intel-research.net/sylvia/cans.pdf), [Chord](http://pdos.csail.mit.edu/papers/chord:sigcomm01/chord_sigcomm.pdf),[Pastry](http://research.microsoft.com/~antr/PAST/pastry.pdf), [Tapestry](http://oceanstore.cs.berkeley.edu/publications/papers/pdf/tapestry_sigcomm_tr.pdf)等四种。这些研究主要在算法层面，系统方面的工作主要是在其上建立广域网存储系统。还有一些人在机制层面进行研究，例如如何激励用户共享、防止作弊等。\n\n&#160;\n\n**7\\. Distributed Systems**\n\n**GFS/MapReduce/BigTable/Chubby/Sawzall**\n\nGoogle的系列paper，大家比较熟悉，不再多说。在[此](http://research.google.com/pubs/papers.html)可查。\n\n**Storage**\n\nDistributed storage system的paper太多了。下面列出几篇最相关的。\n\n“[Chain Replication for Supporting High Throughput and Availability](http://www.cs.cornell.edu/fbs/publications/chainreplicosdi.pdf)”, OSDI’04。\n\n“[Dynamo: Amazon’s Highly Available Key-value Store](http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf)”，SOSP’07。\n\n“[BitVault: a Highly Reliable Distributed Data Retention Platform](http://research.microsoft.com/asia/dload_files/group/system/2007/BitVault-SigOpsOSR0704.pdf)”, SIGOPS OSR’07。\n\n“<a>PacificA: Replication inLog-Based Distributed Storage Systems</a>”, MSR-TR。\n\n**Distributed Simulation**\n\n“[Simulating Large-Scale P2P Systems with the WiDS Toolkit](http://research.microsoft.com/asia/dload_files/group/system/wids-mascots.pdf)”, MASCOTS’05。Distributed simulation有意思的地方是simulated protocol是distributed的，而这个simulation engine本身也是distributed的。Logical和physical的time和event交杂在系统中，需要仔细处理。\n\n&#160;\n\n**8\\. Controversial Computing Models**\n\n现在的软件系统已经复杂到了人已经无法掌握的程度，很多系统在发布时都仍然带着许多确定性(deterministic)或非确定性(non-deterministic)的bugs，只能不断的patch。既然作为人类，不够精细的特性决定了我们无法把系统的bug fix干净，我们只能从其他角度入手研究一种让系统在这令人沮丧的环境中仍能工作的方法。这就像一个分布式系统，故障无法避免，我们选择让系统作为整体来提供高可靠性。\n\n以下3个便是典型代表。基本上，主要研究内容都集中于1) 如何正确保存状态；2)如何捕捉错误并恢复状态；3)在进行单元级恢复时，如何做到不影响整体。\n\n[Recovery Oriented Computing](http://roc.cs.berkeley.edu/)\n\n[Failure oblivious computing](http://www.cag.lcs.mit.edu/~rinard/paper/osdi04.pdf), OSDI’04\n\n[Treating Bugs as Allergies](http://opera.cs.uiuc.edu/paper/Rx-SOSP05.pdf), SOSP’05\n\n&#160;\n\n**9\\. Debugging**\n\n系统很复杂，人类无法从逻辑上直接分析，只能通过data mining的方法在宏观上进行观察。\n\nBlack box debugging[“[Performance debugging for distributed systems of black boxes](http://pdos.csail.mit.edu/~athicha/papers/blackboxes:sosp03.pdf)”, SOSP’03]\n\n对大型系统的performance debugging非常困难，因为里面的问题很多都是非确定性的，而且无法重现。只能通过对log的挖掘，找出配对的调用/消息以定位问题。\n\nCP-miner [“A Tool for Finding Copy-paste and Related Bugs in Operating System Code”, OSDI’04]\n\n很多人在重用代码的时候，都使用copy-paste。但有时候简单的CP会带来严重的问题，例如局部变量的重名等。CP-miner通过分析代码，建立语法树结构，然后mine出这类错误。\n\n&#160;\n  > 转载：[http://qing.weibo.com/2244218960/85c41050330031zq.html](http://qing.weibo.com/2244218960/85c41050330031zq.html \"http://qing.weibo.com/2244218960/85c41050330031zq.html\")&#160;&#160; [@林士鼎](http://weibo.com/linshiding)","source":"_posts/system-architecture-stuffs.md","raw":"title: 转 - 系统架构领域的一些学习材料\ntags:\n  - 系统架构\nid: 702\ncategories:\n  - 技术分享\ndate: 2013-03-16 00:00:14\n---\n\n系统架构是一个工程和研究相结合的领域，既注重实践又依赖理论指导，入门容易但精通很难，有时候还要讲点悟性，很具有“伪科学”的特征。要在此领域进阶，除了要不断设计并搭建实际系统，也要注意方法论和设计理念的学习和提炼。\n\n对于工程师来说，到一定阶段后往往会遇到成长瓶颈。要突破此瓶颈，需要在所属技术领域更深入学习，了解本领域的问题本质、方法论与设计理念、发展历史等。以下提供一些架构相关领域的学习材料，附上简单点评，供有兴趣的工程师参考。希望大家能通过对这些领域的了解和学习，掌握更多system design principles，在自己的工作中得心应手，步入自由王国。\n<!--more-->\n\n&#160;\n\n**1\\. Operating Systems**\n\n**Mach** [Intro: [http://www-2.cs.cmu.edu/afs/cs/project/mach/public/www/mach.html](http://www-2.cs.cmu.edu/afs/cs/project/mach/public/www/mach.html),Paper: [http://www-2.cs.cmu.edu/afs/cs/project/mach/public/www/doc/publications.html](http://www-2.cs.cmu.edu/afs/cs/project/mach/public/www/doc/publications.html)]\n\n传统的kernel实现中，对中断的响应是在一个“大函数”里实现的。称为大函数的原因是从中断的入口到出口都是同一个控制流，当有中断重入发生的时候，实现逻辑将变得非常复杂。大多数的OS，如UNIX，都采用这种monolithic kernel architecture。\n\n1985年开始的Mach项目，提出了一种全新的microkernel结构，使得由于70年代UNIX的发展到了极致而觉得后续无枝可依的学术界顿时找到了兴奋点，也开始了沸沸扬扬的monokernel与microkernel的争论。\n\n插播一个花絮：Mach的主导者Richard Rashid，彼时是CMU的教授，受BillGates之托去游说JimGray加盟MS。结果把自己也被绕了进来，组建了Microsoft Research。他到中国来做过几次21Century Computing的keynotes。\n\n**Exokernel** [Intro:[http://pdos.csail.mit.edu/exo/](http://pdos.csail.mit.edu/exo/)，Paper:[http://pdos.csail.mit.edu/PDOS-papers.html#Exokernels](http://pdos.csail.mit.edu/PDOS-papers.html#Exokernels)]\n\n虽然microkernel的结构很好，但实际中并没有广泛应用，因为performance太差，而且大家逐渐发现OS的问题并不在于实现的复杂性，而更多在于如何提高application使用资源的灵活性。这也就是在kernel extension（例如loadable module in Linux）出现后，有关OS kernel architecture的争论就慢慢淡出人们视线的原因。\n\nExokernel正是在这样的背景中出现的，它并不提供传统OS的abstraction（process,virtual memory等），而是专注于资源隔离与复用（resource isolation and multiplexing），由MIT提出。在exokernel之上，提供了一套库，著名的libOS，用于实现各种OS的interface。这样的结构为application提供了最大的灵活度，使不同的application可以或专注于调度公平性或响应实时性，或专注于提高资源使用效率以优化性能。以今天的眼光来看，exokernel更像是一个virtual machine monitor。\n\n**Singularity** [Intro:[http://research.microsoft.com/os/Singularity/](http://research.microsoft.com/os/Singularity/),Paper: [http://www.     \nresearch.microsoft.com/os/singularity/publications/HotOS2005_BroadNewResearch.pdf](http://www.research.microsoft.com/os/singularity/publications/HotOS2005_BroadNewResearch.pdf)]\n\nSingularity出现在virus，spyware取之不尽、杀之不绝的21世纪初期，由Microsoft Research提出。学术界和工业界都在讨论如何提供一个trust-worthy computing环境，如何使计算机系统更具有manage-ability。Singularity认为要解决这些问题，底层系统必须提供hardisolation，而以前人们都依赖的硬件virtual memory机制并无法提供高灵活性和良好性能。在.Net和Java等runtime出现之后，一个软件级的解决方案成为可能。\n\nSingularity在microkernel的基础上，通过.Net构建了一套type-safed assembly作为ABI，同时规定了数据交换的message passing机制，从根本上防止了修改隔离数据的可能。再加上对application的安全性检查，从而提供一个可控、可管理的操作系统。由于.NetCLR的持续优化以及硬件的发展，加了这些检查后的Singularity在性能上的损失相对于它提供的这些良好特性，仍是可以接受的。\n\n这种设计目前还处于实验室阶段，是否能最终胜出，还需要有当年UNIX的机遇。\n\n&#160;\n\n**2\\. Virtual Machines**\n\n**VMWare** [&quot;[MemoryResource Management in VMware ESX Server](http://www.usenix.org/events/osdi02/tech/waldspurger/waldspurger.pdf)&quot;，OSDI’02,Best paper award]\n\n耳熟能详的vmware，无需多说。\n\n**XEN** [“[Xen and the Art of Virtualization](http://www.cl.cam.ac.uk/research/srg/netos/papers/2003-xensosp.pdf)”, OSDI’04]\n\n性能极好的VMM，来自Cambridge。\n\n**Denali** [“[Scaleand Performance in the Denali Isolation Kernel](http://denali.cs.washington.edu/pubs/distpubs/papers/denali_osdi.pdf)”, OSDI’02, UW]\n\n为internetservices而设计的application level virtual machine，在普通机器上可运行数千个VMs。其VMM基于isolation kernel，提供隔离，但并不要求资源分配绝对公平，以此减少性能消耗。\n\n**Entropia** [“[The Entropia VirtualMachine for Desktop Grids](http://www-csag.ucsd.edu/papers/Entropia-VM.pdf)”, VEE’05]\n\n要统一利用公司内桌面机器资源来进行计算，需要对计算任务进行良好的包装，以保证不影响机器正常使用并与用户数据隔离。Entropia就提供了这样的一个计算环境，基于windows实现了一个application level virtual machine。其基本做法就是对计算任务所调用的syscall进行重定向以保证隔离。类似的工作还有FVM：“[AFeather-weight Virtual Machine for Windows Applications](http://www.usenix.org/events/vee06/full_papers/p24-yu.pdf)”。\n\n&#160;\n\n**3\\. Design Revisited**\n\n “[Are Virtual Machine Monitors Microkernels Done Right?](http://www.usenix.org/event/hotos05/final_papers/full_papers/hand/hand.pdf)”，HotOS’05\n\n这个题目乍听起来，十分费解，其意思是VMMs其实就是Microkernel的正确实现方法。里面详细讨论了VMM和Microkernel，是了解这两个概念的极好参考。\n\n“[Thirty Years Is Long Enough: Getting Beyond C](http://www.usenix.org/events/hotos05/final_papers/full_papers/brewer/brewer.pdf)”, HotOS’05\n\nC可能是这个世界上最成功的编程语言，但其缺点也十分明显。比如不支持thread，在今天高度并行的硬件结构中显得有点力不从心，而这方面则是functional programming language的长处，如何结合二者的优点，是一个很promising的领域。\n\n&#160;\n\n**4\\. Programming Model**\n\n“[Why Threads Are a Bad Idea](http://www.stanford.edu/class/cs240/readings/threads-bad-usenix96.pdf)”\n\n单使用thread结构的server是很难真正做到高性能的，原因在于内存使用、切换开销、同步开销和保证锁正确性带来的编程复杂度等。\n\n“[SEDA: An Architecture for Well-Conditioned, Scalable Internet Services](http://www.eecs.harvard.edu/~mdw/papers/seda-sosp01.pdf)”，OSDI’01\n\nThread不好，但event也没法解决所有问题，于是我们寻找一个结合的方法。SEDA将应用拆分为多个stage，不同stage通过queue相连接，同一个stage内可以启动多个thread来执行queue中的event，并且可通过反馈来自动调整thread数量。\n\n**Software Transactional Memory**\n\n如果内存可以提供transaction语义，那么我们面对的世界将完全两样，language, compiler, OS, runtime都将发生根本变化。虽然intel现在正在做hardware transactional memory，但估计可预见的将来不会商用，所以人们转而寻求软件解决方案。可想而知，这个方案无法base在native assembly上，目前有C#,haskell等语言的实现版本。资料比较多，参见[Wikipedia](http://en.wikipedia.org/wiki/Software_transactional_memory)。\n\n&#160;\n\n**5\\. Distributed Algorithms**\n\n**Logical clock**, [“[Time,clocks, and the ordering of events in a distributed system](http://portal.acm.org/ft_gateway.cfm?id=359563&amp;type=pdf&amp;coll=GUIDE&amp;dl=GUIDE&amp;CFID=12744388&amp;CFTOKEN=15273596)”, Leslie Lamport, 1978]\n\n这是一篇关于Logic clock, time stamp, distributed synchronization的经典paper。\n\n**Byzantine** [“[The ByzantineGenerals Problem](http://research.microsoft.com/users/lamport/pubs/byz.pdf)”, Leslie Lamport, 1982]\n\n分布式系统中的错误各种各样，有出错就能停机的，有出错了拖后腿的，更严重的是出错了会做出恶意行为的。最后的这种malicious behavior，就好像出征将军的叛变，将会对系统造成严重影响。对于这类问题，Lamport提出了Byzantine failure model，对于一个由3f+1个replica组成的statemachine，只要叛变的replica数量小于等于f，整个state machine还能正常工作。\n\n**Paxos** [“[The part-time parliament](http://portal.acm.org/ft_gateway.cfm?id=279229&amp;type=pdf&amp;coll=GUIDE&amp;dl=GUIDE&amp;CFID=12744388&amp;CFTOKEN=15273596)”, Leslie Lamport, 1998]\n\n如何在一个异步的分布式环境中达成consensus，这是分布式算法研究的最根本问题。Paxos是这类算法的顶峰。不过这篇paper太难了，据说全世界就3.5人能看懂，所以Lamport后来又写了一篇普及版paper：“[Paxos Made Simple](http://research.microsoft.com/users/lamport/pubs/paxos-simple.pdf)” ，不过还是很难懂。另外，也可参看Butler Lampson写的“[The ABCD’s of Paxos](http://portal.acm.org/citation.cfm?id=383962.383969&amp;coll=GUIDE&amp;dl=GUIDE&amp;CFID=12744978&amp;CFTOKEN=60475496)”（PODC’01），其中关于replicated state machine的描述会严重启发你对并行世界本质的认识，图灵奖的实力可不是盖的。\n\n这上面反复出现了一个名字：[Leslie Lamport](http://research.microsoft.com/users/lamport/)，他在distributed computing这个领域挖坑不辍，终成一代宗师。关于他，也有几则轶事。记得以前他在MSR的主页是这么写的，“当我在研究logicalclock的时候，BillGates还穿着开裆裤(in diaper)…”（大意如此，原文现在找不到了）。另外，他在写paper的时候，很喜欢把其他牛人的名字变换一下编排进去。这可能也是他还没拿到图灵奖的原因。\n\n关于Lamport的其他成就，还可以参见这篇向他60岁生日献礼的paper：“[Lamport on mutual exclusion: 27 years of planting seeds](http://portal.acm.org/ft_gateway.cfm?id=383967&amp;type=pdf&amp;coll=GUIDE&amp;dl=GUIDE&amp;CFID=12744388&amp;CFTOKEN=15273596)”, PODC’01。\n\n&#160;\n\n**6\\. Overlay Networking, and P2P DHT**\n\n**RON** [“[Resilient Overlay Networks](http://nms.lcs.mit.edu/papers/ron-sosp2001.html)”, SOSP’01]\n\nRON描述了如何在应用层搭建一个overlay，以提供秒级广域网网络层故障恢复速度，而现有的通过路由协议来恢复通信的时间至少在几十分钟。这种快速恢复特性和灵活性使得overlay networking现在被广泛应用。\n\n**Application Level Multicast**\n\n“[End System Multicast](http://www.cs.cmu.edu/~hzhang/papers/sigmetrics-2000.ps.gz)”, SigMetrics’00\n\n“[Scalable Application Layer Multicast](http://pages.cs.wisc.edu/~suman/pubs/sigcomm02.pdf)”, SigComm’02\n\n关于ALM的paper很多，基本上都是描述如何搭建一个mesh network用以鲁棒的传输控制信息，另外再搭建一个multicast tree用以高效传输数据，然后再根据多媒体数据的特点做一些layered delivery。前几年出现的coolstream, pplive等系统都是这类系统的商业化产品。\n\n**P2P**\n\nP2P的出现改变了网络。按照各种P2P网络的结构，可以分为三种。\n\n1.&#160;&#160;&#160; Napster式，集中式目录服务，数据传输Peer to peer。\n\n2.&#160;&#160;&#160; Gnutella式，通过在邻居间gossip来查询，也被称为unstructured P2P。\n\n3.&#160;&#160;&#160; DHT，与unstructured P2P不同的是，DHT进行的查询有保证，如果数据存在，可在一定的hop数内返回。这个hop数通常为logN，N为系统节点数。\n\n典型的DHT有[CAN](http://berkeley.intel-research.net/sylvia/cans.pdf), [Chord](http://pdos.csail.mit.edu/papers/chord:sigcomm01/chord_sigcomm.pdf),[Pastry](http://research.microsoft.com/~antr/PAST/pastry.pdf), [Tapestry](http://oceanstore.cs.berkeley.edu/publications/papers/pdf/tapestry_sigcomm_tr.pdf)等四种。这些研究主要在算法层面，系统方面的工作主要是在其上建立广域网存储系统。还有一些人在机制层面进行研究，例如如何激励用户共享、防止作弊等。\n\n&#160;\n\n**7\\. Distributed Systems**\n\n**GFS/MapReduce/BigTable/Chubby/Sawzall**\n\nGoogle的系列paper，大家比较熟悉，不再多说。在[此](http://research.google.com/pubs/papers.html)可查。\n\n**Storage**\n\nDistributed storage system的paper太多了。下面列出几篇最相关的。\n\n“[Chain Replication for Supporting High Throughput and Availability](http://www.cs.cornell.edu/fbs/publications/chainreplicosdi.pdf)”, OSDI’04。\n\n“[Dynamo: Amazon’s Highly Available Key-value Store](http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf)”，SOSP’07。\n\n“[BitVault: a Highly Reliable Distributed Data Retention Platform](http://research.microsoft.com/asia/dload_files/group/system/2007/BitVault-SigOpsOSR0704.pdf)”, SIGOPS OSR’07。\n\n“<a>PacificA: Replication inLog-Based Distributed Storage Systems</a>”, MSR-TR。\n\n**Distributed Simulation**\n\n“[Simulating Large-Scale P2P Systems with the WiDS Toolkit](http://research.microsoft.com/asia/dload_files/group/system/wids-mascots.pdf)”, MASCOTS’05。Distributed simulation有意思的地方是simulated protocol是distributed的，而这个simulation engine本身也是distributed的。Logical和physical的time和event交杂在系统中，需要仔细处理。\n\n&#160;\n\n**8\\. Controversial Computing Models**\n\n现在的软件系统已经复杂到了人已经无法掌握的程度，很多系统在发布时都仍然带着许多确定性(deterministic)或非确定性(non-deterministic)的bugs，只能不断的patch。既然作为人类，不够精细的特性决定了我们无法把系统的bug fix干净，我们只能从其他角度入手研究一种让系统在这令人沮丧的环境中仍能工作的方法。这就像一个分布式系统，故障无法避免，我们选择让系统作为整体来提供高可靠性。\n\n以下3个便是典型代表。基本上，主要研究内容都集中于1) 如何正确保存状态；2)如何捕捉错误并恢复状态；3)在进行单元级恢复时，如何做到不影响整体。\n\n[Recovery Oriented Computing](http://roc.cs.berkeley.edu/)\n\n[Failure oblivious computing](http://www.cag.lcs.mit.edu/~rinard/paper/osdi04.pdf), OSDI’04\n\n[Treating Bugs as Allergies](http://opera.cs.uiuc.edu/paper/Rx-SOSP05.pdf), SOSP’05\n\n&#160;\n\n**9\\. Debugging**\n\n系统很复杂，人类无法从逻辑上直接分析，只能通过data mining的方法在宏观上进行观察。\n\nBlack box debugging[“[Performance debugging for distributed systems of black boxes](http://pdos.csail.mit.edu/~athicha/papers/blackboxes:sosp03.pdf)”, SOSP’03]\n\n对大型系统的performance debugging非常困难，因为里面的问题很多都是非确定性的，而且无法重现。只能通过对log的挖掘，找出配对的调用/消息以定位问题。\n\nCP-miner [“A Tool for Finding Copy-paste and Related Bugs in Operating System Code”, OSDI’04]\n\n很多人在重用代码的时候，都使用copy-paste。但有时候简单的CP会带来严重的问题，例如局部变量的重名等。CP-miner通过分析代码，建立语法树结构，然后mine出这类错误。\n\n&#160;\n  > 转载：[http://qing.weibo.com/2244218960/85c41050330031zq.html](http://qing.weibo.com/2244218960/85c41050330031zq.html \"http://qing.weibo.com/2244218960/85c41050330031zq.html\")&#160;&#160; [@林士鼎](http://weibo.com/linshiding)","slug":"system-architecture-stuffs","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg620v000vsb8ft22vrm2a"},{"title":"学校与社会学习的不同","id":"118","date":"2011-03-08T16:59:51.000Z","_content":"\n我现在谈这个似乎还挺嫩，但是还是表达一下自己的看法吧，给以后更成熟的我做一个对比。\n\n从小受我爸的熏陶，官场商场酒桌歌厅到处溜达，也见识了不少社会的“陋习”。酒桌文化、烟文化等。可以说，大学前我还算一个小混混吧，留着近似齐肩的头发，穿着长似连衣裙的衣服，踩着牛腿粗的裤脚，带着蝙蝠侠的白色镜框，不过还好我不抽烟不嗜酒不打牌。\n\n<!--more-->很幸运，我考到了湖南师范大学这个“人文”气息很浓的学校，让我这理科生受了不少熏陶。同时，在这四年的学习生活中，我也开始思考人生，思考我的价值观。我不爱金钱，可能是因为我不“太缺”；我不爱购物，可能是我没相关“品位”；我不爱享乐，可能是因为我一直生活在快乐中。\n\n我一个很好的朋友向往纸醉金迷的生活，我也向往，我向往我内心的“纸醉金迷”。那么，如何让我内心“纸醉金迷”呢？琢磨了这么多年，想到了几种方式。第一，多读书，充实自己；第二，如GZ所说，朋友好，才是真的好；第三，达到自己改变世界的梦想，很难，但是很有诱惑力。\n\n那么，回到我的标题，学校与社会学习的不同。我在思考，如果我没有读大学，那么现在的我是什么样的？可能也有点小成就，但是那时候的我会真正快乐吗？\n\n根据我上面说的，不知道你有没有看出来，我要说的不同在哪。我认为的不同就是这两种知识的吸收内容以及方式不同。大学吸收的基础的知识，社会吸收的应用的知识；大学吸收方方面面的知识，社会吸收为人处世交际的知识；大学扎实的吸收，社会浮躁的吸收。\n\n为什么这么说呢，大学是百科知识的大熔炉，而社会是分门别类的机器工厂，社会只看重利益，人容易迷失自己的方向，而喜欢走捷径去达到想到的目标，这样的方式本身并没有错，但是我觉得会导致精神的空虚，但是想摆脱这样的环境的确很难，有几人能做到出污泥而不染呢？我不能，我能做的，就是尽量少“染”一些污泥，少染的方法只能多读书多见识多交流，以从精神上充实自己。\n\n这也算一个愿意在学校里面再待几年的原因，我想在学校里面再扎实的吸收一些基础的方方面面的知识，让精神在可能的境况下尽可能的多吸收。\n\n现在，你能谈谈你对学校与社会学习的不同吗？顺带问句，你空虚吗？","source":"_posts/study-school-sociey.md","raw":"title: 学校与社会学习的不同\ntags:\n  - 价值观\nid: 118\ncategories:\n  - 生活分享\ndate: 2011-03-09 00:59:51\n---\n\n我现在谈这个似乎还挺嫩，但是还是表达一下自己的看法吧，给以后更成熟的我做一个对比。\n\n从小受我爸的熏陶，官场商场酒桌歌厅到处溜达，也见识了不少社会的“陋习”。酒桌文化、烟文化等。可以说，大学前我还算一个小混混吧，留着近似齐肩的头发，穿着长似连衣裙的衣服，踩着牛腿粗的裤脚，带着蝙蝠侠的白色镜框，不过还好我不抽烟不嗜酒不打牌。\n\n<!--more-->很幸运，我考到了湖南师范大学这个“人文”气息很浓的学校，让我这理科生受了不少熏陶。同时，在这四年的学习生活中，我也开始思考人生，思考我的价值观。我不爱金钱，可能是因为我不“太缺”；我不爱购物，可能是我没相关“品位”；我不爱享乐，可能是因为我一直生活在快乐中。\n\n我一个很好的朋友向往纸醉金迷的生活，我也向往，我向往我内心的“纸醉金迷”。那么，如何让我内心“纸醉金迷”呢？琢磨了这么多年，想到了几种方式。第一，多读书，充实自己；第二，如GZ所说，朋友好，才是真的好；第三，达到自己改变世界的梦想，很难，但是很有诱惑力。\n\n那么，回到我的标题，学校与社会学习的不同。我在思考，如果我没有读大学，那么现在的我是什么样的？可能也有点小成就，但是那时候的我会真正快乐吗？\n\n根据我上面说的，不知道你有没有看出来，我要说的不同在哪。我认为的不同就是这两种知识的吸收内容以及方式不同。大学吸收的基础的知识，社会吸收的应用的知识；大学吸收方方面面的知识，社会吸收为人处世交际的知识；大学扎实的吸收，社会浮躁的吸收。\n\n为什么这么说呢，大学是百科知识的大熔炉，而社会是分门别类的机器工厂，社会只看重利益，人容易迷失自己的方向，而喜欢走捷径去达到想到的目标，这样的方式本身并没有错，但是我觉得会导致精神的空虚，但是想摆脱这样的环境的确很难，有几人能做到出污泥而不染呢？我不能，我能做的，就是尽量少“染”一些污泥，少染的方法只能多读书多见识多交流，以从精神上充实自己。\n\n这也算一个愿意在学校里面再待几年的原因，我想在学校里面再扎实的吸收一些基础的方方面面的知识，让精神在可能的境况下尽可能的多吸收。\n\n现在，你能谈谈你对学校与社会学习的不同吗？顺带问句，你空虚吗？","slug":"study-school-sociey","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg620w000zsb8fj4kdfeh0"},{"title":"Solr Query Parser学习有感","id":"845","date":"2013-08-31T02:55:12.000Z","_content":"\n**1、前言**\n\n\t早上了解QueryParser的时候，发现了一个有意思的插件-SwitchQueryParser。看名字有种高端大气上档次的感觉，但是用起来好像就没这种感觉了，因为好像功能确实有限，这插件只是提供了一种更为&ldquo;友好&rdquo;的filter query功能。\n\n<!--more-->\n\n\t&nbsp;\n\n\t**2、细说**\n\n\t插件的语法如下：\n\n> fq={!switch case.foo=XXX case.bar=zzz case.yak=qqq}foo\n\n\t这个语法是官方文档里面的，这算个什么嘛，还真只是语法，一点逻辑都没有！！！我就写了带一点点逻辑的查询语句如下：\n\n> fq={!switch case.cs=city:changsha case.bj=city:beijing}cs\n\n\t这句话翻译过来，其实就是：\n\n> fq=city:changsha\n\n\t因为在SwitchQParserPlugin的parse()中，只是找到了localParams的v属性（即cs），再从SWITCH_CASE对应的字段，获得相应的查询语句后，返回子查询对象。由于Solr模块可移植性强加上逻辑实在是过于简单，所以做低版本移植也非常方便，几(M&eacute;i)分(yǒu)钟(y&agrave;n)搞(zh&egrave;ng)定(ā)。\n\n\t如下：\n\n\t[![image](http://hongweiyi.com/wp-content/uploads/2013/08/image_thumb.png \"image\")](http://hongweiyi.com/wp-content/uploads/2013/08/image.png)&nbsp;\n\n\t部分源码：\n\n[code lang=\"java\"]\n/** SwitchQParserPlugin */\n@Override\npublic Query parse() throws SyntaxError {\n  String val = localParams.get(QueryParsing.V);\n\n  // we don't want to wrapDefaults arround params, because then \n  // clients could add their own switch options \n  String subQ = localParams.get(SWITCH_DEFAULT);\n  subQ = StringUtils.isBlank(val)\n    ? localParams.get(SWITCH_CASE, subQ)\n    : localParams.get(SWITCH_CASE + &quot;.&quot; + val.trim(), subQ);\n\n  if (null == subQ) {\n    throw new SyntaxError(&quot;No &quot;+SWITCH_DEFAULT+&quot;, and no switch case matching specified query string: \\&quot;&quot; + val + &quot;\\&quot;&quot;);\n  }\n\n  subParser = subQuery(subQ, null);\n  return subParser.getQuery();\n}\n[/code]\n\n\t&nbsp;\n\n\t**3、有感**\n\n\t这个插件的使用场景我觉得更多的是在业务层使用，由业务层封装多个case，将多个case的值暴露给更上层的业务，提供一个较为友好的交互方式。比如下面这种（肯定实际不是这么做的）：\n\n\t[![QQ图片20130831103315](http://hongweiyi.com/wp-content/uploads/2013/08/QQ20130831103315_thumb.jpg \"QQ图片20130831103315\")](http://hongweiyi.com/wp-content/uploads/2013/08/QQ20130831103315.jpg)\n\n\t总的来说，这个插件对于我们现在的系统而言，用处不大，但是Solr的这种查询方式，这种插件式编码方式，很值得我们借鉴和学习。","source":"_posts/solr-switch-query-parser.md","raw":"title: Solr Query Parser学习有感\ntags:\n  - Solr\nid: 845\ncategories:\n  - 技术分享\ndate: 2013-08-31 10:55:12\n---\n\n**1、前言**\n\n\t早上了解QueryParser的时候，发现了一个有意思的插件-SwitchQueryParser。看名字有种高端大气上档次的感觉，但是用起来好像就没这种感觉了，因为好像功能确实有限，这插件只是提供了一种更为&ldquo;友好&rdquo;的filter query功能。\n\n<!--more-->\n\n\t&nbsp;\n\n\t**2、细说**\n\n\t插件的语法如下：\n\n> fq={!switch case.foo=XXX case.bar=zzz case.yak=qqq}foo\n\n\t这个语法是官方文档里面的，这算个什么嘛，还真只是语法，一点逻辑都没有！！！我就写了带一点点逻辑的查询语句如下：\n\n> fq={!switch case.cs=city:changsha case.bj=city:beijing}cs\n\n\t这句话翻译过来，其实就是：\n\n> fq=city:changsha\n\n\t因为在SwitchQParserPlugin的parse()中，只是找到了localParams的v属性（即cs），再从SWITCH_CASE对应的字段，获得相应的查询语句后，返回子查询对象。由于Solr模块可移植性强加上逻辑实在是过于简单，所以做低版本移植也非常方便，几(M&eacute;i)分(yǒu)钟(y&agrave;n)搞(zh&egrave;ng)定(ā)。\n\n\t如下：\n\n\t[![image](http://hongweiyi.com/wp-content/uploads/2013/08/image_thumb.png \"image\")](http://hongweiyi.com/wp-content/uploads/2013/08/image.png)&nbsp;\n\n\t部分源码：\n\n[code lang=\"java\"]\n/** SwitchQParserPlugin */\n@Override\npublic Query parse() throws SyntaxError {\n  String val = localParams.get(QueryParsing.V);\n\n  // we don't want to wrapDefaults arround params, because then \n  // clients could add their own switch options \n  String subQ = localParams.get(SWITCH_DEFAULT);\n  subQ = StringUtils.isBlank(val)\n    ? localParams.get(SWITCH_CASE, subQ)\n    : localParams.get(SWITCH_CASE + &quot;.&quot; + val.trim(), subQ);\n\n  if (null == subQ) {\n    throw new SyntaxError(&quot;No &quot;+SWITCH_DEFAULT+&quot;, and no switch case matching specified query string: \\&quot;&quot; + val + &quot;\\&quot;&quot;);\n  }\n\n  subParser = subQuery(subQ, null);\n  return subParser.getQuery();\n}\n[/code]\n\n\t&nbsp;\n\n\t**3、有感**\n\n\t这个插件的使用场景我觉得更多的是在业务层使用，由业务层封装多个case，将多个case的值暴露给更上层的业务，提供一个较为友好的交互方式。比如下面这种（肯定实际不是这么做的）：\n\n\t[![QQ图片20130831103315](http://hongweiyi.com/wp-content/uploads/2013/08/QQ20130831103315_thumb.jpg \"QQ图片20130831103315\")](http://hongweiyi.com/wp-content/uploads/2013/08/QQ20130831103315.jpg)\n\n\t总的来说，这个插件对于我们现在的系统而言，用处不大，但是Solr的这种查询方式，这种插件式编码方式，很值得我们借鉴和学习。","slug":"solr-switch-query-parser","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg620y0013sb8fkcydi3hs"},{"title":"单反相机与旁轴相机分别是什么","id":"157","date":"2011-09-01T11:12:50.000Z","_content":"\n**命名：单反为什么叫单反，旁轴为什么叫旁轴**\n\n单反，全名“单镜头反光相机”(Single Lens Reflex，简称SLR)。单反一次只能装一个镜头，所以叫“单镜头”。单反里面有反光板，把通过镜头采集近来的光反射到人眼睛里(下文有详细解释)，所以叫“反光”。单反可以拍照，所以叫“相机”。相机有胶卷的和数码的，所以有胶片单反(Film SLR, FSLR)和数码单反(Digital SLR, DSLR)两种。数码单反是不能装胶卷的。\n\n旁轴(Rangefinder, RF)，解释起来不如单反那么容易。单反凭借其反光板系统，是通过镜头取景的，也就是你眼睛贴到相机上看到的景象是从镜头看出去的景象。而旁轴的取景系统是独立于镜头之外的，取景的光路跟镜头进来的光路是两条不同的光路。那为什么叫旁轴呢？我的理解是除开拍照那条光路轴线，“旁”边还存在取景的那条光路“轴”线，所以叫“旁轴”。可能理解错了，但事实基本上如此。\n\n<!--more-->\n\n**旁轴相机长什么样？**\n\n单反相机大家都见过，大部分记者都用单反。体育场边上长得像大炮一样的镜头后面也都是单反相机。可旁轴相机长得怎样呢？\n\n要想知道这个问题很简单，拿出你的数码相机，关掉它的从屏幕取景的功能，用机背上方的一个小窗子取景拍照，这就是旁轴相机。小时候家里用的那种傻瓜照相机也都是旁轴相机。\n\n**单反与旁轴的最大区别：光路**\n\n[![4d0ebb45de203b32cefca30d](http://www.hongweiyi.com/wp-content/uploads/2011/09/4d0ebb45de203b32cefca30d_thumb.jpg \"4d0ebb45de203b32cefca30d\")](http://www.hongweiyi.com/wp-content/uploads/2011/09/4d0ebb45de203b32cefca30d.jpg)\n\n1：胶卷，或者CCD/CMOS等感光芯片\n\n2：反光板\n\n左边是单反的光路。先不要看虚线，只看实线。平常取景的时候，光线从镜头射进来，射在2上，反射到上面的取景器内，再反射、反射，从取景器射出去，射到眼睛里面去。\n\n拍照的时候，按下快门，反光板2就抬起来，转到虚线所在的位置。从镜头进来的光线没有了2的反射，直接射到1上面，也就是胶卷或者CCD/CMOS上面。\n\n其实1和2之间还有一个快门帘我没有画出来。2抬起来之后，快门帘按照设定的时间(手动或自动设置)向上打开，光线射到胶卷或者CCD/CMOS上面，让胶卷或者CCD/CMOS曝光，留下影像。\n\n所以单反拍照的时候，你按下快门后，取景器里面会黑掉，因为这时光线不会再反射上来，反射到眼睛里。\n\n右边是旁轴的光路。人眼直接从上方的取景窗看出去，看到被拍摄的画面，镜头进来的画面人眼看不到，而是留在了胶卷/CCD/CMOS上。光路简单了很多。\n\n**单反与旁轴的好与不好**\n\n单反相机，人眼看到的就是胶卷/CCD/CMOS上所能看到的，但旁轴相机上，人眼看到的跟胶卷/CCD/CMOS其实存在一定的差别。越是看近处的物体，这种差别越大。想要体会这种差别？你盯住屏幕看10秒，再把头往下移5厘米，再看屏幕，这两种角度是不是有区别？因此旁轴的取景系统其实没有单反那么好。\n\n但正是因为这一个取景模式，导致了单反必须有一套不小的反光板系统，导致相机不可能做得很小。而旁轴就能做得很小巧。\n\n也由于反光板系统的存在，镜头与胶卷/CCD/CMOS间有一定的一段距离，否则镜头屁股就妨碍了反光板的动作。这种局面在光学上有一定的影响：广角镜头很难设计，长焦镜头好设计。于是可以看到这样一个局面，单反相机上，长焦镜头可以无限地长，但广角镜头设计出来，会存在比较大的成像扭曲。旁轴相机上，广角比较好设计，有些镜头结构可以完全还原现实情景而不会出现任何成像扭曲，但长焦就比较难了，据我所知，Leica旁轴的长焦最多也只有135mm，而Carl Zeiss旁轴的长焦最长仅有90mm，但Leica和Carl Zeiss的旁轴广角的成像质量则是单反系统内任何一家厂家都做不出来的。\n\n还是因为这个反光板系统，在按下快门的时候，它会“啪”地一声转上来。于是单反的快门声音再怎么小，都要比旁轴大。而快门的声音很可能破坏现场本身的感觉，比如吓跑了小鸟，警醒了正在被偷拍的mm等，这就很不好了。\n\n**单反与旁轴的著名厂家**\n\n单反，Canon与Nikon加起来占了85%左右的市场份额，差不多一半一半。现在胶卷单反基本没有市场了，都是数码单反了。\n\n旁轴，因为比较简单，所以八仙过海各显神通。但最名贵的旁轴一定是Leica的M系列。Leica生产出了这个世界上第一个35mm的旁轴相机。从M1到M7，都是胶卷的，M8是数码的。Leica在相机届的地位就相当于LV在皮包届的地位。不同的是Leica的相机的功能性是非常强大的，不像LV主要依靠brand image。Leica的镜头的光学质量也基本上是无敌的。\n> 转载： [无疆之行](http://hi.baidu.com/lavituo/blog/item/c413fed38abfb3daa8ec9a00.html)\r> \n> \n> 注：莱卡买不起，但是对富士X100很心动啊","source":"_posts/single-lens-paraxonic.md","raw":"title: 单反相机与旁轴相机分别是什么\ntags:\n  - 摄影\n  - 数码\nid: 157\ncategories:\n  - 生活分享\ndate: 2011-09-01 19:12:50\n---\n\n**命名：单反为什么叫单反，旁轴为什么叫旁轴**\n\n单反，全名“单镜头反光相机”(Single Lens Reflex，简称SLR)。单反一次只能装一个镜头，所以叫“单镜头”。单反里面有反光板，把通过镜头采集近来的光反射到人眼睛里(下文有详细解释)，所以叫“反光”。单反可以拍照，所以叫“相机”。相机有胶卷的和数码的，所以有胶片单反(Film SLR, FSLR)和数码单反(Digital SLR, DSLR)两种。数码单反是不能装胶卷的。\n\n旁轴(Rangefinder, RF)，解释起来不如单反那么容易。单反凭借其反光板系统，是通过镜头取景的，也就是你眼睛贴到相机上看到的景象是从镜头看出去的景象。而旁轴的取景系统是独立于镜头之外的，取景的光路跟镜头进来的光路是两条不同的光路。那为什么叫旁轴呢？我的理解是除开拍照那条光路轴线，“旁”边还存在取景的那条光路“轴”线，所以叫“旁轴”。可能理解错了，但事实基本上如此。\n\n<!--more-->\n\n**旁轴相机长什么样？**\n\n单反相机大家都见过，大部分记者都用单反。体育场边上长得像大炮一样的镜头后面也都是单反相机。可旁轴相机长得怎样呢？\n\n要想知道这个问题很简单，拿出你的数码相机，关掉它的从屏幕取景的功能，用机背上方的一个小窗子取景拍照，这就是旁轴相机。小时候家里用的那种傻瓜照相机也都是旁轴相机。\n\n**单反与旁轴的最大区别：光路**\n\n[![4d0ebb45de203b32cefca30d](http://www.hongweiyi.com/wp-content/uploads/2011/09/4d0ebb45de203b32cefca30d_thumb.jpg \"4d0ebb45de203b32cefca30d\")](http://www.hongweiyi.com/wp-content/uploads/2011/09/4d0ebb45de203b32cefca30d.jpg)\n\n1：胶卷，或者CCD/CMOS等感光芯片\n\n2：反光板\n\n左边是单反的光路。先不要看虚线，只看实线。平常取景的时候，光线从镜头射进来，射在2上，反射到上面的取景器内，再反射、反射，从取景器射出去，射到眼睛里面去。\n\n拍照的时候，按下快门，反光板2就抬起来，转到虚线所在的位置。从镜头进来的光线没有了2的反射，直接射到1上面，也就是胶卷或者CCD/CMOS上面。\n\n其实1和2之间还有一个快门帘我没有画出来。2抬起来之后，快门帘按照设定的时间(手动或自动设置)向上打开，光线射到胶卷或者CCD/CMOS上面，让胶卷或者CCD/CMOS曝光，留下影像。\n\n所以单反拍照的时候，你按下快门后，取景器里面会黑掉，因为这时光线不会再反射上来，反射到眼睛里。\n\n右边是旁轴的光路。人眼直接从上方的取景窗看出去，看到被拍摄的画面，镜头进来的画面人眼看不到，而是留在了胶卷/CCD/CMOS上。光路简单了很多。\n\n**单反与旁轴的好与不好**\n\n单反相机，人眼看到的就是胶卷/CCD/CMOS上所能看到的，但旁轴相机上，人眼看到的跟胶卷/CCD/CMOS其实存在一定的差别。越是看近处的物体，这种差别越大。想要体会这种差别？你盯住屏幕看10秒，再把头往下移5厘米，再看屏幕，这两种角度是不是有区别？因此旁轴的取景系统其实没有单反那么好。\n\n但正是因为这一个取景模式，导致了单反必须有一套不小的反光板系统，导致相机不可能做得很小。而旁轴就能做得很小巧。\n\n也由于反光板系统的存在，镜头与胶卷/CCD/CMOS间有一定的一段距离，否则镜头屁股就妨碍了反光板的动作。这种局面在光学上有一定的影响：广角镜头很难设计，长焦镜头好设计。于是可以看到这样一个局面，单反相机上，长焦镜头可以无限地长，但广角镜头设计出来，会存在比较大的成像扭曲。旁轴相机上，广角比较好设计，有些镜头结构可以完全还原现实情景而不会出现任何成像扭曲，但长焦就比较难了，据我所知，Leica旁轴的长焦最多也只有135mm，而Carl Zeiss旁轴的长焦最长仅有90mm，但Leica和Carl Zeiss的旁轴广角的成像质量则是单反系统内任何一家厂家都做不出来的。\n\n还是因为这个反光板系统，在按下快门的时候，它会“啪”地一声转上来。于是单反的快门声音再怎么小，都要比旁轴大。而快门的声音很可能破坏现场本身的感觉，比如吓跑了小鸟，警醒了正在被偷拍的mm等，这就很不好了。\n\n**单反与旁轴的著名厂家**\n\n单反，Canon与Nikon加起来占了85%左右的市场份额，差不多一半一半。现在胶卷单反基本没有市场了，都是数码单反了。\n\n旁轴，因为比较简单，所以八仙过海各显神通。但最名贵的旁轴一定是Leica的M系列。Leica生产出了这个世界上第一个35mm的旁轴相机。从M1到M7，都是胶卷的，M8是数码的。Leica在相机届的地位就相当于LV在皮包届的地位。不同的是Leica的相机的功能性是非常强大的，不像LV主要依靠brand image。Leica的镜头的光学质量也基本上是无敌的。\n> 转载： [无疆之行](http://hi.baidu.com/lavituo/blog/item/c413fed38abfb3daa8ec9a00.html)\r> \n> \n> 注：莱卡买不起，但是对富士X100很心动啊","slug":"single-lens-paraxonic","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg62100017sb8fg6wrqajc"},{"title":"REWORK - 灵感稍纵即逝","date":"2014-04-14T13:40:00.000Z","_content":"\n昨天在hn上看到37signals，顺带看到《rework》这本书，多看试读了一下，立马亚马逊下单了。怎么说吧，里面的大多数文字都让我产生深深的共鸣，两小时读完，有种恨不得立马去他公司去体验一把的感觉，这感觉是如此奇妙。\n\n苦于自己不善于文字，就只能在这里把书里最后的总结摘抄上来，与大家分享分享：\n\n<!--more-->\n\n> 我们都有想法，想法是不朽的，一直都会存在。\n\n> 最不可能长存的就是灵感。灵感就像新鲜水果或牛奶：有一定的保质期。\n\n> 如果你想去做一件事，就得马上下手。不能把这事搁置起来过两个月再考虑。不要对自己说『以后再说吧』。以后，你压根儿不会再提起这件事了。\n\n> 如果你的灵感是在周五驾临，那就放弃周末，直奔主题。当你为了这个灵感而亢奋时，就能够在24小时内做完两个星期的工作。从这一点来讲，灵感就是时光机。\n\n> 灵感是个奇妙的东西，是效率放大器，是推进器。但是它不会停下来等你。灵感转瞬即逝，当它来找你时，要立即把它捕捉住，将其投入工作中去。\n","source":"_posts/rework-digest.md","raw":"title: REWORK - 灵感稍纵即逝\ndate: 2014-04-14 21:40:00\ncategories: 生活点滴\ntags: REWORK, 37signals, 书摘, 生活\n---\n\n昨天在hn上看到37signals，顺带看到《rework》这本书，多看试读了一下，立马亚马逊下单了。怎么说吧，里面的大多数文字都让我产生深深的共鸣，两小时读完，有种恨不得立马去他公司去体验一把的感觉，这感觉是如此奇妙。\n\n苦于自己不善于文字，就只能在这里把书里最后的总结摘抄上来，与大家分享分享：\n\n<!--more-->\n\n> 我们都有想法，想法是不朽的，一直都会存在。\n\n> 最不可能长存的就是灵感。灵感就像新鲜水果或牛奶：有一定的保质期。\n\n> 如果你想去做一件事，就得马上下手。不能把这事搁置起来过两个月再考虑。不要对自己说『以后再说吧』。以后，你压根儿不会再提起这件事了。\n\n> 如果你的灵感是在周五驾临，那就放弃周末，直奔主题。当你为了这个灵感而亢奋时，就能够在24小时内做完两个星期的工作。从这一点来讲，灵感就是时光机。\n\n> 灵感是个奇妙的东西，是效率放大器，是推进器。但是它不会停下来等你。灵感转瞬即逝，当它来找你时，要立即把它捕捉住，将其投入工作中去。\n","slug":"rework-digest","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg6212001dsb8ffouz1ish"},{"title":"Java 网络编程最佳实践","_content":"\n\n## 通信层\n\n* 直接使用最成熟的网络框架，如 Netty\n* 单连接 & 连接复用 & 长连接\n  * 建议提前设计心跳机制\n  * 集群较小，长连接无需开启心跳\n  * 如果网络情况比较复杂，建议开启心跳。如有防火墙，会将连接清掉且不会向客户端发送 RST 信令，导致长连接变成一个脏连接\n\n<!-- more -->\n\n## 线程模型\n\n如果采用了 Netty 这样的框架，线程模型基本已经决定了，但是 Netty 只需负责 IO 处理，需要提供额外的业务线程池负责处理业务请求。\n\n* 序列化过程在业务线程中处理\n* 请求/响应包多个批量从 IO 线程交给业务线程处理\n* 服务端线程池需要有保护策略\n  * 框架层面的 RejectExcetpion\n  * 业务层面的限流策略\n* 需要定时打印线程池大小，方便性能分析\n\n## 序列化\n\n* 全站都是 Java 系\n\n为了以后能让其它语言更好的交互，协议设计越扁平越好，切忌将整个协议类对象序列化，仅整个序列化方法参数对象列表及返回值对象。\n\n* 全站各种语言百花齐放\n\n可以考虑直接使用 Protobuf 或者 msgpack 这样的跨语言的序列化协议，但我个人没使用经验。\n\n\n## 容灾\n\n* 必须要有超时时间，分布式环境下无超时机制对整体环境影响非常大\n* 需要有连接隔离机制（根据请求量、错误率等）\n  * 可参考 [Netflix 的 ribbon](https://github.com/Netflix/ribbon)\n\n\n## 故障定位\n\n* 客户端发送、服务端接收均需要打印日志，日志必须要有的几个字段：\n  * 时间戳\n  * 唯一ID： 由于客户端和服务端的请求量较大，所以需要有唯一 ID 能够将客户端日志和服务端请求串起来\n  * IP 信息\n  * 如下：\n   * client:time,unique-id,server-ip\n   * server:time,unique-id,client-ip\n* 提供较好的方式打印网络层日志\n  * 经常会发生客户端有请求日志，但是服务端没有接收日志的情况\n  * 这个时候无法判断是客户端出错还是服务端出错，可以提供 debug 日志打印网络层的请求日志\n","source":"_posts/remoting-practice.md","raw":"title: Java 网络编程最佳实践\ncategories: 最佳实践\ntags: [Java, Network]\n---\n\n\n## 通信层\n\n* 直接使用最成熟的网络框架，如 Netty\n* 单连接 & 连接复用 & 长连接\n  * 建议提前设计心跳机制\n  * 集群较小，长连接无需开启心跳\n  * 如果网络情况比较复杂，建议开启心跳。如有防火墙，会将连接清掉且不会向客户端发送 RST 信令，导致长连接变成一个脏连接\n\n<!-- more -->\n\n## 线程模型\n\n如果采用了 Netty 这样的框架，线程模型基本已经决定了，但是 Netty 只需负责 IO 处理，需要提供额外的业务线程池负责处理业务请求。\n\n* 序列化过程在业务线程中处理\n* 请求/响应包多个批量从 IO 线程交给业务线程处理\n* 服务端线程池需要有保护策略\n  * 框架层面的 RejectExcetpion\n  * 业务层面的限流策略\n* 需要定时打印线程池大小，方便性能分析\n\n## 序列化\n\n* 全站都是 Java 系\n\n为了以后能让其它语言更好的交互，协议设计越扁平越好，切忌将整个协议类对象序列化，仅整个序列化方法参数对象列表及返回值对象。\n\n* 全站各种语言百花齐放\n\n可以考虑直接使用 Protobuf 或者 msgpack 这样的跨语言的序列化协议，但我个人没使用经验。\n\n\n## 容灾\n\n* 必须要有超时时间，分布式环境下无超时机制对整体环境影响非常大\n* 需要有连接隔离机制（根据请求量、错误率等）\n  * 可参考 [Netflix 的 ribbon](https://github.com/Netflix/ribbon)\n\n\n## 故障定位\n\n* 客户端发送、服务端接收均需要打印日志，日志必须要有的几个字段：\n  * 时间戳\n  * 唯一ID： 由于客户端和服务端的请求量较大，所以需要有唯一 ID 能够将客户端日志和服务端请求串起来\n  * IP 信息\n  * 如下：\n   * client:time,unique-id,server-ip\n   * server:time,unique-id,client-ip\n* 提供较好的方式打印网络层日志\n  * 经常会发生客户端有请求日志，但是服务端没有接收日志的情况\n  * 这个时候无法判断是客户端出错还是服务端出错，可以提供 debug 日志打印网络层的请求日志\n","slug":"remoting-practice","published":1,"date":"2015-12-29T13:30:15.000Z","updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg6213001isb8fmo597y2n"},{"title":"轻松一刻 - 薛定谔的猫","id":"527","date":"2012-04-26T13:38:33.000Z","_content":"\n今天看到了一个有趣的定理：\n  > 薛定谔的滚：当一个妹子叫你滚的时候，永远不知道她是在叫你滚，还是叫你过来抱紧。  \n\n看到之后，感触良多啊。也顺带想起了这个薛定谔以前玩过一只猫，但是一直没有仔细去了解那只猫的下场，所以就查了查。一不小心查到了有趣的果壳网问答了，里面有一个有趣的问题，如下：\n<!--more-->> **如何向文科生浅显易懂的讲解薛定谔的猫？**  \n\n死性理派的宅男们开始回复了，摘来一些有意思的部分：\n  > [![clip_image002](http://www.hongweiyi.com/wp-content/uploads/2012/04/clip_image002.jpg \"clip_image002\")](http://www.guokr.com/i/0531918429/) [纳谜燕子](http://www.guokr.com/i/0531918429/)\n> \n> 在向你心仪的女神表白之前，你不知道她到底是喜欢你还是不喜欢你，也许连她自己都不是很明确，这时候她对你的感情就处于“喜欢+不喜欢”状态，或者叫薛定谔猫态。\n> \n> 在你表白之后，这个状态就坍缩成“我也喜欢你”和“你是个好人”两种确定的不同的状态，其概率取决于你是高帅富还是吊丝等诸多因素。或者是，在一个宇宙中，你们俩幸福地抱在了一起；而在另一个平行宇宙中，你回家看了个爱情动作片。  > [![clip_image004](http://www.hongweiyi.com/wp-content/uploads/2012/04/clip_image004.jpg \"clip_image004\")](http://www.guokr.com/i/2059939599/) [knightdl](http://www.guokr.com/i/2059939599/)\n> \n> 一张很直观的图\n> \n> [![clip_image005](http://www.hongweiyi.com/wp-content/uploads/2012/04/clip_image005_thumb.jpg \"clip_image005\")](http://www.hongweiyi.com/wp-content/uploads/2012/04/clip_image005.jpg)\n> \n> 没看图的时候，黑白都有。因此薛定谔的猫既alive又dead。\n> \n> 当你观测的时候：\n> \n> &#160;&#160; 1\\. 只看白色：活着（alive）\n> \n> &#160;&#160; 2\\. 只看黑色：死了（dead）  > [![clip_image007](http://www.hongweiyi.com/wp-content/uploads/2012/04/clip_image007.jpg \"clip_image007\")](http://www.guokr.com/i/0660893195/) [huahualipo](http://www.guokr.com/i/0660893195/)\n> \n> 之所以常被提，个人觉得第一：薛定谔的名字起得好。“钱德拉塞卡的猫”就远没这么好记。二，猫比较可爱，要是薛定谔的蚯蚓，估计也木有人会这么感兴趣鸟……  > [![clip_image009](http://www.hongweiyi.com/wp-content/uploads/2012/04/clip_image009.jpg \"clip_image009\")](http://www.guokr.com/i/1792273330/) [不明真相群众](http://www.guokr.com/i/1792273330/)\n> \n> 请不要歧视文科生，我们也是有智商的。  \n\n还真是不明真相的群众啊\n  > [![clip_image011](http://www.hongweiyi.com/wp-content/uploads/2012/04/clip_image011.jpg \"clip_image011\")](http://www.guokr.com/i/0417575823/) [盘缸先生](http://www.guokr.com/i/0417575823/)\n> \n> 2011年底，科学家们发现了迄今为止最大的处于叠加态的宏观量子系统：朝鲜人。一旦被观测到，他们就会瞬间坍缩到“抽搐哭”，“吐白沫哭”，“锤地哭”等不同的态上。#假新闻#  \n\n这个是最有深度的一条回复。\n\n具体那猫是啥，我也只理解了一些。得有空多想想，感觉现实中，这只“猫”挺常见的，顺带让这紧绷的脑子放松放松。\n\nOver…\n\n&#160;\n\n**果壳原地址**：请点击[这里](http://www.guokr.com/question/122203/)。","source":"_posts/relax-schrodinger-cat.md","raw":"title: 轻松一刻 - 薛定谔的猫\ntags:\n  - 果壳网\n  - 生活\nid: 527\ncategories:\n  - 生活分享\ndate: 2012-04-26 21:38:33\n---\n\n今天看到了一个有趣的定理：\n  > 薛定谔的滚：当一个妹子叫你滚的时候，永远不知道她是在叫你滚，还是叫你过来抱紧。  \n\n看到之后，感触良多啊。也顺带想起了这个薛定谔以前玩过一只猫，但是一直没有仔细去了解那只猫的下场，所以就查了查。一不小心查到了有趣的果壳网问答了，里面有一个有趣的问题，如下：\n<!--more-->> **如何向文科生浅显易懂的讲解薛定谔的猫？**  \n\n死性理派的宅男们开始回复了，摘来一些有意思的部分：\n  > [![clip_image002](http://www.hongweiyi.com/wp-content/uploads/2012/04/clip_image002.jpg \"clip_image002\")](http://www.guokr.com/i/0531918429/) [纳谜燕子](http://www.guokr.com/i/0531918429/)\n> \n> 在向你心仪的女神表白之前，你不知道她到底是喜欢你还是不喜欢你，也许连她自己都不是很明确，这时候她对你的感情就处于“喜欢+不喜欢”状态，或者叫薛定谔猫态。\n> \n> 在你表白之后，这个状态就坍缩成“我也喜欢你”和“你是个好人”两种确定的不同的状态，其概率取决于你是高帅富还是吊丝等诸多因素。或者是，在一个宇宙中，你们俩幸福地抱在了一起；而在另一个平行宇宙中，你回家看了个爱情动作片。  > [![clip_image004](http://www.hongweiyi.com/wp-content/uploads/2012/04/clip_image004.jpg \"clip_image004\")](http://www.guokr.com/i/2059939599/) [knightdl](http://www.guokr.com/i/2059939599/)\n> \n> 一张很直观的图\n> \n> [![clip_image005](http://www.hongweiyi.com/wp-content/uploads/2012/04/clip_image005_thumb.jpg \"clip_image005\")](http://www.hongweiyi.com/wp-content/uploads/2012/04/clip_image005.jpg)\n> \n> 没看图的时候，黑白都有。因此薛定谔的猫既alive又dead。\n> \n> 当你观测的时候：\n> \n> &#160;&#160; 1\\. 只看白色：活着（alive）\n> \n> &#160;&#160; 2\\. 只看黑色：死了（dead）  > [![clip_image007](http://www.hongweiyi.com/wp-content/uploads/2012/04/clip_image007.jpg \"clip_image007\")](http://www.guokr.com/i/0660893195/) [huahualipo](http://www.guokr.com/i/0660893195/)\n> \n> 之所以常被提，个人觉得第一：薛定谔的名字起得好。“钱德拉塞卡的猫”就远没这么好记。二，猫比较可爱，要是薛定谔的蚯蚓，估计也木有人会这么感兴趣鸟……  > [![clip_image009](http://www.hongweiyi.com/wp-content/uploads/2012/04/clip_image009.jpg \"clip_image009\")](http://www.guokr.com/i/1792273330/) [不明真相群众](http://www.guokr.com/i/1792273330/)\n> \n> 请不要歧视文科生，我们也是有智商的。  \n\n还真是不明真相的群众啊\n  > [![clip_image011](http://www.hongweiyi.com/wp-content/uploads/2012/04/clip_image011.jpg \"clip_image011\")](http://www.guokr.com/i/0417575823/) [盘缸先生](http://www.guokr.com/i/0417575823/)\n> \n> 2011年底，科学家们发现了迄今为止最大的处于叠加态的宏观量子系统：朝鲜人。一旦被观测到，他们就会瞬间坍缩到“抽搐哭”，“吐白沫哭”，“锤地哭”等不同的态上。#假新闻#  \n\n这个是最有深度的一条回复。\n\n具体那猫是啥，我也只理解了一些。得有空多想想，感觉现实中，这只“猫”挺常见的，顺带让这紧绷的脑子放松放松。\n\nOver…\n\n&#160;\n\n**果壳原地址**：请点击[这里](http://www.guokr.com/question/122203/)。","slug":"relax-schrodinger-cat","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg6215001psb8fk39q4xa3"},{"title":"Redis五大数据结构","id":"451","date":"2012-03-07T09:30:26.000Z","_content":"\n**1、Redis介绍**\n\nRedis是REmote DIctionary Server的缩写，作者定位于一个内存KV存储数据库（In-memory key-value Store），让Redis自豪的并不是那每秒10K的读写速度，而是它那可以应对很多情况的数据结构，我这里就简单的介绍一下它五大数据结构，也可以方便的让自个翻翻API，并给以后翻阅源码打下一个基础。\n<!--more-->\n\n**2****、Strings**\n\n**1****）简介**\n\nString是Redis最基本的数据结构，它的String是二进制安全的，即String中可以存放任意的二进制数据，比如说JPG图片、序列化对象等。String值长度最大可到512mb。\n\n**2****）结构定义**\n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"keyword\">struct</span><span> sdshdr{&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">long</span><span> len;&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">long</span><span> free;&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">char</span><span> buf[];&#160;&#160; </span></span>\n5.  <span>}&#160;&#160; </span> </div>  \n\n**3****）支持命令 **\n\n[APPEND](http://redis.io/commands/append)、[GET](http://redis.io/commands/get)、[GETBIT](http://redis.io/commands/getbit)、[GETRANGE](http://redis.io/commands/getrange)、[GETSET](http://redis.io/commands/getset)、[STRLEN](http://redis.io/commands/strlen)\n\n[MGET](http://redis.io/commands/mget)、[MSET](http://redis.io/commands/mset)、[MSETNX](http://redis.io/commands/msetnx)、[SET](http://redis.io/commands/set)、[SETBIT](http://redis.io/commands/setbit)、[SETEX](http://redis.io/commands/setex)、[SETNX](http://redis.io/commands/setnx)、[SETRANGE](http://redis.io/commands/setrange)\n\n[INCR](http://redis.io/commands/incr)、[INCRBY](http://redis.io/commands/incrby)、[DECR](http://redis.io/commands/decr)、[DECRBY](http://redis.io/commands/decrby)\n\n**3****、Hashes**\n\n**1****）简介**\n\nHashes中存放了多个键值对（field/value），所以Hash结构可方便的表示一个对象。如：\n\nHMSET user:00001 username wikie password ***** gender male\n\n一个Hash可以存放2^32 – 1个键值对。Hash对象是用zipmap存储的，查找、删除均为O(n)，但一般来说对象的field对象不会大多，所以说操作评价还是近似O(1)。如果field/value的大小超过一定限制后，Redis会在内部自动将zipmap替换成正常的Hash实现，可在配置文件中指定：\n\nhash-max-zipmap-entries 64 # 字段最多64个\n\nhash-max-zipmap-value 512 # value最大为512字节\n\n**2****）结构定义**\n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"comment\">//Please check in dict.h </span><span>&#160; </span></span>\n2.  <span></span><span class=\"keyword\">typedef</span><span>&#160;</span><span class=\"keyword\">struct</span><span> dictht {&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160; dictEntry **table;&#160;&#160; </span>\n4.  <span>&#160;&#160;&#160; unsigned </span><span class=\"datatypes\">long</span><span> size;&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; unsigned </span><span class=\"datatypes\">long</span><span> sizemask;&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160; unsigned </span><span class=\"datatypes\">long</span><span> used;&#160;&#160; </span></span>\n7.  <span>} dictht;&#160; </span> </div>  \n\n**3）支持命令 **\n\n[HDEL](http://redis.io/commands/hdel)、[HEXISTS](http://redis.io/commands/hexists)、[HGET](http://redis.io/commands/hget)、[HGETALL](http://redis.io/commands/hgetall)、[HINCRBY](http://redis.io/commands/hincrby)、[HKEYS](http://redis.io/commands/hkeys)、[HLEN](http://redis.io/commands/hlen)\n\n[HMGET](http://redis.io/commands/hmget)、[HMSET](http://redis.io/commands/hmset)、[HSET](http://redis.io/commands/hset)、[HSETNX](http://redis.io/commands/hsetnx)、[HVALS](http://redis.io/commands/hvals)\n\n**4****、Lists**\n\n**1****）简介**\n\nLists是一个简单的strings类型的双向链表，按照插入顺序排序。\n\n最大长度支持2^32-1，可以通过命令从头部或者尾部添加删除元素，即可很方便的实现栈与队列操作。List还可以阻塞，很容易就实现了一个工作队列，而不用轮询。\n\n**2****）结构定义**\n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"comment\">// Check in adlist.h </span><span>&#160; </span></span>\n2.  <span></span><span class=\"keyword\">typedef</span><span>&#160;</span><span class=\"keyword\">struct</span><span> listNode {&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">struct</span><span> listNode *prev;&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">struct</span><span> listNode *next;&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">void</span><span> *value;&#160;&#160; </span></span>\n6.  <span>} listNode;&#160;&#160; </span>\n7.  <span>&#160; </span>\n8.  <span></span><span class=\"keyword\">typedef</span><span>&#160;</span><span class=\"keyword\">struct</span><span> listIter {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160; listNode *next;&#160;&#160; </span>\n10.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">int</span><span> direction;&#160;&#160; </span></span>\n11.  <span>} listIter;&#160;&#160; </span>\n12.  <span>&#160; </span>\n13.  <span></span><span class=\"keyword\">typedef</span><span>&#160;</span><span class=\"keyword\">struct</span><span> list {&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160; listNode *head;&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160; listNode *tail;&#160;&#160; </span>\n16.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">void</span><span> *(*dup)(</span><span class=\"keyword\">void</span><span> *ptr);&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">void</span><span> (*free)(</span><span class=\"keyword\">void</span><span> *ptr);&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">int</span><span> (*match)(</span><span class=\"keyword\">void</span><span> *ptr, </span><span class=\"keyword\">void</span><span> *key);&#160;&#160; </span></span>\n19.  <span>&#160;&#160;&#160; unsigned </span><span class=\"datatypes\">int</span><span> len;&#160;&#160; </span></span>\n20.  <span>} list;&#160; </span> </div>  \n\n**3****）支持命令 **\n\n[BLPOP](http://redis.io/commands/blpop) 、[BRPOP](http://redis.io/commands/brpop) 、[BRPOPLPUSH](http://redis.io/commands/brpoplpush)、[LINDEX](http://redis.io/commands/lindex)、[LINSERT](http://redis.io/commands/linsert)、[LLEN](http://redis.io/commands/llen)\n\n[LPOP](http://redis.io/commands/lpop)、[LPUSH](http://redis.io/commands/lpush)、[LPUSHX](http://redis.io/commands/lpushx)、[LRANGE](http://redis.io/commands/lrange)、[LREM](http://redis.io/commands/lrem)、[LSET](http://redis.io/commands/lset)、[LTRIM](http://redis.io/commands/ltrim)\n\n[RPOP](http://redis.io/commands/rpop)、[RPOPLPUSH](http://redis.io/commands/rpoplpush)、[RPUSH](http://redis.io/commands/rpush)、[RPUSHX](http://redis.io/commands/rpushx)\n\n**5****、Sets**\n\n**1****）简介**\n\n与数学的中的集合概念类似，没有重复的值，对其有添加删除操作，可对都个结合求交、并等操作，key理解为集合的名字。新浪微博中的：“我和她都关注了”只需要一个SINTER命令就可以实现。\n\nSets通过Hash Table实现，添加删除的时间复杂度均为O(n)，HashTable会随着添加或者删除自动调整大小。需要注意的是，调整HashTable大小需要同步（获取写锁）阻塞读写操作，后期可能会采用SkipList（无序如何使用SkipList？）实现。\n\n和其它类型一样，最大支持2^32-1个元素。\n\n**2****）结构定义**\n\n与Hashes中的dict一致。\n\n**3****）支持的方法**\n\n[SADD](http://redis.io/commands/sadd)、[SCAR](http://redis.io/commands/scard)、[SDIFF](http://redis.io/commands/sdiff)、[SDIFFSTORE](http://redis.io/commands/sdiffstore)、[SINTER](http://redis.io/commands/sinter)、[SISMEMBER](http://redis.io/commands/sismember)\n\n[SMEMBERS](http://redis.io/commands/smembers)、[SMOVE](http://redis.io/commands/smove)、[SPOP](http://redis.io/commands/spop)、[SRANDMEMBER](http://redis.io/commands/srandmember)、[SREM](http://redis.io/commands/srem)\n\n[SUNION](http://redis.io/commands/sunion)、[SUNIONSTORE](http://redis.io/commands/sunionstore)\n\n**6****、ZSets**\n\n**1****）简介**\n\nZSets为Set的升级版本，即排序的Sets，在Set的基础之上增加了顺序（Score）属性，每次插入均需要指定，且会自动重新调整值的顺序。Score为double类型，ZSets实现为SkipList与HashTable的混合体。\n\n元素到Score的映射是添加在HashTable中的，所以给定一个元素获取Score开销为O(1)，Score到元素的映射则为SkipList。\n\n**2****）结构定义**\n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"comment\">/* ZSETs use a specialized version of Skiplists */</span><span>&#160; </span></span>2.  <span></span><span class=\"keyword\">typedef</span><span>&#160;</span><span class=\"keyword\">struct</span><span> zskiplistNode {&#160;&#160; </span></span>3.  <span>&#160;&#160;&#160; robj *obj;&#160;&#160; </span>4.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">double</span><span> score;&#160;&#160; </span></span>5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">struct</span><span> zskiplistNode *backward;&#160;&#160; </span></span>6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">struct</span><span> zskiplistLevel {&#160;&#160; </span></span>7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">struct</span><span> zskiplistNode *forward;&#160;&#160; </span></span>8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; unsigned </span><span class=\"datatypes\">int</span><span> span;&#160;&#160; </span></span>9.  <span>&#160;&#160;&#160; } level[];&#160;&#160; </span>10.  <span>} zskiplistNode;&#160;&#160; </span>11.  <span>&#160; </span>12.  <span></span><span class=\"keyword\">typedef</span><span>&#160;</span><span class=\"keyword\">struct</span><span> zskiplist {&#160;&#160; </span></span>13.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">struct</span><span> zskiplistNode *header, *tail;&#160;&#160; </span></span>14.  <span>&#160;&#160;&#160; unsigned </span><span class=\"datatypes\">long</span><span> length;&#160;&#160; </span></span>15.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">int</span><span> level;&#160;&#160; </span></span>16.  <span>} zskiplist;&#160;&#160; </span>17.  <span>&#160; </span>18.  <span></span><span class=\"keyword\">typedef</span><span>&#160;</span><span class=\"keyword\">struct</span><span> zset {&#160;&#160; </span></span>19.  <span>&#160;&#160;&#160; dict *dict;&#160;&#160;&#160; </span><span class=\"comment\">// Value to Score </span><span>&#160; </span></span>20.  <span>&#160;&#160;&#160; zskiplist *zsl;&#160; </span><span class=\"comment\">// Score to Value </span><span>&#160; </span></span>21.  <span>} zset;&#160; </span> </div>  \n\n**3）支持命令 **\n\n[ZADD](http://redis.io/commands/zadd)、[ZCARD](http://redis.io/commands/zcard)、[ZCOUNT](http://redis.io/commands/zcount)、[ZINCRBY](http://redis.io/commands/zincrby)、[ZINTERSTORE](http://redis.io/commands/zinterstore)\n\n[ZRANGE](http://redis.io/commands/zrange)、[ZRANGEBYSCORE](http://redis.io/commands/zrangebyscore)、[ZRANK](http://redis.io/commands/zrank)、[ZREM](http://redis.io/commands/zrem)\n\n[ZREMRANGEBYRANK](http://redis.io/commands/zremrangebyrank)、[ZREMRANGEBYSCORE](http://redis.io/commands/zremrangebyscore)、[ZREVRANGE](http://redis.io/commands/zrevrange)\n\n[ZREVRANGEBYSCORE](http://redis.io/commands/zrevrangebyscore)、[ZREVRANK](http://redis.io/commands/zrevrank)、[ZSCORE](http://redis.io/commands/zscore)、[ZUNIONSTORE](http://redis.io/commands/zunionstore)\n  > 参考资料：\n> \n> [Redis.io](http://redis.io)\n> \n> [The Little Redis Book](http://openmymind.net/2012/1/23/The-Little-Redis-Book/)","source":"_posts/redis-data-strutrue.md","raw":"title: Redis五大数据结构\ntags:\n  - NoSQL\n  - Redis\n  - 数据结构\nid: 451\ncategories:\n  - 技术分享\ndate: 2012-03-07 17:30:26\n---\n\n**1、Redis介绍**\n\nRedis是REmote DIctionary Server的缩写，作者定位于一个内存KV存储数据库（In-memory key-value Store），让Redis自豪的并不是那每秒10K的读写速度，而是它那可以应对很多情况的数据结构，我这里就简单的介绍一下它五大数据结构，也可以方便的让自个翻翻API，并给以后翻阅源码打下一个基础。\n<!--more-->\n\n**2****、Strings**\n\n**1****）简介**\n\nString是Redis最基本的数据结构，它的String是二进制安全的，即String中可以存放任意的二进制数据，比如说JPG图片、序列化对象等。String值长度最大可到512mb。\n\n**2****）结构定义**\n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"keyword\">struct</span><span> sdshdr{&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">long</span><span> len;&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">long</span><span> free;&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">char</span><span> buf[];&#160;&#160; </span></span>\n5.  <span>}&#160;&#160; </span> </div>  \n\n**3****）支持命令 **\n\n[APPEND](http://redis.io/commands/append)、[GET](http://redis.io/commands/get)、[GETBIT](http://redis.io/commands/getbit)、[GETRANGE](http://redis.io/commands/getrange)、[GETSET](http://redis.io/commands/getset)、[STRLEN](http://redis.io/commands/strlen)\n\n[MGET](http://redis.io/commands/mget)、[MSET](http://redis.io/commands/mset)、[MSETNX](http://redis.io/commands/msetnx)、[SET](http://redis.io/commands/set)、[SETBIT](http://redis.io/commands/setbit)、[SETEX](http://redis.io/commands/setex)、[SETNX](http://redis.io/commands/setnx)、[SETRANGE](http://redis.io/commands/setrange)\n\n[INCR](http://redis.io/commands/incr)、[INCRBY](http://redis.io/commands/incrby)、[DECR](http://redis.io/commands/decr)、[DECRBY](http://redis.io/commands/decrby)\n\n**3****、Hashes**\n\n**1****）简介**\n\nHashes中存放了多个键值对（field/value），所以Hash结构可方便的表示一个对象。如：\n\nHMSET user:00001 username wikie password ***** gender male\n\n一个Hash可以存放2^32 – 1个键值对。Hash对象是用zipmap存储的，查找、删除均为O(n)，但一般来说对象的field对象不会大多，所以说操作评价还是近似O(1)。如果field/value的大小超过一定限制后，Redis会在内部自动将zipmap替换成正常的Hash实现，可在配置文件中指定：\n\nhash-max-zipmap-entries 64 # 字段最多64个\n\nhash-max-zipmap-value 512 # value最大为512字节\n\n**2****）结构定义**\n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"comment\">//Please check in dict.h </span><span>&#160; </span></span>\n2.  <span></span><span class=\"keyword\">typedef</span><span>&#160;</span><span class=\"keyword\">struct</span><span> dictht {&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160; dictEntry **table;&#160;&#160; </span>\n4.  <span>&#160;&#160;&#160; unsigned </span><span class=\"datatypes\">long</span><span> size;&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; unsigned </span><span class=\"datatypes\">long</span><span> sizemask;&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160; unsigned </span><span class=\"datatypes\">long</span><span> used;&#160;&#160; </span></span>\n7.  <span>} dictht;&#160; </span> </div>  \n\n**3）支持命令 **\n\n[HDEL](http://redis.io/commands/hdel)、[HEXISTS](http://redis.io/commands/hexists)、[HGET](http://redis.io/commands/hget)、[HGETALL](http://redis.io/commands/hgetall)、[HINCRBY](http://redis.io/commands/hincrby)、[HKEYS](http://redis.io/commands/hkeys)、[HLEN](http://redis.io/commands/hlen)\n\n[HMGET](http://redis.io/commands/hmget)、[HMSET](http://redis.io/commands/hmset)、[HSET](http://redis.io/commands/hset)、[HSETNX](http://redis.io/commands/hsetnx)、[HVALS](http://redis.io/commands/hvals)\n\n**4****、Lists**\n\n**1****）简介**\n\nLists是一个简单的strings类型的双向链表，按照插入顺序排序。\n\n最大长度支持2^32-1，可以通过命令从头部或者尾部添加删除元素，即可很方便的实现栈与队列操作。List还可以阻塞，很容易就实现了一个工作队列，而不用轮询。\n\n**2****）结构定义**\n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"comment\">// Check in adlist.h </span><span>&#160; </span></span>\n2.  <span></span><span class=\"keyword\">typedef</span><span>&#160;</span><span class=\"keyword\">struct</span><span> listNode {&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">struct</span><span> listNode *prev;&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">struct</span><span> listNode *next;&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">void</span><span> *value;&#160;&#160; </span></span>\n6.  <span>} listNode;&#160;&#160; </span>\n7.  <span>&#160; </span>\n8.  <span></span><span class=\"keyword\">typedef</span><span>&#160;</span><span class=\"keyword\">struct</span><span> listIter {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160; listNode *next;&#160;&#160; </span>\n10.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">int</span><span> direction;&#160;&#160; </span></span>\n11.  <span>} listIter;&#160;&#160; </span>\n12.  <span>&#160; </span>\n13.  <span></span><span class=\"keyword\">typedef</span><span>&#160;</span><span class=\"keyword\">struct</span><span> list {&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160; listNode *head;&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160; listNode *tail;&#160;&#160; </span>\n16.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">void</span><span> *(*dup)(</span><span class=\"keyword\">void</span><span> *ptr);&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">void</span><span> (*free)(</span><span class=\"keyword\">void</span><span> *ptr);&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">int</span><span> (*match)(</span><span class=\"keyword\">void</span><span> *ptr, </span><span class=\"keyword\">void</span><span> *key);&#160;&#160; </span></span>\n19.  <span>&#160;&#160;&#160; unsigned </span><span class=\"datatypes\">int</span><span> len;&#160;&#160; </span></span>\n20.  <span>} list;&#160; </span> </div>  \n\n**3****）支持命令 **\n\n[BLPOP](http://redis.io/commands/blpop) 、[BRPOP](http://redis.io/commands/brpop) 、[BRPOPLPUSH](http://redis.io/commands/brpoplpush)、[LINDEX](http://redis.io/commands/lindex)、[LINSERT](http://redis.io/commands/linsert)、[LLEN](http://redis.io/commands/llen)\n\n[LPOP](http://redis.io/commands/lpop)、[LPUSH](http://redis.io/commands/lpush)、[LPUSHX](http://redis.io/commands/lpushx)、[LRANGE](http://redis.io/commands/lrange)、[LREM](http://redis.io/commands/lrem)、[LSET](http://redis.io/commands/lset)、[LTRIM](http://redis.io/commands/ltrim)\n\n[RPOP](http://redis.io/commands/rpop)、[RPOPLPUSH](http://redis.io/commands/rpoplpush)、[RPUSH](http://redis.io/commands/rpush)、[RPUSHX](http://redis.io/commands/rpushx)\n\n**5****、Sets**\n\n**1****）简介**\n\n与数学的中的集合概念类似，没有重复的值，对其有添加删除操作，可对都个结合求交、并等操作，key理解为集合的名字。新浪微博中的：“我和她都关注了”只需要一个SINTER命令就可以实现。\n\nSets通过Hash Table实现，添加删除的时间复杂度均为O(n)，HashTable会随着添加或者删除自动调整大小。需要注意的是，调整HashTable大小需要同步（获取写锁）阻塞读写操作，后期可能会采用SkipList（无序如何使用SkipList？）实现。\n\n和其它类型一样，最大支持2^32-1个元素。\n\n**2****）结构定义**\n\n与Hashes中的dict一致。\n\n**3****）支持的方法**\n\n[SADD](http://redis.io/commands/sadd)、[SCAR](http://redis.io/commands/scard)、[SDIFF](http://redis.io/commands/sdiff)、[SDIFFSTORE](http://redis.io/commands/sdiffstore)、[SINTER](http://redis.io/commands/sinter)、[SISMEMBER](http://redis.io/commands/sismember)\n\n[SMEMBERS](http://redis.io/commands/smembers)、[SMOVE](http://redis.io/commands/smove)、[SPOP](http://redis.io/commands/spop)、[SRANDMEMBER](http://redis.io/commands/srandmember)、[SREM](http://redis.io/commands/srem)\n\n[SUNION](http://redis.io/commands/sunion)、[SUNIONSTORE](http://redis.io/commands/sunionstore)\n\n**6****、ZSets**\n\n**1****）简介**\n\nZSets为Set的升级版本，即排序的Sets，在Set的基础之上增加了顺序（Score）属性，每次插入均需要指定，且会自动重新调整值的顺序。Score为double类型，ZSets实现为SkipList与HashTable的混合体。\n\n元素到Score的映射是添加在HashTable中的，所以给定一个元素获取Score开销为O(1)，Score到元素的映射则为SkipList。\n\n**2****）结构定义**\n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"comment\">/* ZSETs use a specialized version of Skiplists */</span><span>&#160; </span></span>2.  <span></span><span class=\"keyword\">typedef</span><span>&#160;</span><span class=\"keyword\">struct</span><span> zskiplistNode {&#160;&#160; </span></span>3.  <span>&#160;&#160;&#160; robj *obj;&#160;&#160; </span>4.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">double</span><span> score;&#160;&#160; </span></span>5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">struct</span><span> zskiplistNode *backward;&#160;&#160; </span></span>6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">struct</span><span> zskiplistLevel {&#160;&#160; </span></span>7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">struct</span><span> zskiplistNode *forward;&#160;&#160; </span></span>8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; unsigned </span><span class=\"datatypes\">int</span><span> span;&#160;&#160; </span></span>9.  <span>&#160;&#160;&#160; } level[];&#160;&#160; </span>10.  <span>} zskiplistNode;&#160;&#160; </span>11.  <span>&#160; </span>12.  <span></span><span class=\"keyword\">typedef</span><span>&#160;</span><span class=\"keyword\">struct</span><span> zskiplist {&#160;&#160; </span></span>13.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">struct</span><span> zskiplistNode *header, *tail;&#160;&#160; </span></span>14.  <span>&#160;&#160;&#160; unsigned </span><span class=\"datatypes\">long</span><span> length;&#160;&#160; </span></span>15.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">int</span><span> level;&#160;&#160; </span></span>16.  <span>} zskiplist;&#160;&#160; </span>17.  <span>&#160; </span>18.  <span></span><span class=\"keyword\">typedef</span><span>&#160;</span><span class=\"keyword\">struct</span><span> zset {&#160;&#160; </span></span>19.  <span>&#160;&#160;&#160; dict *dict;&#160;&#160;&#160; </span><span class=\"comment\">// Value to Score </span><span>&#160; </span></span>20.  <span>&#160;&#160;&#160; zskiplist *zsl;&#160; </span><span class=\"comment\">// Score to Value </span><span>&#160; </span></span>21.  <span>} zset;&#160; </span> </div>  \n\n**3）支持命令 **\n\n[ZADD](http://redis.io/commands/zadd)、[ZCARD](http://redis.io/commands/zcard)、[ZCOUNT](http://redis.io/commands/zcount)、[ZINCRBY](http://redis.io/commands/zincrby)、[ZINTERSTORE](http://redis.io/commands/zinterstore)\n\n[ZRANGE](http://redis.io/commands/zrange)、[ZRANGEBYSCORE](http://redis.io/commands/zrangebyscore)、[ZRANK](http://redis.io/commands/zrank)、[ZREM](http://redis.io/commands/zrem)\n\n[ZREMRANGEBYRANK](http://redis.io/commands/zremrangebyrank)、[ZREMRANGEBYSCORE](http://redis.io/commands/zremrangebyscore)、[ZREVRANGE](http://redis.io/commands/zrevrange)\n\n[ZREVRANGEBYSCORE](http://redis.io/commands/zrevrangebyscore)、[ZREVRANK](http://redis.io/commands/zrevrank)、[ZSCORE](http://redis.io/commands/zscore)、[ZUNIONSTORE](http://redis.io/commands/zunionstore)\n  > 参考资料：\n> \n> [Redis.io](http://redis.io)\n> \n> [The Little Redis Book](http://openmymind.net/2012/1/23/The-Little-Redis-Book/)","slug":"redis-data-strutrue","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg6218001usb8f1tkoxsrp"},{"title":"小黑改装流水记","id":"746","date":"2013-03-21T09:18:48.000Z","_content":"\n发现最近小黑真的是卡爆了，实在是无法忍受了。但又苦于MBA/RMBP没出更新，更苦于钱包瘦小，无奈只能在小黑身上动刀了。\n\n昨晚在某东上面买了一块SSD，选了金士顿的，120g。250g以上的就得上4位数了，接受不了，好像也用不了这么大，就装系统和软件足够了。好像三星的评价也挺不错，不过被人诟病的就是它采用了TLC SSD颗粒（和盖世系列的塑料后盖和P排一样，三星总要留大槽点给用户），寿命较短（我也不太了解这货，道听途说道听途说）。虽然我觉得电脑用不了多长时间，寿命不是什么问题，但是尝鲜的话，还是买个寿命长的吧（只有几百次擦写不知是神马概念）。\n<!--more-->  \n\n某东的好处就是发货极快啊。今早十点收货，拆了自带的硬盘，把SSD按上后装了系统（将32位换成了64位），装系统就感觉挺快了。原来HDD装系统需要半小时，而SSD只需要十分钟不到。装好系统，初次开机10S左右，速度还是挺满意的。至于自带的硬盘，中午跑中关村买了个光驱位（硬盘托槽），将HDD当移动硬盘使了，直接安在光驱上。顺带买了三星黑条4G*2，也转手将自带的2G*2的三星金条卖了，一条卖60。\n  > **吐槽:** 中关村卖的光驱位真的shi，江湖救急一下吧。中关村水依然深啊……  \n\n这次改造给电脑换了64位系统，升级到8G内存，加了120G的SSD。使用起来还没一个很直观的感受，电脑评分快了，SSD Benchmark快了……\n\n[![未命名11](http://hongweiyi.com/wp-content/uploads/2013/03/11.jpg \"未命名11\") ](http://hongweiyi.com/wp-content/uploads/2013/03/1.jpg)\n  > 哎，最初的10s呢！  \n\n[![1](http://hongweiyi.com/wp-content/uploads/2013/03/1_thumb.jpg \"1\")](http://hongweiyi.com/wp-content/uploads/2013/03/12.jpg)\n  > **原分数：**内存5.9，硬盘5.0。  \n\n[![未命名](http://hongweiyi.com/wp-content/uploads/2013/03/thumb.jpg \"未命名\")](http://hongweiyi.com/wp-content/uploads/2013/03/163306e8e326.jpg) \n  > **继续吐槽：**说好的“惊人的535MB/s读和480MB/s写”呢？这才不到一半啊！！！亲\n> \n> **继续吐槽：**HDD的Benchmark就不上了吧，太慢了，没等下去。","source":"_posts/re-equip-my-little-black.md","raw":"title: 小黑改装流水记\ntags:\n  - SSD\n  - 数码\n  - 生活\nid: 746\ncategories:\n  - 生活分享\ndate: 2013-03-21 17:18:48\n---\n\n发现最近小黑真的是卡爆了，实在是无法忍受了。但又苦于MBA/RMBP没出更新，更苦于钱包瘦小，无奈只能在小黑身上动刀了。\n\n昨晚在某东上面买了一块SSD，选了金士顿的，120g。250g以上的就得上4位数了，接受不了，好像也用不了这么大，就装系统和软件足够了。好像三星的评价也挺不错，不过被人诟病的就是它采用了TLC SSD颗粒（和盖世系列的塑料后盖和P排一样，三星总要留大槽点给用户），寿命较短（我也不太了解这货，道听途说道听途说）。虽然我觉得电脑用不了多长时间，寿命不是什么问题，但是尝鲜的话，还是买个寿命长的吧（只有几百次擦写不知是神马概念）。\n<!--more-->  \n\n某东的好处就是发货极快啊。今早十点收货，拆了自带的硬盘，把SSD按上后装了系统（将32位换成了64位），装系统就感觉挺快了。原来HDD装系统需要半小时，而SSD只需要十分钟不到。装好系统，初次开机10S左右，速度还是挺满意的。至于自带的硬盘，中午跑中关村买了个光驱位（硬盘托槽），将HDD当移动硬盘使了，直接安在光驱上。顺带买了三星黑条4G*2，也转手将自带的2G*2的三星金条卖了，一条卖60。\n  > **吐槽:** 中关村卖的光驱位真的shi，江湖救急一下吧。中关村水依然深啊……  \n\n这次改造给电脑换了64位系统，升级到8G内存，加了120G的SSD。使用起来还没一个很直观的感受，电脑评分快了，SSD Benchmark快了……\n\n[![未命名11](http://hongweiyi.com/wp-content/uploads/2013/03/11.jpg \"未命名11\") ](http://hongweiyi.com/wp-content/uploads/2013/03/1.jpg)\n  > 哎，最初的10s呢！  \n\n[![1](http://hongweiyi.com/wp-content/uploads/2013/03/1_thumb.jpg \"1\")](http://hongweiyi.com/wp-content/uploads/2013/03/12.jpg)\n  > **原分数：**内存5.9，硬盘5.0。  \n\n[![未命名](http://hongweiyi.com/wp-content/uploads/2013/03/thumb.jpg \"未命名\")](http://hongweiyi.com/wp-content/uploads/2013/03/163306e8e326.jpg) \n  > **继续吐槽：**说好的“惊人的535MB/s读和480MB/s写”呢？这才不到一半啊！！！亲\n> \n> **继续吐槽：**HDD的Benchmark就不上了吧，太慢了，没等下去。","slug":"re-equip-my-little-black","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg621a0021sb8fkst4112j"},{"title":"从《社交网络》以及美女排名系统看问题","id":"112","date":"2011-03-06T15:33:20.000Z","_content":"\n![image](/images/ranksystem-in-social-network.png)\n\n**引言：《社交网络》**没有拿到奥斯卡奖，也在情理之中，不符合那学院派的风格嘛。\n\n大概是2个月前看的这部电影，没有过多关注拍摄手法、演技等电影元素，关注的是**[Jesse Eisenberg](http://people.mtime.com/914798/)**对**Mark**的人物演绎。人和人是有差距的，这点我很赞同。那么，我和Mark之间的差距在哪？\n\n<!--more-->来分析下：\n> 1、Mark是一个**Geek**（褒义的），我是一个伪Geek。\r>\n>\n> 2、Mark对技术**狂热**，热到可以不吃不睡以及禁欲，我对技术热爱，爱到可以不吃晚睡但不会禁欲。\r>\n>\n> 3、Mark可以**心无旁骛**的钻研，我可以左顾右盼的学习。\n是的，差距就是这样来的，可能我较Mark好的就是，我对衣着的品位还是好一点，毕竟Mark去年被英国时尚杂志《Esquire》评为十大着装品位最差男人之一嘛，哈哈，玩笑话……\n\n来说说正事吧，一直对Mark的Facemash对女孩评分的算法感兴趣，今天琢磨了一下，写写心得体会。\n\n该排名系统出自Elo Rating System，根据维基百科的介绍：\n\nThe **Elo rating system** is a method for calculating the _relative skill levels_ of players in two-player games such as [chess](http://en.wikipedia.org/wiki/Chess). It is named after its creator [Arpad Elo](http://en.wikipedia.org/wiki/Arpad_Elo), a [Hungarian](http://en.wikipedia.org/wiki/Hungary)-born [American](http://en.wikipedia.org/wiki/United_States) [physics](http://en.wikipedia.org/wiki/Physics) professor.\n\nElo rating system是一个用于计算两人对战模式中参赛者相对技术水平的方法，如象棋。是根据它的创造者匈牙利裔美国物理学家Arpad Elo命名的。\n\nThe Elo system was invented as an improved [chess rating system](http://en.wikipedia.org/wiki/Chess_rating_system), but today it is also used in many other games. It is also used as a rating system for multiplayer competition in a number of [computer games](http://en.wikipedia.org/wiki/Computer_game),[<sup>[1]</sup>](http://en.wikipedia.org/wiki/Elo_rating_system#cite_note-0) and has been adapted to team sports including [association football](http://en.wikipedia.org/wiki/Association_football), American college football and basketball, and [Major League Baseball](http://en.wikipedia.org/wiki/Major_League_Baseball).\n\n这个系统最初设计用来改善国际象棋排名系统，但是现在也用在其它比赛中。同样也可以用在多人竞技的电脑游戏的排名系统，也被团队运动所采纳，如足球比赛、美国大学足球和篮球比赛和棒球联盟比赛。\n\n**Elo假设：**\n\n1.参赛选手在每次比赛中的表现成正态分布；后来普遍认为Logistic分布更为合理（抱歉，由于专业和知识限制，无法解释以及理解Logistic分布）\n\n2.在一局比赛中，赢的一方被认为表现较好，输的一方被认为表现较差；若平局，则双方表现大致相当。虽然这个假设貌似很稀松平常。\n\n**算法如图：**\n\n### [![clip_image003](http://www.hongweiyi.com/wp-content/uploads/2011/03/clip_image003_thumb.png \"clip_image003\")](http://www.hongweiyi.com/wp-content/uploads/2011/03/clip_image003.png)\n\nEa为选手A的期望表现，Ra为选手A当前的等级分排名。\n\n当选手A和B进行比赛时，可根据公式算出两选手的期望表现。\n\nEa + Eb=1\n\n胜方得1分，负方得0分。（在电影中，不会出现平局）\n\n如果选手的表现比期望要好，那么此选手的排名应该上升。相反，若表现不如期望，则排名会下降。\n\n### [![clip_image004](http://www.hongweiyi.com/wp-content/uploads/2011/03/clip_image004_thumb.jpg \"clip_image004\")](http://www.hongweiyi.com/wp-content/uploads/2011/03/clip_image004.jpg)\n\nSa为选手A本局的得分（1或0），Ra为选手A的期望表现。K为常数，在大师级象棋赛中通常取16。得到的Ra’为选手本局比赛后的等级分排名。\n\n初始可认为每个人的等级分排名为0。\n\n第一局是A和B进行比赛。此时Ra=Rb=0，Ea=Eb=0.5。\n\n假设本局A胜B负，则A的得分为1，B的得分为0。\n\nRa'=0+16*(1-0.5)=8\n\nRb'=0+16*(0-0.5)=-8\n\n上面的算法过程主要是转载的**豆瓣网友**的，原文请看**参考资料**。\n\n通过Mark创建Facemash给我的启发很大：**第一**，数学非常重要。**第二**，其实看似很高深的东东，放到生活中就会那么有趣。不过，前提得是你知识的深厚与渊博，这也是我考研的一个目的，尽管落榜了T_T。\n> **参考资料:**\r>\n> <pre> [http://en.wikipedia.org/wiki/Elo_rating_system](http://en.wikipedia.org/wiki/Elo_rating_system)</pre>\r>\n> <pre> [http://www.douban.com/note/122191956/](http://www.douban.com/note/122191956/)</pre>\n","source":"_posts/ranksystem-in-social-network.md","raw":"title: 从《社交网络》以及美女排名系统看问题\ntags:\n  - 电影\n  - 算法\nid: 112\ncategories:\n  - 技术分享\ndate: 2011-03-06 23:33:20\n---\n\n![image](/images/ranksystem-in-social-network.png)\n\n**引言：《社交网络》**没有拿到奥斯卡奖，也在情理之中，不符合那学院派的风格嘛。\n\n大概是2个月前看的这部电影，没有过多关注拍摄手法、演技等电影元素，关注的是**[Jesse Eisenberg](http://people.mtime.com/914798/)**对**Mark**的人物演绎。人和人是有差距的，这点我很赞同。那么，我和Mark之间的差距在哪？\n\n<!--more-->来分析下：\n> 1、Mark是一个**Geek**（褒义的），我是一个伪Geek。\r>\n>\n> 2、Mark对技术**狂热**，热到可以不吃不睡以及禁欲，我对技术热爱，爱到可以不吃晚睡但不会禁欲。\r>\n>\n> 3、Mark可以**心无旁骛**的钻研，我可以左顾右盼的学习。\n是的，差距就是这样来的，可能我较Mark好的就是，我对衣着的品位还是好一点，毕竟Mark去年被英国时尚杂志《Esquire》评为十大着装品位最差男人之一嘛，哈哈，玩笑话……\n\n来说说正事吧，一直对Mark的Facemash对女孩评分的算法感兴趣，今天琢磨了一下，写写心得体会。\n\n该排名系统出自Elo Rating System，根据维基百科的介绍：\n\nThe **Elo rating system** is a method for calculating the _relative skill levels_ of players in two-player games such as [chess](http://en.wikipedia.org/wiki/Chess). It is named after its creator [Arpad Elo](http://en.wikipedia.org/wiki/Arpad_Elo), a [Hungarian](http://en.wikipedia.org/wiki/Hungary)-born [American](http://en.wikipedia.org/wiki/United_States) [physics](http://en.wikipedia.org/wiki/Physics) professor.\n\nElo rating system是一个用于计算两人对战模式中参赛者相对技术水平的方法，如象棋。是根据它的创造者匈牙利裔美国物理学家Arpad Elo命名的。\n\nThe Elo system was invented as an improved [chess rating system](http://en.wikipedia.org/wiki/Chess_rating_system), but today it is also used in many other games. It is also used as a rating system for multiplayer competition in a number of [computer games](http://en.wikipedia.org/wiki/Computer_game),[<sup>[1]</sup>](http://en.wikipedia.org/wiki/Elo_rating_system#cite_note-0) and has been adapted to team sports including [association football](http://en.wikipedia.org/wiki/Association_football), American college football and basketball, and [Major League Baseball](http://en.wikipedia.org/wiki/Major_League_Baseball).\n\n这个系统最初设计用来改善国际象棋排名系统，但是现在也用在其它比赛中。同样也可以用在多人竞技的电脑游戏的排名系统，也被团队运动所采纳，如足球比赛、美国大学足球和篮球比赛和棒球联盟比赛。\n\n**Elo假设：**\n\n1.参赛选手在每次比赛中的表现成正态分布；后来普遍认为Logistic分布更为合理（抱歉，由于专业和知识限制，无法解释以及理解Logistic分布）\n\n2.在一局比赛中，赢的一方被认为表现较好，输的一方被认为表现较差；若平局，则双方表现大致相当。虽然这个假设貌似很稀松平常。\n\n**算法如图：**\n\n### [![clip_image003](http://www.hongweiyi.com/wp-content/uploads/2011/03/clip_image003_thumb.png \"clip_image003\")](http://www.hongweiyi.com/wp-content/uploads/2011/03/clip_image003.png)\n\nEa为选手A的期望表现，Ra为选手A当前的等级分排名。\n\n当选手A和B进行比赛时，可根据公式算出两选手的期望表现。\n\nEa + Eb=1\n\n胜方得1分，负方得0分。（在电影中，不会出现平局）\n\n如果选手的表现比期望要好，那么此选手的排名应该上升。相反，若表现不如期望，则排名会下降。\n\n### [![clip_image004](http://www.hongweiyi.com/wp-content/uploads/2011/03/clip_image004_thumb.jpg \"clip_image004\")](http://www.hongweiyi.com/wp-content/uploads/2011/03/clip_image004.jpg)\n\nSa为选手A本局的得分（1或0），Ra为选手A的期望表现。K为常数，在大师级象棋赛中通常取16。得到的Ra’为选手本局比赛后的等级分排名。\n\n初始可认为每个人的等级分排名为0。\n\n第一局是A和B进行比赛。此时Ra=Rb=0，Ea=Eb=0.5。\n\n假设本局A胜B负，则A的得分为1，B的得分为0。\n\nRa'=0+16*(1-0.5)=8\n\nRb'=0+16*(0-0.5)=-8\n\n上面的算法过程主要是转载的**豆瓣网友**的，原文请看**参考资料**。\n\n通过Mark创建Facemash给我的启发很大：**第一**，数学非常重要。**第二**，其实看似很高深的东东，放到生活中就会那么有趣。不过，前提得是你知识的深厚与渊博，这也是我考研的一个目的，尽管落榜了T_T。\n> **参考资料:**\r>\n> <pre> [http://en.wikipedia.org/wiki/Elo_rating_system](http://en.wikipedia.org/wiki/Elo_rating_system)</pre>\r>\n> <pre> [http://www.douban.com/note/122191956/](http://www.douban.com/note/122191956/)</pre>\n","slug":"ranksystem-in-social-network","published":1,"updated":"2015-12-29T13:38:09.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg621c0027sb8fewtedb9i"},{"title":"Python - 遍历目录","id":"228","date":"2011-12-21T04:21:13.000Z","_content":"\nPython遍历目录经常要用到，所以就在日志mark一下吧。\n <!--more-->  \n\n最开始是用传统的方式写的，找到目录，list它的所有下一级目录，再递归遍历，代码如下：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">import</span><span>&#160;</span><span class=\"commonlibs\">os</span><span>, </span><span class=\"commonlibs\">sys</span><span>&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"comment\"># list files in root by recursion </span><span>&#160; </span></span>\n4.  <span></span><span class=\"keyword\">def</span><span> listfile(root, callback = None):&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">for</span><span> path </span><span class=\"keyword\">in</span><span>&#160;</span><span class=\"commonlibs\">os</span><span>.listdir(root):&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; abs_path = </span><span class=\"commonlibs\">os</span><span>.path.join(root, path)&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span>&#160;</span><span class=\"commonlibs\">os</span><span>.path.isdir(abs_path):&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; listfile(abs_path, callback)&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">else</span><span>:&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> callback: callback(abs_path)&#160;&#160; </span></span>\n11.  <span>&#160; </span>\n12.  <span></span><span class=\"comment\">#do something to the path </span><span>&#160; </span></span>\n13.  <span></span><span class=\"keyword\">def</span><span> dosth(path):&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">print</span><span> path&#160;&#160; </span></span>\n15.  <span>&#160; </span>\n16.  <span></span><span class=\"keyword\">if</span><span>&#160;</span><span class=\"builtins\">__name__</span><span> == &quot;</span><span class=\"builtins\">__main__</span><span>&quot;:&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160; path = </span><span class=\"builtins\">raw_input</span><span>('enter your path: ')&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">try</span><span>:&#160;&#160; </span></span>\n19.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; listfile(path, dosth)&#160;&#160; </span>\n20.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">except</span><span>: </span><span class=\"comment\"># Exception in permissions, sytem file etc </span><span>&#160; </span></span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">pass</span><span>&#160; </span></span>         </div>       </td>     </tr>   </tbody></table>  \n\n看了上面的代码总觉得别扭，连轮子都有的python应该有遍历目录的方法吧，Google之后发现真有，即os.walk(path)方法。\n\nos.walk()可以得到一个三元元组(dirpath, dirnames, filenames)，dirpath是字符串，为起始路径；dirnames是list，为dirpath下的文件夹名；filenames是list，为dirpath下的文件名。\n\n其中dirnames以及filenames均不包含路径信息，如果需要得到全路径，需要使用os.path.join(path,name)。\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">import</span><span>&#160;</span><span class=\"commonlibs\">os</span><span>, </span><span class=\"commonlibs\">sys</span><span>&#160; </span></span>2.  <span>&#160; </span>3.  <span></span><span class=\"comment\"># list files in root by os.walk() </span><span>&#160; </span></span>4.  <span></span><span class=\"keyword\">def</span><span> walkfile(root, callback = None):&#160;&#160; </span></span>5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">for</span><span> dirpath, dirnames, filenames </span><span class=\"keyword\">in</span><span>&#160;</span><span class=\"commonlibs\">os</span><span>.walk(root):&#160;&#160; </span></span>6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">for</span><span> filename </span><span class=\"keyword\">in</span><span> filenames:&#160;&#160; </span></span>7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; abs_path = </span><span class=\"commonlibs\">os</span><span>.path.join(dirpath, filename)&#160;&#160; </span></span>8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> callback: callback(abs_path)&#160;&#160; </span></span>9.  <span>&#160; </span>10.  <span></span><span class=\"comment\">#do something to the path </span><span>&#160; </span></span>11.  <span></span><span class=\"keyword\">def</span><span> dosth(path):&#160;&#160; </span></span>12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">print</span><span> path&#160;&#160; </span></span>13.  <span>&#160; </span>14.  <span></span><span class=\"keyword\">if</span><span>&#160;</span><span class=\"builtins\">__name__</span><span> == &quot;</span><span class=\"builtins\">__main__</span><span>&quot;:&#160;&#160; </span></span>15.  <span>&#160;&#160;&#160; path = </span><span class=\"builtins\">raw_input</span><span>('enter your path: ')&#160;&#160; </span></span>16.  <span>&#160;&#160;&#160; </span><span class=\"comment\">#In theory, there is no permissions/systemfile exception by os.walk </span><span>&#160; </span></span>17.  <span>&#160;&#160;&#160; walkfile(path, dosth)&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>","source":"_posts/python-traverse-dir.md","raw":"title: Python - 遍历目录\ntags:\n  - Python\nid: 228\ncategories:\n  - 技术分享\ndate: 2011-12-21 12:21:13\n---\n\nPython遍历目录经常要用到，所以就在日志mark一下吧。\n <!--more-->  \n\n最开始是用传统的方式写的，找到目录，list它的所有下一级目录，再递归遍历，代码如下：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">import</span><span>&#160;</span><span class=\"commonlibs\">os</span><span>, </span><span class=\"commonlibs\">sys</span><span>&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"comment\"># list files in root by recursion </span><span>&#160; </span></span>\n4.  <span></span><span class=\"keyword\">def</span><span> listfile(root, callback = None):&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">for</span><span> path </span><span class=\"keyword\">in</span><span>&#160;</span><span class=\"commonlibs\">os</span><span>.listdir(root):&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; abs_path = </span><span class=\"commonlibs\">os</span><span>.path.join(root, path)&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span>&#160;</span><span class=\"commonlibs\">os</span><span>.path.isdir(abs_path):&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; listfile(abs_path, callback)&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">else</span><span>:&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> callback: callback(abs_path)&#160;&#160; </span></span>\n11.  <span>&#160; </span>\n12.  <span></span><span class=\"comment\">#do something to the path </span><span>&#160; </span></span>\n13.  <span></span><span class=\"keyword\">def</span><span> dosth(path):&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">print</span><span> path&#160;&#160; </span></span>\n15.  <span>&#160; </span>\n16.  <span></span><span class=\"keyword\">if</span><span>&#160;</span><span class=\"builtins\">__name__</span><span> == &quot;</span><span class=\"builtins\">__main__</span><span>&quot;:&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160; path = </span><span class=\"builtins\">raw_input</span><span>('enter your path: ')&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">try</span><span>:&#160;&#160; </span></span>\n19.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; listfile(path, dosth)&#160;&#160; </span>\n20.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">except</span><span>: </span><span class=\"comment\"># Exception in permissions, sytem file etc </span><span>&#160; </span></span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">pass</span><span>&#160; </span></span>         </div>       </td>     </tr>   </tbody></table>  \n\n看了上面的代码总觉得别扭，连轮子都有的python应该有遍历目录的方法吧，Google之后发现真有，即os.walk(path)方法。\n\nos.walk()可以得到一个三元元组(dirpath, dirnames, filenames)，dirpath是字符串，为起始路径；dirnames是list，为dirpath下的文件夹名；filenames是list，为dirpath下的文件名。\n\n其中dirnames以及filenames均不包含路径信息，如果需要得到全路径，需要使用os.path.join(path,name)。\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">import</span><span>&#160;</span><span class=\"commonlibs\">os</span><span>, </span><span class=\"commonlibs\">sys</span><span>&#160; </span></span>2.  <span>&#160; </span>3.  <span></span><span class=\"comment\"># list files in root by os.walk() </span><span>&#160; </span></span>4.  <span></span><span class=\"keyword\">def</span><span> walkfile(root, callback = None):&#160;&#160; </span></span>5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">for</span><span> dirpath, dirnames, filenames </span><span class=\"keyword\">in</span><span>&#160;</span><span class=\"commonlibs\">os</span><span>.walk(root):&#160;&#160; </span></span>6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">for</span><span> filename </span><span class=\"keyword\">in</span><span> filenames:&#160;&#160; </span></span>7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; abs_path = </span><span class=\"commonlibs\">os</span><span>.path.join(dirpath, filename)&#160;&#160; </span></span>8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> callback: callback(abs_path)&#160;&#160; </span></span>9.  <span>&#160; </span>10.  <span></span><span class=\"comment\">#do something to the path </span><span>&#160; </span></span>11.  <span></span><span class=\"keyword\">def</span><span> dosth(path):&#160;&#160; </span></span>12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">print</span><span> path&#160;&#160; </span></span>13.  <span>&#160; </span>14.  <span></span><span class=\"keyword\">if</span><span>&#160;</span><span class=\"builtins\">__name__</span><span> == &quot;</span><span class=\"builtins\">__main__</span><span>&quot;:&#160;&#160; </span></span>15.  <span>&#160;&#160;&#160; path = </span><span class=\"builtins\">raw_input</span><span>('enter your path: ')&#160;&#160; </span></span>16.  <span>&#160;&#160;&#160; </span><span class=\"comment\">#In theory, there is no permissions/systemfile exception by os.walk </span><span>&#160; </span></span>17.  <span>&#160;&#160;&#160; walkfile(path, dosth)&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>","slug":"python-traverse-dir","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg621e002dsb8f47ka4ywp"},{"title":"人生苦短，我用Python","id":"243","date":"2012-01-20T08:40:51.000Z","_content":"\n用脚本语言的原因就是因为其语法简单，使用方便，但是好像一直没有把握其中的精华。虽然仔细读过网上转载过N次的&lt;[Python少打字小技巧](http://www.joynb.net/blog/archives/120)&gt;，但还是无法很好的运用。\n <!--more-->  \n\n今天逛论坛的时候，看到了一个网友发了一个[ip地址排序](http://bbs.chinaunix.net/thread-823862-1-1.html)的帖子，代码行数60行，核心代码30多行。没有仔细读，看看评论的时候，看到了另一个解法，总代码6行，核心代码4行。用了列表解析、匿名函数等特性，还有内置函数，代码如下：\n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span>iplist=['192.168.1.33','10.5.1.3','10.5.2.4','202.98.96.68','13.12.1.1']&#160;&#160; </span></span>\n2.  <span></span><span class=\"keyword\">def</span><span> ip2int(s):&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160; l = [</span><span class=\"builtins\">int</span><span>(i) </span><span class=\"keyword\">for</span><span> i </span><span class=\"keyword\">in</span><span> s.split('.')]&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> (l[0] &lt;&lt; 24) | (l[1] &lt;&lt; 16) | (l[2] &lt;&lt; 8 ) | l[3]&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160; </span>\n6.  <span>iplist.sort(</span><span class=\"keyword\">lambda</span><span> x, y: </span><span class=\"builtins\">cmp</span><span>(ip2int(x), ip2int(y)))&#160;&#160; </span></span>\n7.  <span></span><span class=\"keyword\">print</span><span> iplist&#160; </span></span> </div>  \n\n按照&lt;[Python少打字小技巧](http://www.joynb.net/blog/archives/120)&gt;里的例子，这个代码核心部分可以缩减到2行（其实可以只有1行），不过，可读性就不敢恭维咯。\n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span>iplist=['192.168.1.33','10.5.1.3','10.5.2.4','202.98.96.68','13.12.1.1']&#160;&#160; </span></span>\n2.  <span>p = </span><span class=\"keyword\">lambda</span><span> ip: </span><span class=\"builtins\">sum</span><span>( [ </span><span class=\"builtins\">int</span><span>(k)*v </span><span class=\"keyword\">for</span><span> k, v </span><span class=\"keyword\">in</span><span>&#160;</span><span class=\"builtins\">zip</span><span>(ip.split('.'), [1&lt;&lt;24, 65536, 256, 1])]);&#160;&#160; </span></span>\n3.  <span>iplist.sort(</span><span class=\"keyword\">lambda</span><span> x, y: </span><span class=\"builtins\">cmp</span><span>(p(x), p(y)))&#160;&#160; </span></span>\n4.  <span></span><span class=\"keyword\">print</span><span> iplist&#160; </span></span> </div>  \n\n既然说到短小精悍，就写写Python的一些特性和函数吧：lambda、map、reduce、filter\n\n**lambda**\n\n匿名函数，和c/c++中的宏定义类似，格式为：lambda [参数] : [表达式]，如：lambda x : x+2，调用的时候可以用一个变量接收这个函数，并传入参数。\n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span>lam = </span><span class=\"keyword\">lambda</span><span> x : x+2&#160;&#160; </span></span>\n2.  <span></span><span class=\"keyword\">print</span><span> lam(2)&#160;&#160; </span></span>\n3.  <span></span><span class=\"keyword\">print</span><span> (</span><span class=\"keyword\">lambda</span><span> x : x+2)(2)&#160; </span></span> </div>  \n\n有些人觉得lambda也就这点功能，但笔者认为，这才是脚本语言，点题：人生苦短，我用Python！这位[**博主**](http://www.cnblogs.com/coderzh/archive/2010/04/30/python-cookbook-lambda.html)写得不错，可以参考参考。\n\n**map，reduce，filter**\n\n其实lambda很多地方都是用在上面这三个函数上面，map(func,seq)、reduce(func,seq,initial=None)、filter(bool_func,seq)。\n\nmap：对seq中的每一个对象都执行func函数，并返回一个列表；\n\nreduce：对seq中的每两个对象依次执行func函数，并返回一个值，如1+2+3+4；\n\nfilter：过滤掉seq中不符合bool_func的对象。\n\n虽然这三个函数中func都可以使用def来定义，但是如果程序需要的逻辑比较简单的话，用lambda就足够了。\n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span>ls = [1,2,3,4,5]&#160;&#160; </span></span>\n2.  <span></span><span class=\"comment\"># every item in ls plus 2 </span><span>&#160; </span></span>\n3.  <span></span><span class=\"keyword\">print</span><span>&#160;</span><span class=\"builtins\">map</span><span>(</span><span class=\"keyword\">lambda</span><span> x : x+2, ls)&#160;&#160; </span></span>\n4.  <span></span><span class=\"comment\"># sum(ls) </span><span>&#160; </span></span>\n5.  <span></span><span class=\"keyword\">print</span><span>&#160;</span><span class=\"builtins\">reduce</span><span>(</span><span class=\"keyword\">lambda</span><span> x, y : x+y, ls)&#160;&#160; </span></span>\n6.  <span></span><span class=\"comment\"># filter the item which less than 2 </span><span>&#160; </span></span>\n7.  <span></span><span class=\"keyword\">print</span><span>&#160;</span><span class=\"builtins\">filter</span><span>(</span><span class=\"keyword\">lambda</span><span> x : x &gt; 2 </span><span class=\"keyword\">and</span><span>&#160;</span><span class=\"builtins\">True</span><span>&#160;</span><span class=\"keyword\">or</span><span>&#160;</span><span class=\"builtins\">False</span><span>, ls)&#160;&#160; </span></span> </div>","source":"_posts/python-chat.md","raw":"title: 人生苦短，我用Python\ntags:\n  - Python\nid: 243\ncategories:\n  - 技术分享\ndate: 2012-01-20 16:40:51\n---\n\n用脚本语言的原因就是因为其语法简单，使用方便，但是好像一直没有把握其中的精华。虽然仔细读过网上转载过N次的&lt;[Python少打字小技巧](http://www.joynb.net/blog/archives/120)&gt;，但还是无法很好的运用。\n <!--more-->  \n\n今天逛论坛的时候，看到了一个网友发了一个[ip地址排序](http://bbs.chinaunix.net/thread-823862-1-1.html)的帖子，代码行数60行，核心代码30多行。没有仔细读，看看评论的时候，看到了另一个解法，总代码6行，核心代码4行。用了列表解析、匿名函数等特性，还有内置函数，代码如下：\n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span>iplist=['192.168.1.33','10.5.1.3','10.5.2.4','202.98.96.68','13.12.1.1']&#160;&#160; </span></span>\n2.  <span></span><span class=\"keyword\">def</span><span> ip2int(s):&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160; l = [</span><span class=\"builtins\">int</span><span>(i) </span><span class=\"keyword\">for</span><span> i </span><span class=\"keyword\">in</span><span> s.split('.')]&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> (l[0] &lt;&lt; 24) | (l[1] &lt;&lt; 16) | (l[2] &lt;&lt; 8 ) | l[3]&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160; </span>\n6.  <span>iplist.sort(</span><span class=\"keyword\">lambda</span><span> x, y: </span><span class=\"builtins\">cmp</span><span>(ip2int(x), ip2int(y)))&#160;&#160; </span></span>\n7.  <span></span><span class=\"keyword\">print</span><span> iplist&#160; </span></span> </div>  \n\n按照&lt;[Python少打字小技巧](http://www.joynb.net/blog/archives/120)&gt;里的例子，这个代码核心部分可以缩减到2行（其实可以只有1行），不过，可读性就不敢恭维咯。\n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span>iplist=['192.168.1.33','10.5.1.3','10.5.2.4','202.98.96.68','13.12.1.1']&#160;&#160; </span></span>\n2.  <span>p = </span><span class=\"keyword\">lambda</span><span> ip: </span><span class=\"builtins\">sum</span><span>( [ </span><span class=\"builtins\">int</span><span>(k)*v </span><span class=\"keyword\">for</span><span> k, v </span><span class=\"keyword\">in</span><span>&#160;</span><span class=\"builtins\">zip</span><span>(ip.split('.'), [1&lt;&lt;24, 65536, 256, 1])]);&#160;&#160; </span></span>\n3.  <span>iplist.sort(</span><span class=\"keyword\">lambda</span><span> x, y: </span><span class=\"builtins\">cmp</span><span>(p(x), p(y)))&#160;&#160; </span></span>\n4.  <span></span><span class=\"keyword\">print</span><span> iplist&#160; </span></span> </div>  \n\n既然说到短小精悍，就写写Python的一些特性和函数吧：lambda、map、reduce、filter\n\n**lambda**\n\n匿名函数，和c/c++中的宏定义类似，格式为：lambda [参数] : [表达式]，如：lambda x : x+2，调用的时候可以用一个变量接收这个函数，并传入参数。\n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span>lam = </span><span class=\"keyword\">lambda</span><span> x : x+2&#160;&#160; </span></span>\n2.  <span></span><span class=\"keyword\">print</span><span> lam(2)&#160;&#160; </span></span>\n3.  <span></span><span class=\"keyword\">print</span><span> (</span><span class=\"keyword\">lambda</span><span> x : x+2)(2)&#160; </span></span> </div>  \n\n有些人觉得lambda也就这点功能，但笔者认为，这才是脚本语言，点题：人生苦短，我用Python！这位[**博主**](http://www.cnblogs.com/coderzh/archive/2010/04/30/python-cookbook-lambda.html)写得不错，可以参考参考。\n\n**map，reduce，filter**\n\n其实lambda很多地方都是用在上面这三个函数上面，map(func,seq)、reduce(func,seq,initial=None)、filter(bool_func,seq)。\n\nmap：对seq中的每一个对象都执行func函数，并返回一个列表；\n\nreduce：对seq中的每两个对象依次执行func函数，并返回一个值，如1+2+3+4；\n\nfilter：过滤掉seq中不符合bool_func的对象。\n\n虽然这三个函数中func都可以使用def来定义，但是如果程序需要的逻辑比较简单的话，用lambda就足够了。\n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span>ls = [1,2,3,4,5]&#160;&#160; </span></span>\n2.  <span></span><span class=\"comment\"># every item in ls plus 2 </span><span>&#160; </span></span>\n3.  <span></span><span class=\"keyword\">print</span><span>&#160;</span><span class=\"builtins\">map</span><span>(</span><span class=\"keyword\">lambda</span><span> x : x+2, ls)&#160;&#160; </span></span>\n4.  <span></span><span class=\"comment\"># sum(ls) </span><span>&#160; </span></span>\n5.  <span></span><span class=\"keyword\">print</span><span>&#160;</span><span class=\"builtins\">reduce</span><span>(</span><span class=\"keyword\">lambda</span><span> x, y : x+y, ls)&#160;&#160; </span></span>\n6.  <span></span><span class=\"comment\"># filter the item which less than 2 </span><span>&#160; </span></span>\n7.  <span></span><span class=\"keyword\">print</span><span>&#160;</span><span class=\"builtins\">filter</span><span>(</span><span class=\"keyword\">lambda</span><span> x : x &gt; 2 </span><span class=\"keyword\">and</span><span>&#160;</span><span class=\"builtins\">True</span><span>&#160;</span><span class=\"keyword\">or</span><span>&#160;</span><span class=\"builtins\">False</span><span>, ls)&#160;&#160; </span></span> </div>","slug":"python-chat","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg621f002hsb8fhgqxcz3e"},{"title":"相机的测光模式详解","id":"156","date":"2011-08-31T19:33:22.000Z","_content":"\n数码相机的测光系统一般是通过测定被摄物反射回来的光线强弱来进行测光的，这样的测光方法称之为反射式测光。其原理非常简单，相机自动假设所测光区域的反光率为18%的灰色（这个数值是通过大量研究得到的），当所拍摄的画面反光率高于18%灰度时，相机就认为画面过曝了，需要调低曝光量（调小光圈，或调快快门），反之就是欠曝，需要增加曝光量。下面我们以尼康D3100为例，来看看该机的测光模式。\n\n![从零开始玩单反 编辑教您怎样正确曝光（未完成） ](http://2a.zol-img.com.cn/product/69_500x2000/678/cem3Ejwh9cAac.gif)\n\n<!--more-->_该相机共有三种不同的测光模式_\n\n**·点测光**\n\n点测光，顾名思义就是只对一个点进行测光，该点和对焦点在同一个位置（其实是一个非常小的区域而已，不是完全的点），这种测光方法的好处是可以根据摄影师的喜好，对某一个摄影师认为正确的点，或者是被拍摄主体进行正确测光，而不会被附近的其他光线干扰，换句话说相机只保证该点的曝光正确，别的地方曝光是否准确它不管。\n\n适用拍摄用途：舞台摄影，个人艺术照，新闻特写等。\n\n[ ](http://detail.zol.com.cn/picture_index_697/index6963692.shtml)\n\n[![MUX~][FR}HT_O3V]~BF]]79](http://www.hongweiyi.com/wp-content/uploads/2011/09/MUXFRHT_O3VBF79.jpg \"MUX~][FR}HT_O3V]~BF]]79\")](http://detail.zol.com.cn/picture_index_697/index6963692.shtml)\n\n[ ](http://detail.zol.com.cn/picture_index_697/index6963692.shtml)\n\n[ ](http://detail.zol.com.cn/picture_index_697/index6963692.shtml)\n\n_点测光对准玩具_\n\n**·中央重点测光**\n\n原理和点测光相同，只是它测的不是一个点，而是一个比较小的区域（一般是画面中心10%左右的区域）。它的优点是在自动拍摄时，更容易获得较为真实的、更接近现实的测光，不会因为测光点对准了错误的地方而造成的曝光错误。缺点是无法对一个非常小的参考点进行正确测光。在大多数情况下中央重点测光是一种非常实用的测光模式，但是如果您需要拍摄的主体不再画面中央的话，中央重点测光就不适用了。\n\n适用拍摄用途：人像照片，特写照片等。\n\n_![从零开始玩单反 编辑教您怎样正确曝光（未完成） ](http://2e.zol-img.com.cn/product/69_500x2000/694/cetwEFJGmxx8Y.jpg)\n中央重点测光的范围比点测光大_\n\n**·矩阵测光**\n\n矩阵测光和评价测光是一样的概念，它是将画面分成几个区域，每个区域单独测光，然后相机处理器汇总各区域测出的数值并通过权重计算得出一个最终值，从而对整个画面进行测光。这个测光模式的好处在于可以轻易获得明暗均衡的画面，不会出现局部的高光过曝或欠曝，整个画面明暗均衡。其缺点是无法满足多种情况，比如，阴影、逆光等等。\n\n适用拍摄用途：集体照片，家庭合影，一般风景照片。\n\n![从零开始玩单反 编辑教您怎样正确曝光（未完成） ](http://2d.zol-img.com.cn/product/69_500x2000/693/ceK2DvqCYZ7g.jpg)\n\n_矩阵测光会照顾到整个画面亮度_\n> 转载：[http://dcdv.zol.com.cn/244/2445668.html](http://dcdv.zol.com.cn/244/2445668.html)\n","source":"_posts/photometry.md","raw":"title: 相机的测光模式详解\ntags:\n  - 摄影\n  - 数码\nid: 156\ncategories:\n  - 生活分享\ndate: 2011-09-01 03:33:22\n---\n\n数码相机的测光系统一般是通过测定被摄物反射回来的光线强弱来进行测光的，这样的测光方法称之为反射式测光。其原理非常简单，相机自动假设所测光区域的反光率为18%的灰色（这个数值是通过大量研究得到的），当所拍摄的画面反光率高于18%灰度时，相机就认为画面过曝了，需要调低曝光量（调小光圈，或调快快门），反之就是欠曝，需要增加曝光量。下面我们以尼康D3100为例，来看看该机的测光模式。\n\n![从零开始玩单反 编辑教您怎样正确曝光（未完成） ](http://2a.zol-img.com.cn/product/69_500x2000/678/cem3Ejwh9cAac.gif)\n\n<!--more-->_该相机共有三种不同的测光模式_\n\n**·点测光**\n\n点测光，顾名思义就是只对一个点进行测光，该点和对焦点在同一个位置（其实是一个非常小的区域而已，不是完全的点），这种测光方法的好处是可以根据摄影师的喜好，对某一个摄影师认为正确的点，或者是被拍摄主体进行正确测光，而不会被附近的其他光线干扰，换句话说相机只保证该点的曝光正确，别的地方曝光是否准确它不管。\n\n适用拍摄用途：舞台摄影，个人艺术照，新闻特写等。\n\n[ ](http://detail.zol.com.cn/picture_index_697/index6963692.shtml)\n\n[![MUX~][FR}HT_O3V]~BF]]79](http://www.hongweiyi.com/wp-content/uploads/2011/09/MUXFRHT_O3VBF79.jpg \"MUX~][FR}HT_O3V]~BF]]79\")](http://detail.zol.com.cn/picture_index_697/index6963692.shtml)\n\n[ ](http://detail.zol.com.cn/picture_index_697/index6963692.shtml)\n\n[ ](http://detail.zol.com.cn/picture_index_697/index6963692.shtml)\n\n_点测光对准玩具_\n\n**·中央重点测光**\n\n原理和点测光相同，只是它测的不是一个点，而是一个比较小的区域（一般是画面中心10%左右的区域）。它的优点是在自动拍摄时，更容易获得较为真实的、更接近现实的测光，不会因为测光点对准了错误的地方而造成的曝光错误。缺点是无法对一个非常小的参考点进行正确测光。在大多数情况下中央重点测光是一种非常实用的测光模式，但是如果您需要拍摄的主体不再画面中央的话，中央重点测光就不适用了。\n\n适用拍摄用途：人像照片，特写照片等。\n\n_![从零开始玩单反 编辑教您怎样正确曝光（未完成） ](http://2e.zol-img.com.cn/product/69_500x2000/694/cetwEFJGmxx8Y.jpg)\n中央重点测光的范围比点测光大_\n\n**·矩阵测光**\n\n矩阵测光和评价测光是一样的概念，它是将画面分成几个区域，每个区域单独测光，然后相机处理器汇总各区域测出的数值并通过权重计算得出一个最终值，从而对整个画面进行测光。这个测光模式的好处在于可以轻易获得明暗均衡的画面，不会出现局部的高光过曝或欠曝，整个画面明暗均衡。其缺点是无法满足多种情况，比如，阴影、逆光等等。\n\n适用拍摄用途：集体照片，家庭合影，一般风景照片。\n\n![从零开始玩单反 编辑教您怎样正确曝光（未完成） ](http://2d.zol-img.com.cn/product/69_500x2000/693/ceK2DvqCYZ7g.jpg)\n\n_矩阵测光会照顾到整个画面亮度_\n> 转载：[http://dcdv.zol.com.cn/244/2445668.html](http://dcdv.zol.com.cn/244/2445668.html)\n","slug":"photometry","published":1,"updated":"2015-12-29T13:43:38.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg621h002ksb8fq5nlr8x6"},{"title":"OOM Killer 的一次问题定位","date":"2015-03-16T14:01:01.000Z","_content":"\n这两天为了节省服务器资源，讲多个不同的 JVM 部署到了同一个 VM 上，想着应该没什么事，大不了处理速度慢一点而已，但是没想到确出现了意想不到的状况：各个 VM 上的 JVM 不约而同的挂了。挂了没事，解决 Bug 嘛，但是问题在于 JVM 是怎么挂掉了就没有搞清楚，也没有特殊日志打印，我花了半天时间定位了问题。\n<!--more-->\n\n### 1. JVM 为什么挂掉了？\n\n正常来说，JVM 挂了要么会生成内存 dump ，要么直接生成 core 文件，我的机器什么都没有产生。于是乎只能借助系统工具了，如下命令能够捕获进程信号：\n\n```\nstrace -e trace=signal -o /home/admin/strace.log -p [PID];\n```\n\n等了几个小时后，有 JVM 挂了，日志输出如下：\n\n```\n+++ killed by SIGKILL +++\n```\n\n[signal - overview of signals](http://man7.org/linux/man-pages/man7/signal.7.html) 这里可以看到，SIGKILL 就是 kill -9，进程不会做任何处理直接退出。看到这个我以为咱们的 OS 部署了监控进程，会用来 kill 掉耗资源的进程，咨询运维人员后，没有这样的程序部署，排除他方的因素，自身程序有问题可能性较大。\n\n从信号上看不出什么端倪，就只能从系统日志上面来找了，通过以下命令发现 JVM 挂掉的原因：\n\n```\ndmesg | egrep -i -B100 'killed process'\n[5673702.665338] [20189]   522 20189     1017       22   2       0             0 sleep\n[5673702.665338] [20308]     0 20308    47967    20414   3       0             0 puppet\n[5673702.665338] [20536]     0 20536    47969    20419   1       0             0 puppet\n[5673702.665338] Out of memory: Kill process 29953 (java) score 431 or sacrifice child\n[5673702.665338] Killed process 29953, UID 500, (java) total-vm:9805316kB, anon-rss:2344496kB, file-rss:128kB\n```\n\n是由于 Out of memory 导致 JVM 被直接 kill 掉，这也是较为常见的 OOM Killer 了，关于 OOM Killer 网上有篇不错的解析文章，摘抄见后文。\n\n> 定位 OOM 具体问题，除了 dump 内存分析之外，还有一些较为简单快捷的方式对整个内存进行一次摸底。\n  pmap -x [PID]: 能查看进程的内存映射;\n  jmap -heap [PID]: 快速查看 JVM 各内存区域的使用情况。</blockquote>\n\n### 2. 理解和配置 Linux 下的 OOM Killer\n\n最近有位 VPS 客户抱怨 MySQL 无缘无故挂掉，还有位客户抱怨 VPS 经常死机，登陆到终端看了一下，都是常见的 Out of memory 问题。这通常是因为某时刻应用程序大量请求内存导致系统内存不足造成的，这通常会触发 Linux 内核里的 Out of Memory (OOM) killer，OOM killer 会杀掉某个进程以腾出内存留给系统用，不致于让系统立刻崩溃。如果检查相关的日志文件（`/var/log/messages`）就会看到下面类似的 `Out of memory: Kill process` 信息：\n\n```\n...\nOut of memory: Kill process 9682 (mysqld) score 9 or sacrifice child\nKilled process 9682, UID 27, (mysqld) total-vm:47388kB, anon-rss:3744kB, file-rss:80kB\nhttpd invoked oom-killer: gfp_mask=0x201da, order=0, oom_adj=0, oom_score_adj=0\nhttpd cpuset=/ mems_allowed=0\nPid: 8911, comm: httpd Not tainted 2.6.32-279.1.1.el6.i686 #1\n...\n21556 total pagecache pages\n21049 pages in swap cache\nSwap cache stats: add 12819103, delete 12798054, find 3188096/4634617\nFree swap  = 0kB\nTotal swap = 524280kB\n131071 pages RAM\n0 pages HighMem\n3673 pages reserved\n67960 pages shared\n124940 pages non-shared\n```\n\nLinux 内核根据应用程序的要求分配内存，通常来说应用程序分配了内存但是并没有实际全部使用，为了提高性能，这部分没用的内存可以留作它用，这部分内存是属于每个进程的，内核直接回收利用的话比较麻烦，所以内核采用一种过度分配内存（over-commit memory）的办法来间接利用这部分 “空闲” 的内存，提高整体内存的使用效率。一般来说这样做没有问题，但当大多数应用程序都消耗完自己的内存的时候麻烦就来了，因为这些应用程序的内存需求加起来超出了物理内存（包括 swap）的容量，内核（OOM killer）必须杀掉一些进程才能腾出空间保障系统正常运行。用银行的例子来讲可能更容易懂一些，部分人取钱的时候银行不怕，银行有足够的存款应付，当全国人民（或者绝大多数）都取钱而且每个人都想把自己钱取完的时候银行的麻烦就来了，银行实际上是没有这么多钱给大家取的。\n\n内核检测到系统内存不足、挑选并杀掉某个进程的过程可以参考内核源代码 [linux/mm/oom_kill.c] (https://github.com/torvalds/linux/blob/master/mm/oom_kill.c)，当系统内存不足的时候，`out_of_memory()` 被触发，然后调用 `select_bad_process()` 选择一个 “bad” 进程杀掉，如何判断和选择一个 “bad” 进程呢，总不能随机选吧？挑选的过程由 `oom_badness()` 决定，挑选的算法和想法都很简单很朴实：最 bad 的那个进程就是那个最占用内存的进程。\n\n``` c\n/**\n * oom_badness - heuristic function to determine which candidate task to kill\n * @p: task struct of which task we should calculate\n * @totalpages: total present RAM allowed for page allocation\n *\n * The heuristic for determining which task to kill is made to be as simple and\n * predictable as possible.  The goal is to return the highest value for the\n * task consuming the most memory to avoid subsequent oom failures.\n */\nunsigned long oom_badness(struct task_struct *p, struct mem_cgroup *memcg,\n\t\t\t  const nodemask_t *nodemask, unsigned long totalpages)\n{\n\tlong points;\n\tlong adj;\n\n\tif (oom_unkillable_task(p, memcg, nodemask))\n\t\treturn 0;\n\n\tp = find_lock_task_mm(p);\n\tif (!p)\n\t\treturn 0;\n\n\tadj = (long)p-&gt;signal-&gt;oom_score_adj;\n\tif (adj == OOM_SCORE_ADJ_MIN) {\n\t\ttask_unlock(p);\n\t\treturn 0;\n\t}\n\n\t/*\n\t * The baseline for the badness score is the proportion of RAM that each\n\t * task's rss, pagetable and swap space use.\n\t */\n\tpoints = get_mm_rss(p-&gt;mm) + p-&gt;mm-&gt;nr_ptes +\n\t\t get_mm_counter(p-&gt;mm, MM_SWAPENTS);\n\ttask_unlock(p);\n\n\t/*\n\t * Root processes get 3% bonus, just like the __vm_enough_memory()\n\t * implementation used by LSMs.\n\t */\n\tif (has_capability_noaudit(p, CAP_SYS_ADMIN))\n\t\tadj -= 30;\n\n\t/* Normalize to oom_score_adj units */\n\tadj *= totalpages / 1000;\n\tpoints += adj;\n\n\t/*\n\t * Never return 0 for an eligible task regardless of the root bonus and\n\t * oom_score_adj (oom_score_adj can't be OOM_SCORE_ADJ_MIN here).\n\t */\n\treturn points &gt; 0 ? points : 1;\n}\n```\n\n上面代码里的注释写的很明白，理解了这个算法我们就理解了为啥 MySQL 躺着也能中枪了，因为它的体积总是最大（一般来说它在系统上占用内存最多），所以如果 Out of Memeory (OOM) 的话总是不幸第一个被 kill 掉。解决这个问题最简单的办法就是增加内存，或者[想办法优化 MySQL 使其占用更少的内存](http://www.vpsee.com/2009/06/64mb-vps-optimize-mysql/)，除了优化 MySQL 外还可以优化系统（[优化 Debian 5](http://www.vpsee.com/2009/06/64mb-vps-optimize-debian5/)，[优化 CentOS 5.x](http://www.vpsee.com/2009/06/128mb-vps-optimize-centos5/)），让系统尽可能使用少的内存以便应用程序（如 MySQL) 能使用更多的内存，还有一个临时的办法就是调整内核参数，让 MySQL 进程不容易被 OOM killer 发现。\n\n#### 2.1 配置 OOM killer\n\n我们可以通过一些内核参数来调整 OOM killer 的行为，避免系统在那里不停的杀进程。比如我们可以在触发 OOM 后立刻触发 kernel panic，kernel panic 10秒后自动重启系统。\n\n```\n# sysctl -w vm.panic_on_oom=1\nvm.panic_on_oom = 1\n\n# sysctl -w kernel.panic=10\nkernel.panic = 10\n\n# echo \"vm.panic_on_oom=1\" &gt;&gt; /etc/sysctl.conf\n# echo \"kernel.panic=10\" &gt;&gt; /etc/sysctl.conf\n```\n\n从上面的 oom_kill.c 代码里可以看到 `oom_badness()` 给每个进程打分，根据 points 的高低来决定杀哪个进程，这个 points 可以根据 adj 调节，root 权限的进程通常被认为很重要，不应该被轻易杀掉，所以打分的时候可以得到 3% 的优惠（adj -= 30; 分数越低越不容易被杀掉）。我们可以在用户空间通过操作每个进程的 oom_adj 内核参数来决定哪些进程不这么容易被 OOM killer 选中杀掉。比如，如果不想 MySQL 进程被轻易杀掉的话可以找到 MySQL 运行的进程号后，调整 oom_score_adj 为 -15（注意 points 越小越不容易被杀）：\n\n```\n# ps aux | grep mysqld\nmysql    2196  1.6  2.1 623800 44876 ?        Ssl  09:42   0:00 /usr/sbin/mysqld\n\n# cat /proc/2196/oom_score_adj\n0\n# echo -15 &gt; /proc/2196/oom_score_adj\n```\n\n当然，如果需要的话可以完全关闭 OOM killer（不推荐用在生产环境）：\n\n```\n# sysctl -w vm.overcommit_memory=2\n\n# echo \"vm.overcommit_memory=2\" &gt;&gt; /etc/sysctl.conf\n```\n\n#### 2.2 找出最有可能被 OOM Killer 杀掉的进程\n\n我们知道了在用户空间可以通过操作每个进程的 oom_adj 内核参数来调整进程的分数，这个分数也可以通过 oom_score 这个内核参数看到，比如查看进程号为981的 omm_score，这个分数被上面提到的 omm_score_adj 参数调整后（－15），就变成了3：\n\n```\n# cat /proc/981/oom_score\n18\n\n# echo -15 &gt; /proc/981/oom_score_adj\n# cat /proc/981/oom_score\n3\n```\n\n下面这个 bash 脚本可用来打印当前系统上 oom_score 分数最高（最容易被 OOM Killer 杀掉）的进程：\n\n```\n# vi oomscore.sh\n#!/bin/bash\nfor proc in $(find /proc -maxdepth 1 -regex '/proc/[0-9]+'); do\n    printf \"%2d %5d %s\\n\" \\\n        \"$(cat $proc/oom_score)\" \\\n        \"$(basename $proc)\" \\\n        \"$(cat $proc/cmdline | tr '\\0' ' ' | head -c 50)\"\ndone 2&gt;/dev/null | sort -nr | head -n 10\n\n# chmod +x oomscore.sh\n# ./oomscore.sh\n18   981 /usr/sbin/mysqld\n 4 31359 -bash\n 4 31056 -bash\n 1 31358 sshd: root@pts/6\n 1 31244 sshd: vpsee [priv]\n 1 31159 -bash\n 1 31158 sudo -i\n 1 31055 sshd: root@pts/3\n 1 30912 sshd: vpsee [priv]\n 1 29547 /usr/sbin/sshd -D\n```\n\n> 原文链接：http://www.vpsee.com/2013/10/how-to-configure-the-linux-oom-killer/\n","source":"_posts/oom-killer-1.md","raw":"title: OOM Killer 的一次问题定位\ndate: 2015-03-16 22:01:01\ncategories: 最佳实践\ntags: [Java, JVM, OOM Killer]\n---\n\n这两天为了节省服务器资源，讲多个不同的 JVM 部署到了同一个 VM 上，想着应该没什么事，大不了处理速度慢一点而已，但是没想到确出现了意想不到的状况：各个 VM 上的 JVM 不约而同的挂了。挂了没事，解决 Bug 嘛，但是问题在于 JVM 是怎么挂掉了就没有搞清楚，也没有特殊日志打印，我花了半天时间定位了问题。\n<!--more-->\n\n### 1. JVM 为什么挂掉了？\n\n正常来说，JVM 挂了要么会生成内存 dump ，要么直接生成 core 文件，我的机器什么都没有产生。于是乎只能借助系统工具了，如下命令能够捕获进程信号：\n\n```\nstrace -e trace=signal -o /home/admin/strace.log -p [PID];\n```\n\n等了几个小时后，有 JVM 挂了，日志输出如下：\n\n```\n+++ killed by SIGKILL +++\n```\n\n[signal - overview of signals](http://man7.org/linux/man-pages/man7/signal.7.html) 这里可以看到，SIGKILL 就是 kill -9，进程不会做任何处理直接退出。看到这个我以为咱们的 OS 部署了监控进程，会用来 kill 掉耗资源的进程，咨询运维人员后，没有这样的程序部署，排除他方的因素，自身程序有问题可能性较大。\n\n从信号上看不出什么端倪，就只能从系统日志上面来找了，通过以下命令发现 JVM 挂掉的原因：\n\n```\ndmesg | egrep -i -B100 'killed process'\n[5673702.665338] [20189]   522 20189     1017       22   2       0             0 sleep\n[5673702.665338] [20308]     0 20308    47967    20414   3       0             0 puppet\n[5673702.665338] [20536]     0 20536    47969    20419   1       0             0 puppet\n[5673702.665338] Out of memory: Kill process 29953 (java) score 431 or sacrifice child\n[5673702.665338] Killed process 29953, UID 500, (java) total-vm:9805316kB, anon-rss:2344496kB, file-rss:128kB\n```\n\n是由于 Out of memory 导致 JVM 被直接 kill 掉，这也是较为常见的 OOM Killer 了，关于 OOM Killer 网上有篇不错的解析文章，摘抄见后文。\n\n> 定位 OOM 具体问题，除了 dump 内存分析之外，还有一些较为简单快捷的方式对整个内存进行一次摸底。\n  pmap -x [PID]: 能查看进程的内存映射;\n  jmap -heap [PID]: 快速查看 JVM 各内存区域的使用情况。</blockquote>\n\n### 2. 理解和配置 Linux 下的 OOM Killer\n\n最近有位 VPS 客户抱怨 MySQL 无缘无故挂掉，还有位客户抱怨 VPS 经常死机，登陆到终端看了一下，都是常见的 Out of memory 问题。这通常是因为某时刻应用程序大量请求内存导致系统内存不足造成的，这通常会触发 Linux 内核里的 Out of Memory (OOM) killer，OOM killer 会杀掉某个进程以腾出内存留给系统用，不致于让系统立刻崩溃。如果检查相关的日志文件（`/var/log/messages`）就会看到下面类似的 `Out of memory: Kill process` 信息：\n\n```\n...\nOut of memory: Kill process 9682 (mysqld) score 9 or sacrifice child\nKilled process 9682, UID 27, (mysqld) total-vm:47388kB, anon-rss:3744kB, file-rss:80kB\nhttpd invoked oom-killer: gfp_mask=0x201da, order=0, oom_adj=0, oom_score_adj=0\nhttpd cpuset=/ mems_allowed=0\nPid: 8911, comm: httpd Not tainted 2.6.32-279.1.1.el6.i686 #1\n...\n21556 total pagecache pages\n21049 pages in swap cache\nSwap cache stats: add 12819103, delete 12798054, find 3188096/4634617\nFree swap  = 0kB\nTotal swap = 524280kB\n131071 pages RAM\n0 pages HighMem\n3673 pages reserved\n67960 pages shared\n124940 pages non-shared\n```\n\nLinux 内核根据应用程序的要求分配内存，通常来说应用程序分配了内存但是并没有实际全部使用，为了提高性能，这部分没用的内存可以留作它用，这部分内存是属于每个进程的，内核直接回收利用的话比较麻烦，所以内核采用一种过度分配内存（over-commit memory）的办法来间接利用这部分 “空闲” 的内存，提高整体内存的使用效率。一般来说这样做没有问题，但当大多数应用程序都消耗完自己的内存的时候麻烦就来了，因为这些应用程序的内存需求加起来超出了物理内存（包括 swap）的容量，内核（OOM killer）必须杀掉一些进程才能腾出空间保障系统正常运行。用银行的例子来讲可能更容易懂一些，部分人取钱的时候银行不怕，银行有足够的存款应付，当全国人民（或者绝大多数）都取钱而且每个人都想把自己钱取完的时候银行的麻烦就来了，银行实际上是没有这么多钱给大家取的。\n\n内核检测到系统内存不足、挑选并杀掉某个进程的过程可以参考内核源代码 [linux/mm/oom_kill.c] (https://github.com/torvalds/linux/blob/master/mm/oom_kill.c)，当系统内存不足的时候，`out_of_memory()` 被触发，然后调用 `select_bad_process()` 选择一个 “bad” 进程杀掉，如何判断和选择一个 “bad” 进程呢，总不能随机选吧？挑选的过程由 `oom_badness()` 决定，挑选的算法和想法都很简单很朴实：最 bad 的那个进程就是那个最占用内存的进程。\n\n``` c\n/**\n * oom_badness - heuristic function to determine which candidate task to kill\n * @p: task struct of which task we should calculate\n * @totalpages: total present RAM allowed for page allocation\n *\n * The heuristic for determining which task to kill is made to be as simple and\n * predictable as possible.  The goal is to return the highest value for the\n * task consuming the most memory to avoid subsequent oom failures.\n */\nunsigned long oom_badness(struct task_struct *p, struct mem_cgroup *memcg,\n\t\t\t  const nodemask_t *nodemask, unsigned long totalpages)\n{\n\tlong points;\n\tlong adj;\n\n\tif (oom_unkillable_task(p, memcg, nodemask))\n\t\treturn 0;\n\n\tp = find_lock_task_mm(p);\n\tif (!p)\n\t\treturn 0;\n\n\tadj = (long)p-&gt;signal-&gt;oom_score_adj;\n\tif (adj == OOM_SCORE_ADJ_MIN) {\n\t\ttask_unlock(p);\n\t\treturn 0;\n\t}\n\n\t/*\n\t * The baseline for the badness score is the proportion of RAM that each\n\t * task's rss, pagetable and swap space use.\n\t */\n\tpoints = get_mm_rss(p-&gt;mm) + p-&gt;mm-&gt;nr_ptes +\n\t\t get_mm_counter(p-&gt;mm, MM_SWAPENTS);\n\ttask_unlock(p);\n\n\t/*\n\t * Root processes get 3% bonus, just like the __vm_enough_memory()\n\t * implementation used by LSMs.\n\t */\n\tif (has_capability_noaudit(p, CAP_SYS_ADMIN))\n\t\tadj -= 30;\n\n\t/* Normalize to oom_score_adj units */\n\tadj *= totalpages / 1000;\n\tpoints += adj;\n\n\t/*\n\t * Never return 0 for an eligible task regardless of the root bonus and\n\t * oom_score_adj (oom_score_adj can't be OOM_SCORE_ADJ_MIN here).\n\t */\n\treturn points &gt; 0 ? points : 1;\n}\n```\n\n上面代码里的注释写的很明白，理解了这个算法我们就理解了为啥 MySQL 躺着也能中枪了，因为它的体积总是最大（一般来说它在系统上占用内存最多），所以如果 Out of Memeory (OOM) 的话总是不幸第一个被 kill 掉。解决这个问题最简单的办法就是增加内存，或者[想办法优化 MySQL 使其占用更少的内存](http://www.vpsee.com/2009/06/64mb-vps-optimize-mysql/)，除了优化 MySQL 外还可以优化系统（[优化 Debian 5](http://www.vpsee.com/2009/06/64mb-vps-optimize-debian5/)，[优化 CentOS 5.x](http://www.vpsee.com/2009/06/128mb-vps-optimize-centos5/)），让系统尽可能使用少的内存以便应用程序（如 MySQL) 能使用更多的内存，还有一个临时的办法就是调整内核参数，让 MySQL 进程不容易被 OOM killer 发现。\n\n#### 2.1 配置 OOM killer\n\n我们可以通过一些内核参数来调整 OOM killer 的行为，避免系统在那里不停的杀进程。比如我们可以在触发 OOM 后立刻触发 kernel panic，kernel panic 10秒后自动重启系统。\n\n```\n# sysctl -w vm.panic_on_oom=1\nvm.panic_on_oom = 1\n\n# sysctl -w kernel.panic=10\nkernel.panic = 10\n\n# echo \"vm.panic_on_oom=1\" &gt;&gt; /etc/sysctl.conf\n# echo \"kernel.panic=10\" &gt;&gt; /etc/sysctl.conf\n```\n\n从上面的 oom_kill.c 代码里可以看到 `oom_badness()` 给每个进程打分，根据 points 的高低来决定杀哪个进程，这个 points 可以根据 adj 调节，root 权限的进程通常被认为很重要，不应该被轻易杀掉，所以打分的时候可以得到 3% 的优惠（adj -= 30; 分数越低越不容易被杀掉）。我们可以在用户空间通过操作每个进程的 oom_adj 内核参数来决定哪些进程不这么容易被 OOM killer 选中杀掉。比如，如果不想 MySQL 进程被轻易杀掉的话可以找到 MySQL 运行的进程号后，调整 oom_score_adj 为 -15（注意 points 越小越不容易被杀）：\n\n```\n# ps aux | grep mysqld\nmysql    2196  1.6  2.1 623800 44876 ?        Ssl  09:42   0:00 /usr/sbin/mysqld\n\n# cat /proc/2196/oom_score_adj\n0\n# echo -15 &gt; /proc/2196/oom_score_adj\n```\n\n当然，如果需要的话可以完全关闭 OOM killer（不推荐用在生产环境）：\n\n```\n# sysctl -w vm.overcommit_memory=2\n\n# echo \"vm.overcommit_memory=2\" &gt;&gt; /etc/sysctl.conf\n```\n\n#### 2.2 找出最有可能被 OOM Killer 杀掉的进程\n\n我们知道了在用户空间可以通过操作每个进程的 oom_adj 内核参数来调整进程的分数，这个分数也可以通过 oom_score 这个内核参数看到，比如查看进程号为981的 omm_score，这个分数被上面提到的 omm_score_adj 参数调整后（－15），就变成了3：\n\n```\n# cat /proc/981/oom_score\n18\n\n# echo -15 &gt; /proc/981/oom_score_adj\n# cat /proc/981/oom_score\n3\n```\n\n下面这个 bash 脚本可用来打印当前系统上 oom_score 分数最高（最容易被 OOM Killer 杀掉）的进程：\n\n```\n# vi oomscore.sh\n#!/bin/bash\nfor proc in $(find /proc -maxdepth 1 -regex '/proc/[0-9]+'); do\n    printf \"%2d %5d %s\\n\" \\\n        \"$(cat $proc/oom_score)\" \\\n        \"$(basename $proc)\" \\\n        \"$(cat $proc/cmdline | tr '\\0' ' ' | head -c 50)\"\ndone 2&gt;/dev/null | sort -nr | head -n 10\n\n# chmod +x oomscore.sh\n# ./oomscore.sh\n18   981 /usr/sbin/mysqld\n 4 31359 -bash\n 4 31056 -bash\n 1 31358 sshd: root@pts/6\n 1 31244 sshd: vpsee [priv]\n 1 31159 -bash\n 1 31158 sudo -i\n 1 31055 sshd: root@pts/3\n 1 30912 sshd: vpsee [priv]\n 1 29547 /usr/sbin/sshd -D\n```\n\n> 原文链接：http://www.vpsee.com/2013/10/how-to-configure-the-linux-oom-killer/\n","slug":"oom-killer-1","published":1,"updated":"2015-12-29T13:43:39.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg621j002osb8ff1bosx26"},{"title":"记一次java性能问题定位","id":"861","date":"2013-10-22T15:21:52.000Z","_content":"\n**1、前言**\n\n\t前一段时间检查集群状态时，发现某部分机器的load较高，故登录服务器查看，某几个java进程的cpu使用率为1000%，没见过这么高的cpu时间，顿时就长见识了！长完见识问题还是要解决的，故本文记录下问题定位的过程。\n\n\t<!--more-->\n\n\t**2、定位流程**\n\n\t**2.1 定位问题进程**\n\n\ttop命令可以简单定位进程pid，如下：\n\n\t[![Image](http://hongweiyi.com/wp-content/uploads/2013/10/Image_thumb.png \"Image\")](http://hongweiyi.com/wp-content/uploads/2013/10/Image.png)\n\n\tjps -vm | grep 15195 可以查看java进程的参数或者日志地址等，如果没有显示参数的话，可以cd到/proc/15195/cwd目录，该目录便是进程的运行目录。\n\n\t**2.2 查看日志**\n\n\t常规做法就是查看日志了，但是扫了几遍日志也没发现问题，因为这个进程这几天的请求都不是很多，难道是线程空转了？\n\n\t**2.3 定位问题线程**\n\n\t既然日志没有发现异常，那只是通过查看进程内部发现问题了。man top可以看到top命令的详细信息，-H则是线程开关，传入该参数的话，top界面会显示所有单独的线程列表。\n\n\t[![Image(1)](http://hongweiyi.com/wp-content/uploads/2013/10/Image1_thumb.png \"Image(1)\")](http://hongweiyi.com/wp-content/uploads/2013/10/Image1.png)\n\n\t不看不知道，一看吓一跳啊，cpu跑满的线程挺多的，第一列便是他们的线程id。\n\n\t**2.4 Thread dump**\n\n\t拿到异常的线程id后，便可以将该进程的线程栈全部输出了，用到的工具是jstack。\n\n\tjstack 15195 &gt; jstack.15195.dump\n\n\t[![Image(2)](http://hongweiyi.com/wp-content/uploads/2013/10/Image2_thumb.png \"Image(2)\")](http://hongweiyi.com/wp-content/uploads/2013/10/Image2.png)\n\n\t快速搜索的话，可以直接拿pid转换成16进程定位，当然，也可以慢慢看那些线程处于RUNNABLE状态，不过定位问题较慢。\n\n\t通过查询异常线程pid，发现所有的都是Parallel GC Threads，实在是太奇怪了。\n\n\t**2.5 查看gc状态**\n\n\tjstat -gc 15195 获得当前进程的gc状态，会发现该线程在不断的进行FullGC操作：\n\n\t[![Image(3)](http://hongweiyi.com/wp-content/uploads/2013/10/Image3_thumb.png \"Image(3)\")](http://hongweiyi.com/wp-content/uploads/2013/10/Image3.png)\n\n\t[![Image(4)](http://hongweiyi.com/wp-content/uploads/2013/10/Image4_thumb.png \"Image(4)\")](http://hongweiyi.com/wp-content/uploads/2013/10/Image4.png)\n\n\t短短几分钟，就FGC了28次！初步定位问题为FGC问题。\n\n> 注：用jstat -gcutil $PID $INTERVAL $TIMES查询可能会更直接，我查到这里应用被停止了，就木有现场了。\n\n\t**3、问题解决**\n\n\t现在出现的问题就是表现在了full gc次数频繁，从上面的应用而言，可以发现PU(PermGen Usage)占用非常高，约为95.7%。由于Perm代过高，且CMS GC无法回收掉Perm区内容，而导致频繁GC。\n\n\tCMS GC与普通的STW Full GC不同，不会暂停应用，但是会导致CPU使用率非常高。\n\n\t解决方法有两种：1）提高Perm区大小，-XX:PermSize -XX:MaxPermSize，2）关掉Perm区收集机制，取消-XX:+CMSClassUnloadingEnabled。\n\n\t这里有关于Perm区GC时机的深入且详细的解释，[http://rednaxelafx.iteye.com/blog/1108439](http://rednaxelafx.iteye.com/blog/1108439)\n\n> CMS收集器的使用好像有很多很多的优(jiu)化(shi)点(keng)啊！\r> \n> \n> \t\t还得深入学习实践一下！","source":"_posts/once-java-profiling.md","raw":"title: 记一次java性能问题定位\ntags:\n  - java\n  - JVM\nid: 861\ncategories:\n  - 技术分享\ndate: 2013-10-22 23:21:52\n---\n\n**1、前言**\n\n\t前一段时间检查集群状态时，发现某部分机器的load较高，故登录服务器查看，某几个java进程的cpu使用率为1000%，没见过这么高的cpu时间，顿时就长见识了！长完见识问题还是要解决的，故本文记录下问题定位的过程。\n\n\t<!--more-->\n\n\t**2、定位流程**\n\n\t**2.1 定位问题进程**\n\n\ttop命令可以简单定位进程pid，如下：\n\n\t[![Image](http://hongweiyi.com/wp-content/uploads/2013/10/Image_thumb.png \"Image\")](http://hongweiyi.com/wp-content/uploads/2013/10/Image.png)\n\n\tjps -vm | grep 15195 可以查看java进程的参数或者日志地址等，如果没有显示参数的话，可以cd到/proc/15195/cwd目录，该目录便是进程的运行目录。\n\n\t**2.2 查看日志**\n\n\t常规做法就是查看日志了，但是扫了几遍日志也没发现问题，因为这个进程这几天的请求都不是很多，难道是线程空转了？\n\n\t**2.3 定位问题线程**\n\n\t既然日志没有发现异常，那只是通过查看进程内部发现问题了。man top可以看到top命令的详细信息，-H则是线程开关，传入该参数的话，top界面会显示所有单独的线程列表。\n\n\t[![Image(1)](http://hongweiyi.com/wp-content/uploads/2013/10/Image1_thumb.png \"Image(1)\")](http://hongweiyi.com/wp-content/uploads/2013/10/Image1.png)\n\n\t不看不知道，一看吓一跳啊，cpu跑满的线程挺多的，第一列便是他们的线程id。\n\n\t**2.4 Thread dump**\n\n\t拿到异常的线程id后，便可以将该进程的线程栈全部输出了，用到的工具是jstack。\n\n\tjstack 15195 &gt; jstack.15195.dump\n\n\t[![Image(2)](http://hongweiyi.com/wp-content/uploads/2013/10/Image2_thumb.png \"Image(2)\")](http://hongweiyi.com/wp-content/uploads/2013/10/Image2.png)\n\n\t快速搜索的话，可以直接拿pid转换成16进程定位，当然，也可以慢慢看那些线程处于RUNNABLE状态，不过定位问题较慢。\n\n\t通过查询异常线程pid，发现所有的都是Parallel GC Threads，实在是太奇怪了。\n\n\t**2.5 查看gc状态**\n\n\tjstat -gc 15195 获得当前进程的gc状态，会发现该线程在不断的进行FullGC操作：\n\n\t[![Image(3)](http://hongweiyi.com/wp-content/uploads/2013/10/Image3_thumb.png \"Image(3)\")](http://hongweiyi.com/wp-content/uploads/2013/10/Image3.png)\n\n\t[![Image(4)](http://hongweiyi.com/wp-content/uploads/2013/10/Image4_thumb.png \"Image(4)\")](http://hongweiyi.com/wp-content/uploads/2013/10/Image4.png)\n\n\t短短几分钟，就FGC了28次！初步定位问题为FGC问题。\n\n> 注：用jstat -gcutil $PID $INTERVAL $TIMES查询可能会更直接，我查到这里应用被停止了，就木有现场了。\n\n\t**3、问题解决**\n\n\t现在出现的问题就是表现在了full gc次数频繁，从上面的应用而言，可以发现PU(PermGen Usage)占用非常高，约为95.7%。由于Perm代过高，且CMS GC无法回收掉Perm区内容，而导致频繁GC。\n\n\tCMS GC与普通的STW Full GC不同，不会暂停应用，但是会导致CPU使用率非常高。\n\n\t解决方法有两种：1）提高Perm区大小，-XX:PermSize -XX:MaxPermSize，2）关掉Perm区收集机制，取消-XX:+CMSClassUnloadingEnabled。\n\n\t这里有关于Perm区GC时机的深入且详细的解释，[http://rednaxelafx.iteye.com/blog/1108439](http://rednaxelafx.iteye.com/blog/1108439)\n\n> CMS收集器的使用好像有很多很多的优(jiu)化(shi)点(keng)啊！\r> \n> \n> \t\t还得深入学习实践一下！","slug":"once-java-profiling","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg621l002vsb8fgozjki59"},{"title":"新手说自然语言处理","id":"504","date":"2012-04-09T07:41:27.000Z","_content":"\n**1****、自然语言处理（Natural Language Processing）**\n\n看自然语言处理的材料、书籍也有一段时间了，最近好像快看出点门道了，今天就以一个新手的角度来说说我所理解的自然语言处理。\n  <!--more-->\n\n自然语言处理是研究计算机如何处理人类语言的学科，我一般大白话解释就是：让计算机能懂我的话，这就叫自然语言处理。不过维基百科将“懂”人类语言称之为“自然语言认知”，我认为无论对自然语言做何种处理，计算机都需要“懂”一点这个语言，无论以何种方式。至于何谓计算机的“懂”，我觉得可以参考一下[图灵测试（Turing Test）](http://en.wikipedia.org/wiki/Turing_test)，以及前两篇转载的Matrix67的博客，你应该会对计算机的“懂”有所理解。 \n\n平常和朋友聊NLP，或者他们翻我的书时，一般都会问一句：“怎么这么像编译原理呢？”。从我看来，基本思想差不太多，所不同的是编译原理所处理的是人工语言，而NLP则是处理分析的自然语言。自然语言处理起来会有其特殊性，最常见也是最难的就是处理歧义了，在人工语言中决不允许出现歧义，因为规矩定死了，自然语言就不一样了，拿最近很火的小明来说：\n  > “小明，昨天下午你抱着的是谁啊？你女朋友吧？”“你妹！！！我妹！！”  \n\n你们觉得计算机能知道小明抱着的是谁么？我相信，以后能！！！\n\n**2****、读书有感**\n\n以上就是我对自然语言处理的大致理解，现在我来梳理梳理我看书的知识。\n\n**2.1 NLP****研究方向**\n\nNLP研究主要有两个方法：理性（规则）主义方法以及基于经验（统计）主义方法。现在主流的好像是理性与经验相结合。\n\n**理性（规则）主义方法**\n\n就是认为计算机必须按照人的思维方式来思考语言，按照严格的规则来处理自然语言。语言学家乔姆斯基（Noam Chomsky）曾经把语言定义为：按照一定规律构成的句子和符号串的有限或无限的集合。我国学者吴蔚天则认为，可以将语言看成一个抽象的数学系统。语言无论是集合还是数学系统，都可以用数学的方法（规则）来刻画与描述。这个规则一般来说应该是语法，但是NLP中被定义为形式语言，是用来精确地描述语言及其结构的手段。\n\n形式语言的语法是一个四元组，G=（N，Σ，P，S）。N为非终结符（non-terminal symbol）的有限集合，Σ为终结符（terminal-symbol）的有限集合，N与Σ无交集，N并Σ就是称之为总词汇表。P是一组重写规则的有限集合：P = {a -&gt; b}，a，b均是词汇表中的，但是a中必须包含一个非终结符。S是初始符，也属于N。\n\n例如，有如下的形式语法：\n  > G=（N，Σ，P，S）， N={S，B，N，A }\n> \n> Σ ={wikie，is，a，handsome，boy}  \n\n规则P如下：\n  > S -&gt; NBN， N -&gt; AN，B -&gt; BB\n> \n> B -&gt; is | a，N -&gt;wikie | boy，A -&gt; handsome  \n\n所以根据语法简单推导就是：\n  > S -&gt; NBN \n> \n> Wikie is boy或者Boy is wikie或者wikie a boy或者 boy a wikie  \n\n当然，最后的推导应该是这样：\n  > S -&gt; NBN -&gt; NBBN -&gt; NBBAN\n> \n> Wikie is a handsome boy.  \n\n觉得怎么样，以上语法是不是清晰明了？但这只是简单的情况，真实的情况下远比这复杂。\n\n**基于经验（统计）主义方法**\n\n以上形式语法虽然清晰明了，但是应对真正的千变万化的语言来说，总有无法形式表达的情况。而且很多排斥理性主义方法的人都有这样的一个想法：文盲从来没有学过语法，但TA不仅能够理解语言，而且说不定还能说得很溜很好。那么文盲为什么能听懂且说出话来呢？\n\n语言模型在自然语言处理中占有重要的地位，一个语言模型通常构建为字符串s的概率分布p（s），这里的p（s）试图反映的是字符串s作为一个句子出现的频率。\n\n例如，Yes这个词出现在我们的英语课本中的频率非常高，所以同学们和老外交流的时候，大部分时间在听，听完之后不管啥内容都会说一句：Yes，Yes！还有Oh这个语气词无论在电影还是书本中，都很多，同学们在回答了一个Oh的时候，突然会很习惯性的接上一个词Yeah，即：Oh, yeah yeah，高兴的话，还有可能是：Oh, yeah, yeah, you’re right！\n\n这个频率和习惯都可以反映成语言模型，即某个句子出现的概率，概率高出现的可能性就大，低则反之。对于一个句子s=w1w2w3w4…wl来说，其概率计算公式可以表示为：\n  > p(s) = p(w1)p(w2|w1)p(w3|w1w2)…p(wl|w1…w(l-1)) // | 表示条件概率  \n\n需要注意的是，如果以上计算中，有一个值为0，p(s)则为0。显然，这个是不够准确的，所以需要进行平滑操作。顾名思义，线平滑即将折线平滑成曲线，语言模型即提高低概率（如0概率），降低高概率，尽量使概率分布趋于均匀。\n\n有了语言模型，文盲还不能够听与说，因为TA不知道出现的那句话对应的意思是什么。所以文盲还会在脑子存一个音与意的映射，在NLP中就是语料库了。听到一个词，就去查一下，听到一个词，就去查一下。\n\n顺带简单说一下机器学习，以前我怎么都不理解机器到底是怎么学习的，可能是我也仔细分析过我是怎么学习的。机器学习和人其实差不多，归纳法加演绎法。如有一段材料：鸟会飞，鹦鹉是鸟。计算机就能学会：鹦鹉会飞。不过这仅是我粗浅的理解，还有待继续深入。\n\n**2.2 NLP****理论基础**\n\n上面介绍了两个大方向，理论基础也就是大方向的理论基础：语言学、概率论、信息论。在这里就不一一说了，不过我还是得单独都搞本书看看咯。\n\n**2.3 NLP****分析步骤**\n\n觉着还是和编译原理差不多，不过多了一个分词的步骤，具体见下：\n\n**分词**\n\n分词是每个语言都要碰到的问题，很多地方说英语没有这个问题，因为有空格作为分隔符。但是我觉得英语也有词组，分词组应该也不是一件容易的事情。具体分词可以参加：[漫话中文自动分词和语义识别（上）：中文分词算法](http://www.hongweiyi.com/2012/04/nlp-repost-segmentation/)。\n\n**语法分析**\n\n分完词后，就需要进行语法分析了，即分析这句话是否通顺合理。语法分析又分为词法分析与句法分析。词法分析就是分析诸如名词性短语、动词性短语，句法分析就是分析诸如主谓宾、从句等结构，但这都是从理性主义方法出发，关于这个可以参加：[漫话中文自动分词和语义识别（下）：句法结构和语义结构](http://www.hongweiyi.com/2012/04/nlp-repost-semantic/)。目前更实用的，则是对大规模真实语料的概率统计分析与机器学习算法。简单理解就是，一个词一个句，出现的概率大就是正确的。\n\n**语义分析**\n\n到了我觉得最难的地方了，句子的语义分析。高中考试的时候，句子出现歧义了，我这个大活人有时候都会理解错误，能让计算机理解更是难上加难。再加上国人说话隐晦，一语双关。说个有趣的HSK（汉语水平考试）考试题目：\n\n张三找了个女朋友，李四问：“你女朋友长得怎么样？”张三答：“她人还不错。”问：张三的女朋友长得好么？\n\nA、长得好 B、长得不好 C、她人不错 D、不知道\n\n套用书本的话说就是：自然语言的语义计算问题十分困难，如何模拟人脑思维的过程，建立语言、知识与客观世界之间可计算的逻辑关系，并实现具有高区分能力的语义计算模型，至今任是个未能解决的难题。\n\n**2.4 NLP****应用领域**\n\n**机器翻译类**\n\n这个应该是常人能看到体会到的，从文曲星到金山词霸再到Google翻译，机器翻译伴随着我们80后一起成长。Google翻译更是论文翻译的必须物，尽管得到的结果有时候会惨不忍睹。如：今天天气好好啊 -&gt; Today the weather good ah。多么直白的翻译。\n\n机器翻译的主要方法和NLP的方法差不多，不过过程有些不一样，有两种：基于中间语言与不基于中间语言。\n\n基于中间语言，就是相当于将所有语言互译成一种语言（如世界语），所有全世界N种语言翻译就只需要与同一种语言互译N次即可。但是是否能够构造出表示各种不同的自然语言语法、语义的中间语言，至少目前还是个未知数。此外，由于翻译都是误差，误差传递两次会有更大的误差，无法很好的生成对应的各种语言。\n\n不基于中间语言的又有：基于统计和基于实例的，统计就和前面提到的语言模型类似，基于实例的就是将不断累积的已经译好的文本作为机器翻译的样本，翻译的时候直接查看是否有类似的翻译。\n\n话说，以前老师说做同声传译一小时有5W，等到机器翻译完美解决那一刻，同声传译一小时多少捏？哇哈哈，很是邪恶啊！当然，我们的路还有很长。\n\n**阅读理解类**\n\n阅读理解无外乎就是读完文章，让我们说出文章的中心思想，文章内容以及文章类型。说出文章的中心思想就是自动文摘生成技术，说出文章内容的就是信息抽取技术，说出文章类型就是文本分类技术。不过书还没看到这里来，就不继续写了。\n\n**问答类**\n\nSiri横空出世，让业内业外人士都开了眼界，52nlp中有一篇关于siri的文章，见：[这里](http://www.52nlp.cn/sir)，不知道作者是褒还是贬。同时，移动10086在siri之前也有小机器人可以相互扯淡，这里也有一个获奖的开源自然语言的人工智能的聊天机器人：[A.L.I.C.E](http://www.alicebot.org/)，我一朋友还和AliceBot聊了好一会儿天。\n\n问答类我觉得是NLP与AI关系最为密切的一个环节，也是图灵测试直接使用的工具，现在一个叫[CleverBot](http://cleverbot.com/)的机器人号称通过了图灵测试，成功欺骗了800位观众。当然，现在问答类的系统并不是仅仅用于扯淡的，主要的还是类似与10086那样的客服系统，基于某个领域的问答，难度相较而言没那么高。\n\n**3****、小结**\n\n以上很多仅仅是一些肤浅的理解，对NLP内部实现有些许了解，但是不深入。还需要继续阅读书籍以及相关文献，而且还得再恶补数学相关的知识。NLP刚入门，路还长着……\n\n虽然自己有拿着开源分词软件、微博练练手，但是还没一直对NLP很直观的感受，不知各位看官有啥推荐的NLP的Hello World程序，在此小e不甚感激！\n\n&#160;\n  > **参考资料：**\n> \n> 1\\. [维基百科](http://en.wikipedia.org/wiki/Wiki)\n> \n> 2\\. [52NLP](http://www.52nlp.cn/)\n> \n> 3\\. 《统计自然语言处理》 宗成庆\n> \n> 4\\. 《自然语言处理的原理及其应用》 杨宪泽\n> \n> 5\\. 《自然语言处理》 江铭虎","source":"_posts/nlp-say-hi.md","raw":"title: 新手说自然语言处理\ntags:\n  - 自然语言处理\nid: 504\ncategories:\n  - 技术分享\ndate: 2012-04-09 15:41:27\n---\n\n**1****、自然语言处理（Natural Language Processing）**\n\n看自然语言处理的材料、书籍也有一段时间了，最近好像快看出点门道了，今天就以一个新手的角度来说说我所理解的自然语言处理。\n  <!--more-->\n\n自然语言处理是研究计算机如何处理人类语言的学科，我一般大白话解释就是：让计算机能懂我的话，这就叫自然语言处理。不过维基百科将“懂”人类语言称之为“自然语言认知”，我认为无论对自然语言做何种处理，计算机都需要“懂”一点这个语言，无论以何种方式。至于何谓计算机的“懂”，我觉得可以参考一下[图灵测试（Turing Test）](http://en.wikipedia.org/wiki/Turing_test)，以及前两篇转载的Matrix67的博客，你应该会对计算机的“懂”有所理解。 \n\n平常和朋友聊NLP，或者他们翻我的书时，一般都会问一句：“怎么这么像编译原理呢？”。从我看来，基本思想差不太多，所不同的是编译原理所处理的是人工语言，而NLP则是处理分析的自然语言。自然语言处理起来会有其特殊性，最常见也是最难的就是处理歧义了，在人工语言中决不允许出现歧义，因为规矩定死了，自然语言就不一样了，拿最近很火的小明来说：\n  > “小明，昨天下午你抱着的是谁啊？你女朋友吧？”“你妹！！！我妹！！”  \n\n你们觉得计算机能知道小明抱着的是谁么？我相信，以后能！！！\n\n**2****、读书有感**\n\n以上就是我对自然语言处理的大致理解，现在我来梳理梳理我看书的知识。\n\n**2.1 NLP****研究方向**\n\nNLP研究主要有两个方法：理性（规则）主义方法以及基于经验（统计）主义方法。现在主流的好像是理性与经验相结合。\n\n**理性（规则）主义方法**\n\n就是认为计算机必须按照人的思维方式来思考语言，按照严格的规则来处理自然语言。语言学家乔姆斯基（Noam Chomsky）曾经把语言定义为：按照一定规律构成的句子和符号串的有限或无限的集合。我国学者吴蔚天则认为，可以将语言看成一个抽象的数学系统。语言无论是集合还是数学系统，都可以用数学的方法（规则）来刻画与描述。这个规则一般来说应该是语法，但是NLP中被定义为形式语言，是用来精确地描述语言及其结构的手段。\n\n形式语言的语法是一个四元组，G=（N，Σ，P，S）。N为非终结符（non-terminal symbol）的有限集合，Σ为终结符（terminal-symbol）的有限集合，N与Σ无交集，N并Σ就是称之为总词汇表。P是一组重写规则的有限集合：P = {a -&gt; b}，a，b均是词汇表中的，但是a中必须包含一个非终结符。S是初始符，也属于N。\n\n例如，有如下的形式语法：\n  > G=（N，Σ，P，S）， N={S，B，N，A }\n> \n> Σ ={wikie，is，a，handsome，boy}  \n\n规则P如下：\n  > S -&gt; NBN， N -&gt; AN，B -&gt; BB\n> \n> B -&gt; is | a，N -&gt;wikie | boy，A -&gt; handsome  \n\n所以根据语法简单推导就是：\n  > S -&gt; NBN \n> \n> Wikie is boy或者Boy is wikie或者wikie a boy或者 boy a wikie  \n\n当然，最后的推导应该是这样：\n  > S -&gt; NBN -&gt; NBBN -&gt; NBBAN\n> \n> Wikie is a handsome boy.  \n\n觉得怎么样，以上语法是不是清晰明了？但这只是简单的情况，真实的情况下远比这复杂。\n\n**基于经验（统计）主义方法**\n\n以上形式语法虽然清晰明了，但是应对真正的千变万化的语言来说，总有无法形式表达的情况。而且很多排斥理性主义方法的人都有这样的一个想法：文盲从来没有学过语法，但TA不仅能够理解语言，而且说不定还能说得很溜很好。那么文盲为什么能听懂且说出话来呢？\n\n语言模型在自然语言处理中占有重要的地位，一个语言模型通常构建为字符串s的概率分布p（s），这里的p（s）试图反映的是字符串s作为一个句子出现的频率。\n\n例如，Yes这个词出现在我们的英语课本中的频率非常高，所以同学们和老外交流的时候，大部分时间在听，听完之后不管啥内容都会说一句：Yes，Yes！还有Oh这个语气词无论在电影还是书本中，都很多，同学们在回答了一个Oh的时候，突然会很习惯性的接上一个词Yeah，即：Oh, yeah yeah，高兴的话，还有可能是：Oh, yeah, yeah, you’re right！\n\n这个频率和习惯都可以反映成语言模型，即某个句子出现的概率，概率高出现的可能性就大，低则反之。对于一个句子s=w1w2w3w4…wl来说，其概率计算公式可以表示为：\n  > p(s) = p(w1)p(w2|w1)p(w3|w1w2)…p(wl|w1…w(l-1)) // | 表示条件概率  \n\n需要注意的是，如果以上计算中，有一个值为0，p(s)则为0。显然，这个是不够准确的，所以需要进行平滑操作。顾名思义，线平滑即将折线平滑成曲线，语言模型即提高低概率（如0概率），降低高概率，尽量使概率分布趋于均匀。\n\n有了语言模型，文盲还不能够听与说，因为TA不知道出现的那句话对应的意思是什么。所以文盲还会在脑子存一个音与意的映射，在NLP中就是语料库了。听到一个词，就去查一下，听到一个词，就去查一下。\n\n顺带简单说一下机器学习，以前我怎么都不理解机器到底是怎么学习的，可能是我也仔细分析过我是怎么学习的。机器学习和人其实差不多，归纳法加演绎法。如有一段材料：鸟会飞，鹦鹉是鸟。计算机就能学会：鹦鹉会飞。不过这仅是我粗浅的理解，还有待继续深入。\n\n**2.2 NLP****理论基础**\n\n上面介绍了两个大方向，理论基础也就是大方向的理论基础：语言学、概率论、信息论。在这里就不一一说了，不过我还是得单独都搞本书看看咯。\n\n**2.3 NLP****分析步骤**\n\n觉着还是和编译原理差不多，不过多了一个分词的步骤，具体见下：\n\n**分词**\n\n分词是每个语言都要碰到的问题，很多地方说英语没有这个问题，因为有空格作为分隔符。但是我觉得英语也有词组，分词组应该也不是一件容易的事情。具体分词可以参加：[漫话中文自动分词和语义识别（上）：中文分词算法](http://www.hongweiyi.com/2012/04/nlp-repost-segmentation/)。\n\n**语法分析**\n\n分完词后，就需要进行语法分析了，即分析这句话是否通顺合理。语法分析又分为词法分析与句法分析。词法分析就是分析诸如名词性短语、动词性短语，句法分析就是分析诸如主谓宾、从句等结构，但这都是从理性主义方法出发，关于这个可以参加：[漫话中文自动分词和语义识别（下）：句法结构和语义结构](http://www.hongweiyi.com/2012/04/nlp-repost-semantic/)。目前更实用的，则是对大规模真实语料的概率统计分析与机器学习算法。简单理解就是，一个词一个句，出现的概率大就是正确的。\n\n**语义分析**\n\n到了我觉得最难的地方了，句子的语义分析。高中考试的时候，句子出现歧义了，我这个大活人有时候都会理解错误，能让计算机理解更是难上加难。再加上国人说话隐晦，一语双关。说个有趣的HSK（汉语水平考试）考试题目：\n\n张三找了个女朋友，李四问：“你女朋友长得怎么样？”张三答：“她人还不错。”问：张三的女朋友长得好么？\n\nA、长得好 B、长得不好 C、她人不错 D、不知道\n\n套用书本的话说就是：自然语言的语义计算问题十分困难，如何模拟人脑思维的过程，建立语言、知识与客观世界之间可计算的逻辑关系，并实现具有高区分能力的语义计算模型，至今任是个未能解决的难题。\n\n**2.4 NLP****应用领域**\n\n**机器翻译类**\n\n这个应该是常人能看到体会到的，从文曲星到金山词霸再到Google翻译，机器翻译伴随着我们80后一起成长。Google翻译更是论文翻译的必须物，尽管得到的结果有时候会惨不忍睹。如：今天天气好好啊 -&gt; Today the weather good ah。多么直白的翻译。\n\n机器翻译的主要方法和NLP的方法差不多，不过过程有些不一样，有两种：基于中间语言与不基于中间语言。\n\n基于中间语言，就是相当于将所有语言互译成一种语言（如世界语），所有全世界N种语言翻译就只需要与同一种语言互译N次即可。但是是否能够构造出表示各种不同的自然语言语法、语义的中间语言，至少目前还是个未知数。此外，由于翻译都是误差，误差传递两次会有更大的误差，无法很好的生成对应的各种语言。\n\n不基于中间语言的又有：基于统计和基于实例的，统计就和前面提到的语言模型类似，基于实例的就是将不断累积的已经译好的文本作为机器翻译的样本，翻译的时候直接查看是否有类似的翻译。\n\n话说，以前老师说做同声传译一小时有5W，等到机器翻译完美解决那一刻，同声传译一小时多少捏？哇哈哈，很是邪恶啊！当然，我们的路还有很长。\n\n**阅读理解类**\n\n阅读理解无外乎就是读完文章，让我们说出文章的中心思想，文章内容以及文章类型。说出文章的中心思想就是自动文摘生成技术，说出文章内容的就是信息抽取技术，说出文章类型就是文本分类技术。不过书还没看到这里来，就不继续写了。\n\n**问答类**\n\nSiri横空出世，让业内业外人士都开了眼界，52nlp中有一篇关于siri的文章，见：[这里](http://www.52nlp.cn/sir)，不知道作者是褒还是贬。同时，移动10086在siri之前也有小机器人可以相互扯淡，这里也有一个获奖的开源自然语言的人工智能的聊天机器人：[A.L.I.C.E](http://www.alicebot.org/)，我一朋友还和AliceBot聊了好一会儿天。\n\n问答类我觉得是NLP与AI关系最为密切的一个环节，也是图灵测试直接使用的工具，现在一个叫[CleverBot](http://cleverbot.com/)的机器人号称通过了图灵测试，成功欺骗了800位观众。当然，现在问答类的系统并不是仅仅用于扯淡的，主要的还是类似与10086那样的客服系统，基于某个领域的问答，难度相较而言没那么高。\n\n**3****、小结**\n\n以上很多仅仅是一些肤浅的理解，对NLP内部实现有些许了解，但是不深入。还需要继续阅读书籍以及相关文献，而且还得再恶补数学相关的知识。NLP刚入门，路还长着……\n\n虽然自己有拿着开源分词软件、微博练练手，但是还没一直对NLP很直观的感受，不知各位看官有啥推荐的NLP的Hello World程序，在此小e不甚感激！\n\n&#160;\n  > **参考资料：**\n> \n> 1\\. [维基百科](http://en.wikipedia.org/wiki/Wiki)\n> \n> 2\\. [52NLP](http://www.52nlp.cn/)\n> \n> 3\\. 《统计自然语言处理》 宗成庆\n> \n> 4\\. 《自然语言处理的原理及其应用》 杨宪泽\n> \n> 5\\. 《自然语言处理》 江铭虎","slug":"nlp-say-hi","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg621n0030sb8flqq1w280"},{"title":"转 - 漫话中文自动分词和语义识别（下）：句法结构和语义结构","id":"499","date":"2012-04-01T09:54:48.000Z","_content":"\n这篇文章是[漫话中文分词算法](http://www.matrix67.com/blog/archives/4212)的续篇。在这里，我们将紧接着上一篇文章的内容继续探讨下去：如果计算机可以对一句话进行自动分词，它还能进一步整理句子的结构，甚至理解句子的意思吗？这两篇文章的关系十分紧密，因此，我把前一篇文章改名为了《漫话中文自动分词和语义识别（上）》，这篇文章自然就是它的下篇。我已经在很多不同的地方做过与这个话题有关的演讲了，在这里我想把它们写下来，和更多的人一同分享。\n<!--more-->\n\n什么叫做句法结构呢？让我们来看一些例子。“白天鹅在水中游”，这句话是有歧义的，它可能指的是“白天有一只鹅在水中游”，也可能指的是“有一只白天鹅在水中游”。不同的分词方案，产生了不同的意义。有没有什么句子，它的分词方案是唯一的，但也会产生不同的意思呢？有。比如“门没有锁”，它可能是指的“门没有被锁上”，也有可能是指的“门上根本就没有挂锁”。这个句子虽然只能切分成“门／没有／锁”，但由于“锁”这个词既有可能是动词，也有可能是名词，因而让整句话产生了不同的意思。有没有什么句子，它的分词方案是唯一的，并且每个词的词义也都不再变化，但整个句子仍然有歧义呢？有可能。看看这句话：“咬死了猎人的狗”。这句话有可能指的是“把猎人的狗咬死了”，也有可能指的是“一只咬死了猎人的狗”。这个歧义是怎么产生的呢？仔细体会两种不同的意思后，你会发现，句子中最底层的成分可以以不同的顺序组合起来，歧义由此产生。\n\n在前一篇文章中，我们看到了，利用概率转移的方法，我们可以有效地给一句话分词。事实上，利用相同的模型，我们也能给每一个词标注词性。更好的做法则是，我们直接把同一个词不同词性的用法当作是不同的词，从而把分词和词性标注的工作统一起来。但是，所有这样的工作都是对句子进行从左至右线性的分析，而句子结构实际上比这要复杂多了，它是这些词有顺序有层次地组合在一起的。计算机要想正确地解析一个句子，在分词和标注词性后，接下来该做的就是分析句法结构的层次。\n\n在计算机中，怎样描述一个句子的句法结构呢？ 1957 年， Noam Chomsky 出版了《句法结构》一书，把这种语言的层次化结构用形式化的方式清晰地描述了出来，这也就是所谓的“生成语法”模型。这本书是 20 世纪为数不多的几本真正的著作之一，文字非常简练，思路非常明晰，震撼了包括语言学、计算机理论在内的多个领域。记得 Quora 上曾经有人问 [Who are the best minds of the world today](http://www.quora.com/Best-Of/Who-are-the-best-minds-of-the-world-today-and-why) ，投出来的答案就是 Noam Chomsky 。\n\n随便取一句很长很复杂的话，比如“汽车被开车的师傅修好了”，我们总能至顶向下地一层层分析出它的结构。这个句子最顶层的结构就是“汽车修好了”。汽车怎么修好了呢？汽车被师傅修好了。汽车被什么样的师傅修好了呢？哦，汽车被开车的师傅修好了。当然，我们还可以无限地扩展下去，继续把句子中的每一个最底层的成分替换成更详细更复杂的描述，就好像小学语文中的扩句练习那样。这就是生成语法的核心思想。\n\n熟悉编译原理的朋友们可能知道“上下文无关文法”。其实，上面提到的扩展规则本质上就是一种上下文无关文法。例如，一个句子可以是“什么怎么样”的形式，我们就把这条规则记作\n  > 句子 → 名词性短语＋动词性短语  \n\n其中，“名词性短语”指的是一个具有名词功能的成分，它有可能就是一个名词，也有可能还有它自己的内部结构。例如，它有可能是一个形容词性短语加上“的”再加上另一个名词性短语构成的，比如“便宜的汽车”；它还有可能是由“动词性短语＋的＋名词性短语”构成的，比如“抛锚了的汽车”；它甚至可能是由“名词性短语＋的＋名词性短语”构成的，比如“老师的汽车”。我们把名词性短语的生成规则也都记下来：\n  > 名词性短语 → 名词\n> \n> 名词性短语 → 形容词性短语＋的＋名词性短语\n> \n> 名词性短语 → 动词性短语＋的＋名词性短语\n> \n> 名词性短语 → 名词性短语＋的＋名词性短语\n> \n>  ⋯⋯  \n\n类似地，动词性短语也有诸多具体的形式：\n  > 动词性短语 → 动词\n> \n> 动词性短语 → 动词性短语＋了\n> \n> 动词性短语 → 介词短语＋动词性短语\n> \n> ⋯⋯  \n\n上面我们涉及到了介词短语，它也有自己的生成规则：\n  > 介词短语 → 介词＋名词性短语\n> \n> ⋯⋯  \n\n我们构造句子的任务，也就是从“句子”这个初始结点出发，不断调用规则，产生越来越复杂的句型框架，然后从词库中选择相应词性的单词，填进这个框架里：\n\n![](http://www.matrix67.com/blogimage_2012/201201051.png)\n\n而分析句法结构的任务，则是已知一个句子从左到右各词的词性，要反过来求出一棵满足要求的“句法结构树”。这可以用 [Earley parser](http://en.wikipedia.org/wiki/Earley_parser) 来实现。\n\n这样看来，句法结构的问题似乎就已经完美的解决了。其实，我们还差得很远。生成语法有两个大问题。首先，句法结构正确的句子不见得都是好句子。 Chomsky 本人给出了一个经典的例子： Colorless green ideas sleep furiously 。形容词加形容词加名词加动词加副词，这是一个完全符合句法要求的序列，但随便拼凑会闹出很多笑话——什么叫做“无色的绿色的想法在狂暴地睡觉”？顺便插播个广告，如果你还挺喜欢这句话的意境的，欢迎去我以前做的 [IdeaGenerator](http://www.matrix67.com/ideagen/) 玩玩。不过，如果我们不涉及句子的生成，只关心句子的结构分析，这个缺陷对我们来说影响似乎并不大。生成语法的第二个问题就比较麻烦了：从同一个词性序列出发，可能会构建出不同的句法结构树。比较下面两个例子：\n  > 老师 被 迟到 的 学生 逗乐 了\n> \n> 电话 被 窃听 的 房间 找到 了  \n\n它们都是“名词＋介词＋动词＋的＋名词＋动词＋了”，但它们的结构并不一样，前者是老师被逗乐了，“迟到”是修饰“学生”的，后者是房间找到了，“电话被窃听”是一起来修饰房间的。但是，纯粹运用前面的模型，我们无法区分出哪句话应该是哪个句法结构树。如何强化句法分析的模型和算法，让计算机构建出一棵正确的句法树，这成了一个大问题。\n\n让我们来看一个更简单的例子吧。同样是“动词＋形容词＋名词”，我们有两种构建句法结构树的方案：\n\n![](http://www.matrix67.com/blogimage_2012/201201052.png)\n\n未经过汉语语法训练的朋友可能会问，“点亮蜡烛”和“踢新皮球”的句法结构真的不同吗？我们能证明，这里面真的存在不同。我们造一个句子“踢破皮球”，你会发现对于这个句子来说，两种句法结构都是成立的，于是出现了歧义：把皮球踢破了（结构和“点亮蜡烛”一致），或者是，踢一个破的皮球（结构和“踢新皮球”一致）。\n\n但为什么“点亮蜡烛”只有一种理解方式呢？这是因为我们通常不会把“亮”字直接放在名词前做定语，我们一般不说“一根亮蜡烛”、“一颗亮星星”等等。为什么“踢新皮球”也只有一种理解方式呢？这是因为我们通常不会把“新”直接放在动词后面作补语，不会说“皮球踢新了”，“衣服洗新了”等等。但是“破”既能作定语又能作补语，于是“踢破皮球”就产生了两种不同的意思。如果我们把每个形容词能否作定语，能否作补语都记下来，然后在生成规则中添加限制条件，不就能完美解决这个问题了吗？\n\n基于规则的句法分析器就是这么做的。汉语语言学家们已经列出了所有词的各种特征：\n\n亮：词性 = 形容词，能作补语 = True ，能作定语 = False ⋯⋯\n\n新：词性 = 形容词，能作补语 = False ，能作定语 = True ⋯⋯\n\n⋯⋯\n\n当然，每个动词也有一大堆属性：\n  > 点：词性 = 动词，能带宾语 = True ，能带补语 = True ⋯⋯\n> \n> 踢：词性 = 动词，能带宾语 = True ，能带补语 = True ⋯⋯\n> \n> 污染：词性 = 动词，能带宾语 = True ，能带补语 = False ⋯⋯\n> \n> 排队：词性 = 动词，能带宾语 = False ，能带补语 = False ⋯⋯\n> \n> ⋯⋯  \n\n名词也不例外：\n  > 蜡烛：词性 = 名词，能作主语 = True ，能作宾语 = True ，能受数量词修饰 = True ⋯⋯\n> \n> 皮球：词性 = 名词，能作主语 = True ，能作宾语 = True ，能受数量词修饰 = True ⋯⋯\n> \n> ⋯⋯  \n\n有人估计会觉得奇怪了：“能作主语”也是一个属性，莫非有些名词不能做主语？哈哈，这样的名词不但有，而且还真不少：剧毒、看头、厉害、正轨、存亡⋯⋯这些词都不放在动词前面。难道有些名词不能做宾语吗？这样的词也有不少：享年、芳龄、心术、浑身、家丑⋯⋯这些词都不放在动词后面。这样说来，存在不受数量词修饰的词也就不奇怪了，事实上上面这些怪异的名词前面基本上都不能加数量词。\n\n另外一个至关重要的就是，这些性质可以“向上传递”。比方说，我们规定，套用规则\n  > 名词性短语 → 形容词性短语＋名词性短语  \n\n后，整个名词性短语能否作主语、能否作宾语、能否受数量词修饰，这将取决于它的第二个构成成分。通俗地讲就是，如果“皮球”能够作主语，那么“新皮球”也能够作主语。有了“词语知识库”，又确保了这些知识能够在更高层次得到保留，我们就能给语法生成规则添加限制条件了。例如，我们可以规定，套用规则\n  > 动词性短语 → 动词性短语＋名词性短语  \n\n的前提条件就是，那个动词性短语的“能带宾语”属性为 True ，并且那个名词性短语“能作宾语”的属性为 True 。另外，我们规定\n  > 动词性短语 → 动词性短语＋形容词性短语  \n\n必须满足动词性短语的“能带补语”属性为 True ，并且形容词性短语“能作补语”属性为 True 。这样便阻止了“踢新皮球”中的“踢”和“新”先结合起来，因为“新”不能作补语。\n\n最后我们规定，套用规则\n  > 名词性短语 → 形容词性短语＋名词性短语  \n\n时，形容词性短语必须要能作定语。这就避免了“点亮蜡烛”中的“亮”和“蜡烛”先组合起来，因为“亮”通常不作定语。这样，我们便解决了“动词＋形容词＋名词”的结构分析问题。\n\n当然，这只是一个很简单的例子。在[这里](http://www.matrix67.com/blog/archives/508)的问题 6 、 7 、 8 中你可以看到，一条语法生成规则往往有很多限制条件，这些限制条件不光是简单的“功能相符”和“前后一致”，有些复杂的限制条件甚至需要用 IF … THEN … 的方式来描述。你可以在[这里](http://www.matrix67.com/blog/archives/4858)看到，汉语中词与词之间还有各种怪异的区别特征，并且哪个词拥有哪些性质纯粹是知识库的问题，完全没有规律可循。一个实用的句法结构分析系统，往往拥有上百种属性标签。北京大学计算语言所编写了《现代汉语语法信息词典》，它里面包含了 579 种属性。我们的理想目标就是，找到汉语中每一种可能会影响句法结构的因素，并据此为词库里的每一个词打上标签；再列出汉语语法中的每一条生成规则，找到每一条生成规则的应用条件，以及应用这条规则之后，整个成分将会以怎样的方式继承哪些子成分的哪些属性，又会在什么样的情况下产生哪些新的属性。按照生成语言学的观点，计算机就应该能正确解析所有的汉语句子了。\n\n那么，这样一来，计算机是否就已经能从句子中获取到理解语义需要的所有信息了呢？答案是否定的。还有这么一些句子，它从分词到词义到结构都没有两可的情况，但整个句子仍然有歧义。考虑这句话“鸡不吃了”，它有两种意思：鸡不吃东西了，或者我们不吃鸡了。但是，这种歧义并不是由分词或者词义或者结构导致的，两种意思所对应的语法结构完全相同，都是“鸡”加上“不吃了”。但为什么歧义仍然产生了呢？这是因为，在句法结构内部，还有更深层次的语义结构，两者并不相同。\n\n汉语就是这么奇怪，位于主语位置上的事物既有可能是动作的发出者，也有可能是动作的承受者。“我吃完了”可以说，“苹果吃完了”也能讲。然而，“鸡”这个东西既能吃，也能被吃，歧义由此产生。\n\n位于宾语位置上的事物也不一定就是动作的承受者，“来客人了”、“住了一个人”都是属于宾语反而是动作发出者的情况。记得某次数理逻辑课上老师感叹，汉语的谓词非常不规范，明明是太阳在晒我，为什么要说成是“我晒太阳”呢？事实上，汉语的动宾搭配范围极其广泛，还有很多更怪异的例子：“写字”是我们真正在写的东西，“写书”是写的结果，“写毛笔”是写的工具，“写楷体”是写的方式，“写地上”是写的场所，“写一只狗”，等等，什么叫做“写一只狗”啊？我们能说“写一只狗”吗？当然可以，这是写的内容嘛，“同学们这周作文写什么啊”，“我写一只狗”。大家可以想像，学中文的老外看了这个会是什么表情。虽然通过句法分析，我们能够判断出句子中的每样东西都和哪个动词相关联，但从语义层面上看这个关联是什么，我们还需要新的模型。\n\n汉语语言学家把事物与动词的语义关系分为了 17 种，叫做 17 种“语义角色”，它们是施事、感事、当事、动力、受事、结果、系事、工具、材料、方式、内容、与事、对象、场所、目标、起点、时间。你可以看到，语义角色的划分非常详细。同样是动作的发出者，施事指的是真正意义上的发出动作，比如“他吃饭”中的“他”；感事则是指某种感知活动的经验者，比如“他知道这件事了”中的“他”；当事则是指性质状态的主体，比如“他病了”中的“他”；动力则是自然力量的发出者，比如“洪水淹没了村庄”中的“洪水”。语义角色的具体划分以及 17 这个数目是有争议的，不过不管怎样，这个模型本身能够非常贴切地回答“什么是语义”这个问题。\n\n汉语有一种“投射理论”，即一个句子的结构是由这个句子中的谓语投射出来的。给定一个动词后，这个动词能够带多少个语义角色，这几个语义角色都是什么，基本上都已经确定了。因而，完整的句子所应有的结构实际上也就已经确定了。比如，说到“休息”这个动词，你就会觉得它缺少一个施事，而且也不缺别的了。我们只会说“老王休息”，不会说“老王休息手”或者“老王休息沙发”。因而我们认为，“休息”只有一个“论元”。它的“论元结构”是：\n  > 休息 &lt;施事&gt;  \n\n因此，一旦在句子中看到“休息”这个词，我们就需要在句内或者句外寻找“休息”所需要的施事。这个过程有一个很帅的名字，叫做“配价”。“休息”就是一个典型的“一价动词”。我们平时接触的比较多的则是二价动词。不过，它们具体的论元有可能不一样：\n  > 吃 &lt;施事，受事&gt;\n> \n> 去 &lt;施事，目标&gt;\n> \n> 淹没 &lt;动力，受事&gt;  \n\n三价动词也是有的，例如\n  > 送 &lt;施事，受事，与事&gt;  \n\n甚至还有零价动词，例如\n  > 下雨 &lt;Ф&gt;  \n\n下面我们要教计算机做的，就是怎样给动词配价。之前，我们已经给出了解析句法结构的方法，这样计算机便能判断出每个动词究竟在和哪些词发生关系。语义分析的实质，就是确定出它们具体是什么关系。因此，语义识别的问题，也就转化为了“语义角色标注”的问题。然而，语义角色出现的位置并不固定，施事也能出现在动词后面，受事也能出现在动词前面，怎样让计算机识别语义角色呢？在回答这个问题之前，我们不妨问问自己：我们是怎么知道，“我吃完了”中的“我”是“吃”的施事，“苹果吃完了”中的“苹果”是“吃”的受事的呢？大家肯定会说，废话，“我”当然只能是“吃”的施事，因为我显然不会“被吃”；“苹果”当然只能是“吃”的受事，因为苹果显然不能发出“吃”动作。也就是说，“吃”的两个论元都有语义类的要求。我们把“吃”的论元结构写得更详细一些：\n  > 吃 &lt;施事[语义类：人|动物]，受事[语义类：食物|药物]&gt;  \n\n而“淹没”一词的论元结构则可以补充为：\n  > 淹没 &lt;动力[语义类：自然事物]，受事[语义类：建筑物|空间]&gt;  \n\n所以，为了完成计算机自动标注语义角色的任务，我们需要人肉建立两个庞大的数据库：语义类词典和论元结构词典。这样的人肉工程早就已经做过了。北京语言大学 1990 年 5 月启动的“九〇￼五语义工程”就是人工构建的一棵规模相当大的语义树。它把词语分成了事物、运动、时空、属性四大类，其中事物类分为事类和物类，物类又分为具体物和抽象物，具体物则再分为生物和非生物，生物之下则分了人类、动物、植物、微生物、生物构件五类，非生物之下则分了天然物、人工物、遗弃物、几何图形和非生物构件五类，其中人工物之下又包括设施物、运载物、器具物、原材料、耗散物、信息物、钱财七类。整棵语义树有 414 个结点，其中叶子结点 309 个，深度最大的地方达到了 9 层。论元结构方面则有清华大学和人民大学共同完成的《现代汉语述语动词机器词典》，词典中包括了各种动词的拼音、释义、分类、论元数、论元的语义角色、论元的语义限制等语法和语义信息。\n\n说到语义工程，不得不提到董振东先生的[知网](http://www.keenage.com/html/c_index.html)。这是一个综合了语义分类和语义关系的知识库，不但通过语义树反映了词与词的共性，还通过语义关系反映了每个词的个性。它不但能告诉你“医生”和“病人”都是人，还告诉了你“医生”可以对“病人”发出一个“医治”的动作。知网的理念和 WordNet 工程很相似，后者是 Princeton 在 1985 年就已经开始构建的英文单词语义关系词典，背后也是一个语义关系网的概念，词与词的关系涉及同义词、反义词、上下位词、整体与部分、子集与超集、材料与成品等等。如果你装了 Mathematica，你可以通过 WordData 函数获取到 WordNet 的数据。至于前面说的那几个中文知识库嘛，别问我，我也不知道上哪儿取去。\n\n看到这里，想必大家会欢呼，啊，这下子，在中文信息处理领域，从语法到语义都已经漂亮的解决了吧。其实并没有。上面的论元语义角色的模型有很多问题。其中一个很容易想到的就是隐喻的问题，比如“信息淹没了我”、“悲伤淹没了我”。一旦出现动词的新用法，我们只能更新论元结构：\n  > 淹没 &lt;动力[语义类：自然事物|抽象事物]，受事[语义类：建筑物|空间|人类]&gt;  \n\n但更麻烦的则是下面这些违背语义规则的情况。一个是否定句，比如“张三不可能吃思想”。一个是疑问句，比如“张三怎么可能吃思想”。更麻烦的就是超常现象。随便在新闻网站上一搜，你就会发现各种不符合语义规则的情形。我搜了一个“吃金属”，立即看到某新闻标题《法国一位老人以吃金属为生》。要想解决这些问题，需要给配价模型打上不少补丁。\n\n然而，配价模型也仅仅解决了动词的语义问题。其他词呢？好在，我们也可以为名词发展一套类似的配价理论。我们通常认为“教师”是一个零价名词，而“老师”则是一个一价名词，因为说到“老师”时，我们通常会说“谁的老师”。“态度”则是一个二价的名词，因为我们通常要说“谁对谁的态度”才算完整。事实上，形容词也有配价，“优秀”就是一个一价形容词，“友好”则是一个二价形容词，原因也是类似的。配价理论还有很多更复杂的内容，这里我们就不再详说了。\n\n但还有很多配价理论完全无法解决的问题。比如，语义有指向的问题。“砍光了”、“砍累了”、“砍钝了”、“砍快了”，都是动词后面跟形容词作补语，但实际意义各不相同。“砍光了”指的是“树砍光了”，“砍累了”指的是“人砍累了”，“砍钝了”指的是“斧子砍钝了”，“砍快了”指的是“砍砍快了”。看来，一个动词的每个论元不但有语义类的限制，还有“评价方式”的限制。\n\n两个动词连用，也有语义关系的问题。“抓住不放”中，“抓住”和“不放”这两个动作构成一种反复的关系，抓住就等于不放。“说起来气人”中，“说起来”和“气人”这两个动作构成了一种条件关系，即每次发生了“说起来”这个事件后，都会产生“气人”这个结果。大家或许又会说，这两种情况真的有区别吗？是的，而且我能证明这一点。让我们造一个句子“留着没用”，你会发现它出现了歧义：既可以像“抓住不放”一样理解为反复关系，一直把它留着一直没有使用；又可以像“说起来气人”一样理解为条件关系，留着的话是不会有用的。因此，动词与动词连用确实会产生不同的语义关系，这需要另一套模型来处理。\n\n虚词的语义更麻烦。别以为“了”就是表示完成，“这本书看了三天”表示这本书看完了，“这本书看了三天了”反而表示这本书没看完。“了”到底有多少个义项，现在也没有一个定论。副词也算虚词，副词的语义同样捉摸不定。比较“张三和李四结婚了”与“张三和李四都结婚了”，你会发现描述“都”字的语义没那么简单。\n\n不过，在实际的产品应用中，前面所说的这些问题都不大。这篇文章中讲到的基本上都是基于规则的语言学处理方法。目前更实用的，则是对大规模真实语料的概率统计分析与机器学习算法，这条路子可以无视很多具体的语言学问题，并且效果也相当理想。最大熵模型和条件随机场都是目前非常常用的自然语言处理手段，感兴趣的朋友可以深入研究一下。但是，这些方法也有它们自己的缺点，就是它们的不可预测性。不管哪条路，似乎都离目标还有很远的一段距离。期待在未来的某一日，自然语言处理领域会迎来一套全新的语言模型，一举解决前面提到的所有难题。\n\n&#160;\n  > **转载：**\n> \n> [Matrix67](http://www.matrix67.com/blog/archives/4870)","source":"_posts/nlp-repost-semantic.md","raw":"title: 转 - 漫话中文自动分词和语义识别（下）：句法结构和语义结构\ntags:\n  - 算法\n  - 自然语言处理\n  - 语义\nid: 499\ncategories:\n  - 技术分享\ndate: 2012-04-01 17:54:48\n---\n\n这篇文章是[漫话中文分词算法](http://www.matrix67.com/blog/archives/4212)的续篇。在这里，我们将紧接着上一篇文章的内容继续探讨下去：如果计算机可以对一句话进行自动分词，它还能进一步整理句子的结构，甚至理解句子的意思吗？这两篇文章的关系十分紧密，因此，我把前一篇文章改名为了《漫话中文自动分词和语义识别（上）》，这篇文章自然就是它的下篇。我已经在很多不同的地方做过与这个话题有关的演讲了，在这里我想把它们写下来，和更多的人一同分享。\n<!--more-->\n\n什么叫做句法结构呢？让我们来看一些例子。“白天鹅在水中游”，这句话是有歧义的，它可能指的是“白天有一只鹅在水中游”，也可能指的是“有一只白天鹅在水中游”。不同的分词方案，产生了不同的意义。有没有什么句子，它的分词方案是唯一的，但也会产生不同的意思呢？有。比如“门没有锁”，它可能是指的“门没有被锁上”，也有可能是指的“门上根本就没有挂锁”。这个句子虽然只能切分成“门／没有／锁”，但由于“锁”这个词既有可能是动词，也有可能是名词，因而让整句话产生了不同的意思。有没有什么句子，它的分词方案是唯一的，并且每个词的词义也都不再变化，但整个句子仍然有歧义呢？有可能。看看这句话：“咬死了猎人的狗”。这句话有可能指的是“把猎人的狗咬死了”，也有可能指的是“一只咬死了猎人的狗”。这个歧义是怎么产生的呢？仔细体会两种不同的意思后，你会发现，句子中最底层的成分可以以不同的顺序组合起来，歧义由此产生。\n\n在前一篇文章中，我们看到了，利用概率转移的方法，我们可以有效地给一句话分词。事实上，利用相同的模型，我们也能给每一个词标注词性。更好的做法则是，我们直接把同一个词不同词性的用法当作是不同的词，从而把分词和词性标注的工作统一起来。但是，所有这样的工作都是对句子进行从左至右线性的分析，而句子结构实际上比这要复杂多了，它是这些词有顺序有层次地组合在一起的。计算机要想正确地解析一个句子，在分词和标注词性后，接下来该做的就是分析句法结构的层次。\n\n在计算机中，怎样描述一个句子的句法结构呢？ 1957 年， Noam Chomsky 出版了《句法结构》一书，把这种语言的层次化结构用形式化的方式清晰地描述了出来，这也就是所谓的“生成语法”模型。这本书是 20 世纪为数不多的几本真正的著作之一，文字非常简练，思路非常明晰，震撼了包括语言学、计算机理论在内的多个领域。记得 Quora 上曾经有人问 [Who are the best minds of the world today](http://www.quora.com/Best-Of/Who-are-the-best-minds-of-the-world-today-and-why) ，投出来的答案就是 Noam Chomsky 。\n\n随便取一句很长很复杂的话，比如“汽车被开车的师傅修好了”，我们总能至顶向下地一层层分析出它的结构。这个句子最顶层的结构就是“汽车修好了”。汽车怎么修好了呢？汽车被师傅修好了。汽车被什么样的师傅修好了呢？哦，汽车被开车的师傅修好了。当然，我们还可以无限地扩展下去，继续把句子中的每一个最底层的成分替换成更详细更复杂的描述，就好像小学语文中的扩句练习那样。这就是生成语法的核心思想。\n\n熟悉编译原理的朋友们可能知道“上下文无关文法”。其实，上面提到的扩展规则本质上就是一种上下文无关文法。例如，一个句子可以是“什么怎么样”的形式，我们就把这条规则记作\n  > 句子 → 名词性短语＋动词性短语  \n\n其中，“名词性短语”指的是一个具有名词功能的成分，它有可能就是一个名词，也有可能还有它自己的内部结构。例如，它有可能是一个形容词性短语加上“的”再加上另一个名词性短语构成的，比如“便宜的汽车”；它还有可能是由“动词性短语＋的＋名词性短语”构成的，比如“抛锚了的汽车”；它甚至可能是由“名词性短语＋的＋名词性短语”构成的，比如“老师的汽车”。我们把名词性短语的生成规则也都记下来：\n  > 名词性短语 → 名词\n> \n> 名词性短语 → 形容词性短语＋的＋名词性短语\n> \n> 名词性短语 → 动词性短语＋的＋名词性短语\n> \n> 名词性短语 → 名词性短语＋的＋名词性短语\n> \n>  ⋯⋯  \n\n类似地，动词性短语也有诸多具体的形式：\n  > 动词性短语 → 动词\n> \n> 动词性短语 → 动词性短语＋了\n> \n> 动词性短语 → 介词短语＋动词性短语\n> \n> ⋯⋯  \n\n上面我们涉及到了介词短语，它也有自己的生成规则：\n  > 介词短语 → 介词＋名词性短语\n> \n> ⋯⋯  \n\n我们构造句子的任务，也就是从“句子”这个初始结点出发，不断调用规则，产生越来越复杂的句型框架，然后从词库中选择相应词性的单词，填进这个框架里：\n\n![](http://www.matrix67.com/blogimage_2012/201201051.png)\n\n而分析句法结构的任务，则是已知一个句子从左到右各词的词性，要反过来求出一棵满足要求的“句法结构树”。这可以用 [Earley parser](http://en.wikipedia.org/wiki/Earley_parser) 来实现。\n\n这样看来，句法结构的问题似乎就已经完美的解决了。其实，我们还差得很远。生成语法有两个大问题。首先，句法结构正确的句子不见得都是好句子。 Chomsky 本人给出了一个经典的例子： Colorless green ideas sleep furiously 。形容词加形容词加名词加动词加副词，这是一个完全符合句法要求的序列，但随便拼凑会闹出很多笑话——什么叫做“无色的绿色的想法在狂暴地睡觉”？顺便插播个广告，如果你还挺喜欢这句话的意境的，欢迎去我以前做的 [IdeaGenerator](http://www.matrix67.com/ideagen/) 玩玩。不过，如果我们不涉及句子的生成，只关心句子的结构分析，这个缺陷对我们来说影响似乎并不大。生成语法的第二个问题就比较麻烦了：从同一个词性序列出发，可能会构建出不同的句法结构树。比较下面两个例子：\n  > 老师 被 迟到 的 学生 逗乐 了\n> \n> 电话 被 窃听 的 房间 找到 了  \n\n它们都是“名词＋介词＋动词＋的＋名词＋动词＋了”，但它们的结构并不一样，前者是老师被逗乐了，“迟到”是修饰“学生”的，后者是房间找到了，“电话被窃听”是一起来修饰房间的。但是，纯粹运用前面的模型，我们无法区分出哪句话应该是哪个句法结构树。如何强化句法分析的模型和算法，让计算机构建出一棵正确的句法树，这成了一个大问题。\n\n让我们来看一个更简单的例子吧。同样是“动词＋形容词＋名词”，我们有两种构建句法结构树的方案：\n\n![](http://www.matrix67.com/blogimage_2012/201201052.png)\n\n未经过汉语语法训练的朋友可能会问，“点亮蜡烛”和“踢新皮球”的句法结构真的不同吗？我们能证明，这里面真的存在不同。我们造一个句子“踢破皮球”，你会发现对于这个句子来说，两种句法结构都是成立的，于是出现了歧义：把皮球踢破了（结构和“点亮蜡烛”一致），或者是，踢一个破的皮球（结构和“踢新皮球”一致）。\n\n但为什么“点亮蜡烛”只有一种理解方式呢？这是因为我们通常不会把“亮”字直接放在名词前做定语，我们一般不说“一根亮蜡烛”、“一颗亮星星”等等。为什么“踢新皮球”也只有一种理解方式呢？这是因为我们通常不会把“新”直接放在动词后面作补语，不会说“皮球踢新了”，“衣服洗新了”等等。但是“破”既能作定语又能作补语，于是“踢破皮球”就产生了两种不同的意思。如果我们把每个形容词能否作定语，能否作补语都记下来，然后在生成规则中添加限制条件，不就能完美解决这个问题了吗？\n\n基于规则的句法分析器就是这么做的。汉语语言学家们已经列出了所有词的各种特征：\n\n亮：词性 = 形容词，能作补语 = True ，能作定语 = False ⋯⋯\n\n新：词性 = 形容词，能作补语 = False ，能作定语 = True ⋯⋯\n\n⋯⋯\n\n当然，每个动词也有一大堆属性：\n  > 点：词性 = 动词，能带宾语 = True ，能带补语 = True ⋯⋯\n> \n> 踢：词性 = 动词，能带宾语 = True ，能带补语 = True ⋯⋯\n> \n> 污染：词性 = 动词，能带宾语 = True ，能带补语 = False ⋯⋯\n> \n> 排队：词性 = 动词，能带宾语 = False ，能带补语 = False ⋯⋯\n> \n> ⋯⋯  \n\n名词也不例外：\n  > 蜡烛：词性 = 名词，能作主语 = True ，能作宾语 = True ，能受数量词修饰 = True ⋯⋯\n> \n> 皮球：词性 = 名词，能作主语 = True ，能作宾语 = True ，能受数量词修饰 = True ⋯⋯\n> \n> ⋯⋯  \n\n有人估计会觉得奇怪了：“能作主语”也是一个属性，莫非有些名词不能做主语？哈哈，这样的名词不但有，而且还真不少：剧毒、看头、厉害、正轨、存亡⋯⋯这些词都不放在动词前面。难道有些名词不能做宾语吗？这样的词也有不少：享年、芳龄、心术、浑身、家丑⋯⋯这些词都不放在动词后面。这样说来，存在不受数量词修饰的词也就不奇怪了，事实上上面这些怪异的名词前面基本上都不能加数量词。\n\n另外一个至关重要的就是，这些性质可以“向上传递”。比方说，我们规定，套用规则\n  > 名词性短语 → 形容词性短语＋名词性短语  \n\n后，整个名词性短语能否作主语、能否作宾语、能否受数量词修饰，这将取决于它的第二个构成成分。通俗地讲就是，如果“皮球”能够作主语，那么“新皮球”也能够作主语。有了“词语知识库”，又确保了这些知识能够在更高层次得到保留，我们就能给语法生成规则添加限制条件了。例如，我们可以规定，套用规则\n  > 动词性短语 → 动词性短语＋名词性短语  \n\n的前提条件就是，那个动词性短语的“能带宾语”属性为 True ，并且那个名词性短语“能作宾语”的属性为 True 。另外，我们规定\n  > 动词性短语 → 动词性短语＋形容词性短语  \n\n必须满足动词性短语的“能带补语”属性为 True ，并且形容词性短语“能作补语”属性为 True 。这样便阻止了“踢新皮球”中的“踢”和“新”先结合起来，因为“新”不能作补语。\n\n最后我们规定，套用规则\n  > 名词性短语 → 形容词性短语＋名词性短语  \n\n时，形容词性短语必须要能作定语。这就避免了“点亮蜡烛”中的“亮”和“蜡烛”先组合起来，因为“亮”通常不作定语。这样，我们便解决了“动词＋形容词＋名词”的结构分析问题。\n\n当然，这只是一个很简单的例子。在[这里](http://www.matrix67.com/blog/archives/508)的问题 6 、 7 、 8 中你可以看到，一条语法生成规则往往有很多限制条件，这些限制条件不光是简单的“功能相符”和“前后一致”，有些复杂的限制条件甚至需要用 IF … THEN … 的方式来描述。你可以在[这里](http://www.matrix67.com/blog/archives/4858)看到，汉语中词与词之间还有各种怪异的区别特征，并且哪个词拥有哪些性质纯粹是知识库的问题，完全没有规律可循。一个实用的句法结构分析系统，往往拥有上百种属性标签。北京大学计算语言所编写了《现代汉语语法信息词典》，它里面包含了 579 种属性。我们的理想目标就是，找到汉语中每一种可能会影响句法结构的因素，并据此为词库里的每一个词打上标签；再列出汉语语法中的每一条生成规则，找到每一条生成规则的应用条件，以及应用这条规则之后，整个成分将会以怎样的方式继承哪些子成分的哪些属性，又会在什么样的情况下产生哪些新的属性。按照生成语言学的观点，计算机就应该能正确解析所有的汉语句子了。\n\n那么，这样一来，计算机是否就已经能从句子中获取到理解语义需要的所有信息了呢？答案是否定的。还有这么一些句子，它从分词到词义到结构都没有两可的情况，但整个句子仍然有歧义。考虑这句话“鸡不吃了”，它有两种意思：鸡不吃东西了，或者我们不吃鸡了。但是，这种歧义并不是由分词或者词义或者结构导致的，两种意思所对应的语法结构完全相同，都是“鸡”加上“不吃了”。但为什么歧义仍然产生了呢？这是因为，在句法结构内部，还有更深层次的语义结构，两者并不相同。\n\n汉语就是这么奇怪，位于主语位置上的事物既有可能是动作的发出者，也有可能是动作的承受者。“我吃完了”可以说，“苹果吃完了”也能讲。然而，“鸡”这个东西既能吃，也能被吃，歧义由此产生。\n\n位于宾语位置上的事物也不一定就是动作的承受者，“来客人了”、“住了一个人”都是属于宾语反而是动作发出者的情况。记得某次数理逻辑课上老师感叹，汉语的谓词非常不规范，明明是太阳在晒我，为什么要说成是“我晒太阳”呢？事实上，汉语的动宾搭配范围极其广泛，还有很多更怪异的例子：“写字”是我们真正在写的东西，“写书”是写的结果，“写毛笔”是写的工具，“写楷体”是写的方式，“写地上”是写的场所，“写一只狗”，等等，什么叫做“写一只狗”啊？我们能说“写一只狗”吗？当然可以，这是写的内容嘛，“同学们这周作文写什么啊”，“我写一只狗”。大家可以想像，学中文的老外看了这个会是什么表情。虽然通过句法分析，我们能够判断出句子中的每样东西都和哪个动词相关联，但从语义层面上看这个关联是什么，我们还需要新的模型。\n\n汉语语言学家把事物与动词的语义关系分为了 17 种，叫做 17 种“语义角色”，它们是施事、感事、当事、动力、受事、结果、系事、工具、材料、方式、内容、与事、对象、场所、目标、起点、时间。你可以看到，语义角色的划分非常详细。同样是动作的发出者，施事指的是真正意义上的发出动作，比如“他吃饭”中的“他”；感事则是指某种感知活动的经验者，比如“他知道这件事了”中的“他”；当事则是指性质状态的主体，比如“他病了”中的“他”；动力则是自然力量的发出者，比如“洪水淹没了村庄”中的“洪水”。语义角色的具体划分以及 17 这个数目是有争议的，不过不管怎样，这个模型本身能够非常贴切地回答“什么是语义”这个问题。\n\n汉语有一种“投射理论”，即一个句子的结构是由这个句子中的谓语投射出来的。给定一个动词后，这个动词能够带多少个语义角色，这几个语义角色都是什么，基本上都已经确定了。因而，完整的句子所应有的结构实际上也就已经确定了。比如，说到“休息”这个动词，你就会觉得它缺少一个施事，而且也不缺别的了。我们只会说“老王休息”，不会说“老王休息手”或者“老王休息沙发”。因而我们认为，“休息”只有一个“论元”。它的“论元结构”是：\n  > 休息 &lt;施事&gt;  \n\n因此，一旦在句子中看到“休息”这个词，我们就需要在句内或者句外寻找“休息”所需要的施事。这个过程有一个很帅的名字，叫做“配价”。“休息”就是一个典型的“一价动词”。我们平时接触的比较多的则是二价动词。不过，它们具体的论元有可能不一样：\n  > 吃 &lt;施事，受事&gt;\n> \n> 去 &lt;施事，目标&gt;\n> \n> 淹没 &lt;动力，受事&gt;  \n\n三价动词也是有的，例如\n  > 送 &lt;施事，受事，与事&gt;  \n\n甚至还有零价动词，例如\n  > 下雨 &lt;Ф&gt;  \n\n下面我们要教计算机做的，就是怎样给动词配价。之前，我们已经给出了解析句法结构的方法，这样计算机便能判断出每个动词究竟在和哪些词发生关系。语义分析的实质，就是确定出它们具体是什么关系。因此，语义识别的问题，也就转化为了“语义角色标注”的问题。然而，语义角色出现的位置并不固定，施事也能出现在动词后面，受事也能出现在动词前面，怎样让计算机识别语义角色呢？在回答这个问题之前，我们不妨问问自己：我们是怎么知道，“我吃完了”中的“我”是“吃”的施事，“苹果吃完了”中的“苹果”是“吃”的受事的呢？大家肯定会说，废话，“我”当然只能是“吃”的施事，因为我显然不会“被吃”；“苹果”当然只能是“吃”的受事，因为苹果显然不能发出“吃”动作。也就是说，“吃”的两个论元都有语义类的要求。我们把“吃”的论元结构写得更详细一些：\n  > 吃 &lt;施事[语义类：人|动物]，受事[语义类：食物|药物]&gt;  \n\n而“淹没”一词的论元结构则可以补充为：\n  > 淹没 &lt;动力[语义类：自然事物]，受事[语义类：建筑物|空间]&gt;  \n\n所以，为了完成计算机自动标注语义角色的任务，我们需要人肉建立两个庞大的数据库：语义类词典和论元结构词典。这样的人肉工程早就已经做过了。北京语言大学 1990 年 5 月启动的“九〇￼五语义工程”就是人工构建的一棵规模相当大的语义树。它把词语分成了事物、运动、时空、属性四大类，其中事物类分为事类和物类，物类又分为具体物和抽象物，具体物则再分为生物和非生物，生物之下则分了人类、动物、植物、微生物、生物构件五类，非生物之下则分了天然物、人工物、遗弃物、几何图形和非生物构件五类，其中人工物之下又包括设施物、运载物、器具物、原材料、耗散物、信息物、钱财七类。整棵语义树有 414 个结点，其中叶子结点 309 个，深度最大的地方达到了 9 层。论元结构方面则有清华大学和人民大学共同完成的《现代汉语述语动词机器词典》，词典中包括了各种动词的拼音、释义、分类、论元数、论元的语义角色、论元的语义限制等语法和语义信息。\n\n说到语义工程，不得不提到董振东先生的[知网](http://www.keenage.com/html/c_index.html)。这是一个综合了语义分类和语义关系的知识库，不但通过语义树反映了词与词的共性，还通过语义关系反映了每个词的个性。它不但能告诉你“医生”和“病人”都是人，还告诉了你“医生”可以对“病人”发出一个“医治”的动作。知网的理念和 WordNet 工程很相似，后者是 Princeton 在 1985 年就已经开始构建的英文单词语义关系词典，背后也是一个语义关系网的概念，词与词的关系涉及同义词、反义词、上下位词、整体与部分、子集与超集、材料与成品等等。如果你装了 Mathematica，你可以通过 WordData 函数获取到 WordNet 的数据。至于前面说的那几个中文知识库嘛，别问我，我也不知道上哪儿取去。\n\n看到这里，想必大家会欢呼，啊，这下子，在中文信息处理领域，从语法到语义都已经漂亮的解决了吧。其实并没有。上面的论元语义角色的模型有很多问题。其中一个很容易想到的就是隐喻的问题，比如“信息淹没了我”、“悲伤淹没了我”。一旦出现动词的新用法，我们只能更新论元结构：\n  > 淹没 &lt;动力[语义类：自然事物|抽象事物]，受事[语义类：建筑物|空间|人类]&gt;  \n\n但更麻烦的则是下面这些违背语义规则的情况。一个是否定句，比如“张三不可能吃思想”。一个是疑问句，比如“张三怎么可能吃思想”。更麻烦的就是超常现象。随便在新闻网站上一搜，你就会发现各种不符合语义规则的情形。我搜了一个“吃金属”，立即看到某新闻标题《法国一位老人以吃金属为生》。要想解决这些问题，需要给配价模型打上不少补丁。\n\n然而，配价模型也仅仅解决了动词的语义问题。其他词呢？好在，我们也可以为名词发展一套类似的配价理论。我们通常认为“教师”是一个零价名词，而“老师”则是一个一价名词，因为说到“老师”时，我们通常会说“谁的老师”。“态度”则是一个二价的名词，因为我们通常要说“谁对谁的态度”才算完整。事实上，形容词也有配价，“优秀”就是一个一价形容词，“友好”则是一个二价形容词，原因也是类似的。配价理论还有很多更复杂的内容，这里我们就不再详说了。\n\n但还有很多配价理论完全无法解决的问题。比如，语义有指向的问题。“砍光了”、“砍累了”、“砍钝了”、“砍快了”，都是动词后面跟形容词作补语，但实际意义各不相同。“砍光了”指的是“树砍光了”，“砍累了”指的是“人砍累了”，“砍钝了”指的是“斧子砍钝了”，“砍快了”指的是“砍砍快了”。看来，一个动词的每个论元不但有语义类的限制，还有“评价方式”的限制。\n\n两个动词连用，也有语义关系的问题。“抓住不放”中，“抓住”和“不放”这两个动作构成一种反复的关系，抓住就等于不放。“说起来气人”中，“说起来”和“气人”这两个动作构成了一种条件关系，即每次发生了“说起来”这个事件后，都会产生“气人”这个结果。大家或许又会说，这两种情况真的有区别吗？是的，而且我能证明这一点。让我们造一个句子“留着没用”，你会发现它出现了歧义：既可以像“抓住不放”一样理解为反复关系，一直把它留着一直没有使用；又可以像“说起来气人”一样理解为条件关系，留着的话是不会有用的。因此，动词与动词连用确实会产生不同的语义关系，这需要另一套模型来处理。\n\n虚词的语义更麻烦。别以为“了”就是表示完成，“这本书看了三天”表示这本书看完了，“这本书看了三天了”反而表示这本书没看完。“了”到底有多少个义项，现在也没有一个定论。副词也算虚词，副词的语义同样捉摸不定。比较“张三和李四结婚了”与“张三和李四都结婚了”，你会发现描述“都”字的语义没那么简单。\n\n不过，在实际的产品应用中，前面所说的这些问题都不大。这篇文章中讲到的基本上都是基于规则的语言学处理方法。目前更实用的，则是对大规模真实语料的概率统计分析与机器学习算法，这条路子可以无视很多具体的语言学问题，并且效果也相当理想。最大熵模型和条件随机场都是目前非常常用的自然语言处理手段，感兴趣的朋友可以深入研究一下。但是，这些方法也有它们自己的缺点，就是它们的不可预测性。不管哪条路，似乎都离目标还有很远的一段距离。期待在未来的某一日，自然语言处理领域会迎来一套全新的语言模型，一举解决前面提到的所有难题。\n\n&#160;\n  > **转载：**\n> \n> [Matrix67](http://www.matrix67.com/blog/archives/4870)","slug":"nlp-repost-semantic","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg621p0034sb8fwobft8w3"},{"title":"转 – 漫话中文自动分词和语义识别（上）：中文分词算法","id":"497","date":"2012-04-01T09:48:00.000Z","_content":"\nM牛的这篇博文实在是太精彩了，读了一遍又一遍，最后干脆就直接转过来了。有兴趣的可以直接看他的博客：[matrix67](http://www.matrix67.com/blog/archives/4212)\n<!--more-->\n\n记得第一次了解中文分词算法是在 [Google 黑板报](http://www.google.com.hk/ggblog/googlechinablog/2006/04/blog-post_7327.html) 上看到的，当初看到那个算法时我彻底被震撼住了，想不到一个看似不可能完成的任务竟然有如此神奇巧妙的算法。最近在詹卫东老师的《中文信息处理导论》课上再次学到中文分词算法，才知道这并不是中文分词算法研究的全部，前前后后还有很多故事可讲。在没有建立统计语言模型时，人们还在语言学的角度对自动分词进行研究，期间诞生了很多有意思的理论。\n\n中文分词的主要困难在于分词歧义。“结婚的和尚未结婚的”，应该分成“结婚／的／和／尚未／结婚／的”，还是“结婚／的／和尚／未／结婚／的”？人来判断很容易，要交给计算机来处理就麻烦了。问题的关键就是，“和尚未”里的“和尚”也是一个词，“尚未”也是一个词，从计算机的角度看上去，两者似乎都有可能。对于计算机来说，这样的分词困境就叫做“交集型歧义”。\n\n有时候，交集型歧义的“歧义链”有可能会更长。“中外科学名著”里，“中外”、“外科”、“科学”、“学名”、“名著”全是词，光从词库的角度来看，随便切几刀下去，得出的切分都是合理的。类似的例子数不胜数，“提高产品质量”、“鞭炮声响彻夜空”、“努力学习语法规则”等句子都有这样的现象。在这些极端例子下，分词算法谁优谁劣可谓是一试便知。\n\n最简单的，也是最容易想到的自动分词算法，便是“最大匹配法”了。也就是说，从句子左端开始，不断匹配最长的词（组不了词的单字则单独划开），直到把句子划分完。算法的理由很简单：人在阅读时也是从左往右逐字读入的，最大匹配法是与人的习惯相符的。而在大多数情况下，这种算法也的确能侥幸成功。不过，这种算法并不可靠，构造反例可以不费吹灰之力。例如，“北京大学生前来应聘”本应是“北京／大学生／前来／应聘”，却会被误分成“北京大学／生前／来／应聘”。\n\n维护一个特殊规则表，可以修正一些很机械的问题，效果相当不错。例如，“不可能”要划分成“不／可能”，“会诊”后面接“断”、“疗”、“脉”、“治”时要把“会”单独切出，“的确切”后面是抽象名词时要把“的确切”分成“的／确切”，等等。\n\n还有一个适用范围相当广的特殊规则，这个强大的规则能修正很多交集型歧义的划分错误。首先我们要维护一个一般不单独成词的字表，比如“民”、“尘”、“伟”、“习”等等；这些字通常不会单独划出来，都要跟旁边的字一块儿组成一个词。在分词过程中时，一旦发现这些字被孤立出来，都重新考虑它与前面的字组词的可能。例如，在用最大匹配法切分“为人民服务”时，算法会先划出“为人”一词，而后发现“民”字只能单独成词了。查表却发现，“民”并不能单独划出，于是考虑进行修正——把“为人”的“人”字分配给“民”字。巧在这下“为”和“人民”正好都能成词，据此便可得出正确的划分“为／人民／服务”。\n\n不过，上述算法归根结底，都是在像人一样从左到右地扫描文字。为了把问题变得更加形式化，充分利用计算机的优势，我们还有一种与人的阅读习惯完全不同的算法思路：把句子作为一个整体来考虑，从全局的角度评价一个句子划分方案的好坏。设计自动分词算法的问题，也就变成了如何评估分词方案优劣的问题。最初所用的办法就是，寻找词数最少的划分。注意，每次都匹配最长的词，得出的划分不见得是词数最少的，错误的贪心很可能会不慎错过一些更优的路。因而，在有的情况下，最少词数法比最大匹配法效果更好。若用最大匹配法来划分，“独立自主和平等互利的原则”将被分成“独立自主／和平／等／互利／的／原则”，一共有 6 个词；但词数更少的方案则是“独立自主／和／平等互利／的／原则”，一共只有 5 个词。\n\n当然，最少词数法也会有踩大便的时候。“为人民办公益”的最大匹配划分和最少词数划分都是“为人／民办／公益”，而正确的划分则是“为／人民／办／公益”。同时，很多句子也有不止一个词数最少的分词方案，最少词数法并不能从中选出一个最佳答案。不过，把之前提到的“不成词字表”装备到最少词数法上，我们就有了一种简明而强大的算法：\n\n对于一种分词方案，里面有多少词，就罚多少分；每出现一个不成词的单字，就加罚一分。最好的分词方案，也就是罚分最少的方案。\n\n这种算法的效果出人意料的好。“他说的确实在理”是一个很困难的测试用例，“的确”和“实在”碰巧也成词，这给自动分词带来了很大的障碍。但是“确”、“实”、“理”通常都不单独成词的，因此很多切分方案都会被扣掉不少分：\n  > 他／说／的／确实／在理 （罚分：1+1+1+1+1 = 5 ）     \n> &#160;&#160;&#160;&#160; 他／说／的确／实／在理 （罚分：1+1+1+2+1 = 6 ）      \n> &#160;&#160;&#160;&#160; 他／说／的确／实在／理 （罚分：1+1+1+1+2 = 6 ）  \n\n正确答案胜出。\n\n需要指出的是，这个算法并不需要枚举所有的划分可能。整个问题可以转化为图论中的最短路径问题，利用动态规划效率则会更高。\n\n算法还有进一步加强的余地。大家或许已经想到了，“字不成词”有一个程度的问题。“民”是一个不成词的语素，它是绝对不会单独成词的。“鸭”一般不单独成词，但在儿歌童谣和科技语体中除外。“见”则是一个可以单独成词的语素，只是平时我们不常说罢了。换句话说，每个字成词都有一定的概率，每个词出现的频率也是不同的。\n\n何不用每个词出现的概率，来衡量分词的优劣？于是我们有了一个更标准、更连续、更自动的改进算法：先统计大量真实语料中各个词出现的频率，然后把每种分词方案中各词的出现概率乘起来作为这种方案的得分。利用动态规划，不难求出得分最高的方案。\n\n以“有意见分歧”为例，让我们看看最大概率法是如何工作的。查表可知，在大量真实语料中，“有”、“有意”、“意见”、“见”、“分歧”的出现概率分别是 0.0181 、 0.0005 、 0.0010 、 0.0002 、 0.0001 ，因此“有／意见／分歧”的得分为 1.8×10<sup>-9</sup> ，但“有意／见／分歧”的得分只有 1.0×10<sup>-11</sup> ，正确方案完胜。\n\n这里的假设是，用词造句无非是随机选词连在一块儿，是一个简单的一元过程。显然，这个假设理想得有点不合理，必然会有很多问题。考虑下面这句话：\n  > 这／事／的确／定／不／下来  \n\n但是概率算法却会把这个句子分成：\n  > 这／事／的／确定／不／下来  \n\n原因是，“的”字的出现概率太高了，它几乎总会从“的确”中挣脱出来。\n\n其实，以上所有的分词算法都还有一个共同的大缺陷：它们虽然已经能很好地处理交集型歧义的问题，却完全无法解决另外一种被称为“组合型歧义”的问题。所谓组合型歧义，就是指同一个字串既可合又可分。比如说，“个人恩怨”中的“个人”就是一个词，“这个人”里的“个人”就必须拆开；“这扇门的把手”中的“把手”就是一个词，“把手抬起来”的“把手”就必须拆开；“学生会宣传部”中的“学生会”就是一个词，“学生会主动完成作业”里的“学生会”就必须拆开。这样的例子非常多，“难过”、“马上”、“将来”、“才能”、“过人”、“研究所”、“原子能”都有此问题。究竟是合还是分，还得取决于它两侧的词语。到目前为止，所有算法对划分方案的评价标准都是基于每个词固有性质的，完全不考虑相邻词语之间的影响；因而一旦涉及到组合型歧义的问题，最大匹配、最少词数、概率最大等所有策略都不能实现具体情况具体分析。\n\n于是，我们不得不跳出一元假设。此时，便有了那个 Google 黑板报上提到的统计语言模型算法。对于任意两个词语 w<sub>1</sub> 、 w<sub>2</sub> ，统计在语料库中词语 w<sub>1</sub> 后面恰好是 w<sub>2</sub> 的概率 P(w<sub>1</sub>, w<sub>2</sub>) 。这样便会生成一个很大的二维表。再定义一个句子的划分方案的得分为 P(∅, w<sub>1</sub>) · P(w<sub>1</sub>, w<sub>2</sub>) · … · P(w<sub>n-1</sub>, w<sub>n</sub>) ，其中 w<sub>1</sub>, w<sub>2</sub>, …, w<sub>n</sub> 依次表示分出的词。我们同样可以利用动态规划求出得分最高的分词方案。这真是一个天才的模型，这个模型一并解决了词类标注、语音识别等各类自然语言处理问题。\n\n至此，中文自动分词算是有了一个漂亮而实用的算法。\n\n但是，随便拿份报纸读读，你就会发现我们之前给出的测试用例都太理想了，简直就是用来喂给计算机的。在中文分词中，还有一个比分词歧义更令人头疼的东西——未登录词。中文没有首字母大写，专名号也被取消了，这叫计算机如何辨认人名地名之类的东西？最近十年来，中文分词领域都在集中攻克这一难关。\n\n在汉语的未定义词中，中国人名的规律是最强的了。根据统计，汉语姓氏大约有 1000 多个，其中“王”、“陈”、“李”、“张”、“刘”五大姓氏的覆盖率高达 32% ，前 400 个姓氏覆盖率高达 99% 。人名的用字也比较集中，“英”、“华”、“玉”、“秀”、“明”、“珍”六个字的覆盖率就有 10.35% ，最常用的 400 字则有 90% 的覆盖率。虽然这些字分布在包括文言虚词在内的各种词类里，但就用字的感情色彩来看，人名多用褒义字和中性字，少有不雅用字，因此规律性还是非常强的。根据这些信息，我们足以计算一个字符串能成为名字的概率，结合预先设置的阈值便能很好地识别出可能的人名。\n\n可是，如何把人名从句子中切出来呢？换句话说，如果句中几个连续字都是姓名常用字，人名究竟应该从哪儿取到哪儿呢？人名以姓氏为左边界，相对容易判定一些。人名的右边界则可以从下文的提示确定出来：人名后面通常会接“先生”、“同志”、“校长”、“主任”、“医生”等身份词，以及“是”、“说”、“报道”、“参加”、“访问”、“表示”等动作词。\n\n但麻烦的情况也是有的。一些高频姓氏本身也是经常单独成词的常用字，例如“于”、“马”、“黄”、“常”、“高”等等。很多反映时代性的名字也是本身就成词的，例如“建国”、“建设”、“国庆”、“跃进”等等。更讨厌的就是那些整个名字本身就是常用词的人了，他们会彻底打乱之前的各种模型。如果分词程序也有智能的话，他一定会把所有叫“高峰”、“汪洋”、”庞博“的人拖出去斩了；要是听说了有人居然敢叫“令计划”，估计直接就崩溃了。\n\n还有那些恰好与上下文组合成词的人名，例如：\n  > 费孝通向人大常委会提交书面报告     \n> &#160;&#160;&#160;&#160; 邓颖超生前使用过的物品  \n\n这就是最考验分词算法的句子了。\n\n相比之下，中国地名的用字就分散得多了。北京有一个地方叫“臭泥坑”，网上搜索“臭泥坑”，第一页全是“臭泥坑地图”、“臭泥坑附近酒店”之类的信息。某年《重庆晨报》刊登停电通知，上面赫然印着“停电范围包括沙坪坝区的犀牛屙屎和犀牛屙屎抽水”，读者纷纷去电投诉印刷错误。记者仔细一查，你猜怎么着，印刷并无错误，重庆真的就有叫“犀牛屙屎”和“犀牛屙屎抽水”的地方。\n\n好在，中国地名数量有限，这是可以枚举的。中国地名委员会编写了《中华人民共和国地名录》，收录了从高原盆地到桥梁电站共 10 万多个地名，这让中国地名的识别便利了很多。\n\n真正有些困难的就是识别机构名了，虽然机构名的后缀比较集中，但左边界的判断就有些难了。更难的就是品牌名了。如今各行各业大打创意战，品牌名可以说是无奇不有，而且经常本身就包含常用词，更是给自动分词添加了不少障碍。\n\n最难识别的未登录词就是缩略语了。“高数”、“抵京”、“女单”、“发改委”、“北医三院”都是比较好认的缩略语了，有些缩略语搞得连人也是丈二和尚摸不着头脑。你能猜到“人影办”是什么机构的简称吗？打死你都想不到，是“人工影响天气办公室”。\n\n汉语中构造缩略语的规律很诡异，目前也没有一个定论。初次听到这个问题，几乎每个人都会做出这样的猜想：缩略语都是选用各个成分中最核心的字，比如“安全检查”缩成“安检”，“人民警察”缩成“民警”等等。不过，反例也是有的，“邮政编码”就被缩成了“邮编”，但“码”无疑是更能概括“编码”一词的。当然，这几个缩略语已经逐渐成词，可以加进词库了；不过新近出现的或者临时构造的缩略语该怎么办，还真是个大问题。\n\n说到新词，网络新词的大量出现才是分词系统真正的敌人。这些新词汇的来源千奇百怪，几乎没有固定的产生机制。要想实现对网络文章的自动分词，目前来看可以说是相当困难的。革命尚未成功，分词算法还有很多进步的余地。","source":"_posts/nlp-repost-segmentation.md","raw":"title: 转 – 漫话中文自动分词和语义识别（上）：中文分词算法\ntags:\n  - 算法\n  - 自然语言处理\n  - 语义\nid: 497\ncategories:\n  - 技术分享\ndate: 2012-04-01 17:48:00\n---\n\nM牛的这篇博文实在是太精彩了，读了一遍又一遍，最后干脆就直接转过来了。有兴趣的可以直接看他的博客：[matrix67](http://www.matrix67.com/blog/archives/4212)\n<!--more-->\n\n记得第一次了解中文分词算法是在 [Google 黑板报](http://www.google.com.hk/ggblog/googlechinablog/2006/04/blog-post_7327.html) 上看到的，当初看到那个算法时我彻底被震撼住了，想不到一个看似不可能完成的任务竟然有如此神奇巧妙的算法。最近在詹卫东老师的《中文信息处理导论》课上再次学到中文分词算法，才知道这并不是中文分词算法研究的全部，前前后后还有很多故事可讲。在没有建立统计语言模型时，人们还在语言学的角度对自动分词进行研究，期间诞生了很多有意思的理论。\n\n中文分词的主要困难在于分词歧义。“结婚的和尚未结婚的”，应该分成“结婚／的／和／尚未／结婚／的”，还是“结婚／的／和尚／未／结婚／的”？人来判断很容易，要交给计算机来处理就麻烦了。问题的关键就是，“和尚未”里的“和尚”也是一个词，“尚未”也是一个词，从计算机的角度看上去，两者似乎都有可能。对于计算机来说，这样的分词困境就叫做“交集型歧义”。\n\n有时候，交集型歧义的“歧义链”有可能会更长。“中外科学名著”里，“中外”、“外科”、“科学”、“学名”、“名著”全是词，光从词库的角度来看，随便切几刀下去，得出的切分都是合理的。类似的例子数不胜数，“提高产品质量”、“鞭炮声响彻夜空”、“努力学习语法规则”等句子都有这样的现象。在这些极端例子下，分词算法谁优谁劣可谓是一试便知。\n\n最简单的，也是最容易想到的自动分词算法，便是“最大匹配法”了。也就是说，从句子左端开始，不断匹配最长的词（组不了词的单字则单独划开），直到把句子划分完。算法的理由很简单：人在阅读时也是从左往右逐字读入的，最大匹配法是与人的习惯相符的。而在大多数情况下，这种算法也的确能侥幸成功。不过，这种算法并不可靠，构造反例可以不费吹灰之力。例如，“北京大学生前来应聘”本应是“北京／大学生／前来／应聘”，却会被误分成“北京大学／生前／来／应聘”。\n\n维护一个特殊规则表，可以修正一些很机械的问题，效果相当不错。例如，“不可能”要划分成“不／可能”，“会诊”后面接“断”、“疗”、“脉”、“治”时要把“会”单独切出，“的确切”后面是抽象名词时要把“的确切”分成“的／确切”，等等。\n\n还有一个适用范围相当广的特殊规则，这个强大的规则能修正很多交集型歧义的划分错误。首先我们要维护一个一般不单独成词的字表，比如“民”、“尘”、“伟”、“习”等等；这些字通常不会单独划出来，都要跟旁边的字一块儿组成一个词。在分词过程中时，一旦发现这些字被孤立出来，都重新考虑它与前面的字组词的可能。例如，在用最大匹配法切分“为人民服务”时，算法会先划出“为人”一词，而后发现“民”字只能单独成词了。查表却发现，“民”并不能单独划出，于是考虑进行修正——把“为人”的“人”字分配给“民”字。巧在这下“为”和“人民”正好都能成词，据此便可得出正确的划分“为／人民／服务”。\n\n不过，上述算法归根结底，都是在像人一样从左到右地扫描文字。为了把问题变得更加形式化，充分利用计算机的优势，我们还有一种与人的阅读习惯完全不同的算法思路：把句子作为一个整体来考虑，从全局的角度评价一个句子划分方案的好坏。设计自动分词算法的问题，也就变成了如何评估分词方案优劣的问题。最初所用的办法就是，寻找词数最少的划分。注意，每次都匹配最长的词，得出的划分不见得是词数最少的，错误的贪心很可能会不慎错过一些更优的路。因而，在有的情况下，最少词数法比最大匹配法效果更好。若用最大匹配法来划分，“独立自主和平等互利的原则”将被分成“独立自主／和平／等／互利／的／原则”，一共有 6 个词；但词数更少的方案则是“独立自主／和／平等互利／的／原则”，一共只有 5 个词。\n\n当然，最少词数法也会有踩大便的时候。“为人民办公益”的最大匹配划分和最少词数划分都是“为人／民办／公益”，而正确的划分则是“为／人民／办／公益”。同时，很多句子也有不止一个词数最少的分词方案，最少词数法并不能从中选出一个最佳答案。不过，把之前提到的“不成词字表”装备到最少词数法上，我们就有了一种简明而强大的算法：\n\n对于一种分词方案，里面有多少词，就罚多少分；每出现一个不成词的单字，就加罚一分。最好的分词方案，也就是罚分最少的方案。\n\n这种算法的效果出人意料的好。“他说的确实在理”是一个很困难的测试用例，“的确”和“实在”碰巧也成词，这给自动分词带来了很大的障碍。但是“确”、“实”、“理”通常都不单独成词的，因此很多切分方案都会被扣掉不少分：\n  > 他／说／的／确实／在理 （罚分：1+1+1+1+1 = 5 ）     \n> &#160;&#160;&#160;&#160; 他／说／的确／实／在理 （罚分：1+1+1+2+1 = 6 ）      \n> &#160;&#160;&#160;&#160; 他／说／的确／实在／理 （罚分：1+1+1+1+2 = 6 ）  \n\n正确答案胜出。\n\n需要指出的是，这个算法并不需要枚举所有的划分可能。整个问题可以转化为图论中的最短路径问题，利用动态规划效率则会更高。\n\n算法还有进一步加强的余地。大家或许已经想到了，“字不成词”有一个程度的问题。“民”是一个不成词的语素，它是绝对不会单独成词的。“鸭”一般不单独成词，但在儿歌童谣和科技语体中除外。“见”则是一个可以单独成词的语素，只是平时我们不常说罢了。换句话说，每个字成词都有一定的概率，每个词出现的频率也是不同的。\n\n何不用每个词出现的概率，来衡量分词的优劣？于是我们有了一个更标准、更连续、更自动的改进算法：先统计大量真实语料中各个词出现的频率，然后把每种分词方案中各词的出现概率乘起来作为这种方案的得分。利用动态规划，不难求出得分最高的方案。\n\n以“有意见分歧”为例，让我们看看最大概率法是如何工作的。查表可知，在大量真实语料中，“有”、“有意”、“意见”、“见”、“分歧”的出现概率分别是 0.0181 、 0.0005 、 0.0010 、 0.0002 、 0.0001 ，因此“有／意见／分歧”的得分为 1.8×10<sup>-9</sup> ，但“有意／见／分歧”的得分只有 1.0×10<sup>-11</sup> ，正确方案完胜。\n\n这里的假设是，用词造句无非是随机选词连在一块儿，是一个简单的一元过程。显然，这个假设理想得有点不合理，必然会有很多问题。考虑下面这句话：\n  > 这／事／的确／定／不／下来  \n\n但是概率算法却会把这个句子分成：\n  > 这／事／的／确定／不／下来  \n\n原因是，“的”字的出现概率太高了，它几乎总会从“的确”中挣脱出来。\n\n其实，以上所有的分词算法都还有一个共同的大缺陷：它们虽然已经能很好地处理交集型歧义的问题，却完全无法解决另外一种被称为“组合型歧义”的问题。所谓组合型歧义，就是指同一个字串既可合又可分。比如说，“个人恩怨”中的“个人”就是一个词，“这个人”里的“个人”就必须拆开；“这扇门的把手”中的“把手”就是一个词，“把手抬起来”的“把手”就必须拆开；“学生会宣传部”中的“学生会”就是一个词，“学生会主动完成作业”里的“学生会”就必须拆开。这样的例子非常多，“难过”、“马上”、“将来”、“才能”、“过人”、“研究所”、“原子能”都有此问题。究竟是合还是分，还得取决于它两侧的词语。到目前为止，所有算法对划分方案的评价标准都是基于每个词固有性质的，完全不考虑相邻词语之间的影响；因而一旦涉及到组合型歧义的问题，最大匹配、最少词数、概率最大等所有策略都不能实现具体情况具体分析。\n\n于是，我们不得不跳出一元假设。此时，便有了那个 Google 黑板报上提到的统计语言模型算法。对于任意两个词语 w<sub>1</sub> 、 w<sub>2</sub> ，统计在语料库中词语 w<sub>1</sub> 后面恰好是 w<sub>2</sub> 的概率 P(w<sub>1</sub>, w<sub>2</sub>) 。这样便会生成一个很大的二维表。再定义一个句子的划分方案的得分为 P(∅, w<sub>1</sub>) · P(w<sub>1</sub>, w<sub>2</sub>) · … · P(w<sub>n-1</sub>, w<sub>n</sub>) ，其中 w<sub>1</sub>, w<sub>2</sub>, …, w<sub>n</sub> 依次表示分出的词。我们同样可以利用动态规划求出得分最高的分词方案。这真是一个天才的模型，这个模型一并解决了词类标注、语音识别等各类自然语言处理问题。\n\n至此，中文自动分词算是有了一个漂亮而实用的算法。\n\n但是，随便拿份报纸读读，你就会发现我们之前给出的测试用例都太理想了，简直就是用来喂给计算机的。在中文分词中，还有一个比分词歧义更令人头疼的东西——未登录词。中文没有首字母大写，专名号也被取消了，这叫计算机如何辨认人名地名之类的东西？最近十年来，中文分词领域都在集中攻克这一难关。\n\n在汉语的未定义词中，中国人名的规律是最强的了。根据统计，汉语姓氏大约有 1000 多个，其中“王”、“陈”、“李”、“张”、“刘”五大姓氏的覆盖率高达 32% ，前 400 个姓氏覆盖率高达 99% 。人名的用字也比较集中，“英”、“华”、“玉”、“秀”、“明”、“珍”六个字的覆盖率就有 10.35% ，最常用的 400 字则有 90% 的覆盖率。虽然这些字分布在包括文言虚词在内的各种词类里，但就用字的感情色彩来看，人名多用褒义字和中性字，少有不雅用字，因此规律性还是非常强的。根据这些信息，我们足以计算一个字符串能成为名字的概率，结合预先设置的阈值便能很好地识别出可能的人名。\n\n可是，如何把人名从句子中切出来呢？换句话说，如果句中几个连续字都是姓名常用字，人名究竟应该从哪儿取到哪儿呢？人名以姓氏为左边界，相对容易判定一些。人名的右边界则可以从下文的提示确定出来：人名后面通常会接“先生”、“同志”、“校长”、“主任”、“医生”等身份词，以及“是”、“说”、“报道”、“参加”、“访问”、“表示”等动作词。\n\n但麻烦的情况也是有的。一些高频姓氏本身也是经常单独成词的常用字，例如“于”、“马”、“黄”、“常”、“高”等等。很多反映时代性的名字也是本身就成词的，例如“建国”、“建设”、“国庆”、“跃进”等等。更讨厌的就是那些整个名字本身就是常用词的人了，他们会彻底打乱之前的各种模型。如果分词程序也有智能的话，他一定会把所有叫“高峰”、“汪洋”、”庞博“的人拖出去斩了；要是听说了有人居然敢叫“令计划”，估计直接就崩溃了。\n\n还有那些恰好与上下文组合成词的人名，例如：\n  > 费孝通向人大常委会提交书面报告     \n> &#160;&#160;&#160;&#160; 邓颖超生前使用过的物品  \n\n这就是最考验分词算法的句子了。\n\n相比之下，中国地名的用字就分散得多了。北京有一个地方叫“臭泥坑”，网上搜索“臭泥坑”，第一页全是“臭泥坑地图”、“臭泥坑附近酒店”之类的信息。某年《重庆晨报》刊登停电通知，上面赫然印着“停电范围包括沙坪坝区的犀牛屙屎和犀牛屙屎抽水”，读者纷纷去电投诉印刷错误。记者仔细一查，你猜怎么着，印刷并无错误，重庆真的就有叫“犀牛屙屎”和“犀牛屙屎抽水”的地方。\n\n好在，中国地名数量有限，这是可以枚举的。中国地名委员会编写了《中华人民共和国地名录》，收录了从高原盆地到桥梁电站共 10 万多个地名，这让中国地名的识别便利了很多。\n\n真正有些困难的就是识别机构名了，虽然机构名的后缀比较集中，但左边界的判断就有些难了。更难的就是品牌名了。如今各行各业大打创意战，品牌名可以说是无奇不有，而且经常本身就包含常用词，更是给自动分词添加了不少障碍。\n\n最难识别的未登录词就是缩略语了。“高数”、“抵京”、“女单”、“发改委”、“北医三院”都是比较好认的缩略语了，有些缩略语搞得连人也是丈二和尚摸不着头脑。你能猜到“人影办”是什么机构的简称吗？打死你都想不到，是“人工影响天气办公室”。\n\n汉语中构造缩略语的规律很诡异，目前也没有一个定论。初次听到这个问题，几乎每个人都会做出这样的猜想：缩略语都是选用各个成分中最核心的字，比如“安全检查”缩成“安检”，“人民警察”缩成“民警”等等。不过，反例也是有的，“邮政编码”就被缩成了“邮编”，但“码”无疑是更能概括“编码”一词的。当然，这几个缩略语已经逐渐成词，可以加进词库了；不过新近出现的或者临时构造的缩略语该怎么办，还真是个大问题。\n\n说到新词，网络新词的大量出现才是分词系统真正的敌人。这些新词汇的来源千奇百怪，几乎没有固定的产生机制。要想实现对网络文章的自动分词，目前来看可以说是相当困难的。革命尚未成功，分词算法还有很多进步的余地。","slug":"nlp-repost-segmentation","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg621r003asb8fia88xgop"},{"title":"netty-mina深入学习与对比（二）","date":"2014-05-17T14:03:00.000Z","_content":"\n上文讲了对netty-mina的线程模型以及任务调度粒度的理解，这篇则主要是讲nio编程中的注意事项，netty-mina的对这些注意事项的实现方式的差异，以及业务层会如何处理这些注意事项。\n\n<!--more-->\n\n### 1. 数据是如何write出去的\njava nio如果是non-blocking的话，在每次write(bytes[N])的时候，并不会将N字节全部write出去，每次write仅一部分（具体大小和`tcp_write_buffer`有关）。那么，mina和netty是怎么处理这种情况的呢？\n\n#### 1.1 代码\n\n* `mina-1.1.7`: SocketIoProcessor.doFlush\n* `mina-2.0.4`: AbstractPollingIoProcessor.flushNow\n* `mina-3.0.0.M3-SNAPSHOT`: AbstractNioSession.processWrite\n* `netty-3.5.8.Final`: AbstractNioWorker.write0\n* `netty-4.0.6.Final`: AbstractNioByteChannel.doWrite\n\n#### 1.2 分析\n\nmina1、2，netty3的方式基本一致。 在发送端每个session均有一个writeBufferQueue，有这样一个队列，可以保证写入与写出均有序。在真正write时，大致逻辑均是一一将队列中的writeBuffer取出，写入socket。但有一些不同的是，mina1是每次peek一次，当该buffer全部写出之后再poll（mina3也是这种机制）；而mina2、netty3则是直接poll第一个，将其存为currentWriteRequest，直到currentWriteRequest全部写出之后，才会再poll下一个。这样的做法是为了省几次peek的时间么？\n\n同时mina、netty在write时，有一种spin write的机制，即循环write多次。mina1的spin write count为256，写死在代码里了，表示256有点大；mina2这个机制废除但代码保留；netty3则可以配置，默认为16。netty在这里略胜一筹！\n\nnetty4与netty3的机制差不多，但是netty4为这个事情特意写了一个ChannelOutboundBuffer类，输出队列写在了该类的flushed:Object[]成员中，但表示ChannelOutboundBuffer这个类的代码有点长，就暂不深究了。\n\n### 2. 数据是如何read进来的\n如第三段内容，每次write只是输出了一部分数据，read同理，也有可能只会读入部分数据，这样就是导致读入的数据是残缺的。而mina和netty默认不会理会这种由于nio导致的数据分片，需要由业务层自己额外做配置或者处理。\n\n#### 2.1 代码\n\n* `nfs-rpc`: ProtocolUtils.decode\n* `mina-1.1.7`: SocketIoProcessor.read, CumulativeProtocolDecoder.decode\n* `mina-2.0.4`: AbstractPollingIoProcessor.read, CumulativeProtocolDecoder.decode\n* `mina-3.0.0.M3-SNAPSHOT`: NioSelectorLoop.readBuffer\n* `netty-3.5.8.Final`: NioWorker.read, FrameDecoder\n* `netty-4.0.6.Fianl`: AbstractNioByteChannel$NioByteUnsafe.read\n\n#### 2.2 业务层处理\n\nnfs-rpc在协议反序列化的过程中，就会考虑这个的问题，依次读入每个字节，当发现当前字节或者剩余字节数不够时，会将buf的readerIndex设置为初始状态。具体的实现，有兴趣的同学可以学习`nfs-rpc：ProtocolUtils.decode`\n\nnfs-rpc在decode时，出现错误就会将buf的readerIndex设为0，把readerIndex设置为0就必须要有个前提假设：每次decode时buf是同一个，即该buf是复用的。那么，具体情况是怎样呢？\n\n#### 2.3 框架层处理\n\n我看读mina与netty这块的代码，发现主要演进与不同的点在两个地方：读buffer的创建与数据分片的处理方式。\n\n**mina:**\n\nmina1、2的读buffer创建方式比较土，在每次read之前，会重新allocate一个新的buf对象，该buf对象的大小是根据读入数据大小动态调整。当本次读入数据等于该buf大小，下一次allocate的buf对象大小会翻倍；当本次读入数据不足该buf大小的二分之一，下一次allocate的buf对象同样会缩小至一半。需要注意的是，\\*2与/2的代码都可以用位运算，但是mina1竟没用位运算，有意思。\n\nmina1、2处理数据分片可以继承CumulativeProtocolDecoder，该decoder会在session中存入(BUFFER, cumulativeBuffer)。decode过程为：1）先将message追加至cumulativeBuffer；2）调用具体的decode逻辑；3）判断cumulativeBuffer.hasRemaining()，为true则压缩cumulativeBuffer，为false则直接删除(BUFFER, cumulativeBuffer)。实现业务的decode逻辑可以参考nfs-rpc中MinaProtocolDecoder的代码。\n\nmina3在处理读buffer的创建与数据分片比较巧妙，它所有的读buffer共用一个buffer对象（默认64kb），每次均会将读入的数据追加至该buffer中，这样即省去了buffer的创建与销毁事件，也省去了cumulativeDecoder的处理逻辑，让代码很清爽啊！\n\n**netty:**\n\nnetty3在读buffer创建部分的代码还是挺有意思的，首先，它创建了一个SocketReceiveBufferAllocator的allocate对象，名字为recvBufferPool，但是里面代码完全和pool扯不上关系；其次，它每次创建buffer也会动态修改初始大小的机制，它设计了232个大小档位，最大值为Integer.MAX_VALUE，没有具体考究，这种实现方式似乎比每次大小翻倍优雅一点，具体代码可以参考：`AdaptiveReceiveBufferSizePredictor`。\n\n对应mina的CumulativeProtocolDecoder类，在netty中则是FrameDecoder和ReplayingDecoder，没深入只是大致扫了下代码，原理基本一致。BTW，ReplayingDecoder似乎挺强大的，有兴趣的可以看看这两篇：\n\n> [High speed custom codecs with ReplayingDecoder](http://biasedbit.com/netty-tutorial-replaying-decoder)\n> [An enhanced version of ReplayingDecoder for Netty](http://biasedbit.com/an-enhanced-version-of-replayingdecoder-for-netty/)\n\nnetty4在读buffer创建部分机制与netty3大同小异，不过由于netty有了ByteBufAllocator的概念，要想每次不重新创建销毁buffer的话，可以采用PooledByteBufAllocator。\n\n在处理分片上，netty4抽象出了Message这样的概念，我的理解就是，一个Message就是业务可读的数据，转换Message的抽象类：ByteToMessageDecoder，当然也有netty3中的ReplayingDecoder，继承自ByteToMessageDecoder，具体可以研究代码。\n\n### 3. ByteBuffer设计的差异\n\n#### 3.1 自建buffer的原因\n\n**mina:**\n\n需要说明的是，只有mina1、2才有自己的buffer类，mina3内部只用nio的原生ByteBuffer类（提供了一个组合buffer的代理类-IoBuffer）。mina1、2自建buffer的原因如下：\n\n* It doesn’t provide useful getters and putters such as fill,get/putString, and get/putAsciiInt()enough.\n* It is difficult to write variable-length data due to its fixed capacity\n\n第一条比较好理解，即提供了更为方便的方法用以操作buffer。第二条则是觉得nio的ByteBuffer是定长的，无法自动扩容或者缩容，所以提供了自动扩/缩容的方法：IoBuffer.setAutoExpand, IoBuffer.setAutoShrink。但是扩/缩容的实现，也是基于nio的ByteBuffer，重新ByteBuffer.allocate(capacity)，再把原有的数据拷贝过去。\n\n**netty:**\n\n在我前面的博文（[Netty 4.x学习笔记 – ByteBuf](http://hongweiyi.com/2014/01/netty-4-x-bytebuf/)）我已经提到这些原因：\n\n* 需要的话，可以自定义buffer类型\n* 通过组合buffer类型，可实现透明的zero-copy\n* 提供动态的buffer类型，如StringBuffer一样(扩容方式也是每次double)，容量是按需扩展\n* 无需调用flip()方法\n* 常常「often」比ByteBuffer快\n\n以上理由来自netty3的API文档：[Package org.jboss.netty.buffer](http://docs.jboss.org/netty/3.2/api/org/jboss/netty/buffer/package-summary.html)，netty4没见到官方的说法，但是我觉得还得加上一个更为重要也是最为重要的理由，就是可以实现buffer池化管理。\n\n#### 3.2 实现的差异\n\n**mina:**\n\nmina的实现较为基础，仅仅只是在ByteBuffer上的一些简单封装。\n\n**netty:**\n\nnetty3与netty4的实现大致相同（ChannlBuffer -&gt; ByteBuf），具体可以参见：[Netty 4.x学习笔记 – ByteBuf](http://hongweiyi.com/2014/01/netty-4-x-bytebuf/)，netty4实现了PooledByteBufAllocator，传闻是可以大大减少GC的压力，但是官方不保证没有内存泄露，我自己压测中也出现了内存泄露的警告，建议生产中谨慎使用该功能。\n\n> netty5.x有一个更为高级的buffer泄露跟踪机制，PooledByteBufAllocator也已经默认开启，有机会可以尝试使用一下。\n","source":"_posts/netty-mina-in-depth-2.md","raw":"title: netty-mina深入学习与对比（二）\ndate: 2014-05-17 22:03:00\ncategories: 技术分享\ntags: [Java, Mina, Netty]\n\n---\n\n上文讲了对netty-mina的线程模型以及任务调度粒度的理解，这篇则主要是讲nio编程中的注意事项，netty-mina的对这些注意事项的实现方式的差异，以及业务层会如何处理这些注意事项。\n\n<!--more-->\n\n### 1. 数据是如何write出去的\njava nio如果是non-blocking的话，在每次write(bytes[N])的时候，并不会将N字节全部write出去，每次write仅一部分（具体大小和`tcp_write_buffer`有关）。那么，mina和netty是怎么处理这种情况的呢？\n\n#### 1.1 代码\n\n* `mina-1.1.7`: SocketIoProcessor.doFlush\n* `mina-2.0.4`: AbstractPollingIoProcessor.flushNow\n* `mina-3.0.0.M3-SNAPSHOT`: AbstractNioSession.processWrite\n* `netty-3.5.8.Final`: AbstractNioWorker.write0\n* `netty-4.0.6.Final`: AbstractNioByteChannel.doWrite\n\n#### 1.2 分析\n\nmina1、2，netty3的方式基本一致。 在发送端每个session均有一个writeBufferQueue，有这样一个队列，可以保证写入与写出均有序。在真正write时，大致逻辑均是一一将队列中的writeBuffer取出，写入socket。但有一些不同的是，mina1是每次peek一次，当该buffer全部写出之后再poll（mina3也是这种机制）；而mina2、netty3则是直接poll第一个，将其存为currentWriteRequest，直到currentWriteRequest全部写出之后，才会再poll下一个。这样的做法是为了省几次peek的时间么？\n\n同时mina、netty在write时，有一种spin write的机制，即循环write多次。mina1的spin write count为256，写死在代码里了，表示256有点大；mina2这个机制废除但代码保留；netty3则可以配置，默认为16。netty在这里略胜一筹！\n\nnetty4与netty3的机制差不多，但是netty4为这个事情特意写了一个ChannelOutboundBuffer类，输出队列写在了该类的flushed:Object[]成员中，但表示ChannelOutboundBuffer这个类的代码有点长，就暂不深究了。\n\n### 2. 数据是如何read进来的\n如第三段内容，每次write只是输出了一部分数据，read同理，也有可能只会读入部分数据，这样就是导致读入的数据是残缺的。而mina和netty默认不会理会这种由于nio导致的数据分片，需要由业务层自己额外做配置或者处理。\n\n#### 2.1 代码\n\n* `nfs-rpc`: ProtocolUtils.decode\n* `mina-1.1.7`: SocketIoProcessor.read, CumulativeProtocolDecoder.decode\n* `mina-2.0.4`: AbstractPollingIoProcessor.read, CumulativeProtocolDecoder.decode\n* `mina-3.0.0.M3-SNAPSHOT`: NioSelectorLoop.readBuffer\n* `netty-3.5.8.Final`: NioWorker.read, FrameDecoder\n* `netty-4.0.6.Fianl`: AbstractNioByteChannel$NioByteUnsafe.read\n\n#### 2.2 业务层处理\n\nnfs-rpc在协议反序列化的过程中，就会考虑这个的问题，依次读入每个字节，当发现当前字节或者剩余字节数不够时，会将buf的readerIndex设置为初始状态。具体的实现，有兴趣的同学可以学习`nfs-rpc：ProtocolUtils.decode`\n\nnfs-rpc在decode时，出现错误就会将buf的readerIndex设为0，把readerIndex设置为0就必须要有个前提假设：每次decode时buf是同一个，即该buf是复用的。那么，具体情况是怎样呢？\n\n#### 2.3 框架层处理\n\n我看读mina与netty这块的代码，发现主要演进与不同的点在两个地方：读buffer的创建与数据分片的处理方式。\n\n**mina:**\n\nmina1、2的读buffer创建方式比较土，在每次read之前，会重新allocate一个新的buf对象，该buf对象的大小是根据读入数据大小动态调整。当本次读入数据等于该buf大小，下一次allocate的buf对象大小会翻倍；当本次读入数据不足该buf大小的二分之一，下一次allocate的buf对象同样会缩小至一半。需要注意的是，\\*2与/2的代码都可以用位运算，但是mina1竟没用位运算，有意思。\n\nmina1、2处理数据分片可以继承CumulativeProtocolDecoder，该decoder会在session中存入(BUFFER, cumulativeBuffer)。decode过程为：1）先将message追加至cumulativeBuffer；2）调用具体的decode逻辑；3）判断cumulativeBuffer.hasRemaining()，为true则压缩cumulativeBuffer，为false则直接删除(BUFFER, cumulativeBuffer)。实现业务的decode逻辑可以参考nfs-rpc中MinaProtocolDecoder的代码。\n\nmina3在处理读buffer的创建与数据分片比较巧妙，它所有的读buffer共用一个buffer对象（默认64kb），每次均会将读入的数据追加至该buffer中，这样即省去了buffer的创建与销毁事件，也省去了cumulativeDecoder的处理逻辑，让代码很清爽啊！\n\n**netty:**\n\nnetty3在读buffer创建部分的代码还是挺有意思的，首先，它创建了一个SocketReceiveBufferAllocator的allocate对象，名字为recvBufferPool，但是里面代码完全和pool扯不上关系；其次，它每次创建buffer也会动态修改初始大小的机制，它设计了232个大小档位，最大值为Integer.MAX_VALUE，没有具体考究，这种实现方式似乎比每次大小翻倍优雅一点，具体代码可以参考：`AdaptiveReceiveBufferSizePredictor`。\n\n对应mina的CumulativeProtocolDecoder类，在netty中则是FrameDecoder和ReplayingDecoder，没深入只是大致扫了下代码，原理基本一致。BTW，ReplayingDecoder似乎挺强大的，有兴趣的可以看看这两篇：\n\n> [High speed custom codecs with ReplayingDecoder](http://biasedbit.com/netty-tutorial-replaying-decoder)\n> [An enhanced version of ReplayingDecoder for Netty](http://biasedbit.com/an-enhanced-version-of-replayingdecoder-for-netty/)\n\nnetty4在读buffer创建部分机制与netty3大同小异，不过由于netty有了ByteBufAllocator的概念，要想每次不重新创建销毁buffer的话，可以采用PooledByteBufAllocator。\n\n在处理分片上，netty4抽象出了Message这样的概念，我的理解就是，一个Message就是业务可读的数据，转换Message的抽象类：ByteToMessageDecoder，当然也有netty3中的ReplayingDecoder，继承自ByteToMessageDecoder，具体可以研究代码。\n\n### 3. ByteBuffer设计的差异\n\n#### 3.1 自建buffer的原因\n\n**mina:**\n\n需要说明的是，只有mina1、2才有自己的buffer类，mina3内部只用nio的原生ByteBuffer类（提供了一个组合buffer的代理类-IoBuffer）。mina1、2自建buffer的原因如下：\n\n* It doesn’t provide useful getters and putters such as fill,get/putString, and get/putAsciiInt()enough.\n* It is difficult to write variable-length data due to its fixed capacity\n\n第一条比较好理解，即提供了更为方便的方法用以操作buffer。第二条则是觉得nio的ByteBuffer是定长的，无法自动扩容或者缩容，所以提供了自动扩/缩容的方法：IoBuffer.setAutoExpand, IoBuffer.setAutoShrink。但是扩/缩容的实现，也是基于nio的ByteBuffer，重新ByteBuffer.allocate(capacity)，再把原有的数据拷贝过去。\n\n**netty:**\n\n在我前面的博文（[Netty 4.x学习笔记 – ByteBuf](http://hongweiyi.com/2014/01/netty-4-x-bytebuf/)）我已经提到这些原因：\n\n* 需要的话，可以自定义buffer类型\n* 通过组合buffer类型，可实现透明的zero-copy\n* 提供动态的buffer类型，如StringBuffer一样(扩容方式也是每次double)，容量是按需扩展\n* 无需调用flip()方法\n* 常常「often」比ByteBuffer快\n\n以上理由来自netty3的API文档：[Package org.jboss.netty.buffer](http://docs.jboss.org/netty/3.2/api/org/jboss/netty/buffer/package-summary.html)，netty4没见到官方的说法，但是我觉得还得加上一个更为重要也是最为重要的理由，就是可以实现buffer池化管理。\n\n#### 3.2 实现的差异\n\n**mina:**\n\nmina的实现较为基础，仅仅只是在ByteBuffer上的一些简单封装。\n\n**netty:**\n\nnetty3与netty4的实现大致相同（ChannlBuffer -&gt; ByteBuf），具体可以参见：[Netty 4.x学习笔记 – ByteBuf](http://hongweiyi.com/2014/01/netty-4-x-bytebuf/)，netty4实现了PooledByteBufAllocator，传闻是可以大大减少GC的压力，但是官方不保证没有内存泄露，我自己压测中也出现了内存泄露的警告，建议生产中谨慎使用该功能。\n\n> netty5.x有一个更为高级的buffer泄露跟踪机制，PooledByteBufAllocator也已经默认开启，有机会可以尝试使用一下。\n","slug":"netty-mina-in-depth-2","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg621t003fsb8fckoq1sqh"},{"title":"netty-mina深入学习与对比（一）","date":"2014-05-17T13:42:00.000Z","_content":"\n这博文的系列主要是为了更好的了解一个完整的nio框架的编程细节以及演进过程，我选了同父（Trustin Lee）的两个框架netty与mina做对比。版本涉及了netty3.x、netty4.x、mina1.x、mina2.x、mina3.x。这里并没有写netty5.x的细节，看了[netty5的修改文档](http://netty.io/wiki/new-and-noteworthy-in-5.x.html)，似乎有一些比较有意思的改动，准备单独写一篇netty4.x与netty5.x的不同。\n\n<!--more-->\n\nnetty从twitter发布的这篇[Netty 4 at Twitter: Reduced GC Overhead](https://blog.twitter.com/2013/netty-4-at-twitter-reduced-gc-overhead)文章让国内Java界为之一振，也小火了一把，同时netty的社区发展也不错，版本迭代非常快，半年不关注大、小版本就发了好几轮了。但是mina就有点淡了，github上面它最后大多数代码最后的修改日期均在2013年，不过我从个人情感上还是挺喜欢mina3的代码，没有太多的用不上的功能（支持各种协议啥的），跑自带的benchmark性能也比netty4好一些。但是如果是生产用的话，就偏向netty多一些了，毕竟社区活跃，版本迭代也快。\n\n### 1. mina、netty的线程模型\n\nmina与netty都是Trustin Lee的作品，所以在很多方面都十分相似，他们线程模型也是基本一致，采用了Reactors in threads模型，即Main Reactor + Sub Reactors的模式。由main reactor处理连接相关的任务：accept、connect等，当连接处理完毕并建立一个socket连接（称之为session）后，给每个session分配一个sub reactor，之后该session的所有IO、业务逻辑处理均交给了该sub reactor。每个reactor均是一个线程，sub reactor中只靠内核调度，没有任何通信且互不打扰。\n\n在前面的博文：[Netty 4.x学习笔记 – 线程模型](http://hongweiyi.com/2014/01/netty-4-x-thread-model/)，对netty的线程模型有一定的介绍。现在来讲讲我对线程模型演进的一些理解：\n\n* **`Thread per Connection`**: 在没有nio之前，这是传统的java网络编程方案所采用的线程模型。即有一个主循环，socket.accept阻塞等待，当建立连接后，创建新的线程/从线程池中取一个，把该socket连接交由新线程全权处理。这种方案优缺点都很明显，优点即实现简单，缺点则是方案的伸缩性受到线程数的限制。\n* **`Reactor in Single Thread`**: 有了nio后，可以采用IO多路复用机制了。我们抽取出一个单线程版的reactor模型，时序图见下文，该方案只有一个线程，所有的socket连接均注册在了该reactor上，由一个线程全权负责所有的任务。它实现简单，且不受线程数的限制。这种方案受限于使用场景，仅适合于IO密集的应用，不太适合CPU密集的应用，且适合于CPU资源紧张的应用上。\n\n<center><div style=\"width: 30%;\">![Reactor Single Thread](/images/reactor-single-thread.png)</div></center>\n\n* **`Reactor + Thread Pool`**: 方案2由于受限于使用场景，但为了可以更充分的使用CPU资源，抽取出一个逻辑处理线程池。reactor仅负责IO任务，线程池负责所有其它逻辑的处理。虽然该方案可以充分利用CPU资源，但是这个方案多了进出thread pool的两次上下文切换。\n\n<center><div style=\"width: 50%;\">![Reactor + Thread Pool](/images/reactor-thread-pool.png)</div></center>\n\n* **`Reactors in threads`**: 基于方案3缺点的考虑，将reactor分成两个部分。main reactor负责连接任务（accept、connect等），sub reactor负责IO、逻辑任务，即mina与netty的线程模型。该方案适应性十分强，可以调整sub reactor的数量适应CPU资源紧张的应用；同时CPU密集型任务时，又可以在业务处理逻辑中将任务交由线程池处理，如方案5。该方案有一个不太明显的缺点，即session没有分优先级，所有session平等对待均分到所有的线程中，这样可能会导致优先级低耗资源的session堵塞高优先级的session，但似乎netty与mina并没有针对这个做优化。\n\n<center><div style=\"width: 60%;\">![Reactors in threads](/images/reactors-in-threads.png)</div></center>\n\n* **`Reactors in threads + Threads pool`**: 这也是我所在公司应用框架采用的模型，可以更为灵活的适应所有的应用场景：调整reactor数量、调整thread pool大小等。\n\n<center><div style=\"width: 70%;\">![Reactors in threads + Thread pool](/images/reactors-in-threads-thread-pool.png)</div></center>\n\n> 以上图片及总结参考：《Linux多线程服务端编程》\n\n### 2. mina、netty的任务调度粒度\n\nmina、netty在线程模型上并没有太大的差异性，主要的差异还是在任务调度的粒度的不同。任务从逻辑上我给它分为成三种类型：连接相关的任务（bind、connect等）、写任务（write、flush）、调度任务（延迟、定时等），读任务则由selector加循环时间控制了。mina、netty任务调度的趋势是逐渐变小，从session级别的调度 -&gt; 类型级别任务的调度 -&gt; 任务的调度。\n\n#### 2.1 代码\n\n* `mina-1.1.7`: SocketIoProcessor$Worker.run\n* `mina-2.0.4`: AbstractPollingIoProcessor$Processor.run\n* `mina-3.0.0.M3-SNAPSHOT`: AbstractNioSession.processWrite\n* `netty-3.5.8.Final`: AbstractNioSelector.run\n* `netty-4.0.6.Final`: NioEventLoop.run\n\n#### 2.2 分析\n\nmina1、2的任务调度粒度为session。mina会将有IO任务的的session写入队列中，当循环执行任务时，则会轮询所有的session，并依次把session中的所有任务取出来运行。这样粗粒度的调度是不公平调度，会导致某些请求的延迟很高。\n\nmina3的模型改动比较大，代码相对就比较难看了，我仅是随便扫了一下，它仅提炼出了writeQueue。\n\n而netty3的调度粒度则是按照IO操作，分成了registerTaskQueue、writeTaskQueue、eventQueue三个队列，当有IO任务时，依次processRegisterTaskQueue、processEventQueue、processWriteTaskQueue、processSelectedKeys(selector.selectedKeys)。\n\nnetty4可能觉得netty3的粒度还是比较粗，将队列细分成了taskQueue和delayedTaskQueue，所有的任务均放在taskQueue中，delayedTaskQueue则是定时调度任务，且netty4可以灵活配置task与selectedKey处理的时间比例。\n\n> BTW: netty3.6.0之后，所有的队列均合并成了一个taskQueue\n\n有意思的是，netty4会优先处理selectedKeys，然后再处理任务，netty3则相反。mina1、2则是先处理新建的session，再处理selectedKeys，再处理任务。\n\n> 难道selectedKeys处理顺序有讲究么？\n","source":"_posts/netty-mina-in-depth-1.md","raw":"title: netty-mina深入学习与对比（一）\ndate: 2014-05-17 21:42:00\ncategories: 技术分享\ntags: [Java, Mina, Netty, 线程模型]\n\n---\n\n这博文的系列主要是为了更好的了解一个完整的nio框架的编程细节以及演进过程，我选了同父（Trustin Lee）的两个框架netty与mina做对比。版本涉及了netty3.x、netty4.x、mina1.x、mina2.x、mina3.x。这里并没有写netty5.x的细节，看了[netty5的修改文档](http://netty.io/wiki/new-and-noteworthy-in-5.x.html)，似乎有一些比较有意思的改动，准备单独写一篇netty4.x与netty5.x的不同。\n\n<!--more-->\n\nnetty从twitter发布的这篇[Netty 4 at Twitter: Reduced GC Overhead](https://blog.twitter.com/2013/netty-4-at-twitter-reduced-gc-overhead)文章让国内Java界为之一振，也小火了一把，同时netty的社区发展也不错，版本迭代非常快，半年不关注大、小版本就发了好几轮了。但是mina就有点淡了，github上面它最后大多数代码最后的修改日期均在2013年，不过我从个人情感上还是挺喜欢mina3的代码，没有太多的用不上的功能（支持各种协议啥的），跑自带的benchmark性能也比netty4好一些。但是如果是生产用的话，就偏向netty多一些了，毕竟社区活跃，版本迭代也快。\n\n### 1. mina、netty的线程模型\n\nmina与netty都是Trustin Lee的作品，所以在很多方面都十分相似，他们线程模型也是基本一致，采用了Reactors in threads模型，即Main Reactor + Sub Reactors的模式。由main reactor处理连接相关的任务：accept、connect等，当连接处理完毕并建立一个socket连接（称之为session）后，给每个session分配一个sub reactor，之后该session的所有IO、业务逻辑处理均交给了该sub reactor。每个reactor均是一个线程，sub reactor中只靠内核调度，没有任何通信且互不打扰。\n\n在前面的博文：[Netty 4.x学习笔记 – 线程模型](http://hongweiyi.com/2014/01/netty-4-x-thread-model/)，对netty的线程模型有一定的介绍。现在来讲讲我对线程模型演进的一些理解：\n\n* **`Thread per Connection`**: 在没有nio之前，这是传统的java网络编程方案所采用的线程模型。即有一个主循环，socket.accept阻塞等待，当建立连接后，创建新的线程/从线程池中取一个，把该socket连接交由新线程全权处理。这种方案优缺点都很明显，优点即实现简单，缺点则是方案的伸缩性受到线程数的限制。\n* **`Reactor in Single Thread`**: 有了nio后，可以采用IO多路复用机制了。我们抽取出一个单线程版的reactor模型，时序图见下文，该方案只有一个线程，所有的socket连接均注册在了该reactor上，由一个线程全权负责所有的任务。它实现简单，且不受线程数的限制。这种方案受限于使用场景，仅适合于IO密集的应用，不太适合CPU密集的应用，且适合于CPU资源紧张的应用上。\n\n<center><div style=\"width: 30%;\">![Reactor Single Thread](/images/reactor-single-thread.png)</div></center>\n\n* **`Reactor + Thread Pool`**: 方案2由于受限于使用场景，但为了可以更充分的使用CPU资源，抽取出一个逻辑处理线程池。reactor仅负责IO任务，线程池负责所有其它逻辑的处理。虽然该方案可以充分利用CPU资源，但是这个方案多了进出thread pool的两次上下文切换。\n\n<center><div style=\"width: 50%;\">![Reactor + Thread Pool](/images/reactor-thread-pool.png)</div></center>\n\n* **`Reactors in threads`**: 基于方案3缺点的考虑，将reactor分成两个部分。main reactor负责连接任务（accept、connect等），sub reactor负责IO、逻辑任务，即mina与netty的线程模型。该方案适应性十分强，可以调整sub reactor的数量适应CPU资源紧张的应用；同时CPU密集型任务时，又可以在业务处理逻辑中将任务交由线程池处理，如方案5。该方案有一个不太明显的缺点，即session没有分优先级，所有session平等对待均分到所有的线程中，这样可能会导致优先级低耗资源的session堵塞高优先级的session，但似乎netty与mina并没有针对这个做优化。\n\n<center><div style=\"width: 60%;\">![Reactors in threads](/images/reactors-in-threads.png)</div></center>\n\n* **`Reactors in threads + Threads pool`**: 这也是我所在公司应用框架采用的模型，可以更为灵活的适应所有的应用场景：调整reactor数量、调整thread pool大小等。\n\n<center><div style=\"width: 70%;\">![Reactors in threads + Thread pool](/images/reactors-in-threads-thread-pool.png)</div></center>\n\n> 以上图片及总结参考：《Linux多线程服务端编程》\n\n### 2. mina、netty的任务调度粒度\n\nmina、netty在线程模型上并没有太大的差异性，主要的差异还是在任务调度的粒度的不同。任务从逻辑上我给它分为成三种类型：连接相关的任务（bind、connect等）、写任务（write、flush）、调度任务（延迟、定时等），读任务则由selector加循环时间控制了。mina、netty任务调度的趋势是逐渐变小，从session级别的调度 -&gt; 类型级别任务的调度 -&gt; 任务的调度。\n\n#### 2.1 代码\n\n* `mina-1.1.7`: SocketIoProcessor$Worker.run\n* `mina-2.0.4`: AbstractPollingIoProcessor$Processor.run\n* `mina-3.0.0.M3-SNAPSHOT`: AbstractNioSession.processWrite\n* `netty-3.5.8.Final`: AbstractNioSelector.run\n* `netty-4.0.6.Final`: NioEventLoop.run\n\n#### 2.2 分析\n\nmina1、2的任务调度粒度为session。mina会将有IO任务的的session写入队列中，当循环执行任务时，则会轮询所有的session，并依次把session中的所有任务取出来运行。这样粗粒度的调度是不公平调度，会导致某些请求的延迟很高。\n\nmina3的模型改动比较大，代码相对就比较难看了，我仅是随便扫了一下，它仅提炼出了writeQueue。\n\n而netty3的调度粒度则是按照IO操作，分成了registerTaskQueue、writeTaskQueue、eventQueue三个队列，当有IO任务时，依次processRegisterTaskQueue、processEventQueue、processWriteTaskQueue、processSelectedKeys(selector.selectedKeys)。\n\nnetty4可能觉得netty3的粒度还是比较粗，将队列细分成了taskQueue和delayedTaskQueue，所有的任务均放在taskQueue中，delayedTaskQueue则是定时调度任务，且netty4可以灵活配置task与selectedKey处理的时间比例。\n\n> BTW: netty3.6.0之后，所有的队列均合并成了一个taskQueue\n\n有意思的是，netty4会优先处理selectedKeys，然后再处理任务，netty3则相反。mina1、2则是先处理新建的session，再处理selectedKeys，再处理任务。\n\n> 难道selectedKeys处理顺序有讲究么？\n","slug":"netty-mina-in-depth-1","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg621u003msb8f24kw3s4n"},{"title":"Netty 4.x学习笔记 - 线程模型","date":"2014-01-14T15:25:00.000Z","_content":"\n### 1、前言\n\n前面两篇学习笔记已经说完了[ByteBuf](http://hongweiyi.com/2014/01/netty-4-x-bytebuf/)和[Channel和Pipeline](http://hongweiyi.com/2014/01/netty-4-x-channel-pipeline/)，这篇开始讲讲前面欠的债——线程模型（EventLoop和EventExecutor）。\n\n<!--more-->\n\n\n### 2、Netty线程模型\n\n将具体代码实现前，先来谈谈Netty的线程模型。正如许多博客所提到的，Netty采用了Reactor模式，但是许多博客也只是提到了而已，同时大家也不会忘记附上几张Doug Lee大神的图，但是并不会深入的解释。为了更好的学习和理解Netty的线程模型，我在这里稍微详细的说一下我对它的理解。\n\nReactor模式有多个变种，Netty基于Multiple Reactors模式（如下图）做了一定的修改，Mutilple Reactors模式有多个reactor：mainReactor和subReactor，其中mainReactor负责客户端的连接请求，并将请求转交给subReactor，后由subReactor负责相应通道的IO请求，非IO请求（具体逻辑处理）的任务则会直接写入队列，等待worker threads进行处理。\n\n<center><div style=\"width: 80%;\">![Multiple Reactors](/images/wpid-Multi-reactors3.png)</div></center>\n\nNetty的线程模型基于Multiple Reactors模式，借用了mainReactor和subReactor的结构，但是从代码里看来，它并没有Thread Pool这个东东。Netty的subReactor与worker thread是同一个线程，采用IO多路复用机制，可以使一个subReactor监听并处理多个channel的IO请求，我给称之为：「Single Thread with many Channel」。我根据代码整理出下面这种Netty线程模型图：\n\n<center><div style=\"width: 80%;\">![Netty线程模型](/images/wpid-Netty-thread-model3.png)</div></center>\n\n上图中的parentGroup和childGroup是Bootstrap构造方法中传入的两个对象，这两个group均是线程池，childGroup线程池会被各个subReactor充分利用，parentGroup线程池则只是在bind某个端口后，获得其中一个线程作为mainReactor。上图我将subReactor和worker thread合并成了一个个的loop，具体的请求操作均在loop中完成，下文会对loop有个稍微详细的解释。&nbsp;\n\n>\t以上均是Nio情况下。Oio采用的是Thread per Channel机制，即每个连接均创建一个线程负责该连接的所有事宜。\n>\tDoug Lee大神的Reactor介绍：[Scalable IO in Java](http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf)\n\n### 3、EventLoop和EventExecutor实现\n\nEventLoop和EventExecutor实现共有4个主要逻辑接口，EventLoop、EventLoopGroup、EventExecutor、EventExecutorGroup，内部实现、继承的逻辑表示无法直视，有种擦边球的感觉。具体的类图如下：\n\n<center><div style=\"width: 80%;\">![EventLoop和EventExecutor类图](/images/wpid-EventLoopAndEventExecutor3.jpg)</div></center>\n\n#### 3.1 EventLoopGroup:\n\n主要方法是newChild，我理解为EventLoop的工厂类。`**EventLoopGroup.newChild`创建`**EventLoop`对象。OioEventLoopGroup除外，它没有实现newChild方法，调用父类的并创建ThreadPerChannelEventLoop对象。\n\n#### 3.2 EventLoop:\n\n主要方法是run()，是整个Netty执行过程的逻辑代码实现，后面细说。\n\n#### 3.3 EventExecutorGroup:\n\n线程池实现，主要成员是children数组，主要方法是next()，获得线程池中的一个线程，由子类调用。由于Oio采用的是Thread per Channel机制，所以没有实现前面两个。\n\n#### 3.4 EventExecutor:\n\nTask的执行类，主要成员是taskQueue以及真正的运行线程对象executor，主要方法是taskQueue操作方法execute、takeTask、addTask等，以及doStartThread方法，后面细说。\n\n### 4、NioEventLoopGroup实现\n\n这里以常用的NioEventLoopGroup为例。NioEventLoopGroup在Bootstrap初始化时作为参数传入构造方法，由于NioEventLoopGroup涉及的代码较多，就不大篇幅的贴代码了，只写流程性的文字或相应类和方法：\n\n#### 4.1 mainReactor:\n\n`1. Bootstrap.bind(port)`\n`2. Bootstrap.initAndRegister()`\n`2.1 Boostrap.init()`\n\n> 初始化Channel，配置Channel参数，以及Pipeline。其中初始化Pipeline中，需要插入ServerBootstrapAcceptor对象用作acceptor接收客户端连接请求，acceptor也是一种ChannelInboundHandlerAdapter。\n\n``` java\np.addLast(new ChannelInitializer<Channel>() {\n  @Override\n  public void initChannel(Channel ch) throws Exception {\n    ch.pipeline().addLast(new ServerBootstrapAcceptor(currentChildHandler, currentChildOptions,\n       currentChildAttrs));\n  }\n});\n```\n\n> 调用channel的unsafe对象注册selector，具体实现类为AbstractChannel$AbstractUnsafe.register。如下：\n\n``` java\npublic final void register(final ChannelPromise promise) {\n  if (eventLoop.inEventLoop()) {  // 是否在Channel的loop中\n    register0(promise);\n  } else {  // 不在\n    try {\n      eventLoop.execute(new Runnable() {  // EventLoop执行一个任务\n        @Override\n        public void run() {\n          register0(promise);\n        }\n      });\n    } catch (Throwable t) {\n    // ...\n    }\n  }\n}\n```\n\n> eventLoop.execute(runnable);是比较重要的一个方法。在没有启动真正线程时，它会启动线程并将待执行任务放入执行队列里面。启动真正线程(startThread())会判断是否该线程已经启动，如果已经启动则会直接跳过，达到线程复用的目的。启动的线程，主要调用方法是NioEventLoop的run()方法，run()方法在下面有详细介绍：\n\n``` java\npublic void execute(Runnable task) {\n  if (task == null) {\n    throw new NullPointerException(&quot;task&quot;);\n  }\n\n  boolean inEventLoop = inEventLoop();\n  if (inEventLoop) {\n    addTask(task);\n  } else {\n    startThread();  // 启动线程\n    addTask(task);  // 添加任务队列\n\n    // ...\n\n  }\n\n  if (!addTaskWakesUp) {\n    wakeup(inEventLoop);\n  }\n}\n```\n\n   2.2 group().register(channel)\n\n> 将 channel 注册到下一个 EventLoop 中。\n\n`3. 接收连接请求`\n\n由NioEventLoop.run()接收到请求：\n\n`3.1 AbstractNioMessageChannel$NioMessageUnsafe.read()`\n\n`3.2 NioServerSocketChannel.doReadMessages()`\n\n> 获得childEventLoopGroup中的EventLoop，并依据该loop创建新的SocketChannel对象。\n\n`3.3 pipeline.fireChannelRead(readBuf.get(i));`\n\n> readBuf.get(i)就是3.2中创建的SocketChannel对象。在2.2初始化Bootstrap的时候，已经将acceptor处理器插入pipeline中，所以理所当然，这个SocketChannel对象由acceptor处理器处理。\n\n`3.4 ServerBootstrapAcceptor$ServerBootstrapAcceptor.channelRead();`\n\n> 该方法流程与2.2、2.3类似，初始化子channel，并注册到相应的selector。注册的时候，也会调用eventLoop.execute用以执行注册任务，execute时，启动子线程。即启动了subReactor。\n\n#### 4.2 subReactor:\n\nsubReactor的流程较为简单，主体完全依赖于loop，用以执行read、write还有自定义的NioTask操作，就不深入了，直接跳过解释loop过程。\n\n**loop:**\n\nloop是我自己提出来的组件，仅是代表subReactor的主要运行逻辑。例子可以参考NioEventLoop.run()。\n\nloop会不断循环一个过程：select -&gt; processSelectedKeys(IO操作) -&gt; runAllTasks(非IO操作)，如下代码：\n\n``` java\nprotected void run() {\n  for (;;) {\n    // ...\n    try {\n      if (hasTasks()) { // 如果队列中仍有任务\n        selectNow();\n      } else {\n        select();\n        // ...\n      }\n\n      // ...\n\n      final long ioStartTime = System.nanoTime();  // 用以控制IO任务与非IO任务的运行时间比\n      needsToSelectAgain = false;\n      // IO任务\n      if (selectedKeys != null) {\n        processSelectedKeysOptimized(selectedKeys.flip());\n      } else {\n        processSelectedKeysPlain(selector.selectedKeys());\n      }\n      final long ioTime = System.nanoTime() - ioStartTime;\n\n      final int ioRatio = this.ioRatio;\n      // 非IO任务\n      runAllTasks(ioTime * (100 - ioRatio) / ioRatio);\n\n      if (isShuttingDown()) {\n        closeAll();\n        if (confirmShutdown()) {\n          break;\n        }\n      }\n    } catch (Throwable t) {\n    // ...\n    }\n  }\n}\n```\n\n\n就目前而言，基本上IO任务都会走processSelectedKeysOptimized方法，该方法即代表使用了优化的SelectedKeys。除非采用了比较特殊的JDK实现，基本都会走该方法。\n\n> 1. selectedKeys在openSelector()方法中初始化，Netty通过反射修改了Selector的selectedKeys成员和publicSelectedKeys成员。替换成了自己的实现&mdash;&mdash;SelectedSelectionKeySet。\n> 2. 从OpenJDK 6/7的SelectorImpl中可以看到，selectedKeys和publicSeletedKeys均采用了HashSet实现。HashSet采用HashMap实现，插入需要计算Hash并解决Hash冲突并挂链，而SelectedSelectionKeySet实现使用了双数组，每次插入尾部，扩展策略为double，调用flip()则返回当前数组并切换到另外一个数据。\n> 3. ByteBuf中去掉了flip，在这里是否也可以呢？\n\nprocessSelectedKeysOptimized主要流程如下：\n\n``` java\nfinal Object a = k.attachment();\n\nif (a instanceof AbstractNioChannel) {\n  processSelectedKey(k, (AbstractNioChannel) a);\n} else {\n  @SuppressWarnings(&quot;unchecked&quot;)\n  NioTask<SelectableChannel> task = (NioTask<SelectableChannel>) a;\n  processSelectedKey(k, task);\n}\n```\n\n在获得attachment后，判断是Channel呢还是其他，其他则是NioTask。找遍代码并没有发现Netty有注册NioTask的行为，同时也没发现NioTask的实现类。只有在NioEventLoop.register方法中有注册NioTask至selector的行为，便判断该行为是由用户调用，可以针对某个Channel注册自己的NioTask。这里就只讲第一个processSelectdKey(k, (AbstractNioChannel) a)，但代码就不贴了。\n\n和常规的NIO代码类似，processSelectdKey是判断SeletedKeys的readyOps，并做出相应的操作。操作均是unsafe做的。如read可以参考：AbstractNioByteChannel$NioByteUnsafe.read()。IO操作的流程大致都是：\n\n* 获得数据\n* 调用pipeline的方法，`fireChannel***`\n* 插入任务队列\n\n执行完所有IO操作后，开始执行非IO任务（runAllTasks）。Netty会控制IO和非IO任务的比例，ioTime * (100 - ioRatio) / ioRatio，默认ioRatio为50。runAllTasks乃是父类SingleThreadExecutor的方法。方法主体很简单，将任务从TaskQueue拎出来，直接调用任务的run方法即可。\n\n>\t代码调用的是task.run()，而不是task.start()。即是单线程执行所有任务\n\n``` java\nprotected boolean runAllTasks(long timeoutNanos) {\n  fetchFromDelayedQueue();\n  Runnable task = pollTask();\n  if (task == null) {\n    return false;\n  }\n\n  // 控制时间\n  final long deadline = ScheduledFutureTask.nanoTime() + timeoutNanos;\n  long runTasks = 0;\n  long lastExecutionTime;\n  for (;;) {\n    try {\n      task.run();\n    } catch (Throwable t) {\n      logger.warn(&quot;A task raised an exception.&quot;, t);\n    }\n\n    runTasks ++;\n\n    // Check timeout every 64 tasks because nanoTime() is relatively expensive.\n    // XXX: Hard-coded value - will make it configurable if it is really a problem.\n    if ((runTasks & 0x3F) == 0) {\n        lastExecutionTime = ScheduledFutureTask.nanoTime();\n      if (lastExecutionTime >= deadline) {\n        break;\n      }\n    }\n\n    task = pollTask();\n    if (task == null) {\n     lastExecutionTime = ScheduledFutureTask.nanoTime();\n     break;\n    }\n  }\n\n  this.lastExecutionTime = lastExecutionTime;\n  return true;\n}\n```\n\n### 5、总结\n\n以上内容从设计和代码层面总结Netty线程模型的大致内容，中间有很多我的不成熟的思考与理解，请朋友轻拍与指正。\n\n看源码过程中是比较折磨人的。首先得了解你学习东西的业务价值是哪里？即你学了这个之后能用在哪里，只是不考虑场景仅仅为了看代码而看代码比较难以深入理解其内涵；其次，看代码一定一定得从逻辑、结构层面看，从细节层面看只会越陷越深，有种一叶障目不见泰山的感觉；最后，最好是能够将代码逻辑、结构画出来，或者整理出思维导图啥的，可以用以理清思路。前面两篇文章思维道路较为清晰，线程模型的导图有一些但是比较混乱，就不贴出来了，用作自己参考，有兴趣的可以找我要噢。\n","source":"_posts/netty-4-x-thread-model.md","raw":"title: Netty 4.x学习笔记 - 线程模型\ndate: 2014-01-14 23:25:00\ncategories: 技术分享\ntags: [Netty, 线程模型]\n---\n\n### 1、前言\n\n前面两篇学习笔记已经说完了[ByteBuf](http://hongweiyi.com/2014/01/netty-4-x-bytebuf/)和[Channel和Pipeline](http://hongweiyi.com/2014/01/netty-4-x-channel-pipeline/)，这篇开始讲讲前面欠的债——线程模型（EventLoop和EventExecutor）。\n\n<!--more-->\n\n\n### 2、Netty线程模型\n\n将具体代码实现前，先来谈谈Netty的线程模型。正如许多博客所提到的，Netty采用了Reactor模式，但是许多博客也只是提到了而已，同时大家也不会忘记附上几张Doug Lee大神的图，但是并不会深入的解释。为了更好的学习和理解Netty的线程模型，我在这里稍微详细的说一下我对它的理解。\n\nReactor模式有多个变种，Netty基于Multiple Reactors模式（如下图）做了一定的修改，Mutilple Reactors模式有多个reactor：mainReactor和subReactor，其中mainReactor负责客户端的连接请求，并将请求转交给subReactor，后由subReactor负责相应通道的IO请求，非IO请求（具体逻辑处理）的任务则会直接写入队列，等待worker threads进行处理。\n\n<center><div style=\"width: 80%;\">![Multiple Reactors](/images/wpid-Multi-reactors3.png)</div></center>\n\nNetty的线程模型基于Multiple Reactors模式，借用了mainReactor和subReactor的结构，但是从代码里看来，它并没有Thread Pool这个东东。Netty的subReactor与worker thread是同一个线程，采用IO多路复用机制，可以使一个subReactor监听并处理多个channel的IO请求，我给称之为：「Single Thread with many Channel」。我根据代码整理出下面这种Netty线程模型图：\n\n<center><div style=\"width: 80%;\">![Netty线程模型](/images/wpid-Netty-thread-model3.png)</div></center>\n\n上图中的parentGroup和childGroup是Bootstrap构造方法中传入的两个对象，这两个group均是线程池，childGroup线程池会被各个subReactor充分利用，parentGroup线程池则只是在bind某个端口后，获得其中一个线程作为mainReactor。上图我将subReactor和worker thread合并成了一个个的loop，具体的请求操作均在loop中完成，下文会对loop有个稍微详细的解释。&nbsp;\n\n>\t以上均是Nio情况下。Oio采用的是Thread per Channel机制，即每个连接均创建一个线程负责该连接的所有事宜。\n>\tDoug Lee大神的Reactor介绍：[Scalable IO in Java](http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf)\n\n### 3、EventLoop和EventExecutor实现\n\nEventLoop和EventExecutor实现共有4个主要逻辑接口，EventLoop、EventLoopGroup、EventExecutor、EventExecutorGroup，内部实现、继承的逻辑表示无法直视，有种擦边球的感觉。具体的类图如下：\n\n<center><div style=\"width: 80%;\">![EventLoop和EventExecutor类图](/images/wpid-EventLoopAndEventExecutor3.jpg)</div></center>\n\n#### 3.1 EventLoopGroup:\n\n主要方法是newChild，我理解为EventLoop的工厂类。`**EventLoopGroup.newChild`创建`**EventLoop`对象。OioEventLoopGroup除外，它没有实现newChild方法，调用父类的并创建ThreadPerChannelEventLoop对象。\n\n#### 3.2 EventLoop:\n\n主要方法是run()，是整个Netty执行过程的逻辑代码实现，后面细说。\n\n#### 3.3 EventExecutorGroup:\n\n线程池实现，主要成员是children数组，主要方法是next()，获得线程池中的一个线程，由子类调用。由于Oio采用的是Thread per Channel机制，所以没有实现前面两个。\n\n#### 3.4 EventExecutor:\n\nTask的执行类，主要成员是taskQueue以及真正的运行线程对象executor，主要方法是taskQueue操作方法execute、takeTask、addTask等，以及doStartThread方法，后面细说。\n\n### 4、NioEventLoopGroup实现\n\n这里以常用的NioEventLoopGroup为例。NioEventLoopGroup在Bootstrap初始化时作为参数传入构造方法，由于NioEventLoopGroup涉及的代码较多，就不大篇幅的贴代码了，只写流程性的文字或相应类和方法：\n\n#### 4.1 mainReactor:\n\n`1. Bootstrap.bind(port)`\n`2. Bootstrap.initAndRegister()`\n`2.1 Boostrap.init()`\n\n> 初始化Channel，配置Channel参数，以及Pipeline。其中初始化Pipeline中，需要插入ServerBootstrapAcceptor对象用作acceptor接收客户端连接请求，acceptor也是一种ChannelInboundHandlerAdapter。\n\n``` java\np.addLast(new ChannelInitializer<Channel>() {\n  @Override\n  public void initChannel(Channel ch) throws Exception {\n    ch.pipeline().addLast(new ServerBootstrapAcceptor(currentChildHandler, currentChildOptions,\n       currentChildAttrs));\n  }\n});\n```\n\n> 调用channel的unsafe对象注册selector，具体实现类为AbstractChannel$AbstractUnsafe.register。如下：\n\n``` java\npublic final void register(final ChannelPromise promise) {\n  if (eventLoop.inEventLoop()) {  // 是否在Channel的loop中\n    register0(promise);\n  } else {  // 不在\n    try {\n      eventLoop.execute(new Runnable() {  // EventLoop执行一个任务\n        @Override\n        public void run() {\n          register0(promise);\n        }\n      });\n    } catch (Throwable t) {\n    // ...\n    }\n  }\n}\n```\n\n> eventLoop.execute(runnable);是比较重要的一个方法。在没有启动真正线程时，它会启动线程并将待执行任务放入执行队列里面。启动真正线程(startThread())会判断是否该线程已经启动，如果已经启动则会直接跳过，达到线程复用的目的。启动的线程，主要调用方法是NioEventLoop的run()方法，run()方法在下面有详细介绍：\n\n``` java\npublic void execute(Runnable task) {\n  if (task == null) {\n    throw new NullPointerException(&quot;task&quot;);\n  }\n\n  boolean inEventLoop = inEventLoop();\n  if (inEventLoop) {\n    addTask(task);\n  } else {\n    startThread();  // 启动线程\n    addTask(task);  // 添加任务队列\n\n    // ...\n\n  }\n\n  if (!addTaskWakesUp) {\n    wakeup(inEventLoop);\n  }\n}\n```\n\n   2.2 group().register(channel)\n\n> 将 channel 注册到下一个 EventLoop 中。\n\n`3. 接收连接请求`\n\n由NioEventLoop.run()接收到请求：\n\n`3.1 AbstractNioMessageChannel$NioMessageUnsafe.read()`\n\n`3.2 NioServerSocketChannel.doReadMessages()`\n\n> 获得childEventLoopGroup中的EventLoop，并依据该loop创建新的SocketChannel对象。\n\n`3.3 pipeline.fireChannelRead(readBuf.get(i));`\n\n> readBuf.get(i)就是3.2中创建的SocketChannel对象。在2.2初始化Bootstrap的时候，已经将acceptor处理器插入pipeline中，所以理所当然，这个SocketChannel对象由acceptor处理器处理。\n\n`3.4 ServerBootstrapAcceptor$ServerBootstrapAcceptor.channelRead();`\n\n> 该方法流程与2.2、2.3类似，初始化子channel，并注册到相应的selector。注册的时候，也会调用eventLoop.execute用以执行注册任务，execute时，启动子线程。即启动了subReactor。\n\n#### 4.2 subReactor:\n\nsubReactor的流程较为简单，主体完全依赖于loop，用以执行read、write还有自定义的NioTask操作，就不深入了，直接跳过解释loop过程。\n\n**loop:**\n\nloop是我自己提出来的组件，仅是代表subReactor的主要运行逻辑。例子可以参考NioEventLoop.run()。\n\nloop会不断循环一个过程：select -&gt; processSelectedKeys(IO操作) -&gt; runAllTasks(非IO操作)，如下代码：\n\n``` java\nprotected void run() {\n  for (;;) {\n    // ...\n    try {\n      if (hasTasks()) { // 如果队列中仍有任务\n        selectNow();\n      } else {\n        select();\n        // ...\n      }\n\n      // ...\n\n      final long ioStartTime = System.nanoTime();  // 用以控制IO任务与非IO任务的运行时间比\n      needsToSelectAgain = false;\n      // IO任务\n      if (selectedKeys != null) {\n        processSelectedKeysOptimized(selectedKeys.flip());\n      } else {\n        processSelectedKeysPlain(selector.selectedKeys());\n      }\n      final long ioTime = System.nanoTime() - ioStartTime;\n\n      final int ioRatio = this.ioRatio;\n      // 非IO任务\n      runAllTasks(ioTime * (100 - ioRatio) / ioRatio);\n\n      if (isShuttingDown()) {\n        closeAll();\n        if (confirmShutdown()) {\n          break;\n        }\n      }\n    } catch (Throwable t) {\n    // ...\n    }\n  }\n}\n```\n\n\n就目前而言，基本上IO任务都会走processSelectedKeysOptimized方法，该方法即代表使用了优化的SelectedKeys。除非采用了比较特殊的JDK实现，基本都会走该方法。\n\n> 1. selectedKeys在openSelector()方法中初始化，Netty通过反射修改了Selector的selectedKeys成员和publicSelectedKeys成员。替换成了自己的实现&mdash;&mdash;SelectedSelectionKeySet。\n> 2. 从OpenJDK 6/7的SelectorImpl中可以看到，selectedKeys和publicSeletedKeys均采用了HashSet实现。HashSet采用HashMap实现，插入需要计算Hash并解决Hash冲突并挂链，而SelectedSelectionKeySet实现使用了双数组，每次插入尾部，扩展策略为double，调用flip()则返回当前数组并切换到另外一个数据。\n> 3. ByteBuf中去掉了flip，在这里是否也可以呢？\n\nprocessSelectedKeysOptimized主要流程如下：\n\n``` java\nfinal Object a = k.attachment();\n\nif (a instanceof AbstractNioChannel) {\n  processSelectedKey(k, (AbstractNioChannel) a);\n} else {\n  @SuppressWarnings(&quot;unchecked&quot;)\n  NioTask<SelectableChannel> task = (NioTask<SelectableChannel>) a;\n  processSelectedKey(k, task);\n}\n```\n\n在获得attachment后，判断是Channel呢还是其他，其他则是NioTask。找遍代码并没有发现Netty有注册NioTask的行为，同时也没发现NioTask的实现类。只有在NioEventLoop.register方法中有注册NioTask至selector的行为，便判断该行为是由用户调用，可以针对某个Channel注册自己的NioTask。这里就只讲第一个processSelectdKey(k, (AbstractNioChannel) a)，但代码就不贴了。\n\n和常规的NIO代码类似，processSelectdKey是判断SeletedKeys的readyOps，并做出相应的操作。操作均是unsafe做的。如read可以参考：AbstractNioByteChannel$NioByteUnsafe.read()。IO操作的流程大致都是：\n\n* 获得数据\n* 调用pipeline的方法，`fireChannel***`\n* 插入任务队列\n\n执行完所有IO操作后，开始执行非IO任务（runAllTasks）。Netty会控制IO和非IO任务的比例，ioTime * (100 - ioRatio) / ioRatio，默认ioRatio为50。runAllTasks乃是父类SingleThreadExecutor的方法。方法主体很简单，将任务从TaskQueue拎出来，直接调用任务的run方法即可。\n\n>\t代码调用的是task.run()，而不是task.start()。即是单线程执行所有任务\n\n``` java\nprotected boolean runAllTasks(long timeoutNanos) {\n  fetchFromDelayedQueue();\n  Runnable task = pollTask();\n  if (task == null) {\n    return false;\n  }\n\n  // 控制时间\n  final long deadline = ScheduledFutureTask.nanoTime() + timeoutNanos;\n  long runTasks = 0;\n  long lastExecutionTime;\n  for (;;) {\n    try {\n      task.run();\n    } catch (Throwable t) {\n      logger.warn(&quot;A task raised an exception.&quot;, t);\n    }\n\n    runTasks ++;\n\n    // Check timeout every 64 tasks because nanoTime() is relatively expensive.\n    // XXX: Hard-coded value - will make it configurable if it is really a problem.\n    if ((runTasks & 0x3F) == 0) {\n        lastExecutionTime = ScheduledFutureTask.nanoTime();\n      if (lastExecutionTime >= deadline) {\n        break;\n      }\n    }\n\n    task = pollTask();\n    if (task == null) {\n     lastExecutionTime = ScheduledFutureTask.nanoTime();\n     break;\n    }\n  }\n\n  this.lastExecutionTime = lastExecutionTime;\n  return true;\n}\n```\n\n### 5、总结\n\n以上内容从设计和代码层面总结Netty线程模型的大致内容，中间有很多我的不成熟的思考与理解，请朋友轻拍与指正。\n\n看源码过程中是比较折磨人的。首先得了解你学习东西的业务价值是哪里？即你学了这个之后能用在哪里，只是不考虑场景仅仅为了看代码而看代码比较难以深入理解其内涵；其次，看代码一定一定得从逻辑、结构层面看，从细节层面看只会越陷越深，有种一叶障目不见泰山的感觉；最后，最好是能够将代码逻辑、结构画出来，或者整理出思维导图啥的，可以用以理清思路。前面两篇文章思维道路较为清晰，线程模型的导图有一些但是比较混乱，就不贴出来了，用作自己参考，有兴趣的可以找我要噢。\n","slug":"netty-4-x-thread-model","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg621z003tsb8fkbvyuo63"},{"title":"Netty 4.x学习笔记 - Channel和Pipeline","date":"2014-01-07T09:51:00.000Z","_content":"\n### 1、前言\n\nChannel概念与java.nio.channel概念一致，用以连接IO设备（socket、文件等）的纽带。Netty 4.x之后的Channel变化较大，官方的唬人的说法是无法通过简单的关键字替换进行迁移。用得较多应该是：ChannelHandler接口重新设计，换了个较为清晰的名字；write不会主动flush。由于笔者3.x、4.x都没用过，所以也无法深入理解版本的变化了。\n\n<!--more-->\n\n> 关于channel 4.x的新变化可以参考这里：new and noteworthy: Channel API changes\n\n### 2、Channel总览\n\n<center><div style=\"width: 80%;\">![Netty Channel整体结构思维导图](/images/wpid-Channel.png)</div></center>\n\nChannel的IO类型主要有两种：非阻塞IO（NIO）以及阻塞IO（OIO）；数据传输类型有两种：按事件消息传递（Message）以及按字节传递（Byte）；适用方类型也有两种：服务器（ServerSocket）以及客户端（Socket）。还有一些根据传输协议而制定的的Channel，如：UDT、SCTP等。\n\nNetty按照类型逐层设计相应的类。最底层的为抽象类AbstractChannel，再以此根据IO类型、数据传输类型、适用方类型实现。类图可以一目了然，如下图所示：\n\n<center><div style=\"width: 80%;\">![Netty Channel类图](/images/wpid-nio-oio.jpg)</div></center>\n\n### 3、ChannelPipeline实现分析\n\n从AbstractChannel分析，它提供了一些IO操作方法，read、write等，Channel仅仅做了一个封装，方法中将参数直接传递给了Channel的Pipeline成员的相应方法。\n\nPipeline则是Channel里面非常重要的概念。从数据结构的角度，它是一个双向链表，每个节点均是DefaultChannelHandlerContext对象；从逻辑的角度，它则是netty的逻辑处理链，每个节点均包含一个逻辑处理器（ChannelHandler），用以实现网络通信的编/解码、处理等功能。\n\nPipeline的链表上有两种handler，Inbound Handler和Outbound handler。从Netty内部IO线程接读到IO数据，依次经过N个Handler到达最内部的逻辑处理单元，这种称之为Inbound Handler；从Channel发出IO请求，依次经过M个Handler到达Netty内部IO线程，这种称之为Outbound Handler。内部代码实现流程则是：Head -> Tail (Inbound)，Tail -> Head (Outbound)。下图截取自ChannelPipeline的注释中，简单明了：\n\n<center><div style=\"width: 60%;\">![Netty Pipeline](/images/wpid-Netty-ChannelPipeline-.png)</div></center>\n\n### 4、逻辑处理器\n\nChannelPipeline仅仅只是逻辑处理的流程，真正逻辑处理器则是ChannelHandlerInvoker。在获得链表节点后，节点会调用自己的invoker成员执行(invoke)逻辑。\n\n``` java\npublic ChannelFuture writeAndFlush(Object msg, ChannelPromise promise) {\n    DefaultChannelHandlerContext next = findContextOutbound();\n    next.invoker.invokeWriteAndFlush(next, msg, promise);\n    return promise;\n}\n```\n\n在DefaultChannelHandlerInvoker中只有一个成员(executor)，执行逻辑的过程中，Invoker会先判断当前运行线程是否是executor，如果是则直接运行相应方法，不是则启动子线程运行相应方法。\n\n``` java\nprivate void invokeWrite(ChannelHandlerContext ctx, Object msg, boolean flush, ChannelPromise promise) {\n\n    if (executor.inEventLoop()) { // 判断是否是当前线程\n        invokeWriteNow(ctx, msg, promise);\n        if (flush) {\n            invokeFlushNow(ctx);\n        }\n    } else {\n        AbstractChannel channel = (AbstractChannel) ctx.channel();\n        int size = channel.estimatorHandle().size(msg);\n        if (size > 0) {\n            ChannelOutboundBuffer buffer = channel.unsafe().outboundBuffer();\n            // Check for null as it may be set to null if the channel is closed already\n            if (buffer != null) {\n                buffer.incrementPendingOutboundBytes(size);\n            }\n        }\n        // 创建一个新的WriteTask\n        // executor.execute(task);\n        safeExecuteOutbound(WriteTask.newInstance(ctx, msg, size, flush, promise), promise, msg);\n    }\n\n}\n```\n\nexecutor继承自[EventExecutor](http://netty.io/4.0/api/io/netty/util/concurrent/EventExecutor.html)，同时，该对象实现类一般而言也是实现[EventLoop](http://netty.io/4.0/api/io/netty/channel/EventLoop.html)接口。EventLoop的实现体现了Netty 4.x的IO线程模型，非常重要，后面再详细解析。\n\n#### 5、总结\n\n至此，上面简单总结了Channel以及Pipeline的处理流程。`Channel.write -> ChannelPipeline.write -> ChannelHandlerContext.write -> ChannelHandlerInvoker.write -> ChannelHandler.write`。在这个过程中，我也是捡简单的、流程性的代码总结，像EventLoop、EventExecutor这种核心部分并没有深入总结，压后再详细解说。\n","source":"_posts/netty-4-x-channel-pipeline.md","raw":"title: Netty 4.x学习笔记 - Channel和Pipeline\ndate: 2014-01-07 17:51:00\ncategories: 技术分享\ntags: [Netty]\n---\n\n### 1、前言\n\nChannel概念与java.nio.channel概念一致，用以连接IO设备（socket、文件等）的纽带。Netty 4.x之后的Channel变化较大，官方的唬人的说法是无法通过简单的关键字替换进行迁移。用得较多应该是：ChannelHandler接口重新设计，换了个较为清晰的名字；write不会主动flush。由于笔者3.x、4.x都没用过，所以也无法深入理解版本的变化了。\n\n<!--more-->\n\n> 关于channel 4.x的新变化可以参考这里：new and noteworthy: Channel API changes\n\n### 2、Channel总览\n\n<center><div style=\"width: 80%;\">![Netty Channel整体结构思维导图](/images/wpid-Channel.png)</div></center>\n\nChannel的IO类型主要有两种：非阻塞IO（NIO）以及阻塞IO（OIO）；数据传输类型有两种：按事件消息传递（Message）以及按字节传递（Byte）；适用方类型也有两种：服务器（ServerSocket）以及客户端（Socket）。还有一些根据传输协议而制定的的Channel，如：UDT、SCTP等。\n\nNetty按照类型逐层设计相应的类。最底层的为抽象类AbstractChannel，再以此根据IO类型、数据传输类型、适用方类型实现。类图可以一目了然，如下图所示：\n\n<center><div style=\"width: 80%;\">![Netty Channel类图](/images/wpid-nio-oio.jpg)</div></center>\n\n### 3、ChannelPipeline实现分析\n\n从AbstractChannel分析，它提供了一些IO操作方法，read、write等，Channel仅仅做了一个封装，方法中将参数直接传递给了Channel的Pipeline成员的相应方法。\n\nPipeline则是Channel里面非常重要的概念。从数据结构的角度，它是一个双向链表，每个节点均是DefaultChannelHandlerContext对象；从逻辑的角度，它则是netty的逻辑处理链，每个节点均包含一个逻辑处理器（ChannelHandler），用以实现网络通信的编/解码、处理等功能。\n\nPipeline的链表上有两种handler，Inbound Handler和Outbound handler。从Netty内部IO线程接读到IO数据，依次经过N个Handler到达最内部的逻辑处理单元，这种称之为Inbound Handler；从Channel发出IO请求，依次经过M个Handler到达Netty内部IO线程，这种称之为Outbound Handler。内部代码实现流程则是：Head -> Tail (Inbound)，Tail -> Head (Outbound)。下图截取自ChannelPipeline的注释中，简单明了：\n\n<center><div style=\"width: 60%;\">![Netty Pipeline](/images/wpid-Netty-ChannelPipeline-.png)</div></center>\n\n### 4、逻辑处理器\n\nChannelPipeline仅仅只是逻辑处理的流程，真正逻辑处理器则是ChannelHandlerInvoker。在获得链表节点后，节点会调用自己的invoker成员执行(invoke)逻辑。\n\n``` java\npublic ChannelFuture writeAndFlush(Object msg, ChannelPromise promise) {\n    DefaultChannelHandlerContext next = findContextOutbound();\n    next.invoker.invokeWriteAndFlush(next, msg, promise);\n    return promise;\n}\n```\n\n在DefaultChannelHandlerInvoker中只有一个成员(executor)，执行逻辑的过程中，Invoker会先判断当前运行线程是否是executor，如果是则直接运行相应方法，不是则启动子线程运行相应方法。\n\n``` java\nprivate void invokeWrite(ChannelHandlerContext ctx, Object msg, boolean flush, ChannelPromise promise) {\n\n    if (executor.inEventLoop()) { // 判断是否是当前线程\n        invokeWriteNow(ctx, msg, promise);\n        if (flush) {\n            invokeFlushNow(ctx);\n        }\n    } else {\n        AbstractChannel channel = (AbstractChannel) ctx.channel();\n        int size = channel.estimatorHandle().size(msg);\n        if (size > 0) {\n            ChannelOutboundBuffer buffer = channel.unsafe().outboundBuffer();\n            // Check for null as it may be set to null if the channel is closed already\n            if (buffer != null) {\n                buffer.incrementPendingOutboundBytes(size);\n            }\n        }\n        // 创建一个新的WriteTask\n        // executor.execute(task);\n        safeExecuteOutbound(WriteTask.newInstance(ctx, msg, size, flush, promise), promise, msg);\n    }\n\n}\n```\n\nexecutor继承自[EventExecutor](http://netty.io/4.0/api/io/netty/util/concurrent/EventExecutor.html)，同时，该对象实现类一般而言也是实现[EventLoop](http://netty.io/4.0/api/io/netty/channel/EventLoop.html)接口。EventLoop的实现体现了Netty 4.x的IO线程模型，非常重要，后面再详细解析。\n\n#### 5、总结\n\n至此，上面简单总结了Channel以及Pipeline的处理流程。`Channel.write -> ChannelPipeline.write -> ChannelHandlerContext.write -> ChannelHandlerInvoker.write -> ChannelHandler.write`。在这个过程中，我也是捡简单的、流程性的代码总结，像EventLoop、EventExecutor这种核心部分并没有深入总结，压后再详细解说。\n","slug":"netty-4-x-channel-pipeline","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg6223003xsb8fcen68f4q"},{"title":"Netty 4.x学习笔记 - ByteBuf","date":"2014-01-04T16:00:05.000Z","_content":"\n### 1、前言\n\n程序员喜欢说一句话：「不要重复造轮子」，但是程序员又不太会践行这句话。这倒也不是坏事，程序员一般而言看他人代码都不会太爽，这也可能是导致程序员的世界有各式各样的轮子的原因吧。\n\n### 2、ByteBuf与Java NIO Buffer\n\nByteBuf则是Java NIO Buffer的新轮子，官方列出了一些ByteBuf的特性：\n\n* 需要的话，可以自定义buffer类型；\n* 通过组合buffer类型，可实现透明的zero-copy；\n* 提供动态的buffer类型，如StringBuffer一样，容量是按需扩展；\n* 无需调用flip()方法；\n* 常常「often」比ByteBuffer快。\n\n>  参考地址：[Rich Buffer Data Structure](http://docs.jboss.org/netty/3.1/guide/html/architecture.html#d0e1893)\n\n### 3、ByteBuf实现类\n\nByteBuf提供了一些较为丰富的实现类，逻辑上主要分为两种：HeapByteBuf和DirectByteBuf，实现机制则分为两种：PooledByteBuf和UnpooledByteBuf，除了这些之外，Netty还实现了一些衍生ByteBuf（DerivedByteBuf），如：ReadOnlyByteBuf、DuplicatedByteBuf以及SlicedByteBuf。\n\nByteBuf实现类的类图如下：\n\n<center><div style=\"width: 80%;\">![Netty ByteBuf类图](/images/bytebuf-diagram.png)</div></center>\n\nHeapByteBuf和DirectByteBuf区别在于Buffer的管理方式：HeapByteBuf由Heap管理，Heap是Java堆的意思，内部实现直接采用byte[] array；DirectByteBuf使用是堆外内存，Direct应是采用Direct I/O之意，内部实现使用java.nio.DirectByteBuffoer。\n\n* [Direct I/O](http://www.ibm.com/developerworks/cn/linux/l-cn-directio/)\n* [DirectByteBuffer](http://docs.oracle.com/javase/7/docs/api/java/nio/MappedByteBuffer.html)\n\nPooledByteBuf和UnpooledByteBuf，UnpooledByteBuf实现就是普通的ByteBuf了，PooledByteBuf是4.x之后的新特性，稍后再说。\n\nDerivedByteBuf是ByteBuf衍生类，实现采用装饰器模式对原有的ByteBuf进行了一些封装。ReadOnlyByteBuf是某个ByteBuf的只读引用；DuplicatedByteBuf是某个ByteBuf对象的引用；SlicedByteBuf是某个ByteBuf的部分内容。\n\nSwappedByteBuf和CompositedByteBuf我觉得也算某种程度的衍生类吧，SwappedByteBuf封装了一个ByteBuf对象和ByteOrder对象，实现某个ByteBuf对象序列的逆转；CompositedByteBuf内部实现了一个ByteBuf列表，称之为组合ByteBuf，由于不懂相关的技术业务，无法理解该类的存在意义（官方解释：A user can save bulk memory copy operations using a composite buffer at the cost of relatively expensive random access.）。这两个类从逻辑上似乎完全可以继承于DerivedByteBuf，Trustin大神为啥如此设计呢？\n\n### 4、简要的ByteBuf的实现机制\n\n<center><div style=\"width: 80%;\">![Netty 实现机制](/images/bytebuf-priciple.png)</div></center>\n\nByteBuf有两个指针，readerIndex和writerIndex，用以控制buffer数组的读写。读逻辑较为简单，不考虑边界的情况下，就是`return array[readerIndex++];`。这里简要分析一下HeapByteBuf的读逻辑。\n\n 1. AbstractByteBuf.ensureWritable(minWritableBytes);\n 2. calculateNewCapacity(writerIndex + minWritableBytes)\n   2.1 判断是否超过可写入容量 maxCapacity – writerIndex\n   2.2 超过则抛异常，否则计算新容量 writerIndex + minWritableBytes\n   2.3 判断是否超过设定阈值(4MB)，超过每次增加按阈值(4MB)递增，否则\n   2.4 初始大小为64字节(newCapacity)，新容量超过newCapacity则翻倍，直到newCapacity大于新容量为止\n   2.5 返回Min(newCapacity, maxCapacity);\n 3. UnpooledHeapByteBuf.capacity(newCapacity);\n   3.1 确保可访问，有一个`引用计数`的机制，引用计数为0，则抛异常(ensureAccessible)\n   3.2 常规操作：判断是否越界\n   3.3 如果newCapacity比原容量大，则直接创建新数组，并设置。否则\n   3.4 如果readerIndex小于新容量，将readable bytes拷贝至新的数组，反之将readerIndex和writerIndex均设置为newCapacity。\n 4. setByte(writerIndex++, value)\n   4.1 确保可访问\n   4.2 设置\n\n### 5、ByteBuf特殊机制\n\n#### 5.1 Pooled\n\n4.x开发了Pooled Buffer，实现了一个高性能的buffer池，分配策略则是结合了buddy allocation和slab allocation的jemalloc变种，代码在io.netty.buffer.PoolArena。暂未深入研读。\n\n官方说提供了以下优势：\n\n* 频繁分配、释放buffer时减少了GC压力；\n* 在初始化新buffer时减少内存带宽消耗（初始化时不可避免的要给buffer数组赋初始值）；\n* 及时的释放direct buffer。\n\n当然，官方也说了不保证没有内存泄露，所以默认情况下还是采用的UnpooledByteBufAllocator。5.x还处于beta版，~~看它的「new and\\* noteworthy」文档也没说有啥变化，哈哈哈哈，~~查看最新的[「new and noteworthy」](http://netty.io/wiki/new-and-noteworthy-in-5.0.html)文档，PooledByteBufAllocator已经设置为默认的Allocator。\n\n#### 5.2 Reference Count\n\nByteBuf的生命周期管理引入了Reference Count的机制，感觉让我回到了CPP时代。可以通过简单的继承SimpleChannelInboundHandler实现自动释放reference count。SimpleChannelInboundHandler的事件方法如下，在消费完毕msg后，可以AutoRelease之：\n\n``` java\npublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\n    boolean release = true;\n    try {\n        if (acceptInboundMessage(msg)) {\n            @SuppressWarnings(\"unchecked\")\n            I imsg = (I) msg;\n            messageReceived(ctx, imsg);\n        } else {\n            release = false;\n            ctx.fireChannelRead(msg);\n        }\n    } finally {\n        if (autoRelease && release) {\n            ReferenceCountUtil.release(msg);\n        }\n    }\n}\n```\n\n这一小节可以单独拎出来和Pooled放在一起深入研读研读，有兴趣的可以先看看官方文档：[Reference counted objects](http://netty.io/wiki/reference-counted-objects.html)\n\n#### 5.3 Zero Copy\n\nZero-copy与传统意义的[zero-copy](http://en.wikipedia.org/wiki/Zero-copy)不太一样。传统的zero-copy是IO传输过程中，数据无需中内核态到用户态、用户态到内核态的数据拷贝，减少拷贝次数。而Netty的zero-copy则是完全在用户态，或者说传输层的zero-copy机制，可以参考下图。由于协议传输过程中，通常会有拆包、合并包的过程，一般的做法就是System.arrayCopy了，但是Netty通过ByteBuf.slice以及Unpooled.wrappedBuffer等方法拆分、合并Buffer无需拷贝数据。\n\n如何实现zero-copy的呢。slice实现就是创建一个SlicedByteBuf对象，将this对象，以及相应的数据指针传入即可，wrappedBuffer实现机制类似。\n\n<center><div style=\"width: 70%;\">![Netty Bytebuf](/images/bytebuf-combine-slice-buffer.png)</div></center>\n\n> 参考地址：[Combining and Slicing ChannelBuffers](http://netty.io/3.5/guide/#architecture.5.4)\n","source":"_posts/netty-4-x-bytebuf.md","raw":"title: Netty 4.x学习笔记 - ByteBuf\ndate: 2014-01-05 00:00:05\ncategories: 技术分享\ntags: [Netty]\n---\n\n### 1、前言\n\n程序员喜欢说一句话：「不要重复造轮子」，但是程序员又不太会践行这句话。这倒也不是坏事，程序员一般而言看他人代码都不会太爽，这也可能是导致程序员的世界有各式各样的轮子的原因吧。\n\n### 2、ByteBuf与Java NIO Buffer\n\nByteBuf则是Java NIO Buffer的新轮子，官方列出了一些ByteBuf的特性：\n\n* 需要的话，可以自定义buffer类型；\n* 通过组合buffer类型，可实现透明的zero-copy；\n* 提供动态的buffer类型，如StringBuffer一样，容量是按需扩展；\n* 无需调用flip()方法；\n* 常常「often」比ByteBuffer快。\n\n>  参考地址：[Rich Buffer Data Structure](http://docs.jboss.org/netty/3.1/guide/html/architecture.html#d0e1893)\n\n### 3、ByteBuf实现类\n\nByteBuf提供了一些较为丰富的实现类，逻辑上主要分为两种：HeapByteBuf和DirectByteBuf，实现机制则分为两种：PooledByteBuf和UnpooledByteBuf，除了这些之外，Netty还实现了一些衍生ByteBuf（DerivedByteBuf），如：ReadOnlyByteBuf、DuplicatedByteBuf以及SlicedByteBuf。\n\nByteBuf实现类的类图如下：\n\n<center><div style=\"width: 80%;\">![Netty ByteBuf类图](/images/bytebuf-diagram.png)</div></center>\n\nHeapByteBuf和DirectByteBuf区别在于Buffer的管理方式：HeapByteBuf由Heap管理，Heap是Java堆的意思，内部实现直接采用byte[] array；DirectByteBuf使用是堆外内存，Direct应是采用Direct I/O之意，内部实现使用java.nio.DirectByteBuffoer。\n\n* [Direct I/O](http://www.ibm.com/developerworks/cn/linux/l-cn-directio/)\n* [DirectByteBuffer](http://docs.oracle.com/javase/7/docs/api/java/nio/MappedByteBuffer.html)\n\nPooledByteBuf和UnpooledByteBuf，UnpooledByteBuf实现就是普通的ByteBuf了，PooledByteBuf是4.x之后的新特性，稍后再说。\n\nDerivedByteBuf是ByteBuf衍生类，实现采用装饰器模式对原有的ByteBuf进行了一些封装。ReadOnlyByteBuf是某个ByteBuf的只读引用；DuplicatedByteBuf是某个ByteBuf对象的引用；SlicedByteBuf是某个ByteBuf的部分内容。\n\nSwappedByteBuf和CompositedByteBuf我觉得也算某种程度的衍生类吧，SwappedByteBuf封装了一个ByteBuf对象和ByteOrder对象，实现某个ByteBuf对象序列的逆转；CompositedByteBuf内部实现了一个ByteBuf列表，称之为组合ByteBuf，由于不懂相关的技术业务，无法理解该类的存在意义（官方解释：A user can save bulk memory copy operations using a composite buffer at the cost of relatively expensive random access.）。这两个类从逻辑上似乎完全可以继承于DerivedByteBuf，Trustin大神为啥如此设计呢？\n\n### 4、简要的ByteBuf的实现机制\n\n<center><div style=\"width: 80%;\">![Netty 实现机制](/images/bytebuf-priciple.png)</div></center>\n\nByteBuf有两个指针，readerIndex和writerIndex，用以控制buffer数组的读写。读逻辑较为简单，不考虑边界的情况下，就是`return array[readerIndex++];`。这里简要分析一下HeapByteBuf的读逻辑。\n\n 1. AbstractByteBuf.ensureWritable(minWritableBytes);\n 2. calculateNewCapacity(writerIndex + minWritableBytes)\n   2.1 判断是否超过可写入容量 maxCapacity – writerIndex\n   2.2 超过则抛异常，否则计算新容量 writerIndex + minWritableBytes\n   2.3 判断是否超过设定阈值(4MB)，超过每次增加按阈值(4MB)递增，否则\n   2.4 初始大小为64字节(newCapacity)，新容量超过newCapacity则翻倍，直到newCapacity大于新容量为止\n   2.5 返回Min(newCapacity, maxCapacity);\n 3. UnpooledHeapByteBuf.capacity(newCapacity);\n   3.1 确保可访问，有一个`引用计数`的机制，引用计数为0，则抛异常(ensureAccessible)\n   3.2 常规操作：判断是否越界\n   3.3 如果newCapacity比原容量大，则直接创建新数组，并设置。否则\n   3.4 如果readerIndex小于新容量，将readable bytes拷贝至新的数组，反之将readerIndex和writerIndex均设置为newCapacity。\n 4. setByte(writerIndex++, value)\n   4.1 确保可访问\n   4.2 设置\n\n### 5、ByteBuf特殊机制\n\n#### 5.1 Pooled\n\n4.x开发了Pooled Buffer，实现了一个高性能的buffer池，分配策略则是结合了buddy allocation和slab allocation的jemalloc变种，代码在io.netty.buffer.PoolArena。暂未深入研读。\n\n官方说提供了以下优势：\n\n* 频繁分配、释放buffer时减少了GC压力；\n* 在初始化新buffer时减少内存带宽消耗（初始化时不可避免的要给buffer数组赋初始值）；\n* 及时的释放direct buffer。\n\n当然，官方也说了不保证没有内存泄露，所以默认情况下还是采用的UnpooledByteBufAllocator。5.x还处于beta版，~~看它的「new and\\* noteworthy」文档也没说有啥变化，哈哈哈哈，~~查看最新的[「new and noteworthy」](http://netty.io/wiki/new-and-noteworthy-in-5.0.html)文档，PooledByteBufAllocator已经设置为默认的Allocator。\n\n#### 5.2 Reference Count\n\nByteBuf的生命周期管理引入了Reference Count的机制，感觉让我回到了CPP时代。可以通过简单的继承SimpleChannelInboundHandler实现自动释放reference count。SimpleChannelInboundHandler的事件方法如下，在消费完毕msg后，可以AutoRelease之：\n\n``` java\npublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\n    boolean release = true;\n    try {\n        if (acceptInboundMessage(msg)) {\n            @SuppressWarnings(\"unchecked\")\n            I imsg = (I) msg;\n            messageReceived(ctx, imsg);\n        } else {\n            release = false;\n            ctx.fireChannelRead(msg);\n        }\n    } finally {\n        if (autoRelease && release) {\n            ReferenceCountUtil.release(msg);\n        }\n    }\n}\n```\n\n这一小节可以单独拎出来和Pooled放在一起深入研读研读，有兴趣的可以先看看官方文档：[Reference counted objects](http://netty.io/wiki/reference-counted-objects.html)\n\n#### 5.3 Zero Copy\n\nZero-copy与传统意义的[zero-copy](http://en.wikipedia.org/wiki/Zero-copy)不太一样。传统的zero-copy是IO传输过程中，数据无需中内核态到用户态、用户态到内核态的数据拷贝，减少拷贝次数。而Netty的zero-copy则是完全在用户态，或者说传输层的zero-copy机制，可以参考下图。由于协议传输过程中，通常会有拆包、合并包的过程，一般的做法就是System.arrayCopy了，但是Netty通过ByteBuf.slice以及Unpooled.wrappedBuffer等方法拆分、合并Buffer无需拷贝数据。\n\n如何实现zero-copy的呢。slice实现就是创建一个SlicedByteBuf对象，将this对象，以及相应的数据指针传入即可，wrappedBuffer实现机制类似。\n\n<center><div style=\"width: 70%;\">![Netty Bytebuf](/images/bytebuf-combine-slice-buffer.png)</div></center>\n\n> 参考地址：[Combining and Slicing ChannelBuffers](http://netty.io/3.5/guide/#architecture.5.4)\n","slug":"netty-4-x-bytebuf","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg62240040sb8frxp017s4"},{"title":"男儿志在四方","id":"87","date":"2011-02-14T16:35:18.000Z","_content":"\n今天与友人聊天时，她问到：人为什么都想着出去？\n\n拿我来说吧，用句较为俗套但是表达直白的话说就是：男儿志在四方。我在长沙待了21年，大学选在长沙是由于父母原因，也是基本前面的原因，出游次数也不多，到过的省份寥寥无几，虽然爱畅游互联网世界（估计以后也是卖给此行业了），自认为了解甚多，但是毕竟不如行万里路来得痛快。\n\n我虽然不爱那山山水水，但是我爱那各式各异的城市建设；虽然我不会也不可能完全融入地方风俗，但是我能和那地方人瞎扯淡；虽然我可能买不起那老贵的房子（其实那也是不可能的），但是我也想用蛋居来感受别样人生……\n\n这就是我的部分人生观，乐观积极的感受生活感受世界，而不是被束缚在这鸟大的长沙。\n\n不过呢，也听友人叹息过：亲在，子不远游。我爸妈是比较传统的父母，舍不得自己的孩子到处“吃亏”，老爸最近身体一向不太好，估计我这远游也不好游多少时间。所以暂定的是游到30岁就回长沙立业（但不成家）。\n\n30岁，游历9年后会重回故土是什么样的心态呢？那只能等了哦……","source":"_posts/my-motive.md","raw":"title: 男儿志在四方\ntags:\n  - 价值观\nid: 87\ncategories:\n  - 生活分享\ndate: 2011-02-15 00:35:18\n---\n\n今天与友人聊天时，她问到：人为什么都想着出去？\n\n拿我来说吧，用句较为俗套但是表达直白的话说就是：男儿志在四方。我在长沙待了21年，大学选在长沙是由于父母原因，也是基本前面的原因，出游次数也不多，到过的省份寥寥无几，虽然爱畅游互联网世界（估计以后也是卖给此行业了），自认为了解甚多，但是毕竟不如行万里路来得痛快。\n\n我虽然不爱那山山水水，但是我爱那各式各异的城市建设；虽然我不会也不可能完全融入地方风俗，但是我能和那地方人瞎扯淡；虽然我可能买不起那老贵的房子（其实那也是不可能的），但是我也想用蛋居来感受别样人生……\n\n这就是我的部分人生观，乐观积极的感受生活感受世界，而不是被束缚在这鸟大的长沙。\n\n不过呢，也听友人叹息过：亲在，子不远游。我爸妈是比较传统的父母，舍不得自己的孩子到处“吃亏”，老爸最近身体一向不太好，估计我这远游也不好游多少时间。所以暂定的是游到30岁就回长沙立业（但不成家）。\n\n30岁，游历9年后会重回故土是什么样的心态呢？那只能等了哦……","slug":"my-motive","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg62250043sb8fu5kruni6"},{"title":"我的Macbook小记","id":"869","date":"2013-11-06T16:14:10.000Z","_content":"\n上上周在淘宝上下单新款macbook pro retina 15寸，定制版，周二也就是昨天收到货，收货的心情确实非常激动。rMBP也是我想了很久的机器了，一直没狠下心来买，这次买也算是脑子一热吧。不过收货中间曲折种种，让我不得不感叹一下了。\n\n<!--more-->\n\n\t<span style=\"line-height: 1.6em;\">自己本身处在这个电商的中心，所以也一直挺支持自己东家的业务，在淘宝上花销多大也算是比较放心，这次&ldquo;大手笔&rdquo;网上消费，</span><span style=\"line-height: 1.6em;\">从选店家到仔细思考中间的时间也不过几个小时。选了同事&ldquo;推荐&rdquo;的一个商家，其实这个同事也就是随便选了一家，觉得应该没问题就推荐给我了。店家吧，现在看来确实没啥问题，但是就是拿到的货好像那个啥了点。</span>\n\n\t收货的时候直接给我发了裸机+电源+打印发票，收到货的心情是非常激动，但打开货之后，那个心啊！拔凉拔凉的！那种不爽的感觉简直无法用语言形容。不过机器检查了一下，电池循环次数2次，序列号没问题，初步来说应该是好的，所以就简单的找了下店家的麻烦，店家解释似乎也还合理，顺带还补偿了我￥50。谁知，这才是不爽的开始。\n\n> 店家今天给单独把盒子发过来了，看顺丰价格应该是一日达，赞一个！\n\n\t使用了半天macbook，觉得屏幕有点闪，开始觉得是屏幕太好了，我眼拙。随便动了动电源调了调亮度，感觉似乎好像是没问题了，继续使用着。晚上的时候，回家慢慢研究，研究研究着就不太对劲了：诶，这不应该啊，这闪得还挺带感啊，非常规律啊！好吧，不爽开始了！！！\n\n\t最初认为是驱动的问题，想着比较新的Intel Iris Pro加上比较新的Mavericks，应该有点不兼容吧，但也没找到新的驱动，在mac下似乎是没有办法证实这个问题了。好吧，那就装个双系统吧，折腾折腾给装了个双系统Win7，在装的过程中，需要烧录系统盘，中间还格盘格错了，格了一个移动硬盘，1T啊，今天恢复了一天都没恢复过来！！！不小心搞走了我1T的数据不说，最后在Win7下的验证结果是：Win7下，屏幕也在闪！<span style=\"line-height: 1.6em;\">而且装机过程中，发现在option选择磁盘的界面中，屏幕也一如既然的闪烁，仿佛这个世界与她没关一样。</span>\n\n\t<span style=\"line-height: 1.6em;\">基于以上种种，我这里基本上认为是硬件问题了。不带这么搞的啊，还没摸热就发现硬件出问题了，还是最值钱最漂亮的屏幕！！！</span>\n\n\t唉，接下来的流程就比较常规了，电话客服、旺旺店家、游走维修点。客服告之重置SMC的方法，试之无效，请去维修点检测是否硬件有问题；维修点发现问题后，很委婉的告之无能为力，国内没上市，没检测设备也没有更换设备，请送修香港或等国内上市后再来；店家各种&ldquo;呵呵&rdquo;，但也算比较友好，可单程<span style=\"font-size: 13px;\">保价</span>包邮送香港检测。\n\n\t唉，自己也在纠结，送香港的话，店家不上心加上香港方如果直接给拆解再修好，那不如直接等国内上市了。但如果等国内上市，说不定香港又可以包换呢！纠结来纠结去，最后还是听cc的，送香港吧！希望这个小本能有个好的下场。\n\n\t以上只是这两天的一下杂乱思路的整理，整理了一下发现还是很杂乱。嗯，就这么着吧！\n\n> 苹果官方的服务很不错，第一次享受到&ldquo;预约&rdquo;。&ldquo;嗯，苹果和我预约了明天早上10:30的电话&rdquo;\n\n> 这是拿这台Macbook写的，希望这是她的第一次也是最后一次了，换一台吧，别修了！！！","source":"_posts/my-macbook.md","raw":"title: 我的Macbook小记\ntags:\n  - Apple\n  - Macbook\n  - RBMP\nid: 869\ncategories:\n  - 生活分享\ndate: 2013-11-07 00:14:10\n---\n\n上上周在淘宝上下单新款macbook pro retina 15寸，定制版，周二也就是昨天收到货，收货的心情确实非常激动。rMBP也是我想了很久的机器了，一直没狠下心来买，这次买也算是脑子一热吧。不过收货中间曲折种种，让我不得不感叹一下了。\n\n<!--more-->\n\n\t<span style=\"line-height: 1.6em;\">自己本身处在这个电商的中心，所以也一直挺支持自己东家的业务，在淘宝上花销多大也算是比较放心，这次&ldquo;大手笔&rdquo;网上消费，</span><span style=\"line-height: 1.6em;\">从选店家到仔细思考中间的时间也不过几个小时。选了同事&ldquo;推荐&rdquo;的一个商家，其实这个同事也就是随便选了一家，觉得应该没问题就推荐给我了。店家吧，现在看来确实没啥问题，但是就是拿到的货好像那个啥了点。</span>\n\n\t收货的时候直接给我发了裸机+电源+打印发票，收到货的心情是非常激动，但打开货之后，那个心啊！拔凉拔凉的！那种不爽的感觉简直无法用语言形容。不过机器检查了一下，电池循环次数2次，序列号没问题，初步来说应该是好的，所以就简单的找了下店家的麻烦，店家解释似乎也还合理，顺带还补偿了我￥50。谁知，这才是不爽的开始。\n\n> 店家今天给单独把盒子发过来了，看顺丰价格应该是一日达，赞一个！\n\n\t使用了半天macbook，觉得屏幕有点闪，开始觉得是屏幕太好了，我眼拙。随便动了动电源调了调亮度，感觉似乎好像是没问题了，继续使用着。晚上的时候，回家慢慢研究，研究研究着就不太对劲了：诶，这不应该啊，这闪得还挺带感啊，非常规律啊！好吧，不爽开始了！！！\n\n\t最初认为是驱动的问题，想着比较新的Intel Iris Pro加上比较新的Mavericks，应该有点不兼容吧，但也没找到新的驱动，在mac下似乎是没有办法证实这个问题了。好吧，那就装个双系统吧，折腾折腾给装了个双系统Win7，在装的过程中，需要烧录系统盘，中间还格盘格错了，格了一个移动硬盘，1T啊，今天恢复了一天都没恢复过来！！！不小心搞走了我1T的数据不说，最后在Win7下的验证结果是：Win7下，屏幕也在闪！<span style=\"line-height: 1.6em;\">而且装机过程中，发现在option选择磁盘的界面中，屏幕也一如既然的闪烁，仿佛这个世界与她没关一样。</span>\n\n\t<span style=\"line-height: 1.6em;\">基于以上种种，我这里基本上认为是硬件问题了。不带这么搞的啊，还没摸热就发现硬件出问题了，还是最值钱最漂亮的屏幕！！！</span>\n\n\t唉，接下来的流程就比较常规了，电话客服、旺旺店家、游走维修点。客服告之重置SMC的方法，试之无效，请去维修点检测是否硬件有问题；维修点发现问题后，很委婉的告之无能为力，国内没上市，没检测设备也没有更换设备，请送修香港或等国内上市后再来；店家各种&ldquo;呵呵&rdquo;，但也算比较友好，可单程<span style=\"font-size: 13px;\">保价</span>包邮送香港检测。\n\n\t唉，自己也在纠结，送香港的话，店家不上心加上香港方如果直接给拆解再修好，那不如直接等国内上市了。但如果等国内上市，说不定香港又可以包换呢！纠结来纠结去，最后还是听cc的，送香港吧！希望这个小本能有个好的下场。\n\n\t以上只是这两天的一下杂乱思路的整理，整理了一下发现还是很杂乱。嗯，就这么着吧！\n\n> 苹果官方的服务很不错，第一次享受到&ldquo;预约&rdquo;。&ldquo;嗯，苹果和我预约了明天早上10:30的电话&rdquo;\n\n> 这是拿这台Macbook写的，希望这是她的第一次也是最后一次了，换一台吧，别修了！！！","slug":"my-macbook","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg62270046sb8fzbkuwllm"},{"title":"多列group-by及其应用场景","id":"838","date":"2013-05-28T15:31:56.000Z","_content":"\n**1、前言**\n\n一直以来都对多列group by没什么感觉，也不知道它到底要干嘛。这篇文章就粗略的讲一下什么是多列groupby，以及它的应用场景简例，没有什么深度，仅作为自己的知识笔记。\n  > **BTW: **没感觉应该是因为一直没怎么接触数据库吧，罪过罪过(- -)<!--more-->  \n\n**2、group by**\n\ngroup by是SQL的语法，它一般结合一些聚合函数(aggregate functions)一起使用，如：SUM、AVG、MAX等。单列group by，比如group by columnA，就意味着，将A列中，所有相同的值放在同一个group。如下：\n <center>   <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"119\">           \n\n**purchase_date**\n         </td>          <td valign=\"top\" width=\"131\">           \n\n**item**\n         </td>          <td valign=\"top\" width=\"95\">           \n\n**items_purchased**\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-03-25\n         </td>          <td valign=\"top\" width=\"131\">           \n\nWireless Mouse\n         </td>          <td valign=\"top\" width=\"95\">           \n\n2\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-03-25\n         </td>          <td valign=\"top\" width=\"131\">           \n\nWireless Mouse\n         </td>          <td valign=\"top\" width=\"95\">           \n\n5\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-03-25 \n         </td>          <td valign=\"top\" width=\"131\">           \n\nMacBook Pro\n         </td>          <td valign=\"top\" width=\"95\">           \n\n1\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-04-01\n         </td>          <td valign=\"top\" width=\"131\">           \n\nPaper Clips\n         </td>          <td valign=\"top\" width=\"95\">           \n\n20\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-04-01 \n         </td>          <td valign=\"top\" width=\"131\">           \n\nStapler\n         </td>          <td valign=\"top\" width=\"95\">           \n\n3\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-04-01\n         </td>          <td valign=\"top\" width=\"131\">           \n\nPaper Clips\n         </td>          <td valign=\"top\" width=\"95\">           \n\n15\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-05-15 \n         </td>          <td valign=\"top\" width=\"131\">           \n\nDVD player\n         </td>          <td valign=\"top\" width=\"95\">           \n\n3\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-05-15\n         </td>          <td valign=\"top\" width=\"131\">           \n\nDVD player\n         </td>          <td valign=\"top\" width=\"95\">           \n\n8\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-05-15\n         </td>          <td valign=\"top\" width=\"131\">           \n\nStapler\n         </td>          <td valign=\"top\" width=\"95\">           \n\n5\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-05-16\n         </td>          <td valign=\"top\" width=\"131\">           \n\nMacBook Pro\n         </td>          <td valign=\"top\" width=\"95\">           \n\n2\n         </td>       </tr>     </tbody></table> </center>  \n\n用户需要知道，哪天购买的东西最多，那就可以用group by，SQL如下：\n  > select purchase_date, count(items_purchased) as purchased_count \n> \n> from Purchases group by purchase_date order by purchased_count desc; <center>   <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\" width=\"247\"><tbody>       <tr>         <td valign=\"top\" width=\"129\">           \n\n**purchase_date**\n         </td>          <td valign=\"top\" width=\"116\">           \n\n**purchased_count**\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"129\">           \n\n2013-04-01\n         </td>          <td valign=\"top\" width=\"116\">           \n\n38\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"129\">           \n\n2013-05-15 \n         </td>          <td valign=\"top\" width=\"116\">           \n\n16\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"129\">           \n\n2013-03-25\n         </td>          <td valign=\"top\" width=\"116\">           \n\n8\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"129\">           \n\n2013-05-16\n         </td>          <td valign=\"top\" width=\"116\">           \n\n2\n         </td>       </tr>     </tbody></table> </center>  \n\n**3、多列group by**\n\n同上，用户如果想知道，给定日期，该天商品购买的详细情况，这就需要使用多列group by了。\n\n多列group by，比如group by columnA, columnB，就意味着，将A、B两列中均相同的值放在同一个group。SQL可以这样写：\n  > <pre>select purchase_date, item, sum(items_purchased) as \r> \n> &quot;total items&quot; from Purchases group by item, purchase_date;</pre>\n\n返回结果如下：\n\n<center>\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\" width=\"347\"><tbody>\n      <tr>\n        <td valign=\"top\" width=\"115\">\n\n**purchase_date**\n\n        </td>\n\n        <td valign=\"top\" width=\"123\">\n\n**item**\n\n        </td>\n\n        <td valign=\"top\" width=\"107\">\n\n**Total Items**\n\n        </td>\n      </tr>\n\n      <tr>\n        <td valign=\"top\" width=\"115\">\n\n2013-03-25\n\n        </td>\n\n        <td valign=\"top\" width=\"123\">\n\nWireless Mouse\n\n        </td>\n\n        <td valign=\"top\" width=\"107\">\n\n7\n\n        </td>\n      </tr>\n\n      <tr>\n        <td valign=\"top\" width=\"115\">\n\n2013-03-25\n\n        </td>\n\n        <td valign=\"top\" width=\"123\">\n\nMacBook Pro\n\n        </td>\n\n        <td valign=\"top\" width=\"107\">\n\n1\n\n        </td>\n      </tr>\n\n      <tr>\n        <td valign=\"top\" width=\"115\">\n\n2013-04-01\n\n        </td>\n\n        <td valign=\"top\" width=\"123\">\n\nPaper Clips\n\n        </td>\n\n        <td valign=\"top\" width=\"107\">\n\n35\n\n        </td>\n      </tr>\n\n      <tr>\n        <td valign=\"top\" width=\"115\">\n\n2013-04-01\n\n        </td>\n\n        <td valign=\"top\" width=\"123\">\n\nStapler\n\n        </td>\n\n        <td valign=\"top\" width=\"107\">\n\n3\n\n        </td>\n      </tr>\n\n      <tr>\n        <td valign=\"top\" width=\"115\">\n\n2013-05-15\n\n        </td>\n\n        <td valign=\"top\" width=\"123\">\n\nDVD player\n\n        </td>\n\n        <td valign=\"top\" width=\"107\">\n\n11\n\n        </td>\n      </tr>\n\n      <tr>\n        <td valign=\"top\" width=\"115\">\n\n2013-05-15\n\n        </td>\n\n        <td valign=\"top\" width=\"123\">\n\nStapler\n\n        </td>\n\n        <td valign=\"top\" width=\"107\">\n\n5\n\n        </td>\n      </tr>\n\n      <tr>\n        <td valign=\"top\" width=\"115\">\n\n2013-05-16\n\n        </td>\n\n        <td valign=\"top\" width=\"123\">\n\nMacBook Pro\n\n        </td>\n\n        <td valign=\"top\" width=\"107\">\n\n2\n\n        </td>\n      </tr>\n    </tbody></table>\n</center>\n\n多列group by会将被groupby的多列合成相同的group，并可对每个group进行相应的聚合，如前面的sum()。\n\n&#160;\n\n> **参考文献：**\n> \n> **[ProgrammerInterview.com](http://t.cn/zHJvZ7E)**\n> \n> [StackOverflow](http://stackoverflow.com/questions/2421388/using-group-by-on-multiple-columns) - Using group by on multiple columns\n\n> **BTW:** 技术还是看英文吧。","source":"_posts/multi-columns-group-by.md","raw":"title: 多列group-by及其应用场景\ntags:\n  - group by\n  - SQL\nid: 838\ncategories:\n  - 技术分享\ndate: 2013-05-28 23:31:56\n---\n\n**1、前言**\n\n一直以来都对多列group by没什么感觉，也不知道它到底要干嘛。这篇文章就粗略的讲一下什么是多列groupby，以及它的应用场景简例，没有什么深度，仅作为自己的知识笔记。\n  > **BTW: **没感觉应该是因为一直没怎么接触数据库吧，罪过罪过(- -)<!--more-->  \n\n**2、group by**\n\ngroup by是SQL的语法，它一般结合一些聚合函数(aggregate functions)一起使用，如：SUM、AVG、MAX等。单列group by，比如group by columnA，就意味着，将A列中，所有相同的值放在同一个group。如下：\n <center>   <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"119\">           \n\n**purchase_date**\n         </td>          <td valign=\"top\" width=\"131\">           \n\n**item**\n         </td>          <td valign=\"top\" width=\"95\">           \n\n**items_purchased**\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-03-25\n         </td>          <td valign=\"top\" width=\"131\">           \n\nWireless Mouse\n         </td>          <td valign=\"top\" width=\"95\">           \n\n2\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-03-25\n         </td>          <td valign=\"top\" width=\"131\">           \n\nWireless Mouse\n         </td>          <td valign=\"top\" width=\"95\">           \n\n5\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-03-25 \n         </td>          <td valign=\"top\" width=\"131\">           \n\nMacBook Pro\n         </td>          <td valign=\"top\" width=\"95\">           \n\n1\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-04-01\n         </td>          <td valign=\"top\" width=\"131\">           \n\nPaper Clips\n         </td>          <td valign=\"top\" width=\"95\">           \n\n20\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-04-01 \n         </td>          <td valign=\"top\" width=\"131\">           \n\nStapler\n         </td>          <td valign=\"top\" width=\"95\">           \n\n3\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-04-01\n         </td>          <td valign=\"top\" width=\"131\">           \n\nPaper Clips\n         </td>          <td valign=\"top\" width=\"95\">           \n\n15\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-05-15 \n         </td>          <td valign=\"top\" width=\"131\">           \n\nDVD player\n         </td>          <td valign=\"top\" width=\"95\">           \n\n3\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-05-15\n         </td>          <td valign=\"top\" width=\"131\">           \n\nDVD player\n         </td>          <td valign=\"top\" width=\"95\">           \n\n8\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-05-15\n         </td>          <td valign=\"top\" width=\"131\">           \n\nStapler\n         </td>          <td valign=\"top\" width=\"95\">           \n\n5\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"119\">           \n\n2013-05-16\n         </td>          <td valign=\"top\" width=\"131\">           \n\nMacBook Pro\n         </td>          <td valign=\"top\" width=\"95\">           \n\n2\n         </td>       </tr>     </tbody></table> </center>  \n\n用户需要知道，哪天购买的东西最多，那就可以用group by，SQL如下：\n  > select purchase_date, count(items_purchased) as purchased_count \n> \n> from Purchases group by purchase_date order by purchased_count desc; <center>   <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\" width=\"247\"><tbody>       <tr>         <td valign=\"top\" width=\"129\">           \n\n**purchase_date**\n         </td>          <td valign=\"top\" width=\"116\">           \n\n**purchased_count**\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"129\">           \n\n2013-04-01\n         </td>          <td valign=\"top\" width=\"116\">           \n\n38\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"129\">           \n\n2013-05-15 \n         </td>          <td valign=\"top\" width=\"116\">           \n\n16\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"129\">           \n\n2013-03-25\n         </td>          <td valign=\"top\" width=\"116\">           \n\n8\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"129\">           \n\n2013-05-16\n         </td>          <td valign=\"top\" width=\"116\">           \n\n2\n         </td>       </tr>     </tbody></table> </center>  \n\n**3、多列group by**\n\n同上，用户如果想知道，给定日期，该天商品购买的详细情况，这就需要使用多列group by了。\n\n多列group by，比如group by columnA, columnB，就意味着，将A、B两列中均相同的值放在同一个group。SQL可以这样写：\n  > <pre>select purchase_date, item, sum(items_purchased) as \r> \n> &quot;total items&quot; from Purchases group by item, purchase_date;</pre>\n\n返回结果如下：\n\n<center>\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\" width=\"347\"><tbody>\n      <tr>\n        <td valign=\"top\" width=\"115\">\n\n**purchase_date**\n\n        </td>\n\n        <td valign=\"top\" width=\"123\">\n\n**item**\n\n        </td>\n\n        <td valign=\"top\" width=\"107\">\n\n**Total Items**\n\n        </td>\n      </tr>\n\n      <tr>\n        <td valign=\"top\" width=\"115\">\n\n2013-03-25\n\n        </td>\n\n        <td valign=\"top\" width=\"123\">\n\nWireless Mouse\n\n        </td>\n\n        <td valign=\"top\" width=\"107\">\n\n7\n\n        </td>\n      </tr>\n\n      <tr>\n        <td valign=\"top\" width=\"115\">\n\n2013-03-25\n\n        </td>\n\n        <td valign=\"top\" width=\"123\">\n\nMacBook Pro\n\n        </td>\n\n        <td valign=\"top\" width=\"107\">\n\n1\n\n        </td>\n      </tr>\n\n      <tr>\n        <td valign=\"top\" width=\"115\">\n\n2013-04-01\n\n        </td>\n\n        <td valign=\"top\" width=\"123\">\n\nPaper Clips\n\n        </td>\n\n        <td valign=\"top\" width=\"107\">\n\n35\n\n        </td>\n      </tr>\n\n      <tr>\n        <td valign=\"top\" width=\"115\">\n\n2013-04-01\n\n        </td>\n\n        <td valign=\"top\" width=\"123\">\n\nStapler\n\n        </td>\n\n        <td valign=\"top\" width=\"107\">\n\n3\n\n        </td>\n      </tr>\n\n      <tr>\n        <td valign=\"top\" width=\"115\">\n\n2013-05-15\n\n        </td>\n\n        <td valign=\"top\" width=\"123\">\n\nDVD player\n\n        </td>\n\n        <td valign=\"top\" width=\"107\">\n\n11\n\n        </td>\n      </tr>\n\n      <tr>\n        <td valign=\"top\" width=\"115\">\n\n2013-05-15\n\n        </td>\n\n        <td valign=\"top\" width=\"123\">\n\nStapler\n\n        </td>\n\n        <td valign=\"top\" width=\"107\">\n\n5\n\n        </td>\n      </tr>\n\n      <tr>\n        <td valign=\"top\" width=\"115\">\n\n2013-05-16\n\n        </td>\n\n        <td valign=\"top\" width=\"123\">\n\nMacBook Pro\n\n        </td>\n\n        <td valign=\"top\" width=\"107\">\n\n2\n\n        </td>\n      </tr>\n    </tbody></table>\n</center>\n\n多列group by会将被groupby的多列合成相同的group，并可对每个group进行相应的聚合，如前面的sum()。\n\n&#160;\n\n> **参考文献：**\n> \n> **[ProgrammerInterview.com](http://t.cn/zHJvZ7E)**\n> \n> [StackOverflow](http://stackoverflow.com/questions/2421388/using-group-by-on-multiple-columns) - Using group by on multiple columns\n\n> **BTW:** 技术还是看英文吧。","slug":"multi-columns-group-by","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg622b004esb8fryz8m4x3"},{"title":"Maven笔记 - 仓库","id":"726","date":"2013-03-18T02:13:17.000Z","_content":"\n**1、前言**\n\n\t上一篇[博客](http://hongweiyi.com/2013/03/maven-coordinates-dependencies/)介绍了Maven坐标和依赖。在Maven中，任何一个依赖、插件或者项目构建的输出，都可以成为构件。而坐标和依赖是任何一个构件在Maven世界中的逻辑表示方式，构件的物理表示方式是文件，Maven则通过仓库（Repositories）来统一管理这些文件。Maven仓库是通过简单文件系统存储管理的，当遇到与仓库相关的问题，可以直接查找相关文件，方便定位问题。\n\n<!--more-->\n\n\t&nbsp;\n\n\t**2、仓库的分类**\n\n\t对于Maven而言，仓库分为两类：本地仓库和远程仓库。当Maven根据坐标寻找构件的时候，它会首先查看本地仓库，如果本地仓库存在此构件，则直接使用；如果本地仓库不存在此构件，或者需要查看是否有更新的构件版本，Maven就会去远程仓库查找，发现需要的构件之后，下载到本地仓库再使用。如果本地仓库和远程仓库都有没有需要的构件Maven就会报错。\n\n\t这里有三个远程仓库：**中央仓库、私服和其他公共库**。中央仓库是Maven核心自带的远程仓库（http://repo1.maven.org/maven2），它包含了绝大部分的构件。私服是另一种特殊的远程仓库，为了节省带宽和时间，应该在局域网内架设一个私有的仓库服务器，用其代理所有外部的远程仓库。除了以上两种，还有很多公开的远程仓库，比如Java. Net Maven库（http://download.java.net/maven/2/）和JBoss Maven库（http://repository.jboss.com/maven2/）\n\n> **IMPORTANT**：私服最重要的功能应该不在节省速度和带宽，而是可以部署内部构件，供企业内部开发人员使用。\n\n\t[![image](http://hongweiyi.com/wp-content/uploads/2013/03/image_thumb.png \"image\")](http://hongweiyi.com/wp-content/uploads/2013/03/image.png)一图胜千言\n\n\t&nbsp;\n\n\t**3、远程仓库的配置**\n\n\t这位弟兄将《Maven实战》这个部分都给Copy到网上了，并加以标注，可以直接参考：[http://t.cn/zYgRHb7](http://t.cn/zYgRHb7)\n\n\t&nbsp;\n\n\t**4、Maven镜像**\n\n\t如果仓库X可以提供仓库Y存储的所有内容，那么就可以认为X是Y的一个镜像。Maven中央仓库在国内经常不能正常访问，连接超时不能下载资源之类的。在公司内部还挺好，有私服可以用，但是回家之后那龟爬的网速就难说了，一般来说可以配置Maven镜像。配置需要修改~/.m2/settings.xml，内容如下：\n\n[code lang=\"xml\"]\n&lt;settings&gt;\n  &lt;!--…--&gt;\n  &lt;mirrors&gt;\n    &lt;mirror&gt;\n      &lt;id&gt;maven.net.cn&lt;/id&gt;\n      &lt;name&gt;one of the central mirrors in China&lt;/name&gt;\n      &lt;url&gt;http://maven.net.cn/content/groups/public/&lt;/url&gt;\n      &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;\n    &lt;/mirror&gt;\n  &lt;/mirrors&gt;\n  &lt;!--…--&gt;\n&lt;/settings&gt;\n[/code]\n\n> **WARNING: **镜像仓库完全屏蔽了被镜像仓库，当镜像仓库不稳定或者不能访问的时候，Maven将无法访问被访问镜像。\n\n\t&nbsp;\n\n> **参考资料**：《Maven实战》","source":"_posts/maven-repositories.md","raw":"title: Maven笔记 - 仓库\ntags:\n  - java\n  - Maven\nid: 726\ncategories:\n  - 技术分享\ndate: 2013-03-18 10:13:17\n---\n\n**1、前言**\n\n\t上一篇[博客](http://hongweiyi.com/2013/03/maven-coordinates-dependencies/)介绍了Maven坐标和依赖。在Maven中，任何一个依赖、插件或者项目构建的输出，都可以成为构件。而坐标和依赖是任何一个构件在Maven世界中的逻辑表示方式，构件的物理表示方式是文件，Maven则通过仓库（Repositories）来统一管理这些文件。Maven仓库是通过简单文件系统存储管理的，当遇到与仓库相关的问题，可以直接查找相关文件，方便定位问题。\n\n<!--more-->\n\n\t&nbsp;\n\n\t**2、仓库的分类**\n\n\t对于Maven而言，仓库分为两类：本地仓库和远程仓库。当Maven根据坐标寻找构件的时候，它会首先查看本地仓库，如果本地仓库存在此构件，则直接使用；如果本地仓库不存在此构件，或者需要查看是否有更新的构件版本，Maven就会去远程仓库查找，发现需要的构件之后，下载到本地仓库再使用。如果本地仓库和远程仓库都有没有需要的构件Maven就会报错。\n\n\t这里有三个远程仓库：**中央仓库、私服和其他公共库**。中央仓库是Maven核心自带的远程仓库（http://repo1.maven.org/maven2），它包含了绝大部分的构件。私服是另一种特殊的远程仓库，为了节省带宽和时间，应该在局域网内架设一个私有的仓库服务器，用其代理所有外部的远程仓库。除了以上两种，还有很多公开的远程仓库，比如Java. Net Maven库（http://download.java.net/maven/2/）和JBoss Maven库（http://repository.jboss.com/maven2/）\n\n> **IMPORTANT**：私服最重要的功能应该不在节省速度和带宽，而是可以部署内部构件，供企业内部开发人员使用。\n\n\t[![image](http://hongweiyi.com/wp-content/uploads/2013/03/image_thumb.png \"image\")](http://hongweiyi.com/wp-content/uploads/2013/03/image.png)一图胜千言\n\n\t&nbsp;\n\n\t**3、远程仓库的配置**\n\n\t这位弟兄将《Maven实战》这个部分都给Copy到网上了，并加以标注，可以直接参考：[http://t.cn/zYgRHb7](http://t.cn/zYgRHb7)\n\n\t&nbsp;\n\n\t**4、Maven镜像**\n\n\t如果仓库X可以提供仓库Y存储的所有内容，那么就可以认为X是Y的一个镜像。Maven中央仓库在国内经常不能正常访问，连接超时不能下载资源之类的。在公司内部还挺好，有私服可以用，但是回家之后那龟爬的网速就难说了，一般来说可以配置Maven镜像。配置需要修改~/.m2/settings.xml，内容如下：\n\n[code lang=\"xml\"]\n&lt;settings&gt;\n  &lt;!--…--&gt;\n  &lt;mirrors&gt;\n    &lt;mirror&gt;\n      &lt;id&gt;maven.net.cn&lt;/id&gt;\n      &lt;name&gt;one of the central mirrors in China&lt;/name&gt;\n      &lt;url&gt;http://maven.net.cn/content/groups/public/&lt;/url&gt;\n      &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;\n    &lt;/mirror&gt;\n  &lt;/mirrors&gt;\n  &lt;!--…--&gt;\n&lt;/settings&gt;\n[/code]\n\n> **WARNING: **镜像仓库完全屏蔽了被镜像仓库，当镜像仓库不稳定或者不能访问的时候，Maven将无法访问被访问镜像。\n\n\t&nbsp;\n\n> **参考资料**：《Maven实战》","slug":"maven-repositories","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg622e004ksb8fy6qfb57u"},{"title":"Maven笔记 – 坐标与依赖","id":"707","date":"2013-03-17T12:47:05.000Z","_content":"\n**1、前言**\n\n\tMaven ['meivin]，原意为内行、专家，用在Java开发中则是用于项目构建、依赖管理和项目信息管理。仔细总结一下，我们会发现，除了编写源代码，我们每天都有相当一部分时间花在了编译、运行单元测试、生成文档、打包和部署等繁琐且不起眼的工作上，这就是构建了。通过Maven可以通过一个简单的命令，让所有繁琐的步骤都能够自动完成，很方便的得到最终结果。\n\n\t<!--more-->\n\n\t这篇就介绍Maven比较重要的两个基本概念，坐标与依赖。以下大多数都是总结自《Maven实战》的笔记：\n\n\t&nbsp;\n\n\t**2、Maven****坐标元素**\n\n\t在开发项目的时候，开发者会到处收集第三方构件，而第三方构件版本各异并且难以收集，会导致大量时间花费在搜索、浏览网页等工作上。Maven则提供了一种统一的规范，让开发者通过简单的标识来表示一个构件并可以自动找到这个构件，这个标识就是坐标。通过以下坐标元素，可以唯一定义一个构件：\n\n\t**groupId****：**定义当前Maven项目隶属的实际项目\n\n\t**artifactId****：**定义实际项目中的一个Maven项目（模块），推荐使用实际项目名称作为artifactId的前缀，方便寻找实际构件。如nexus-indexer是nexus的indexer模块。\n\n\t**version****：**Maven项目当前所处的版本。\n\n\t**packaging(optional)****：**该元素定义Maven项目的打包方式（jar、war）\n\n\t**classsifier(optional)****：**附属构件，如javadocs、sources等，TestNG就有一个为jdk5的附属构件。BTW，不能直接定义项目的classifer，需要附加的插件帮助生成。\n\n\t[code lang=\"xml\"]&lt;groupId&gt;com.hongweiyi&lt;/groupId&gt;\n&lt;artifactId&gt;HelloWorld&lt;/artifactId&gt;\n&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;\n&lt;packaging&gt;jar&lt;/packaging&gt;\n\n\t[/code]\n\n\t&nbsp;\n\n\t**3、依赖配置**\n\n\t**groupId****、artifactId、version：**这三个基本坐标，必须有。\n\n\t**type****：**依赖的类型，对应于项目坐标定义的packaging，默认值为jar。\n\n\t**scope****：**依赖范围\n\n\tMaven在编译项目住代码、编译执行测试、实际运行项目的时候都会用相应的一套classpath\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**依赖范围**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**对于编译classpath有效**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**对于测试classpath有效**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**对于运行时classpath有效**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**例子**\n\n\t\t\t</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\tcompile\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\tspring-core\n\n\t\t\t</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\ttest\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t-\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**-**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\tJUnit\n\n\t\t\t</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\tprovided\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**-**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\tservlet-api\n\n\t\t\t</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\truntime\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**-**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\tJDBC 驱动实现\n\n\t\t\t</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\tsystem\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**-**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t本地的，Maven仓库之外的类库文件\n\n\t\t\t</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\timport\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**-**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**-**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**-**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t导入依赖范围，并无实际影响\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t&nbsp;\n\n\t传递依赖，在使用某开源项目的时候，经常使用了某三方包后，发现该三方包还依赖其他包，这就不得不一个个导入相应的依赖包。而Maven则很方便，不用考虑三方包依赖了什么，Maven会直接解析各个直接依赖的POM，并将那些必要的间接依赖，以传递性依赖的形式引入到当前的项目中。\n\n\t传递依赖也会有问题，比如：A-&gt;B-&gt;C-&gt;X(1.0)；A-&gt;D-&gt;X(2.0)，在这种情况下，Maven依赖解调第一原则是：路径最近者优先。上面那个例子，X(2.0)路径较近，所以会优先解析它。那么如果路径长度一样怎么解析呢？如：A-&gt;B-&gt;X(1.0) A-&gt;C-&gt;X(2.0)，这个就要用Maven解调的第二原则：第一声明者优先。在路径长度相等的前提下，POM中依赖声明的顺序决定了谁会被解析使用。\n\n> BTW：依赖范围不仅可以控制依赖与三种classpath的关系，还对依赖性传递产生影响，这个影响有点绕，笔者还没弄太明白，就先不发了。T_T\n\n\t**optional****：**可选依赖。 (false / true)\n\n\tA-&gt;B, B-&gt;X(optional), B-&gt;Y(optional)\n\n\tA如果要用X或者Y的话，需要在POM中显示声明该Dependency。\n\n\t[code lang=\"xml\"]&lt;project&gt;\n&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n&lt;dependecies&gt;\n   &lt;dependecy&gt;\n      &lt;groupId&gt;com.hongweiyi.blog&lt;/groupId&gt;\n      &lt;artifactId&gt;project-b&lt;/artifactId&gt;\n      &lt;version&gt;1.0.0&lt;/version&gt;\n   &lt;/dependency&gt;\n   &lt;dependency&gt;        &lt;!-- 显示声明X (Y) --&gt;\n     &lt;groupId&gt;com.hongweiyi.blog&lt;/groupId&gt;\n     &lt;artifactId&gt;project-X&lt;/artifactId&gt; &lt;!--artifactId&gt;project-Y&lt;/artifactId--&gt;\n     &lt;version&gt;1.1.0&lt;/version&gt;\n   &lt;/dependency&gt;\n&lt;/dependencies&gt;\n&lt;/project&gt;\n\n\t[/code]\n\n\t**exclusions：**排除传递性依赖。\n\n\t传递性会给项目隐式地引入很多依赖，简化项目依赖管理的同时，也会带来一些风险。如果有一个三方包依赖，而这三方包依赖了另一个类库的SNAPSHOT版本，这个版本就成为了当前项目的传递性依赖，而SNAPSHOT的不稳定性也会直接影响到当前项目。所以需要将这个SNAPSHOT的版本给排除掉，并显示声明一个好用的版本。\n\n\t[code lang=\"xml\"]&lt;project&gt;\n&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n&lt;dependecies&gt;\n   &lt;dependecy&gt;\n      &lt;groupId&gt;com.hongweiyi.blog&lt;/groupId&gt;\n      &lt;artifactId&gt;project-b&lt;/artifactId&gt;\n      &lt;version&gt;1.0.0&lt;/version&gt;\n      &lt;exclusions&gt;\n         &lt;exclusion&gt;      &lt;!-- 排除project-c --&gt;\n            &lt;groupId&gt;com.hongweiyi.blog&lt;/groupId&gt;\n            &lt;artifactId&gt;project-c&lt;/artifactId&gt;\n          &lt;/exclusion&gt;\n      &lt;exclusions&gt;\n   &lt;/dependency&gt;\n   &lt;dependency&gt;        &lt;!-- 重新声明project-c 1.1.0版 --&gt;\n     &lt;groupId&gt;com.hongweiyi.blog&lt;/groupId&gt;\n     &lt;artifactId&gt;project-c&lt;/artifactId&gt;\n     &lt;version&gt;1.1.0&lt;/version&gt;\n   &lt;/dependency&gt;\n&lt;/dependencies&gt;\n&lt;/project&gt;\n\n\t[/code]\n\n\t&nbsp;\n\n> 参考资料：《Maven实战》","source":"_posts/maven-coordinates-dependencies.md","raw":"title: Maven笔记 – 坐标与依赖\ntags:\n  - java\n  - Maven\nid: 707\ncategories:\n  - 技术分享\ndate: 2013-03-17 20:47:05\n---\n\n**1、前言**\n\n\tMaven ['meivin]，原意为内行、专家，用在Java开发中则是用于项目构建、依赖管理和项目信息管理。仔细总结一下，我们会发现，除了编写源代码，我们每天都有相当一部分时间花在了编译、运行单元测试、生成文档、打包和部署等繁琐且不起眼的工作上，这就是构建了。通过Maven可以通过一个简单的命令，让所有繁琐的步骤都能够自动完成，很方便的得到最终结果。\n\n\t<!--more-->\n\n\t这篇就介绍Maven比较重要的两个基本概念，坐标与依赖。以下大多数都是总结自《Maven实战》的笔记：\n\n\t&nbsp;\n\n\t**2、Maven****坐标元素**\n\n\t在开发项目的时候，开发者会到处收集第三方构件，而第三方构件版本各异并且难以收集，会导致大量时间花费在搜索、浏览网页等工作上。Maven则提供了一种统一的规范，让开发者通过简单的标识来表示一个构件并可以自动找到这个构件，这个标识就是坐标。通过以下坐标元素，可以唯一定义一个构件：\n\n\t**groupId****：**定义当前Maven项目隶属的实际项目\n\n\t**artifactId****：**定义实际项目中的一个Maven项目（模块），推荐使用实际项目名称作为artifactId的前缀，方便寻找实际构件。如nexus-indexer是nexus的indexer模块。\n\n\t**version****：**Maven项目当前所处的版本。\n\n\t**packaging(optional)****：**该元素定义Maven项目的打包方式（jar、war）\n\n\t**classsifier(optional)****：**附属构件，如javadocs、sources等，TestNG就有一个为jdk5的附属构件。BTW，不能直接定义项目的classifer，需要附加的插件帮助生成。\n\n\t[code lang=\"xml\"]&lt;groupId&gt;com.hongweiyi&lt;/groupId&gt;\n&lt;artifactId&gt;HelloWorld&lt;/artifactId&gt;\n&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;\n&lt;packaging&gt;jar&lt;/packaging&gt;\n\n\t[/code]\n\n\t&nbsp;\n\n\t**3、依赖配置**\n\n\t**groupId****、artifactId、version：**这三个基本坐标，必须有。\n\n\t**type****：**依赖的类型，对应于项目坐标定义的packaging，默认值为jar。\n\n\t**scope****：**依赖范围\n\n\tMaven在编译项目住代码、编译执行测试、实际运行项目的时候都会用相应的一套classpath\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**依赖范围**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**对于编译classpath有效**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**对于测试classpath有效**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**对于运行时classpath有效**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**例子**\n\n\t\t\t</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\tcompile\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\tspring-core\n\n\t\t\t</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\ttest\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t-\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**-**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\tJUnit\n\n\t\t\t</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\tprovided\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**-**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\tservlet-api\n\n\t\t\t</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\truntime\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**-**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\tJDBC 驱动实现\n\n\t\t\t</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\tsystem\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**Y**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**-**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t本地的，Maven仓库之外的类库文件\n\n\t\t\t</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\timport\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**-**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**-**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t**-**\n\n\t\t\t</td>\n\t\t\t<td valign=\"top\">\n\n\t\t\t\t\t导入依赖范围，并无实际影响\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t&nbsp;\n\n\t传递依赖，在使用某开源项目的时候，经常使用了某三方包后，发现该三方包还依赖其他包，这就不得不一个个导入相应的依赖包。而Maven则很方便，不用考虑三方包依赖了什么，Maven会直接解析各个直接依赖的POM，并将那些必要的间接依赖，以传递性依赖的形式引入到当前的项目中。\n\n\t传递依赖也会有问题，比如：A-&gt;B-&gt;C-&gt;X(1.0)；A-&gt;D-&gt;X(2.0)，在这种情况下，Maven依赖解调第一原则是：路径最近者优先。上面那个例子，X(2.0)路径较近，所以会优先解析它。那么如果路径长度一样怎么解析呢？如：A-&gt;B-&gt;X(1.0) A-&gt;C-&gt;X(2.0)，这个就要用Maven解调的第二原则：第一声明者优先。在路径长度相等的前提下，POM中依赖声明的顺序决定了谁会被解析使用。\n\n> BTW：依赖范围不仅可以控制依赖与三种classpath的关系，还对依赖性传递产生影响，这个影响有点绕，笔者还没弄太明白，就先不发了。T_T\n\n\t**optional****：**可选依赖。 (false / true)\n\n\tA-&gt;B, B-&gt;X(optional), B-&gt;Y(optional)\n\n\tA如果要用X或者Y的话，需要在POM中显示声明该Dependency。\n\n\t[code lang=\"xml\"]&lt;project&gt;\n&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n&lt;dependecies&gt;\n   &lt;dependecy&gt;\n      &lt;groupId&gt;com.hongweiyi.blog&lt;/groupId&gt;\n      &lt;artifactId&gt;project-b&lt;/artifactId&gt;\n      &lt;version&gt;1.0.0&lt;/version&gt;\n   &lt;/dependency&gt;\n   &lt;dependency&gt;        &lt;!-- 显示声明X (Y) --&gt;\n     &lt;groupId&gt;com.hongweiyi.blog&lt;/groupId&gt;\n     &lt;artifactId&gt;project-X&lt;/artifactId&gt; &lt;!--artifactId&gt;project-Y&lt;/artifactId--&gt;\n     &lt;version&gt;1.1.0&lt;/version&gt;\n   &lt;/dependency&gt;\n&lt;/dependencies&gt;\n&lt;/project&gt;\n\n\t[/code]\n\n\t**exclusions：**排除传递性依赖。\n\n\t传递性会给项目隐式地引入很多依赖，简化项目依赖管理的同时，也会带来一些风险。如果有一个三方包依赖，而这三方包依赖了另一个类库的SNAPSHOT版本，这个版本就成为了当前项目的传递性依赖，而SNAPSHOT的不稳定性也会直接影响到当前项目。所以需要将这个SNAPSHOT的版本给排除掉，并显示声明一个好用的版本。\n\n\t[code lang=\"xml\"]&lt;project&gt;\n&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n&lt;dependecies&gt;\n   &lt;dependecy&gt;\n      &lt;groupId&gt;com.hongweiyi.blog&lt;/groupId&gt;\n      &lt;artifactId&gt;project-b&lt;/artifactId&gt;\n      &lt;version&gt;1.0.0&lt;/version&gt;\n      &lt;exclusions&gt;\n         &lt;exclusion&gt;      &lt;!-- 排除project-c --&gt;\n            &lt;groupId&gt;com.hongweiyi.blog&lt;/groupId&gt;\n            &lt;artifactId&gt;project-c&lt;/artifactId&gt;\n          &lt;/exclusion&gt;\n      &lt;exclusions&gt;\n   &lt;/dependency&gt;\n   &lt;dependency&gt;        &lt;!-- 重新声明project-c 1.1.0版 --&gt;\n     &lt;groupId&gt;com.hongweiyi.blog&lt;/groupId&gt;\n     &lt;artifactId&gt;project-c&lt;/artifactId&gt;\n     &lt;version&gt;1.1.0&lt;/version&gt;\n   &lt;/dependency&gt;\n&lt;/dependencies&gt;\n&lt;/project&gt;\n\n\t[/code]\n\n\t&nbsp;\n\n> 参考资料：《Maven实战》","slug":"maven-coordinates-dependencies","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg622h004psb8fm9udo4dh"},{"title":"Map/Reduce Task源码分析","id":"603","date":"2012-10-18T14:22:02.000Z","_content":"\n**一、序言**\n\n这篇文章从十一前开始写，陆陆续续看源码并理解其中的原理。主要了解了Map/Reduce的运行流程，并仔细分析了Map流程以及一些细节，但是没有分析仔细Reduce Task，因为和一个朋友@[lidonghua1990](http://weibo.com/getix2010)一起分析的，他分析ReduceTask，这篇文章的Reduce的注释部分也是由他添加。等到他分析完Reduce之后，再将链接填上……\n<!--more-->\n\n&#160;\n\n**二、源码流程分析**\n\n**[![clip_image001[4]](http://hongweiyi.com/wp-content/uploads/2012/10/clip_image0014_thumb.jpg \"clip_image001[4]\")](http://hongweiyi.com/wp-content/uploads/2012/10/clip_image0014.jpg)**\n\n-----------------------------Start-----------------------------------    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\" width=\"642\"><tbody>       <tr>         <td valign=\"top\" width=\"640\">           <p>**【****Map Phrase****】**\n\n// MapTask\n\n**1\\. map.run();**\n\n&#160; |- map(getCurrentKey(), getCurrentValue(), context);\n\n// MapTask$NewOutputCollector\n\n**2\\. context.write(key, value);**\n\n&#160; |- collector.collect(key, value, partioner.getPartition());\n\n// MapTask$MapOutputBuffer\n\n**3\\. startSpill();**\n\n&#160; |- spillReady.signal(); // spillThread is waiting\n\n&#160; |- spillThread.sortAndSpill();\n\n&#160; |--- sorter.sort();&#160;&#160;&#160;&#160;&#160;&#160; // default: QuickSort.class\n\n&#160; |--- if (combiner != null) combiner.combine();\n\n&#160; |--- writer.close();&#160;&#160;&#160;&#160; // flush data\n\n// MapTask$NewOutputCollector\n\n// MapTask$MapOutputBuffer\n\n**4\\. output.close(context);**\n\n&#160; |- collector.flush();\n\n&#160; |--- SortAndSpill();&#160;&#160;&#160; // output last mem data\n\n&#160; |--- MergeParts();\n\n&#160; |----- Merge.merge();&#160; // merge and sort\n\n&#160; |----- combinerRunner.combine(kvIter, combineCollector);\n         </td>       </tr>     </tbody></table> </p>  \n\n----------------------Tmp Data(On disk)-------------------------------\n\n[![Image](http://hongweiyi.com/wp-content/uploads/2012/10/Image_thumb.jpg \"Image\")](http://hongweiyi.com/wp-content/uploads/2012/10/Image.jpg)&#160;&#160; <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\" width=\"645\"><tbody>       <tr>         <td valign=\"top\" width=\"643\">           <p>**【****Reduce Phrase****】**\n\n// LocalJobRunner$Job\n\n**0\\. reduce.run(localConf, this);**\n\n// ReduceTask\n\n**1\\. reduceCopier.fetchOutputs();** // only if data is on HDFS\n\n&#160; |- copier.start(); // **mapred.reduce.parallel.copies** MapOutputCopiers\n\n&#160; |--- copyOutput(loc); // loc is the location in buffer\n\n&#160; |----- getMapOutput(); // from remote host to a ramfs/localFS file\n\n&#160; |------- // setup connection, validates header\n\n&#160; |------- boolean shuffleInMemory = ramManager.canFitInMemory(decompressedLength); // check if data fit in mem else use localFS\n\n&#160; |------- shuffleInMemory(); / shuffleToDisk(); // return a MapOutput\n\n&#160; |----- // add to list (if in mem) / rename to final name (if in localFS)\n\n&#160; |- localFSMergerThread.start(); // ReduceTask$ReduceCopier$LocalFSMerger.run()\n\n&#160; |--- // wait if number of files &lt; 2*ioSortFactor - 1\n\n&#160; |--- Merger.merge(**sortSegments==true**); // merge **io.sort.factor** files ino 1\n\n&#160; |- inMemFSMergeThread.start(); // ReduceTask$ReduceCopier$InMemFSMergeThread.run()\n\n&#160; |--- ramManager.waitForDataToMerge();\n\n&#160; |--- doInMemMerge();\n\n&#160; |----- createInMemorySegments(...);\n\n&#160; |----- Merger.merge(**sortSegments==false**);\n\n&#160; |--- if (combinerRunner != null) combinerRunner.combine(rIter, combineCollector);\n\n&#160; |- // schedule until get all required outputs (using exp-back-off for retries on failures)\n\n// multi-pass (**factor** segments/pass), using **hadoop.util.PriorityQueue**\n\n**2\\. Merger.merge();**\n\n&#160; |- factor = getPassFactor(); // btw: first pass is special\n\n&#160; |- // set segmentsToMerge (sorted) and put them into PriorityQueue\n\n&#160; |- // merge into a temp file, add to **MergeQueue.segments**, and sort\n\n&#160; |- // loop until number of segments &lt; factor\n\n**3\\. runReducer();**\n         </td>       </tr>     </tbody></table> </p>  \n\n-----------------------------Done------------------------------------\n\n**三、部分问题分析**\n\n**1****）如何排序并输出的？**\n\nsortAndSpill();\n\nmapper接收到map端的输出后，会将所有的输出数据写入一个缓存中，当缓存大小超过一定阈值的时候，就会锁住部分数据，将这些数据写入磁盘中。没被锁住的数据则可继续写入，不受写操作影响。阈值等于io.sort.mb(100MB) * io.sort.spill.percent(0.8)。\n\n缓存采用的circle buffer，看似简单，但是hadoop中还是会有点小技巧，详细的可以看caibinbupt的博客（[分析1](http://caibinbupt.iteye.com/blog/402849)，[分析2](http://caibinbupt.iteye.com/blog/402214)），里面比较详细。\n\n缓存一般是用byte数组存，因为这样可以严格控制缓存大小。当然，如果记录大小一致的话，可以开相应的对象数组。但是，map中的缓存kv数据大小不一致，这样要排序的话，就会有很多问题：\n\n如何快速定位其中的排序键；定位了快速键之后，由于记录大小不一，原地排序会带来大量的数据交换。\n\n为了避免这样的问题出现，mapreduce实现中提供了两个索引记录，第一个为kvindices（kvpair1[partion1, key1_start, value1_start], kvpair2[partition2, key2_start, value2_start]），这个索引指向缓存中记录的起始位置；第二个为kvoffsets，记录kvindices中kvpair的位置，只需要比较kvoffsets中所对应的partition值以及key值再交换kvoffsets中的值即可完成排序。\n\n**[](http://hongweiyi.com/wp-content/uploads/2012/10/clip_image0054.jpg)**\n\n**[![Image](http://hongweiyi.com/wp-content/uploads/2012/10/Image_thumb1.jpg \"Image\")](http://hongweiyi.com/wp-content/uploads/2012/10/Image1.jpg)**\n\n** 2****）****combine****什么时候执行的？**\n\n· 在map端内存溢写到磁盘的时候会执行combine（可配置不执行，min.num.spills.for.combine默认为3，当spill数少于3的时候，就不会执行）；\n\n· 在map端合并磁盘溢写文件的时候会执行combine；\n\n· 在reduce端合并内存拉取文件的时候会执行combine（inMemFSMergeThread）。\n\n为什么在localFSMergerThread中不执行combine呢？因为这个时候执行的combine就是reduce过程了。\n\n**3****）****segment****和****group****是啥？**\n\n**segment**\n\n每个map端划分出来的partition所对应的数据块为一个segment。如下，partition0/1/2所对应spill.out的一段数据均为一个segment。\n\n即segment是map端merge spills，以及reduce端merge从map端copy过来的数据的逻辑单元。\n\n[![Image](http://hongweiyi.com/wp-content/uploads/2012/10/Image_thumb2.jpg \"Image\")](http://hongweiyi.com/wp-content/uploads/2012/10/Image2.jpg)&#160;**group**\n\n个人理解就是reduce端进入一个reduce()方法的数据称之为一个group。默认按key分组。一般来说，用户涉及到group也就是二次排序的时候需要用到，因为需要自定义分组。可以参见《Hadoop权威指南》第8章的辅助排序。\n\n**4****）如何合并文件？**\n\nMap阶段的合并发生在spill完所有文件之后，而Reduce阶段则发生在copyPhrase结束之后，两者逻辑是一直的，所以hadoop将合并写成了通用组件，即Merger。在分析Merger的前，需要了解segment（Merger$Segment）的概念，可以参见前文。\n\n将合并过程简单化：即有一些已经排好序的文件（Segment），需要对其进行合并并排序。需要和解决方案都很明显，用多路归并排序。\n\nMerger类实现了一个merge方法，该方法生成了一个MergeQueue实例，并调用了该实例的merge方法。MergeQueue继承了PriorityQueue。归并排序的时候需要取多个文件的最小值，hadoop实现是采用的小根堆，比较方法是Merger中的lessThan(a,b)，它会读取segment中当前key，并使用用户自定义类的comparator进行比较。归并路数根据io.sort.factor(10)设置。\n\n**五、我之前的的认识误区**\n\n1）**map****输出记录格式是怎样的？**\n\nmap的输出为：(key1, value1); (key1, value2); (key1, value3)，而不是：(key1, list(value1, value2, value3))，这个只是逻辑上的格式。\n\n为什么这样呢：\n\n猜测： 一个key对应的list过大的话，内存放不下；不如来一条记录，输出一条记录。所以如果设置了combiner的话，最后对数据的压缩是很可观的。\n\n**2****）是否可以将****mr****中的临时数据不写入磁盘？**\n\n从源码的角度来说，是不可能的。可以考虑**[Spark](http://www.spark-project.org/)**以及**[Storm](https://github.com/nathanmarz/storm)**的实现。\n\n**六、参考资料**\n  > [MapReduce: 详解Shuffle流程](http://langyu.iteye.com/blog/992916)\n> \n> [caibinbupt的博客](http://caibinbupt.iteye.com/blog/401374)\n> \n> 《hadoop权威指南》  \n\nP.S.: 源码版本 0.20.203.0","source":"_posts/mapreduce-task-src-analysis.md","raw":"title: Map/Reduce Task源码分析\ntags:\n  - Hadoop\n  - MapReduce\nid: 603\ncategories:\n  - 技术分享\ndate: 2012-10-18 22:22:02\n---\n\n**一、序言**\n\n这篇文章从十一前开始写，陆陆续续看源码并理解其中的原理。主要了解了Map/Reduce的运行流程，并仔细分析了Map流程以及一些细节，但是没有分析仔细Reduce Task，因为和一个朋友@[lidonghua1990](http://weibo.com/getix2010)一起分析的，他分析ReduceTask，这篇文章的Reduce的注释部分也是由他添加。等到他分析完Reduce之后，再将链接填上……\n<!--more-->\n\n&#160;\n\n**二、源码流程分析**\n\n**[![clip_image001[4]](http://hongweiyi.com/wp-content/uploads/2012/10/clip_image0014_thumb.jpg \"clip_image001[4]\")](http://hongweiyi.com/wp-content/uploads/2012/10/clip_image0014.jpg)**\n\n-----------------------------Start-----------------------------------    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\" width=\"642\"><tbody>       <tr>         <td valign=\"top\" width=\"640\">           <p>**【****Map Phrase****】**\n\n// MapTask\n\n**1\\. map.run();**\n\n&#160; |- map(getCurrentKey(), getCurrentValue(), context);\n\n// MapTask$NewOutputCollector\n\n**2\\. context.write(key, value);**\n\n&#160; |- collector.collect(key, value, partioner.getPartition());\n\n// MapTask$MapOutputBuffer\n\n**3\\. startSpill();**\n\n&#160; |- spillReady.signal(); // spillThread is waiting\n\n&#160; |- spillThread.sortAndSpill();\n\n&#160; |--- sorter.sort();&#160;&#160;&#160;&#160;&#160;&#160; // default: QuickSort.class\n\n&#160; |--- if (combiner != null) combiner.combine();\n\n&#160; |--- writer.close();&#160;&#160;&#160;&#160; // flush data\n\n// MapTask$NewOutputCollector\n\n// MapTask$MapOutputBuffer\n\n**4\\. output.close(context);**\n\n&#160; |- collector.flush();\n\n&#160; |--- SortAndSpill();&#160;&#160;&#160; // output last mem data\n\n&#160; |--- MergeParts();\n\n&#160; |----- Merge.merge();&#160; // merge and sort\n\n&#160; |----- combinerRunner.combine(kvIter, combineCollector);\n         </td>       </tr>     </tbody></table> </p>  \n\n----------------------Tmp Data(On disk)-------------------------------\n\n[![Image](http://hongweiyi.com/wp-content/uploads/2012/10/Image_thumb.jpg \"Image\")](http://hongweiyi.com/wp-content/uploads/2012/10/Image.jpg)&#160;&#160; <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\" width=\"645\"><tbody>       <tr>         <td valign=\"top\" width=\"643\">           <p>**【****Reduce Phrase****】**\n\n// LocalJobRunner$Job\n\n**0\\. reduce.run(localConf, this);**\n\n// ReduceTask\n\n**1\\. reduceCopier.fetchOutputs();** // only if data is on HDFS\n\n&#160; |- copier.start(); // **mapred.reduce.parallel.copies** MapOutputCopiers\n\n&#160; |--- copyOutput(loc); // loc is the location in buffer\n\n&#160; |----- getMapOutput(); // from remote host to a ramfs/localFS file\n\n&#160; |------- // setup connection, validates header\n\n&#160; |------- boolean shuffleInMemory = ramManager.canFitInMemory(decompressedLength); // check if data fit in mem else use localFS\n\n&#160; |------- shuffleInMemory(); / shuffleToDisk(); // return a MapOutput\n\n&#160; |----- // add to list (if in mem) / rename to final name (if in localFS)\n\n&#160; |- localFSMergerThread.start(); // ReduceTask$ReduceCopier$LocalFSMerger.run()\n\n&#160; |--- // wait if number of files &lt; 2*ioSortFactor - 1\n\n&#160; |--- Merger.merge(**sortSegments==true**); // merge **io.sort.factor** files ino 1\n\n&#160; |- inMemFSMergeThread.start(); // ReduceTask$ReduceCopier$InMemFSMergeThread.run()\n\n&#160; |--- ramManager.waitForDataToMerge();\n\n&#160; |--- doInMemMerge();\n\n&#160; |----- createInMemorySegments(...);\n\n&#160; |----- Merger.merge(**sortSegments==false**);\n\n&#160; |--- if (combinerRunner != null) combinerRunner.combine(rIter, combineCollector);\n\n&#160; |- // schedule until get all required outputs (using exp-back-off for retries on failures)\n\n// multi-pass (**factor** segments/pass), using **hadoop.util.PriorityQueue**\n\n**2\\. Merger.merge();**\n\n&#160; |- factor = getPassFactor(); // btw: first pass is special\n\n&#160; |- // set segmentsToMerge (sorted) and put them into PriorityQueue\n\n&#160; |- // merge into a temp file, add to **MergeQueue.segments**, and sort\n\n&#160; |- // loop until number of segments &lt; factor\n\n**3\\. runReducer();**\n         </td>       </tr>     </tbody></table> </p>  \n\n-----------------------------Done------------------------------------\n\n**三、部分问题分析**\n\n**1****）如何排序并输出的？**\n\nsortAndSpill();\n\nmapper接收到map端的输出后，会将所有的输出数据写入一个缓存中，当缓存大小超过一定阈值的时候，就会锁住部分数据，将这些数据写入磁盘中。没被锁住的数据则可继续写入，不受写操作影响。阈值等于io.sort.mb(100MB) * io.sort.spill.percent(0.8)。\n\n缓存采用的circle buffer，看似简单，但是hadoop中还是会有点小技巧，详细的可以看caibinbupt的博客（[分析1](http://caibinbupt.iteye.com/blog/402849)，[分析2](http://caibinbupt.iteye.com/blog/402214)），里面比较详细。\n\n缓存一般是用byte数组存，因为这样可以严格控制缓存大小。当然，如果记录大小一致的话，可以开相应的对象数组。但是，map中的缓存kv数据大小不一致，这样要排序的话，就会有很多问题：\n\n如何快速定位其中的排序键；定位了快速键之后，由于记录大小不一，原地排序会带来大量的数据交换。\n\n为了避免这样的问题出现，mapreduce实现中提供了两个索引记录，第一个为kvindices（kvpair1[partion1, key1_start, value1_start], kvpair2[partition2, key2_start, value2_start]），这个索引指向缓存中记录的起始位置；第二个为kvoffsets，记录kvindices中kvpair的位置，只需要比较kvoffsets中所对应的partition值以及key值再交换kvoffsets中的值即可完成排序。\n\n**[](http://hongweiyi.com/wp-content/uploads/2012/10/clip_image0054.jpg)**\n\n**[![Image](http://hongweiyi.com/wp-content/uploads/2012/10/Image_thumb1.jpg \"Image\")](http://hongweiyi.com/wp-content/uploads/2012/10/Image1.jpg)**\n\n** 2****）****combine****什么时候执行的？**\n\n· 在map端内存溢写到磁盘的时候会执行combine（可配置不执行，min.num.spills.for.combine默认为3，当spill数少于3的时候，就不会执行）；\n\n· 在map端合并磁盘溢写文件的时候会执行combine；\n\n· 在reduce端合并内存拉取文件的时候会执行combine（inMemFSMergeThread）。\n\n为什么在localFSMergerThread中不执行combine呢？因为这个时候执行的combine就是reduce过程了。\n\n**3****）****segment****和****group****是啥？**\n\n**segment**\n\n每个map端划分出来的partition所对应的数据块为一个segment。如下，partition0/1/2所对应spill.out的一段数据均为一个segment。\n\n即segment是map端merge spills，以及reduce端merge从map端copy过来的数据的逻辑单元。\n\n[![Image](http://hongweiyi.com/wp-content/uploads/2012/10/Image_thumb2.jpg \"Image\")](http://hongweiyi.com/wp-content/uploads/2012/10/Image2.jpg)&#160;**group**\n\n个人理解就是reduce端进入一个reduce()方法的数据称之为一个group。默认按key分组。一般来说，用户涉及到group也就是二次排序的时候需要用到，因为需要自定义分组。可以参见《Hadoop权威指南》第8章的辅助排序。\n\n**4****）如何合并文件？**\n\nMap阶段的合并发生在spill完所有文件之后，而Reduce阶段则发生在copyPhrase结束之后，两者逻辑是一直的，所以hadoop将合并写成了通用组件，即Merger。在分析Merger的前，需要了解segment（Merger$Segment）的概念，可以参见前文。\n\n将合并过程简单化：即有一些已经排好序的文件（Segment），需要对其进行合并并排序。需要和解决方案都很明显，用多路归并排序。\n\nMerger类实现了一个merge方法，该方法生成了一个MergeQueue实例，并调用了该实例的merge方法。MergeQueue继承了PriorityQueue。归并排序的时候需要取多个文件的最小值，hadoop实现是采用的小根堆，比较方法是Merger中的lessThan(a,b)，它会读取segment中当前key，并使用用户自定义类的comparator进行比较。归并路数根据io.sort.factor(10)设置。\n\n**五、我之前的的认识误区**\n\n1）**map****输出记录格式是怎样的？**\n\nmap的输出为：(key1, value1); (key1, value2); (key1, value3)，而不是：(key1, list(value1, value2, value3))，这个只是逻辑上的格式。\n\n为什么这样呢：\n\n猜测： 一个key对应的list过大的话，内存放不下；不如来一条记录，输出一条记录。所以如果设置了combiner的话，最后对数据的压缩是很可观的。\n\n**2****）是否可以将****mr****中的临时数据不写入磁盘？**\n\n从源码的角度来说，是不可能的。可以考虑**[Spark](http://www.spark-project.org/)**以及**[Storm](https://github.com/nathanmarz/storm)**的实现。\n\n**六、参考资料**\n  > [MapReduce: 详解Shuffle流程](http://langyu.iteye.com/blog/992916)\n> \n> [caibinbupt的博客](http://caibinbupt.iteye.com/blog/401374)\n> \n> 《hadoop权威指南》  \n\nP.S.: 源码版本 0.20.203.0","slug":"mapreduce-task-src-analysis","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg622j004tsb8f9lmz1p8i"},{"title":"MapReduce优化（一）","id":"265","date":"2012-02-11T15:36:10.000Z","_content":"\n**一、概述**\n\n这篇博文主要是解决上一篇&lt;[迭代式MapReduce解决方案（一）](http://www.hongweiyi.com/?p=250)&gt;中总结所提到的第三个问题，与网上大多数Hadoop调优（&lt;[董的博客](http://dongxicheng.org/tag/hadoop%E4%BC%98%E5%8C%96/)&gt;、&lt;[淘宝数据平台](http://www.tbdata.org/archives/1470)&gt;）不太一样，网上告诉的是方法，但是方法是什么以及优化后能达到什么效果没有一个直观的感受。这篇博文讲述了一些简单的优化手段，可将140M的临时文件缩小到4.9M，期望能有一些对优化一些更为直观的感受，起到抛砖引玉的作用。\n <!--more-->  \n\n**二、问题的提出**\n\n用的例子依然是上篇博客讲到的PageRank计算，其中输入数据为随机生成的100W行记录，大小3.22G。我们也可以来粗略的估算一下，单个map task生成的临时文件大小：\n\n3.22G数据，100W记录。每行平均32kb，一个split为64M，约2W行数据。由于是随机生成的数据，所以每行平均约为500个外链地址，每个连接地址都会生成一行临时结果&lt;URL_ID AER_PR&gt;，算每行结果15字节，那么最后的生成结果为2W×500×15b = 150M。\n\n而实际上，在不进行任何优化的情况下，一个map task生成的临时文件为140.6M，很大的结果啊！\n\n**三、优化方案**\n\n**1****、设置combiner**\n\nMapreduce中的Combiner就是为了避免map任务和reduce任务之间的数据传输而设置的，Hadoop允许用户针对map task的输出指定一个合并函数。\n\n对于Combiner有几点需要说明的是：\n\n1）有很多人认为这个combiner和map输出的数据合并是一个过程，其实不然，map输出的数据合并只会产生在有数据spill出的时候，即进行merge操作。\n\n2）与mapper与reducer不同的是，combiner没有默认的实现，需要显式的设置在conf中才有作用。\n\n3）并不是所有的job都适用combiner，只有操作满足结合律的才可设置combiner。combine操作类似于：opt(opt(1, 2, 3), opt(4, 5, 6))。如果opt为求和、求最大值的话，可以使用，但是如果是求中值的话，不适用。\n\n4）一般来说，combiner即reducer，它们俩进行同样的操作。\n\n对于PageRank计算来说，单个reduce操作即对值求和，适用combine操作。添加代码如下：\n  > job.setCombinerClass(PRReducer.class);  \n\n最后输出结果大小28.3M，“压缩”比约为20%。\n\n**2****、数据压缩**\n\n顾名思义，对输出结果进行压缩，Hadoop称之为codec。下面列举一些常见的codec：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"123\">           <p>**压缩格式**\n         </td>          <td valign=\"top\" width=\"406\">           \n\n**HadoopCompressionCodec**\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">           \n\nDEFLATE\n         </td>          <td valign=\"top\" width=\"406\">           \n\norg.apache.hadoop.io.compress.DefaultCodec\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">           \n\ngzip\n         </td>          <td valign=\"top\" width=\"406\">           \n\norg.apache.hadoop.io.compress.GzipCodec\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">           \n\nbzip2\n         </td>          <td valign=\"top\" width=\"406\">           \n\norg.apache.hadoop.io.compress.BZip2Codec\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">           \n\nLZO\n         </td>          <td valign=\"top\" width=\"406\">           \n\ncom.hadoop.compression.lzo.LzopCodec\n         </td>       </tr>     </tbody></table> </p>  \n\n以下两行代码即可：\n  > conf.setBoolean(&quot;mapred.compress.map.output&quot;, true);\n> \n> conf.set (&quot;mapred.map.output.compression.codec&quot;, &quot;***Codec&quot;);  \n\n但需要注意的是，时间与空间永远是矛盾的，若要获得大的压缩比就会降低一些时间效率。通常来说，想要达到cpu和磁盘压缩比的平衡取舍，LzoCodec比较适合。不过由于GPL许可的原因，该库没有包含在Apache的发行版中，需要单独从**[Google Code](http://code.google.com/p/hadoop-gpl-compression)**或**[GitHub](https://github.com/kevinweil/hadoop-lzo)**下载，其中后者包含有修正的软件错误及其它一些工具。\n\n本文使用的是默认的压缩方式DefaultCodec，压缩比约为29%。\n\n**3****、查看临时文件内部，具体情况具体分析**\n\n[![clip_image002](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image002_thumb.jpg \"clip_image002\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image002.jpg)\n\n上面的文件就是我的临时文件内部格式， value在内存中为DoubleWritable，没有考虑精度问题。一个value数据输出后，就会占20字节，我们是否需要这么高的精度呢？\n\n我觉得是不需要，不需要的话，就是将输出数据精度降低，实验中将double精度降至6位，“压缩”比约为59%。这个例子很实在，即对于每个任务来说，不仅仅是job conf需要优化，其自身算法或者说数据格式都还有很大的优化空间。没有最好，只有更好！\n\n**四、总结**\n\n经过上面几个“简单”的优化，代码行数修改寥寥几行，临时数据从140.6M降到了4.9M，压缩比为3.49%。需要注意的是，实验所用数据是模拟的，且数据分布较为均匀，故在实际生产环境中压缩比应该没这么高，所以需要根据job的实际情况，选择combine、压缩、数据格式，但其所带来的优化结果仍会很可观。\n\n本文只是简要的抽出了一些方便做实验的优化方法，更多的更广的配置、代码优化方法，敬请期待以后的博文。\n  > **参考资料：**\n> \n> &lt; [hadoop作业调优参数整理及原理](http://www.tbdata.org/archives/1470)&gt;\n> \n> &lt;Hadoop权威指南 &gt;","source":"_posts/mapred-optimize.md","raw":"title: MapReduce优化（一）\ntags:\n  - Hadoop\n  - MapReduce\nid: 265\ncategories:\n  - 技术分享\ndate: 2012-02-11 23:36:10\n---\n\n**一、概述**\n\n这篇博文主要是解决上一篇&lt;[迭代式MapReduce解决方案（一）](http://www.hongweiyi.com/?p=250)&gt;中总结所提到的第三个问题，与网上大多数Hadoop调优（&lt;[董的博客](http://dongxicheng.org/tag/hadoop%E4%BC%98%E5%8C%96/)&gt;、&lt;[淘宝数据平台](http://www.tbdata.org/archives/1470)&gt;）不太一样，网上告诉的是方法，但是方法是什么以及优化后能达到什么效果没有一个直观的感受。这篇博文讲述了一些简单的优化手段，可将140M的临时文件缩小到4.9M，期望能有一些对优化一些更为直观的感受，起到抛砖引玉的作用。\n <!--more-->  \n\n**二、问题的提出**\n\n用的例子依然是上篇博客讲到的PageRank计算，其中输入数据为随机生成的100W行记录，大小3.22G。我们也可以来粗略的估算一下，单个map task生成的临时文件大小：\n\n3.22G数据，100W记录。每行平均32kb，一个split为64M，约2W行数据。由于是随机生成的数据，所以每行平均约为500个外链地址，每个连接地址都会生成一行临时结果&lt;URL_ID AER_PR&gt;，算每行结果15字节，那么最后的生成结果为2W×500×15b = 150M。\n\n而实际上，在不进行任何优化的情况下，一个map task生成的临时文件为140.6M，很大的结果啊！\n\n**三、优化方案**\n\n**1****、设置combiner**\n\nMapreduce中的Combiner就是为了避免map任务和reduce任务之间的数据传输而设置的，Hadoop允许用户针对map task的输出指定一个合并函数。\n\n对于Combiner有几点需要说明的是：\n\n1）有很多人认为这个combiner和map输出的数据合并是一个过程，其实不然，map输出的数据合并只会产生在有数据spill出的时候，即进行merge操作。\n\n2）与mapper与reducer不同的是，combiner没有默认的实现，需要显式的设置在conf中才有作用。\n\n3）并不是所有的job都适用combiner，只有操作满足结合律的才可设置combiner。combine操作类似于：opt(opt(1, 2, 3), opt(4, 5, 6))。如果opt为求和、求最大值的话，可以使用，但是如果是求中值的话，不适用。\n\n4）一般来说，combiner即reducer，它们俩进行同样的操作。\n\n对于PageRank计算来说，单个reduce操作即对值求和，适用combine操作。添加代码如下：\n  > job.setCombinerClass(PRReducer.class);  \n\n最后输出结果大小28.3M，“压缩”比约为20%。\n\n**2****、数据压缩**\n\n顾名思义，对输出结果进行压缩，Hadoop称之为codec。下面列举一些常见的codec：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"123\">           <p>**压缩格式**\n         </td>          <td valign=\"top\" width=\"406\">           \n\n**HadoopCompressionCodec**\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">           \n\nDEFLATE\n         </td>          <td valign=\"top\" width=\"406\">           \n\norg.apache.hadoop.io.compress.DefaultCodec\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">           \n\ngzip\n         </td>          <td valign=\"top\" width=\"406\">           \n\norg.apache.hadoop.io.compress.GzipCodec\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">           \n\nbzip2\n         </td>          <td valign=\"top\" width=\"406\">           \n\norg.apache.hadoop.io.compress.BZip2Codec\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">           \n\nLZO\n         </td>          <td valign=\"top\" width=\"406\">           \n\ncom.hadoop.compression.lzo.LzopCodec\n         </td>       </tr>     </tbody></table> </p>  \n\n以下两行代码即可：\n  > conf.setBoolean(&quot;mapred.compress.map.output&quot;, true);\n> \n> conf.set (&quot;mapred.map.output.compression.codec&quot;, &quot;***Codec&quot;);  \n\n但需要注意的是，时间与空间永远是矛盾的，若要获得大的压缩比就会降低一些时间效率。通常来说，想要达到cpu和磁盘压缩比的平衡取舍，LzoCodec比较适合。不过由于GPL许可的原因，该库没有包含在Apache的发行版中，需要单独从**[Google Code](http://code.google.com/p/hadoop-gpl-compression)**或**[GitHub](https://github.com/kevinweil/hadoop-lzo)**下载，其中后者包含有修正的软件错误及其它一些工具。\n\n本文使用的是默认的压缩方式DefaultCodec，压缩比约为29%。\n\n**3****、查看临时文件内部，具体情况具体分析**\n\n[![clip_image002](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image002_thumb.jpg \"clip_image002\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image002.jpg)\n\n上面的文件就是我的临时文件内部格式， value在内存中为DoubleWritable，没有考虑精度问题。一个value数据输出后，就会占20字节，我们是否需要这么高的精度呢？\n\n我觉得是不需要，不需要的话，就是将输出数据精度降低，实验中将double精度降至6位，“压缩”比约为59%。这个例子很实在，即对于每个任务来说，不仅仅是job conf需要优化，其自身算法或者说数据格式都还有很大的优化空间。没有最好，只有更好！\n\n**四、总结**\n\n经过上面几个“简单”的优化，代码行数修改寥寥几行，临时数据从140.6M降到了4.9M，压缩比为3.49%。需要注意的是，实验所用数据是模拟的，且数据分布较为均匀，故在实际生产环境中压缩比应该没这么高，所以需要根据job的实际情况，选择combine、压缩、数据格式，但其所带来的优化结果仍会很可观。\n\n本文只是简要的抽出了一些方便做实验的优化方法，更多的更广的配置、代码优化方法，敬请期待以后的博文。\n  > **参考资料：**\n> \n> &lt; [hadoop作业调优参数整理及原理](http://www.tbdata.org/archives/1470)&gt;\n> \n> &lt;Hadoop权威指南 &gt;","slug":"mapred-optimize","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg622l004zsb8fn9vq0ke5"},{"title":"MapReduce优化（二） —— 善用Writable","id":"588","date":"2012-09-27T13:44:55.000Z","_content":"\n**一、简述**\n\n上文主要是数据压缩的角度来分析了MapReduce压缩临时数据的优化，参见：[MapReduce优化（一）](http://www.hongweiyi.com/2012/02/mapred-optimize/)。而这篇会更多的从代码层面说MR任务优化。\n\nMapReduce大多数任务都是做日志分析，而一般的日志分析也就是高级点的WordCount程序：读入一段文本 -&gt; 获取需要的信息 -&gt; 统计输出。\n<!--more-->  \n\n我这里的任务会从SequenceFile中读取文档（每个文档4M），每条文档里面有许多行记录，每个记录有一个词和词频。任务需要统计记录中所有词出现的绝对频率以及文档频率。格式如下：   <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>word1 freq1\\n\n\nword2 freq2\\n\n\nword3 freq3\\n\n         </td>       </tr>     </tbody></table> </p>  \n\n**二、善用****Writable**\n\n程序逻辑应该是这样的：\n\n1）根据换行符分隔文档；\n\n2）读取每一行数据；\n\n3）并输出绝对频率(word, freq)与文档频率(word, ONE)两条记录。\n\n简单明了的程序处理方式应该是这样的：   <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>1\\. String str = value.toString(); \n\n2\\. String[] ln = str.split(&quot;\\n&quot;); \n\n3\\. for(String l : ln) {\n\n4.&#160;&#160;&#160;&#160; String[] words = ln.split(&quot; &quot;);\n\n5.&#160;&#160;&#160;&#160; context.write(new Text(words[0]), new LongWritable(1));\n\n6.&#160;&#160;&#160;&#160; context.write(new Text(words[0]), new LongWritable(Long.parseLong(words[1]));\n\n7\\. }\n         </td>       </tr>     </tbody></table> </p>  \n\n上面代码可优化的地方有三：\n\n1）在1行代码中，value的toString方法会对数据进行decode，decode效率很慢。而且该方法会分配内存空间；\n\n2）在2行代码中，和split(&quot;\\n&quot;)效率低下；\n\n3）5和6行中，每次都会“新”创建“两对”Text，LongWritable对象，GC频繁。\n\n在上面的问题中，问题1和问题2可以一起解决，避免decode和分配内存就需要直接处理byte数组重写Text这个Writable类。只需要继承Text类并添加nextLine()方法即可。添加nextLine()方法是为了逻辑清晰，如果为了更高的效率的话，可以添加nextWord()与nextFreq()方法。\n\n问题3比较常见，在很多资料以及Hadoop自带的Example里面可以看到，输出的键值对均是复用的。用一个全局的KEY和VALUE，直接将新数据set进KEY、VALUE中即可，无需每次新创建相应对象。上面还有一个小地方可以优化的就是，将LongWritable改为IntWritable，减少数据输出。\n\n上面的解决方案似乎还不错了，但是map输出的临时数据依然很大。回查代码，发现context.write()数据太多了，最后的解决方案是将文档频率和绝对频率合并起来，简单点的格式就是：d_freq#freq。这样临时数据一下就减少了一半。\n\n以下是修改后的代码流程：   <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>1\\. while (value.hasNext()) {\n\n2.&#160;&#160;&#160;&#160; KEY.set(value.nextWord());\n\n3.&#160;&#160;&#160;&#160; VALUE.set(&quot;1#&quot; + value.nextFreq());\n\n4.&#160;&#160;&#160;&#160; context.write(KEY, VALUE);\n\n5\\. }\n         </td>       </tr>     </tbody></table> </p>  \n\n**三、优化结果**\n\n通过上面的优化，处理300G的数据，单个map task平均时间从3'30''降到45''，FILE_BYTE_WRITEN从1000G降到了450G，任务总时间从4小时降到了30分钟。\n\nP.S.: 20台节点。\n\n**四、后记**\n\n后来我在这个任务里面使用了Gzip压缩，压缩率约为44%。但是对效率的影响太大了，单个map task平均时间从45''升到1'20''，打了一半的折扣，着实让人难以接受。由于对集群没有完全的管理权限，所以无法在这个任务上面尝试Lzo压缩编码，有机会在尝试吧。","source":"_posts/mapred-optimize-writable.md","raw":"title: MapReduce优化（二） —— 善用Writable\ntags:\n  - Hadoop\n  - MapReduce\nid: 588\ncategories:\n  - 技术分享\ndate: 2012-09-27 21:44:55\n---\n\n**一、简述**\n\n上文主要是数据压缩的角度来分析了MapReduce压缩临时数据的优化，参见：[MapReduce优化（一）](http://www.hongweiyi.com/2012/02/mapred-optimize/)。而这篇会更多的从代码层面说MR任务优化。\n\nMapReduce大多数任务都是做日志分析，而一般的日志分析也就是高级点的WordCount程序：读入一段文本 -&gt; 获取需要的信息 -&gt; 统计输出。\n<!--more-->  \n\n我这里的任务会从SequenceFile中读取文档（每个文档4M），每条文档里面有许多行记录，每个记录有一个词和词频。任务需要统计记录中所有词出现的绝对频率以及文档频率。格式如下：   <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>word1 freq1\\n\n\nword2 freq2\\n\n\nword3 freq3\\n\n         </td>       </tr>     </tbody></table> </p>  \n\n**二、善用****Writable**\n\n程序逻辑应该是这样的：\n\n1）根据换行符分隔文档；\n\n2）读取每一行数据；\n\n3）并输出绝对频率(word, freq)与文档频率(word, ONE)两条记录。\n\n简单明了的程序处理方式应该是这样的：   <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>1\\. String str = value.toString(); \n\n2\\. String[] ln = str.split(&quot;\\n&quot;); \n\n3\\. for(String l : ln) {\n\n4.&#160;&#160;&#160;&#160; String[] words = ln.split(&quot; &quot;);\n\n5.&#160;&#160;&#160;&#160; context.write(new Text(words[0]), new LongWritable(1));\n\n6.&#160;&#160;&#160;&#160; context.write(new Text(words[0]), new LongWritable(Long.parseLong(words[1]));\n\n7\\. }\n         </td>       </tr>     </tbody></table> </p>  \n\n上面代码可优化的地方有三：\n\n1）在1行代码中，value的toString方法会对数据进行decode，decode效率很慢。而且该方法会分配内存空间；\n\n2）在2行代码中，和split(&quot;\\n&quot;)效率低下；\n\n3）5和6行中，每次都会“新”创建“两对”Text，LongWritable对象，GC频繁。\n\n在上面的问题中，问题1和问题2可以一起解决，避免decode和分配内存就需要直接处理byte数组重写Text这个Writable类。只需要继承Text类并添加nextLine()方法即可。添加nextLine()方法是为了逻辑清晰，如果为了更高的效率的话，可以添加nextWord()与nextFreq()方法。\n\n问题3比较常见，在很多资料以及Hadoop自带的Example里面可以看到，输出的键值对均是复用的。用一个全局的KEY和VALUE，直接将新数据set进KEY、VALUE中即可，无需每次新创建相应对象。上面还有一个小地方可以优化的就是，将LongWritable改为IntWritable，减少数据输出。\n\n上面的解决方案似乎还不错了，但是map输出的临时数据依然很大。回查代码，发现context.write()数据太多了，最后的解决方案是将文档频率和绝对频率合并起来，简单点的格式就是：d_freq#freq。这样临时数据一下就减少了一半。\n\n以下是修改后的代码流程：   <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>1\\. while (value.hasNext()) {\n\n2.&#160;&#160;&#160;&#160; KEY.set(value.nextWord());\n\n3.&#160;&#160;&#160;&#160; VALUE.set(&quot;1#&quot; + value.nextFreq());\n\n4.&#160;&#160;&#160;&#160; context.write(KEY, VALUE);\n\n5\\. }\n         </td>       </tr>     </tbody></table> </p>  \n\n**三、优化结果**\n\n通过上面的优化，处理300G的数据，单个map task平均时间从3'30''降到45''，FILE_BYTE_WRITEN从1000G降到了450G，任务总时间从4小时降到了30分钟。\n\nP.S.: 20台节点。\n\n**四、后记**\n\n后来我在这个任务里面使用了Gzip压缩，压缩率约为44%。但是对效率的影响太大了，单个map task平均时间从45''升到1'20''，打了一半的折扣，着实让人难以接受。由于对集群没有完全的管理权限，所以无法在这个任务上面尝试Lzo压缩编码，有机会在尝试吧。","slug":"mapred-optimize-writable","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg622n0053sb8fc6aqce3h"},{"title":"Shell常用命令 文本操作篇","id":"647","date":"2013-01-19T14:41:44.000Z","_content":"\n**3.0 ****前言**\n\n\t《Linux/Unix设计思想》中有一条准则：&ldquo;采用纯文本文件来存储数据&rdquo;，原因如下：\n\n> 1）文本是通用的可转换格式\r> \n> \n> \t\t2）文本文件易于阅读和编辑\r> \n> \n> \t\t3）文本数据文件简化了Unix工具的使用\r> \n> \n> \t\t4）可移植性的提高克服了速度的不足\r> \n> \n> \t\t5）速度欠佳的缺点会被明年的机器克服\n\n\t在实战中有能感受到，文本文件的方便，也有非常多的工具辅助开发者处理、查看、编辑它们，如：awk、sed等，这篇博文就介绍与文本操作相关的常用命令。\n\n\t<!--more-->\n\n\t&nbsp;\n\n\t**3.1 ****输入输出流**\n\n\t**echo****：**\n\n\techo如同python中的print，不过不需要引号包住字符串，echo后接的除管理和重定向字符外均会输出。\n\n\t**cat****（****Concatenate****）：**\n\n\t它主要的功能是将文件的内容连续（concatenate）的输出到屏幕上，在上篇博文中就已经看到了，用来合并多个split的文件。\n\n\t**|****：**\n\n\t管道符号，接收管道左边命令的输出，并输入到右边的命令。在Linux中，管道是一种使用非常频繁的通信机制。从本质上说，管道也是一种文件，但它又和一般的文件有所不同。在 Linux 中，管道的实现并没有使用专门的数据结构，而是借助了文件系统的file结构和VFS的索引节点inode。通过将两个 file 结构指向同一个临时的 VFS 索引节点，而这个 VFS 索引节点又指向一个物理页面而实现的。\n\n\t这样，左边命令将数据写到索引节点，右边读取索引节点，读完之后方能继续写。详细实现机制可参考：[Linux管道的实现机制](http://oss.org.cn/kernel-book/ch07/7.1.1.htm)\n\n\t**输出重定向：**\n\n\t&gt;: 将左边的输出输入到右边的文件\n\n\t&gt;&gt;: 将左边命令的输出追加输入到右边的文件\n\n\t标准输出流重定向：\n\n\t0、1、2分别代表了标准输入、标准输出、标准错误信息输出，实战中经常会将错误输出重定向到标准输出中，可用 2&gt;&amp;1。同时，linux中有特殊的文件，/dev/null可理解为回收站，所有输出输入到该文件中均会&ldquo;消失&rdquo;。\n\n\t**read:**\n\n\tUsage: read [option] [var(default:REPLY)]\n\n\t从标准输出流中读取一行，并给一个变量赋值。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"619\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"617\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ echo &quot;hello world&quot; &gt; new.txt\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ cat new.txt\n\n\t\t\t\t\t&nbsp; hello world\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ echo &quot;again&quot; &gt;&gt; new.txt\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ cat new.txt\n\n\t\t\t\t\t&nbsp; hello world\n\n\t\t\t\t\t&nbsp; again\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ echo &quot;col1 col2&quot; | awk &#39;{print $1}&#39;\n\n\t\t\t\t\t&nbsp; col1\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ read newline &lt; new.txt; echo $newline\n\n\t\t\t\t\t&nbsp; hello world\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ read &lt; new.txt; echo $REPLY\n\n\t\t\t\t\t&nbsp; hello world\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **TIPS1:** read最常见的应该是用在while循环中了，cat file | while read line; do do_sth; done;\r> \n> \n> \t\t**TIPS2:** 2&gt;&amp;1常见的地方是用在定时任务中，将所有输出结果均输出到/dev/null中，/bin/sh your.sh &gt; /dev/null 2&gt;&amp;1\r> \n> \n> \t\t**TIPS3:** Linux中最快的创建空文件的方法不是touch，而是&quot;&gt; newfile&quot;。哈哈，贱笑贱笑。\n\n\t&nbsp;\n\n\t**3.2&nbsp;****文本查看**\n\n\tcat、head、tail、more、less均是查看文本的好工具，有时候结合起来效果会更好。\n\n\t**head(tail)：**\n\n\t查看文件首（尾）十行\n\n\t**more：**\n\n\t先显示文件一屏，再等待用户输入，回车是再显示下一行，空格是下一屏，q(ctrl+c)则退出\n\n\t**less：**\n\n\t类似more，不过可以往上翻。可用上下键，也可以用u(up)，d(down)键。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"629\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"627\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ tail -n 1000 file | more&nbsp;&nbsp;&nbsp; # 查看文件的最后1k行\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ head -n 10010 file | tail&nbsp;&nbsp;&nbsp;&nbsp; # 查看文件的第10k行\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ head -c 1(b|k|m) file&nbsp;&nbsp;&nbsp; # 查看文件的前1B|K|M数据\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t&nbsp;\n\n\t**3.3&nbsp;****文本字符集**\n\n\t字符集一直开发者的一个痛，按照东犇的说法是，要废除除utf8外所有字符集。此话虽然暴力，但是也有道理，不过要实现这个想法也基本是不太可能。开发者就只能一步一个脚印的走了。\n\n\t**file:**\n\n\t这是查看文本字符串的命令，不过个人觉得，基本不靠谱。因为要查看的数据都是代码生成的，输出的数据也不会有BOM信息，file也没有实现自检测文本字符功能。所以，现实中一般就是连蒙带猜了，不是gbk就是utf8。哈哈\n\n\t**iconv:**\n\n\t字符集转换工具\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"632\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"630\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ iconv -f from_code -t to_code file\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t文本字符集转换在这篇文章就只能点到为止了，字符集的问题三两句话基本讲不清楚，改天有机会单独写篇文章讲讲。\n\n> **TIPS1:** 输出文本到屏幕，显示的字符集是由终端所设置的。当出现乱码的时候，不要误认为是数据出错了，很有可能就是你的字符集设置有问题。\r> \n> \n> \t\t**TIPS2:** 按照东犇的说法，建议开发者统一使用utf8编码。他也提供了一种较为方便的查看gbk文本的方法。\r> \n> \n> \t<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"605\">\r> \n> \t\t<tbody>\r> \n> \t\t\t<tr>\r> \n> \t\t\t\t<td valign=\"top\" width=\"603\">\r> \n> \n> \t\t\t\t\t\t&nbsp; &gt;&gt; $ echo -e &quot;\\n&quot;alias conv_gbk=\\&quot;iconv -f gbk -t utf8\\&quot; &gt;&gt; ~/.bashrc\r> \n> \n> \t\t\t\t\t\t&nbsp; &gt;&gt; $ source ~/.bashrc\r> \n> \n> \t\t\t\t\t\t&nbsp; &gt;&gt; $ cat file | conv_gbk\r> \n> \n> \t\t\t\t</td>\r> \n> \t\t\t</tr>\r> \n> \t\t</tbody>\r> \n> \t</table>\n\n\t**3.4&nbsp;****文本其他工具**\n\n\t**grep:**\n\n\t查找命令，是开发中使用频率非常高的命令。像我们这边，代码就是文档，最好的翻阅文档工具就是grep了。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"636\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"634\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ grep [pattern] [file]&nbsp;&nbsp;&nbsp; # grep是基于正则表达式的，查找file中符合pattern的行\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ grep -v pattern file&nbsp;&nbsp;&nbsp; # 查找file中不符合pattern的行\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ grep pattern . -r&nbsp;&nbsp;&nbsp; # -r recursive 查找当前目录下所有符合pattern的文件\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**wc:**\n\n\twordcount工具，表示中国文字基本用不到。可以用其中一个：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"635\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"633\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ wc -l file&nbsp;&nbsp;&nbsp; # 统计file的行数\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ ls . | wc -l&nbsp;&nbsp;&nbsp; # 统计当前目录下文件的数目\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ grep pattern file | wc -l&nbsp;&nbsp;&nbsp; # 统计file中符合pattern的行数\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**sort:**\n\n\t排序工具：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"634\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"632\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ sort -k n (-n) (-r) file&nbsp;&nbsp; # 按照第n列，给file排序。-n numeric-sort -r reverse\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ ls -l . | sort -k 5 -n&nbsp;&nbsp;&nbsp; # 列出当前目录的文件，并按文件大小排序\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ ls -l . | sort -k5n -k6&nbsp;&nbsp;&nbsp; # 列出当前目录的文件，并按文件大小及时间排序\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**uniq:**\n\n\t去除连续重复行：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"633\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"631\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ cat file\n\n\t\t\t\t\t&nbsp; test1\n\n\t\t\t\t\t&nbsp; test2\n\n\t\t\t\t\t&nbsp; test2\n\n\t\t\t\t\t&nbsp; test1\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ uniq file\n\n\t\t\t\t\t&nbsp; test1\n\n\t\t\t\t\t&nbsp; test2\n\n\t\t\t\t\t&nbsp; test1\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ sort file | uniq&nbsp;&nbsp;&nbsp;&nbsp; # 去除所有重复行\n\n\t\t\t\t\t&nbsp; test1\n\n\t\t\t\t\t&nbsp; test2\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**diff &amp; patch:**\n\n\t文本比较工具，和svn里面的diff一样。diff的文件较小的话，结果还可以忍受，如果过大，那结果就不是给人看的了，需要让机器来做一些工作了，如做增量拷贝。这个命令就是patch。\n\n\t命令较为繁琐，且个人用得较少，就直接引用其他文章了：**[用diff和patch工具维护源码](https://www.ibm.com/developerworks/cn/linux/l-diffp/)**\n\n\t**awk &amp; sed:**\n\n\tsed(stream editor)意为流编辑器，我的理解就是它是按行处理。而awk则不仅仅可以按行，还可以按列。想必前面的文章，也看到了不少用awk的命令。两者各有所长，且博大精深啊，也有关于这两个工具的书。笔者在这里也只介绍我常用到的功能。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"632\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"630\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ echo &quot;col1 col2 col3&quot; | awk &#39;{print $1&quot;\\t&quot;$3}&#39;&nbsp;&nbsp;&nbsp; # $0：输入串 $1：col1 $2：col2 $3：col3 ...\n\n\t\t\t\t\t&nbsp; col1[tab]col3\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ echo &quot;col1 col2 col3&quot; | awk &#39;{print $1, $3}&#39;\n\n\t\t\t\t\t&nbsp; col1[space]col3\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ sed -i &quot;s/pattern/replace_pattern/g&quot; file&nbsp;&nbsp;&nbsp; # 替换字符串\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **WARNING:** 当文本为中文的时候，sed -i &quot;s/char/replace_char/g&quot;替换ascii标点的时候，需要特别注意。因为gbk编码中有些字节会小于128，而sed替换也是逐字节对比替换，所以有时候会导致中文乱码。","source":"_posts/linux-text-shell.md","raw":"title: Shell常用命令 文本操作篇\ntags:\n  - Linux\n  - Shell\nid: 647\ncategories:\n  - 技术分享\ndate: 2013-01-19 22:41:44\n---\n\n**3.0 ****前言**\n\n\t《Linux/Unix设计思想》中有一条准则：&ldquo;采用纯文本文件来存储数据&rdquo;，原因如下：\n\n> 1）文本是通用的可转换格式\r> \n> \n> \t\t2）文本文件易于阅读和编辑\r> \n> \n> \t\t3）文本数据文件简化了Unix工具的使用\r> \n> \n> \t\t4）可移植性的提高克服了速度的不足\r> \n> \n> \t\t5）速度欠佳的缺点会被明年的机器克服\n\n\t在实战中有能感受到，文本文件的方便，也有非常多的工具辅助开发者处理、查看、编辑它们，如：awk、sed等，这篇博文就介绍与文本操作相关的常用命令。\n\n\t<!--more-->\n\n\t&nbsp;\n\n\t**3.1 ****输入输出流**\n\n\t**echo****：**\n\n\techo如同python中的print，不过不需要引号包住字符串，echo后接的除管理和重定向字符外均会输出。\n\n\t**cat****（****Concatenate****）：**\n\n\t它主要的功能是将文件的内容连续（concatenate）的输出到屏幕上，在上篇博文中就已经看到了，用来合并多个split的文件。\n\n\t**|****：**\n\n\t管道符号，接收管道左边命令的输出，并输入到右边的命令。在Linux中，管道是一种使用非常频繁的通信机制。从本质上说，管道也是一种文件，但它又和一般的文件有所不同。在 Linux 中，管道的实现并没有使用专门的数据结构，而是借助了文件系统的file结构和VFS的索引节点inode。通过将两个 file 结构指向同一个临时的 VFS 索引节点，而这个 VFS 索引节点又指向一个物理页面而实现的。\n\n\t这样，左边命令将数据写到索引节点，右边读取索引节点，读完之后方能继续写。详细实现机制可参考：[Linux管道的实现机制](http://oss.org.cn/kernel-book/ch07/7.1.1.htm)\n\n\t**输出重定向：**\n\n\t&gt;: 将左边的输出输入到右边的文件\n\n\t&gt;&gt;: 将左边命令的输出追加输入到右边的文件\n\n\t标准输出流重定向：\n\n\t0、1、2分别代表了标准输入、标准输出、标准错误信息输出，实战中经常会将错误输出重定向到标准输出中，可用 2&gt;&amp;1。同时，linux中有特殊的文件，/dev/null可理解为回收站，所有输出输入到该文件中均会&ldquo;消失&rdquo;。\n\n\t**read:**\n\n\tUsage: read [option] [var(default:REPLY)]\n\n\t从标准输出流中读取一行，并给一个变量赋值。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"619\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"617\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ echo &quot;hello world&quot; &gt; new.txt\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ cat new.txt\n\n\t\t\t\t\t&nbsp; hello world\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ echo &quot;again&quot; &gt;&gt; new.txt\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ cat new.txt\n\n\t\t\t\t\t&nbsp; hello world\n\n\t\t\t\t\t&nbsp; again\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ echo &quot;col1 col2&quot; | awk &#39;{print $1}&#39;\n\n\t\t\t\t\t&nbsp; col1\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ read newline &lt; new.txt; echo $newline\n\n\t\t\t\t\t&nbsp; hello world\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ read &lt; new.txt; echo $REPLY\n\n\t\t\t\t\t&nbsp; hello world\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **TIPS1:** read最常见的应该是用在while循环中了，cat file | while read line; do do_sth; done;\r> \n> \n> \t\t**TIPS2:** 2&gt;&amp;1常见的地方是用在定时任务中，将所有输出结果均输出到/dev/null中，/bin/sh your.sh &gt; /dev/null 2&gt;&amp;1\r> \n> \n> \t\t**TIPS3:** Linux中最快的创建空文件的方法不是touch，而是&quot;&gt; newfile&quot;。哈哈，贱笑贱笑。\n\n\t&nbsp;\n\n\t**3.2&nbsp;****文本查看**\n\n\tcat、head、tail、more、less均是查看文本的好工具，有时候结合起来效果会更好。\n\n\t**head(tail)：**\n\n\t查看文件首（尾）十行\n\n\t**more：**\n\n\t先显示文件一屏，再等待用户输入，回车是再显示下一行，空格是下一屏，q(ctrl+c)则退出\n\n\t**less：**\n\n\t类似more，不过可以往上翻。可用上下键，也可以用u(up)，d(down)键。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"629\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"627\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ tail -n 1000 file | more&nbsp;&nbsp;&nbsp; # 查看文件的最后1k行\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ head -n 10010 file | tail&nbsp;&nbsp;&nbsp;&nbsp; # 查看文件的第10k行\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ head -c 1(b|k|m) file&nbsp;&nbsp;&nbsp; # 查看文件的前1B|K|M数据\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t&nbsp;\n\n\t**3.3&nbsp;****文本字符集**\n\n\t字符集一直开发者的一个痛，按照东犇的说法是，要废除除utf8外所有字符集。此话虽然暴力，但是也有道理，不过要实现这个想法也基本是不太可能。开发者就只能一步一个脚印的走了。\n\n\t**file:**\n\n\t这是查看文本字符串的命令，不过个人觉得，基本不靠谱。因为要查看的数据都是代码生成的，输出的数据也不会有BOM信息，file也没有实现自检测文本字符功能。所以，现实中一般就是连蒙带猜了，不是gbk就是utf8。哈哈\n\n\t**iconv:**\n\n\t字符集转换工具\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"632\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"630\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ iconv -f from_code -t to_code file\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t文本字符集转换在这篇文章就只能点到为止了，字符集的问题三两句话基本讲不清楚，改天有机会单独写篇文章讲讲。\n\n> **TIPS1:** 输出文本到屏幕，显示的字符集是由终端所设置的。当出现乱码的时候，不要误认为是数据出错了，很有可能就是你的字符集设置有问题。\r> \n> \n> \t\t**TIPS2:** 按照东犇的说法，建议开发者统一使用utf8编码。他也提供了一种较为方便的查看gbk文本的方法。\r> \n> \n> \t<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"605\">\r> \n> \t\t<tbody>\r> \n> \t\t\t<tr>\r> \n> \t\t\t\t<td valign=\"top\" width=\"603\">\r> \n> \n> \t\t\t\t\t\t&nbsp; &gt;&gt; $ echo -e &quot;\\n&quot;alias conv_gbk=\\&quot;iconv -f gbk -t utf8\\&quot; &gt;&gt; ~/.bashrc\r> \n> \n> \t\t\t\t\t\t&nbsp; &gt;&gt; $ source ~/.bashrc\r> \n> \n> \t\t\t\t\t\t&nbsp; &gt;&gt; $ cat file | conv_gbk\r> \n> \n> \t\t\t\t</td>\r> \n> \t\t\t</tr>\r> \n> \t\t</tbody>\r> \n> \t</table>\n\n\t**3.4&nbsp;****文本其他工具**\n\n\t**grep:**\n\n\t查找命令，是开发中使用频率非常高的命令。像我们这边，代码就是文档，最好的翻阅文档工具就是grep了。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"636\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"634\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ grep [pattern] [file]&nbsp;&nbsp;&nbsp; # grep是基于正则表达式的，查找file中符合pattern的行\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ grep -v pattern file&nbsp;&nbsp;&nbsp; # 查找file中不符合pattern的行\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ grep pattern . -r&nbsp;&nbsp;&nbsp; # -r recursive 查找当前目录下所有符合pattern的文件\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**wc:**\n\n\twordcount工具，表示中国文字基本用不到。可以用其中一个：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"635\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"633\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ wc -l file&nbsp;&nbsp;&nbsp; # 统计file的行数\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ ls . | wc -l&nbsp;&nbsp;&nbsp; # 统计当前目录下文件的数目\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ grep pattern file | wc -l&nbsp;&nbsp;&nbsp; # 统计file中符合pattern的行数\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**sort:**\n\n\t排序工具：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"634\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"632\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ sort -k n (-n) (-r) file&nbsp;&nbsp; # 按照第n列，给file排序。-n numeric-sort -r reverse\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ ls -l . | sort -k 5 -n&nbsp;&nbsp;&nbsp; # 列出当前目录的文件，并按文件大小排序\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ ls -l . | sort -k5n -k6&nbsp;&nbsp;&nbsp; # 列出当前目录的文件，并按文件大小及时间排序\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**uniq:**\n\n\t去除连续重复行：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"633\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"631\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ cat file\n\n\t\t\t\t\t&nbsp; test1\n\n\t\t\t\t\t&nbsp; test2\n\n\t\t\t\t\t&nbsp; test2\n\n\t\t\t\t\t&nbsp; test1\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ uniq file\n\n\t\t\t\t\t&nbsp; test1\n\n\t\t\t\t\t&nbsp; test2\n\n\t\t\t\t\t&nbsp; test1\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ sort file | uniq&nbsp;&nbsp;&nbsp;&nbsp; # 去除所有重复行\n\n\t\t\t\t\t&nbsp; test1\n\n\t\t\t\t\t&nbsp; test2\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**diff &amp; patch:**\n\n\t文本比较工具，和svn里面的diff一样。diff的文件较小的话，结果还可以忍受，如果过大，那结果就不是给人看的了，需要让机器来做一些工作了，如做增量拷贝。这个命令就是patch。\n\n\t命令较为繁琐，且个人用得较少，就直接引用其他文章了：**[用diff和patch工具维护源码](https://www.ibm.com/developerworks/cn/linux/l-diffp/)**\n\n\t**awk &amp; sed:**\n\n\tsed(stream editor)意为流编辑器，我的理解就是它是按行处理。而awk则不仅仅可以按行，还可以按列。想必前面的文章，也看到了不少用awk的命令。两者各有所长，且博大精深啊，也有关于这两个工具的书。笔者在这里也只介绍我常用到的功能。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"632\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"630\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ echo &quot;col1 col2 col3&quot; | awk &#39;{print $1&quot;\\t&quot;$3}&#39;&nbsp;&nbsp;&nbsp; # $0：输入串 $1：col1 $2：col2 $3：col3 ...\n\n\t\t\t\t\t&nbsp; col1[tab]col3\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ echo &quot;col1 col2 col3&quot; | awk &#39;{print $1, $3}&#39;\n\n\t\t\t\t\t&nbsp; col1[space]col3\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ sed -i &quot;s/pattern/replace_pattern/g&quot; file&nbsp;&nbsp;&nbsp; # 替换字符串\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **WARNING:** 当文本为中文的时候，sed -i &quot;s/char/replace_char/g&quot;替换ascii标点的时候，需要特别注意。因为gbk编码中有些字节会小于128，而sed替换也是逐字节对比替换，所以有时候会导致中文乱码。","slug":"linux-text-shell","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg622p0057sb8fd2majmpk"},{"title":"Shell常用命令 终端优化前篇","id":"630","date":"2013-01-17T15:18:50.000Z","_content":"\n在黑框框shell下作业也一年多了，其中实战占了9个月，从最开始的翻阅各种书籍，到后面问谷歌，也算是能熟练&ldquo;掌握&rdquo;这门工具，也搜集了一些&ldquo;奇技淫巧&rdquo;。现在好好的总结一下吧，顺带也查漏补缺&hellip;&hellip;\n\n\t<!--more-->\n\n\t**1.1 ****终端设置**\n\n\t下载一个好用的终端，如**[xshell](http://www.netsarang.com/products/xsh_overview.html)**，[**putty**](http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html)。\n\n\t设置Encoding、Terminal Type，一般来说在终端中设置一下即可。Encoding为utf8，Terminal Type设置为xterm、VT100、linux都可以，设置其他的类型有的可能ls文件会没有颜色（这个情况在screen命令中也会出现，到时候再讲解决方案吧），或者Home/End键不好用（代替快捷键：Ctrl+a/e）之类的。\n\n\t**1.2 shell****提示符设置**\n\n\t终端提示符默认的就是白色的用户名，看着非常不舒服，可以设置一下当前环境的提示符颜色，变量是PS1：\n\n\t[![image](http://hongweiyi.com/wp-content/uploads/2013/01/image_thumb.png \"image\")](http://hongweiyi.com/wp-content/uploads/2013/01/image.png)\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"626\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"624\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ echo $PS1\n\n\t\t\t\t\t&nbsp; \\[\\e[31;1m\\]\\u\\[\\e[0m\\]@\\[\\e[32;1m\\]your ip\\[\\e[0m\\]:\\[\\e[35;1m\\]\\w\\[\\e[0m\\]\\\\$\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t你也可以不填写ip，用命令获得当前ip：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"626\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"624\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ export PS1=&quot;\\[\\e[31;1m\\]\\u\\[\\e[0m\\]@\\[\\e[32;1m\\]`/sbin/ifconfig eth1|grep \"inet&nbsp;&nbsp; addr:\"|cut -d: -f 2|cut -d\" \" -f1`\\[\\e[0m\\]:\\[\\e[35;1m\\]\\w\\[\\e[0m\\]\\\\$ &quot;\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t其他颜色可参考：**[Linux终端下的颜色设置](http://unix-cd.com/unixcd12/article_7281.html)**\n\n\t上面的PS1变量可以设置在用户配置中，文件为~/.bashrc，在该文件中添加一行：export PS1=&times;&times;&times;即可。如果再次登陆的时候，该命令没有生效，则添加~/.bash_profile文件，当shell被打开时，该文件会被执行一次。在文件中添加命令即可加载~/.bashrc：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"625\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"623\">\n\n\t\t\t\t\t&nbsp; # Get the aliases and functions\n\n\t\t\t\t\t&nbsp; if [ -f ~/.bashrc ]; then\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; . ~/.bashrc\n\n\t\t\t\t\t&nbsp; fi\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t如果你想该文件立即生效，可以用source ~/.bashrc命令立即加载执行该文件。\n\n\t&nbsp;\n\n\t**1.3 ****别名设置**\n\n\t可以用一些简单的别名代替一些复杂的命令，如下：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"626\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"624\">\n\n\t\t\t\t\t&nbsp; alias ..=&quot;cd ..&quot;\n\n\t\t\t\t\t&nbsp; alias ...=&quot;cd ../..&quot;\n\n\t\t\t\t\t&nbsp;\n\n\t\t\t\t\t&nbsp; alias cd..=&quot;cd ..&quot;\n\n\t\t\t\t\t&nbsp; alias ll=&quot;ls -l&quot;\n\n\t\t\t\t\t&nbsp; alias la=&quot;ls -a&quot;\n\n\t\t\t\t\t&nbsp; alias tree=&quot;~/code/tree&quot;\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t将alias添加进~/.bashrc中。~/code/tree是一个shell脚本，脚本内容如下：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"626\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"624\">\n\n\t\t\t\t\t&nbsp; #!/bin/sh\n\n\t\t\t\t\t&nbsp; function tree_files()\n\n\t\t\t\t\t&nbsp; {\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; find . -print 2&gt;/dev/null|\\\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; awk &#39;!/\\.$/ {for (i=1;i&lt;NF;i++){\\\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; d=length($i);if ( d &lt; 5 &amp;&amp; i != 1 )d=5;printf(&quot;%&quot;d&quot;s&quot;,&quot;|&quot;)}print &quot;---&quot;$NF}&#39; \\\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; FS=&#39;/&#39; | more\n\n\t\t\t\t\t&nbsp; }\n\n\t\t\t\t\t&nbsp; function tree_dirs()\n\n\t\t\t\t\t&nbsp; {\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; find . -type d -print 2&gt;/dev/null|\\\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; awk &#39;!/\\.$/ {for (i=1;i&lt;NF;i++){\\\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; d=length($i);if ( d &lt; 5 &amp;&amp; i != 1 )d=5;printf(&quot;%&quot;d&quot;s&quot;,&quot;|&quot;)}print &quot;---&quot;$NF}&#39; \\\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; FS=&#39;/&#39; | more\n\n\t\t\t\t\t&nbsp; }\n\n\t\t\t\t\t&nbsp; function help()\n\n\t\t\t\t\t&nbsp; {\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; echo &quot;Usage: tree [-f|-d]&quot;\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; echo &quot;&nbsp; -f: list files of current directory&quot;\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; echo &quot;&nbsp; -d: list direcotries of current directory&quot;\n\n\t\t\t\t\t&nbsp; }\n\n\t\t\t\t\t&nbsp; if [ $# = 0 ]; then\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tree_dirs\n\n\t\t\t\t\t&nbsp; elif [ $# = 1 ]; then\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if [ $1 = \"-f\" ]; then\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tree_files\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; elif [ $1 = \"-d\" ]; then\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tree_dirs\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; else\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; help\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fi\n\n\t\t\t\t\t&nbsp; fi\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t&nbsp;\n\n\t**1.4 ****文档编辑器设置**\n\n\t我用的是vim，配置文件为~/.vimrc。由于工作机较多，所以没有一个个去配置，不可缺少的是syntax on（开启高亮），indent都没太大必要了。当然，专用开发机需要配置一个比较好用的，因人而异，如需要较好配置文件的可自行谷歌。\n\n\t有了以上四步，基本上一个简单方便好用的终端就有了，接下来我会一一介绍常用的shell命令：文件/目录操作、输入/输出操作、文本操作、进程操作等。\n\n> **BTW：**个人不太喜欢装各种各样的辅助工具（tmux、vim相关、make相关。tree的工具也不想装，直接写shell多方便），因为环境多变，如果突然没了插件可能会不知所措，喜欢最原始最朴素的命令和工具，认为这才是王道！","source":"_posts/linux-shell-term-tuning.md","raw":"title: Shell常用命令 终端优化前篇\ntags:\n  - Linux\n  - Shell\nid: 630\ncategories:\n  - 技术分享\ndate: 2013-01-17 23:18:50\n---\n\n在黑框框shell下作业也一年多了，其中实战占了9个月，从最开始的翻阅各种书籍，到后面问谷歌，也算是能熟练&ldquo;掌握&rdquo;这门工具，也搜集了一些&ldquo;奇技淫巧&rdquo;。现在好好的总结一下吧，顺带也查漏补缺&hellip;&hellip;\n\n\t<!--more-->\n\n\t**1.1 ****终端设置**\n\n\t下载一个好用的终端，如**[xshell](http://www.netsarang.com/products/xsh_overview.html)**，[**putty**](http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html)。\n\n\t设置Encoding、Terminal Type，一般来说在终端中设置一下即可。Encoding为utf8，Terminal Type设置为xterm、VT100、linux都可以，设置其他的类型有的可能ls文件会没有颜色（这个情况在screen命令中也会出现，到时候再讲解决方案吧），或者Home/End键不好用（代替快捷键：Ctrl+a/e）之类的。\n\n\t**1.2 shell****提示符设置**\n\n\t终端提示符默认的就是白色的用户名，看着非常不舒服，可以设置一下当前环境的提示符颜色，变量是PS1：\n\n\t[![image](http://hongweiyi.com/wp-content/uploads/2013/01/image_thumb.png \"image\")](http://hongweiyi.com/wp-content/uploads/2013/01/image.png)\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"626\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"624\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ echo $PS1\n\n\t\t\t\t\t&nbsp; \\[\\e[31;1m\\]\\u\\[\\e[0m\\]@\\[\\e[32;1m\\]your ip\\[\\e[0m\\]:\\[\\e[35;1m\\]\\w\\[\\e[0m\\]\\\\$\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t你也可以不填写ip，用命令获得当前ip：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"626\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"624\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ export PS1=&quot;\\[\\e[31;1m\\]\\u\\[\\e[0m\\]@\\[\\e[32;1m\\]`/sbin/ifconfig eth1|grep \"inet&nbsp;&nbsp; addr:\"|cut -d: -f 2|cut -d\" \" -f1`\\[\\e[0m\\]:\\[\\e[35;1m\\]\\w\\[\\e[0m\\]\\\\$ &quot;\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t其他颜色可参考：**[Linux终端下的颜色设置](http://unix-cd.com/unixcd12/article_7281.html)**\n\n\t上面的PS1变量可以设置在用户配置中，文件为~/.bashrc，在该文件中添加一行：export PS1=&times;&times;&times;即可。如果再次登陆的时候，该命令没有生效，则添加~/.bash_profile文件，当shell被打开时，该文件会被执行一次。在文件中添加命令即可加载~/.bashrc：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"625\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"623\">\n\n\t\t\t\t\t&nbsp; # Get the aliases and functions\n\n\t\t\t\t\t&nbsp; if [ -f ~/.bashrc ]; then\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; . ~/.bashrc\n\n\t\t\t\t\t&nbsp; fi\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t如果你想该文件立即生效，可以用source ~/.bashrc命令立即加载执行该文件。\n\n\t&nbsp;\n\n\t**1.3 ****别名设置**\n\n\t可以用一些简单的别名代替一些复杂的命令，如下：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"626\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"624\">\n\n\t\t\t\t\t&nbsp; alias ..=&quot;cd ..&quot;\n\n\t\t\t\t\t&nbsp; alias ...=&quot;cd ../..&quot;\n\n\t\t\t\t\t&nbsp;\n\n\t\t\t\t\t&nbsp; alias cd..=&quot;cd ..&quot;\n\n\t\t\t\t\t&nbsp; alias ll=&quot;ls -l&quot;\n\n\t\t\t\t\t&nbsp; alias la=&quot;ls -a&quot;\n\n\t\t\t\t\t&nbsp; alias tree=&quot;~/code/tree&quot;\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t将alias添加进~/.bashrc中。~/code/tree是一个shell脚本，脚本内容如下：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"626\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"624\">\n\n\t\t\t\t\t&nbsp; #!/bin/sh\n\n\t\t\t\t\t&nbsp; function tree_files()\n\n\t\t\t\t\t&nbsp; {\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; find . -print 2&gt;/dev/null|\\\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; awk &#39;!/\\.$/ {for (i=1;i&lt;NF;i++){\\\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; d=length($i);if ( d &lt; 5 &amp;&amp; i != 1 )d=5;printf(&quot;%&quot;d&quot;s&quot;,&quot;|&quot;)}print &quot;---&quot;$NF}&#39; \\\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; FS=&#39;/&#39; | more\n\n\t\t\t\t\t&nbsp; }\n\n\t\t\t\t\t&nbsp; function tree_dirs()\n\n\t\t\t\t\t&nbsp; {\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; find . -type d -print 2&gt;/dev/null|\\\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; awk &#39;!/\\.$/ {for (i=1;i&lt;NF;i++){\\\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; d=length($i);if ( d &lt; 5 &amp;&amp; i != 1 )d=5;printf(&quot;%&quot;d&quot;s&quot;,&quot;|&quot;)}print &quot;---&quot;$NF}&#39; \\\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; FS=&#39;/&#39; | more\n\n\t\t\t\t\t&nbsp; }\n\n\t\t\t\t\t&nbsp; function help()\n\n\t\t\t\t\t&nbsp; {\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; echo &quot;Usage: tree [-f|-d]&quot;\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; echo &quot;&nbsp; -f: list files of current directory&quot;\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; echo &quot;&nbsp; -d: list direcotries of current directory&quot;\n\n\t\t\t\t\t&nbsp; }\n\n\t\t\t\t\t&nbsp; if [ $# = 0 ]; then\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tree_dirs\n\n\t\t\t\t\t&nbsp; elif [ $# = 1 ]; then\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if [ $1 = \"-f\" ]; then\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tree_files\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; elif [ $1 = \"-d\" ]; then\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tree_dirs\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; else\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; help\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fi\n\n\t\t\t\t\t&nbsp; fi\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t&nbsp;\n\n\t**1.4 ****文档编辑器设置**\n\n\t我用的是vim，配置文件为~/.vimrc。由于工作机较多，所以没有一个个去配置，不可缺少的是syntax on（开启高亮），indent都没太大必要了。当然，专用开发机需要配置一个比较好用的，因人而异，如需要较好配置文件的可自行谷歌。\n\n\t有了以上四步，基本上一个简单方便好用的终端就有了，接下来我会一一介绍常用的shell命令：文件/目录操作、输入/输出操作、文本操作、进程操作等。\n\n> **BTW：**个人不太喜欢装各种各样的辅助工具（tmux、vim相关、make相关。tree的工具也不想装，直接写shell多方便），因为环境多变，如果突然没了插件可能会不知所措，喜欢最原始最朴素的命令和工具，认为这才是王道！","slug":"linux-shell-term-tuning","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg622r005dsb8fg3pzkwkv"},{"title":"Shell常用命令 进程操作篇","id":"656","date":"2013-01-22T13:57:57.000Z","_content":"\n**4.0 ****前言**\n\n\t这篇算是尾篇了，命令较多也较繁杂，每个都是点到为止，基本也够用。有兴趣深入的朋友可自行谷歌学习。\n\n\t<!--more-->\n\n\t**4.1 ****进程执行**\n\n\t进程执行无外乎前台运行，但是前台运行需要用户等待程序运行完毕才可继续，所以就有了后台运行进程这一说。后台进程又分两种，当前终端后台进程，以及托管给OS的后台进程。这里就稍微介绍一下如何运行这些个进程吧。\n\n> **BTW:** 以上分类都是我瞎分的，仅供参考。\n\n\t**后台运行进程:**\n\n\t在运行命令末尾加上&amp;符号，该程序就会在后台运行，如果忘记敲&amp;命令的话，也可以同过ctrl+z，暂停当前进程，再用bg(backgroud)命令即可让暂停任务变成后台运行。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"632\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"630\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ /bin/sh your.sh &amp;\n\n\t\t\t\t\t&nbsp; [1]&nbsp;&nbsp;&nbsp; pid&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # 输出进程在当前终端的序号以及pid\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ /bin/sh your.sh&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # ctrl + z\n\n\t\t\t\t\t&nbsp; [1]+&nbsp; Stopped&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /bin/sh your.sh\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ bg %1&nbsp;&nbsp; # %1 代表当前终端的第一个进程\n\n\t\t\t\t\t&nbsp; [1]+&nbsp; /bin/sh your.sh &amp;\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **TIPS:** The plus sign shows the most recently invoked job; the minus sign shows the next most recently invoked job.- &lt;Learning the Korn Shell, 2nd Edition&gt;\r> \n> \n> \t\t**WARNING:** 当运行某个有大量输出的进程，如果直接让其进入后台运行是很不明智的，一般来说会将输出写入文件中。如： $ /bin/sh your.sh &gt; ./your.log 2&gt;&amp;1 &amp;\n\n\t**前台运行进程：**\n\n\t有了后台，就有相应的前台运行进程了。fg(foreground)就是了，但一般来说，很少需要将后台进程推到前台的需求，我一般是这样用的：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"632\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"630\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ vim your_file&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # ctrl + z\n\n\t\t\t\t\t&nbsp; [1]+&nbsp;&nbsp; Stopped&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; vim your_file\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ fg %1&nbsp;\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**托管进程：**\n\n\t上面的命令均是在当前终端运行，如果终端关闭，相应的进程也关闭了，如果想进程继续运行，则需要将进程托管给系统管理。主要命令是nohup。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"631\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"629\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ nohup /bin/sh your.sh &amp;\n\n\t\t\t\t\t&nbsp; [1]&nbsp;&nbsp;&nbsp; pid\n\n\t\t\t\t\t&nbsp; nohup: appending output to &lsquo;nohup.out&#39;\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t<span style=\"line-height: 1.6em;\">实战的时候，更多的情况是这样的：突然有事要走开一下，又生怕跑了半天的程序因为终端挂了，想将其托管给系统。那么就可以用disown命令。</span>\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"631\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"629\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ /bin/sh your.sh &amp;\n\n\t\t\t\t\t&nbsp; [1]&nbsp;&nbsp;&nbsp; pid\n\n\t\t\t\t\t&nbsp; &gt;&gt; disown %1\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **REFE:** 看这个解释得更为详细，我对其理解较为肤浅：[**Linux****技巧：让后台在后台可靠运行的几种方法**](http://www.ibm.com/developerworks/cn/linux/l-cn-nohup/)**。**\n\n\t**screen:**\n\n\t上面两个命令都不是最好用的，最好用的应该是screen命令了。screen 提供了 ANSI/VT100 的终端模拟器，使它能够在一个真实终端下运行多个全屏的伪终端。screen用好了，感觉也不比tmux差多少。\n\n\t要同时跑多个screen，并想快速切换的换，可以添加几个screen的alias。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"631\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"629\">\n\n\t\t\t\t\talias s=&quot;screen&quot;\n\n\t\t\t\t\talias sr=&quot;screen -r&quot;&nbsp;&nbsp;&nbsp;&nbsp; # 连接到某个模拟器\n\n\t\t\t\t\talias sl=&quot;screen -ls&quot;&nbsp;&nbsp;&nbsp;&nbsp; # 显示当前所有模拟器\n\n\t\t\t\t\talias sl=&quot;screen -d&quot;&nbsp;&nbsp;&nbsp;&nbsp; # 强制断开某个模拟器连接\n\n\t\t\t\t\tctrl+a :sessionname MyName&nbsp;&nbsp; # 在screen模拟器中，修改模拟器名字\n\n\t\t\t\t\tctrl+a :kill&nbsp;&nbsp;&nbsp; # 强制关闭模拟器（模拟器有时候会莫名其妙的没响应）\n\n\t\t\t\t\tctrl+a :encoding gbk&nbsp;&nbsp;&nbsp;&nbsp; # 设置screen编码\n\n\t\t\t\t\tctrl+a d&nbsp;&nbsp;&nbsp;&nbsp; # detached模拟器（就是临时退出）\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **TIPS**: screen终端ls文件没有颜色，是因为screen终端类型比较特殊，echo $TERM显示为screen或者screen.linux类型，解决方案是修改/etc/DIR_COLORS或者复制/etc/DIR_COLORS到~/.dir_colors，加入一句：&quot;TERM screen&quot;注销重登即可。\n\n\t**jobs:**\n\n\t列出当前终端运行的后台进程。\n\n\t**ps:**\n\n\t列出系统正在运行的程序。\n\n\t**top:**\n\n\t理解为win下面的任务管理器，需要注意的地方应该是load average了，Load Average表示了CPU的Load，它所包含的信息不是 CPU的使用率状况，而是在一段时间内CPU正在处理以及等待CPU处理的进程数之和的统计信息，也就是 CPU使用队列的长度的统计信息。load average: 0.06, 0.60, 0.48，三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值。需要注意，load average如果超过一定的数的话，系统负载较高。\n\n\t**Load Average &lt; CPU个数 * 核数 *0.7**\n\n\t我常用的命令也不多，如下：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"635\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"633\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ top\n\n\t\t\t\t\t&nbsp; ...\n\n\t\t\t\t\t&nbsp; ...\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ top -p pid [-p pid2 ...]\n\n\t\t\t\t\t&nbsp; ...&nbsp;&nbsp;&nbsp; # 只查看pid这个进程\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**crontab:**\n\n\t定时任务命令，这个东西有时候也折磨了好一段时间。内容格式说着也简单：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"635\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"633\">\n\n\t\t\t\t\t&gt;&gt; $ crontab -e&nbsp;&nbsp;&nbsp; # 编辑定时任务列表\n\n\t\t\t\t\t* * * * * cmd &gt; /dev/null 2&gt;&amp;1&nbsp;&nbsp;&nbsp;&nbsp; # 5个*分别代表分、时、日、月、周。需要将输出写到某个文件或者/dev/null中，因为它的所有输出均会按邮件发到服务器上，日积月累也是个负担\n\n\t\t\t\t\t*/2 * * * * cmd &gt; /dev/null 2&gt;&amp;1&nbsp;&nbsp;&nbsp;&nbsp; # 代表每两分钟执行一次cmd\n\n\t\t\t\t\t&gt;&gt; $ crontab -l&nbsp;&nbsp;&nbsp; # 显示定时任务列表\n\n\t\t\t\t\t&gt;&gt; $ crontab -r&nbsp;&nbsp;&nbsp; # 删除定时任务列表（- -，不知道为什么要有这个选项）\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **REFE:** 偷懒，直接贴其他人的帖子吧：[Crontab 错误分析及不执行原因](http://www.cnblogs.com/cosiray/archive/2012/03/09/2387361.html)\n\n\t**history:**\n\n\t查看命令历史，以下是常用方法和有用的设置：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"635\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"633\">\n\n\t\t\t\t\t&gt;&gt; $ history | more\n\n\t\t\t\t\t&gt;&gt; $ history | grep ls\n\n\t\t\t\t\t&gt;&gt; $ vi ~/.bashrc\n\n\t\t\t\t\tHISTFILESIZE=2000&nbsp;&nbsp;&nbsp;&nbsp; # history 记录长度\n\n\t\t\t\t\tHISTTIMEFORMAT=&#39;%F %T &#39;&nbsp;&nbsp;&nbsp;&nbsp; # 给记录添加时间戳\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **TIPS1:** 输入命令前，输入一个空格，该记录不添加进history中。嘿嘿嘿嘿&hellip;&hellip;\r> \n> \n> \t\t**TIPS2:** ctrl + r是找历史记录，查找过程中继续按ctrl+r是当前查找结果的上一条\n\n\t**ssh:**\n\n\t最后一个说ssh，好像也没啥说的。远程登录，远程拷贝&hellip;&hellip;\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"634\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"632\">\n\n\t\t\t\t\t&gt;&gt; $ ssh -l user ip [-p port]\n\n\t\t\t\t\t&gt;&gt; $ ssh user@ip\n\n\t\t\t\t\t&gt;&gt; $ scp user@ip:/src/dir/or/file user@ip:/dest/dir/or/file\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **FINAL TIPS:** 拷贝的时候需要输入对方的用户密码，可以添加相关的密钥一劳永逸。但是添加密钥的方式有点微麻烦，所以可以用其他方式代替，那就是用expect命令。下面这段脚本可以实现无间断的远程push，可以自己改成远程pull。\r> \n> \n> \t\t&nbsp;\r> \n> \n> \t<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"605\">\r> \n> \t\t<tbody>\r> \n> \t\t\t<tr>\r> \n> \t\t\t\t<td valign=\"top\" width=\"603\">\r> \n> \n> \t\t\t\t\t\t#!/usr/bin/expect\r> \n> \n> \t\t\t\t\t\tset user [lindex $argv 0]\r> \n> \n> \t\t\t\t\t\tset passwd [lindex $argv 1]\r> \n> \n> \t\t\t\t\t\tset ip [lindex $argv 2]\r> \n> \n> \t\t\t\t\t\tset src [lindex $argv 3]\r> \n> \n> \t\t\t\t\t\tset des [lindex $argv 4]\r> \n> \n> \t\t\t\t\t\tset timeout 60\r> \n> \n> \t\t\t\t\t\tspawn /usr/local/bin/scp -r ${src} ${user}@${ip}:${des}\r> \n> \n> \t\t\t\t\t\texpect {\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; &quot;*assword:&quot; {\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp; send &quot;${passwd}\\n&quot;\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp; exp_continue\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; }\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; &quot;fcr_parse_raw&quot; {\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; close\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; exit -2\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; }\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; timeout {\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; close\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; exit -1\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; }\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; eof {\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; catch wait result\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; exit [lindex $result 3]\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; }\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; -re . {\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; exp_continue\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; }\r> \n> \n> \t\t\t\t\t\t}\r> \n> \n> \t\t\t\t</td>\r> \n> \t\t\t</tr>\r> \n> \t\t</tbody>\r> \n> \t</table>","source":"_posts/linux-process-shell.md","raw":"title: Shell常用命令 进程操作篇\ntags:\n  - Linux\n  - Shell\nid: 656\ncategories:\n  - 技术分享\ndate: 2013-01-22 21:57:57\n---\n\n**4.0 ****前言**\n\n\t这篇算是尾篇了，命令较多也较繁杂，每个都是点到为止，基本也够用。有兴趣深入的朋友可自行谷歌学习。\n\n\t<!--more-->\n\n\t**4.1 ****进程执行**\n\n\t进程执行无外乎前台运行，但是前台运行需要用户等待程序运行完毕才可继续，所以就有了后台运行进程这一说。后台进程又分两种，当前终端后台进程，以及托管给OS的后台进程。这里就稍微介绍一下如何运行这些个进程吧。\n\n> **BTW:** 以上分类都是我瞎分的，仅供参考。\n\n\t**后台运行进程:**\n\n\t在运行命令末尾加上&amp;符号，该程序就会在后台运行，如果忘记敲&amp;命令的话，也可以同过ctrl+z，暂停当前进程，再用bg(backgroud)命令即可让暂停任务变成后台运行。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"632\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"630\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ /bin/sh your.sh &amp;\n\n\t\t\t\t\t&nbsp; [1]&nbsp;&nbsp;&nbsp; pid&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # 输出进程在当前终端的序号以及pid\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ /bin/sh your.sh&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # ctrl + z\n\n\t\t\t\t\t&nbsp; [1]+&nbsp; Stopped&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /bin/sh your.sh\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ bg %1&nbsp;&nbsp; # %1 代表当前终端的第一个进程\n\n\t\t\t\t\t&nbsp; [1]+&nbsp; /bin/sh your.sh &amp;\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **TIPS:** The plus sign shows the most recently invoked job; the minus sign shows the next most recently invoked job.- &lt;Learning the Korn Shell, 2nd Edition&gt;\r> \n> \n> \t\t**WARNING:** 当运行某个有大量输出的进程，如果直接让其进入后台运行是很不明智的，一般来说会将输出写入文件中。如： $ /bin/sh your.sh &gt; ./your.log 2&gt;&amp;1 &amp;\n\n\t**前台运行进程：**\n\n\t有了后台，就有相应的前台运行进程了。fg(foreground)就是了，但一般来说，很少需要将后台进程推到前台的需求，我一般是这样用的：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"632\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"630\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ vim your_file&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # ctrl + z\n\n\t\t\t\t\t&nbsp; [1]+&nbsp;&nbsp; Stopped&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; vim your_file\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ fg %1&nbsp;\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**托管进程：**\n\n\t上面的命令均是在当前终端运行，如果终端关闭，相应的进程也关闭了，如果想进程继续运行，则需要将进程托管给系统管理。主要命令是nohup。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"631\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"629\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ nohup /bin/sh your.sh &amp;\n\n\t\t\t\t\t&nbsp; [1]&nbsp;&nbsp;&nbsp; pid\n\n\t\t\t\t\t&nbsp; nohup: appending output to &lsquo;nohup.out&#39;\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t<span style=\"line-height: 1.6em;\">实战的时候，更多的情况是这样的：突然有事要走开一下，又生怕跑了半天的程序因为终端挂了，想将其托管给系统。那么就可以用disown命令。</span>\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"631\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"629\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ /bin/sh your.sh &amp;\n\n\t\t\t\t\t&nbsp; [1]&nbsp;&nbsp;&nbsp; pid\n\n\t\t\t\t\t&nbsp; &gt;&gt; disown %1\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **REFE:** 看这个解释得更为详细，我对其理解较为肤浅：[**Linux****技巧：让后台在后台可靠运行的几种方法**](http://www.ibm.com/developerworks/cn/linux/l-cn-nohup/)**。**\n\n\t**screen:**\n\n\t上面两个命令都不是最好用的，最好用的应该是screen命令了。screen 提供了 ANSI/VT100 的终端模拟器，使它能够在一个真实终端下运行多个全屏的伪终端。screen用好了，感觉也不比tmux差多少。\n\n\t要同时跑多个screen，并想快速切换的换，可以添加几个screen的alias。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"631\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"629\">\n\n\t\t\t\t\talias s=&quot;screen&quot;\n\n\t\t\t\t\talias sr=&quot;screen -r&quot;&nbsp;&nbsp;&nbsp;&nbsp; # 连接到某个模拟器\n\n\t\t\t\t\talias sl=&quot;screen -ls&quot;&nbsp;&nbsp;&nbsp;&nbsp; # 显示当前所有模拟器\n\n\t\t\t\t\talias sl=&quot;screen -d&quot;&nbsp;&nbsp;&nbsp;&nbsp; # 强制断开某个模拟器连接\n\n\t\t\t\t\tctrl+a :sessionname MyName&nbsp;&nbsp; # 在screen模拟器中，修改模拟器名字\n\n\t\t\t\t\tctrl+a :kill&nbsp;&nbsp;&nbsp; # 强制关闭模拟器（模拟器有时候会莫名其妙的没响应）\n\n\t\t\t\t\tctrl+a :encoding gbk&nbsp;&nbsp;&nbsp;&nbsp; # 设置screen编码\n\n\t\t\t\t\tctrl+a d&nbsp;&nbsp;&nbsp;&nbsp; # detached模拟器（就是临时退出）\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **TIPS**: screen终端ls文件没有颜色，是因为screen终端类型比较特殊，echo $TERM显示为screen或者screen.linux类型，解决方案是修改/etc/DIR_COLORS或者复制/etc/DIR_COLORS到~/.dir_colors，加入一句：&quot;TERM screen&quot;注销重登即可。\n\n\t**jobs:**\n\n\t列出当前终端运行的后台进程。\n\n\t**ps:**\n\n\t列出系统正在运行的程序。\n\n\t**top:**\n\n\t理解为win下面的任务管理器，需要注意的地方应该是load average了，Load Average表示了CPU的Load，它所包含的信息不是 CPU的使用率状况，而是在一段时间内CPU正在处理以及等待CPU处理的进程数之和的统计信息，也就是 CPU使用队列的长度的统计信息。load average: 0.06, 0.60, 0.48，三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值。需要注意，load average如果超过一定的数的话，系统负载较高。\n\n\t**Load Average &lt; CPU个数 * 核数 *0.7**\n\n\t我常用的命令也不多，如下：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"635\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"633\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ top\n\n\t\t\t\t\t&nbsp; ...\n\n\t\t\t\t\t&nbsp; ...\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ top -p pid [-p pid2 ...]\n\n\t\t\t\t\t&nbsp; ...&nbsp;&nbsp;&nbsp; # 只查看pid这个进程\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**crontab:**\n\n\t定时任务命令，这个东西有时候也折磨了好一段时间。内容格式说着也简单：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"635\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"633\">\n\n\t\t\t\t\t&gt;&gt; $ crontab -e&nbsp;&nbsp;&nbsp; # 编辑定时任务列表\n\n\t\t\t\t\t* * * * * cmd &gt; /dev/null 2&gt;&amp;1&nbsp;&nbsp;&nbsp;&nbsp; # 5个*分别代表分、时、日、月、周。需要将输出写到某个文件或者/dev/null中，因为它的所有输出均会按邮件发到服务器上，日积月累也是个负担\n\n\t\t\t\t\t*/2 * * * * cmd &gt; /dev/null 2&gt;&amp;1&nbsp;&nbsp;&nbsp;&nbsp; # 代表每两分钟执行一次cmd\n\n\t\t\t\t\t&gt;&gt; $ crontab -l&nbsp;&nbsp;&nbsp; # 显示定时任务列表\n\n\t\t\t\t\t&gt;&gt; $ crontab -r&nbsp;&nbsp;&nbsp; # 删除定时任务列表（- -，不知道为什么要有这个选项）\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **REFE:** 偷懒，直接贴其他人的帖子吧：[Crontab 错误分析及不执行原因](http://www.cnblogs.com/cosiray/archive/2012/03/09/2387361.html)\n\n\t**history:**\n\n\t查看命令历史，以下是常用方法和有用的设置：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"635\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"633\">\n\n\t\t\t\t\t&gt;&gt; $ history | more\n\n\t\t\t\t\t&gt;&gt; $ history | grep ls\n\n\t\t\t\t\t&gt;&gt; $ vi ~/.bashrc\n\n\t\t\t\t\tHISTFILESIZE=2000&nbsp;&nbsp;&nbsp;&nbsp; # history 记录长度\n\n\t\t\t\t\tHISTTIMEFORMAT=&#39;%F %T &#39;&nbsp;&nbsp;&nbsp;&nbsp; # 给记录添加时间戳\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **TIPS1:** 输入命令前，输入一个空格，该记录不添加进history中。嘿嘿嘿嘿&hellip;&hellip;\r> \n> \n> \t\t**TIPS2:** ctrl + r是找历史记录，查找过程中继续按ctrl+r是当前查找结果的上一条\n\n\t**ssh:**\n\n\t最后一个说ssh，好像也没啥说的。远程登录，远程拷贝&hellip;&hellip;\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"634\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"632\">\n\n\t\t\t\t\t&gt;&gt; $ ssh -l user ip [-p port]\n\n\t\t\t\t\t&gt;&gt; $ ssh user@ip\n\n\t\t\t\t\t&gt;&gt; $ scp user@ip:/src/dir/or/file user@ip:/dest/dir/or/file\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **FINAL TIPS:** 拷贝的时候需要输入对方的用户密码，可以添加相关的密钥一劳永逸。但是添加密钥的方式有点微麻烦，所以可以用其他方式代替，那就是用expect命令。下面这段脚本可以实现无间断的远程push，可以自己改成远程pull。\r> \n> \n> \t\t&nbsp;\r> \n> \n> \t<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"605\">\r> \n> \t\t<tbody>\r> \n> \t\t\t<tr>\r> \n> \t\t\t\t<td valign=\"top\" width=\"603\">\r> \n> \n> \t\t\t\t\t\t#!/usr/bin/expect\r> \n> \n> \t\t\t\t\t\tset user [lindex $argv 0]\r> \n> \n> \t\t\t\t\t\tset passwd [lindex $argv 1]\r> \n> \n> \t\t\t\t\t\tset ip [lindex $argv 2]\r> \n> \n> \t\t\t\t\t\tset src [lindex $argv 3]\r> \n> \n> \t\t\t\t\t\tset des [lindex $argv 4]\r> \n> \n> \t\t\t\t\t\tset timeout 60\r> \n> \n> \t\t\t\t\t\tspawn /usr/local/bin/scp -r ${src} ${user}@${ip}:${des}\r> \n> \n> \t\t\t\t\t\texpect {\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; &quot;*assword:&quot; {\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp; send &quot;${passwd}\\n&quot;\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp; exp_continue\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; }\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; &quot;fcr_parse_raw&quot; {\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; close\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; exit -2\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; }\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; timeout {\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; close\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; exit -1\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; }\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; eof {\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; catch wait result\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; exit [lindex $result 3]\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; }\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; -re . {\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; exp_continue\r> \n> \n> \t\t\t\t\t\t&nbsp;&nbsp;&nbsp; }\r> \n> \n> \t\t\t\t\t\t}\r> \n> \n> \t\t\t\t</td>\r> \n> \t\t\t</tr>\r> \n> \t\t</tbody>\r> \n> \t</table>","slug":"linux-process-shell","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg622s005hsb8fpcni6h4n"},{"title":"Shell常用命令 文件/目录操作篇","id":"637","date":"2013-01-18T12:38:24.000Z","_content":"\n**2.1 ****基本操作**\n\n\tls(list), cd(change directory), rm(remove), touch, mkdir(make directory), rmdir(remove directory), pwd(print working dir)\n\n> **TIPS: **cd - 可以返回上次所处目录。\r> \n> \n> \t\t**WARNING:** 慎用rm -rf *，想当年某同学就rm掉了工作目录，不过代码有备份。\n\n\t<!--more-->\n\n\t&nbsp;\n\n\t**2.2 ****文件查找**\n\n\t最常用的当属**find**命令了。find的使用格式及我常用例子如下：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"631\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"629\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ find -help\n\n\t\t\t\t\t&nbsp; Usage: find [path] [expression](&lt;option&gt; &lt;action&gt;) # commented by wikie\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ find . -name &quot;*.txt&quot;&nbsp;&nbsp;&nbsp; # 查找当前目录下所有符合&quot;*.txt&quot;的文件\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ find . -type f|d|l&nbsp;&nbsp;&nbsp; # 查找当前目录下所有普通文件|目录|链接符号\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ find . -size 1024(c)&nbsp;&nbsp;&nbsp; # 查找当前目录大小为1024个块（字节）的文件\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ find . -maxdepth 1 -name &quot;*.txt&quot;&nbsp;&nbsp;&nbsp; # 设置最大查找深入，1表示为当前目录\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ find . -a(m)time -1&nbsp;&nbsp;&nbsp; # 查找当前目录下最后24小时访问（修改）的文件\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ find . -name &quot;*.tmp&quot; -exec(-ok) rm {} \\;&nbsp;&nbsp; # 删除当前目录的所有tmp文件，-ok表示执行前先询问用户\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **TIPS1:** 如不太喜欢用-exec，也可以用 find . | while read line; do do_sth to $line; done;\r> \n> \n> \t\t**TIPS2:** 最好的参考文档莫过于man find了\n\n\t**locate****：**\n\n\tlocate命令其实是&ldquo;find -name&rdquo;的另一种写法，但是要比后者快得多，原因在于它不搜索具体目录，而是搜索一个数据库（/var/lib/locatedb），这个数据库中含有本地所有文件信息。Linux系统自动创建这个数据库，并且每天自动更新一次，所以使用locate命令查不到最新变动过的文件。为了避免这种情况，可以在使用locate之前，先使用updatedb命令，手动更新数据库。不过需要root权限。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"631\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"629\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ locate your_file\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**whereis:**\n\n\twhereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"632\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"630\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ whereis whereis\n\n\t\t\t\t\t&nbsp; whereis: /usr/bin/whereis /usr/share/man/man1/whereis.1.gz\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**which:**\n\n\twhich命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"633\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"631\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ which gcc\n\n\t\t\t\t\t&nbsp; /usr/bin/gcc\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **REFE: **以上多数文字摘抄自阮一峰的文章 - 《[Linux的五个查找命令](http://www.ruanyifeng.com/blog/2009/10/5_ways_to_search_for_files_using_the_terminal.html)》\n\n\t&nbsp;\n\n\t**2.3 ****磁盘操作**\n\n\tdu(disk usage)查看目录大小，df(disk free)查看磁盘状况。均有-h参数，代表human-readable，即数据小大会显示单位。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"634\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"632\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ du -sh .&nbsp;&nbsp;&nbsp;&nbsp; # -s summay\n\n\t\t\t\t\t&nbsp; 10G&nbsp;&nbsp;&nbsp;&nbsp; .\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ df -h\n\n\t\t\t\t\t&nbsp; Filesystem&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Size&nbsp;&nbsp; Used&nbsp;&nbsp; Avail&nbsp;&nbsp; Use%&nbsp;&nbsp; Mounted on\n\n\t\t\t\t\t&nbsp; /dev/hda1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 62G&nbsp;&nbsp;&nbsp; 21G&nbsp;&nbsp;&nbsp; 42G&nbsp;&nbsp;&nbsp; 34%&nbsp;&nbsp;&nbsp;&nbsp; /\n\n\t\t\t\t\t&nbsp; tmpfs&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 502M&nbsp;&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp; 502M&nbsp;&nbsp;&nbsp; 0%&nbsp;&nbsp;&nbsp;&nbsp; /dev/shm\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ df -ih&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # -i inode usage\n\n\t\t\t\t\t&nbsp; Filesystem&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Inodes&nbsp;&nbsp; IUsed&nbsp;&nbsp; IFree&nbsp;&nbsp; IUse%&nbsp;&nbsp; Mounted on\n\n\t\t\t\t\t&nbsp; /dev/hda1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 63M&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 197K&nbsp;&nbsp;&nbsp; 62M&nbsp;&nbsp;&nbsp; 1%&nbsp;&nbsp; /\n\n\t\t\t\t\t&nbsp; tmpfs&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 126K&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 126K&nbsp;&nbsp;&nbsp; 1%&nbsp;&nbsp; /dev/shm\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **WARNING: **这两个命令非常重要，在机器上运行大任务的同时，切忌注意磁盘空间是否充裕（我们这里规定超过85%就报警）。经常有同事撑爆服务器，上头就过来找我麻烦T_T，真的冤枉。话说，以前也因为没有估量自己任务大小，撑爆一个集群的情况出现&hellip;&hellip;\r> \n> \n> \t\t**TIPS:** df是针对整个文件系统的，它通过系统调用statfs从文件系统的超级块中获取整个文件系统的磁盘使用情况，它没有没法针对任意目录来统计，但统计磁盘大小速度更快。如果需要统计磁盘大小，可以用df代替du：df -h | grep mounted_disk | awk &#39;{print $4}&#39;\n\n\t&nbsp;\n\n\t**2.4 ****权限管理**\n\n\tchmod(change mode), chown(change owner)\n\n\t说实在的，这两个命令在非管理员的情况下一般用不到。用得多的是chmod +x file，给文件添加执行权限。其他的还有需求自行谷歌。\n\n\t&nbsp;\n\n\t**2.5 ****文件压缩、裁剪**\n\n\t压缩用的是tar命令，也有用zip的但是不多。tar的参数实在是太多了，列不过来，就说两个常用的压缩解压缩吧：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"630\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"628\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ tar zcvf file.tar.gz file&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # z 以gzip的压缩方式压缩&nbsp; c 压缩\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ tar zxvf file.tar.gz [-C untar_dir]\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **WARNING: **需要注意gzip压缩解压缩非常耗时且耗cpu\r> \n> \n> \t\t**TIPS: **在远程拷贝（scp）文件的时候，如果文件非常大，需要考虑拷贝中断所带来的痛苦。所以适当的将文件裁剪成多个再scp，拷贝中断带来的痛苦系数会大大减小。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"632\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"630\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ split --help\n\n\t\t\t\t\t&nbsp; Usage: split [OPTION] [INPUT [PREFIX]]\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ split -b 1024b(k)(m) filename (splited_filename)&nbsp;&nbsp; # 按大小裁剪\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ split -l 1000 filename (splited_filename)&nbsp;&nbsp; # 按行数裁剪\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ cat splited_filename* &gt; filename&nbsp;&nbsp; # 合并被裁剪文件\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>","source":"_posts/linux-file-directory-shell.md","raw":"title: Shell常用命令 文件/目录操作篇\ntags:\n  - Linux\n  - Shell\nid: 637\ncategories:\n  - 技术分享\ndate: 2013-01-18 20:38:24\n---\n\n**2.1 ****基本操作**\n\n\tls(list), cd(change directory), rm(remove), touch, mkdir(make directory), rmdir(remove directory), pwd(print working dir)\n\n> **TIPS: **cd - 可以返回上次所处目录。\r> \n> \n> \t\t**WARNING:** 慎用rm -rf *，想当年某同学就rm掉了工作目录，不过代码有备份。\n\n\t<!--more-->\n\n\t&nbsp;\n\n\t**2.2 ****文件查找**\n\n\t最常用的当属**find**命令了。find的使用格式及我常用例子如下：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"631\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"629\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ find -help\n\n\t\t\t\t\t&nbsp; Usage: find [path] [expression](&lt;option&gt; &lt;action&gt;) # commented by wikie\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ find . -name &quot;*.txt&quot;&nbsp;&nbsp;&nbsp; # 查找当前目录下所有符合&quot;*.txt&quot;的文件\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ find . -type f|d|l&nbsp;&nbsp;&nbsp; # 查找当前目录下所有普通文件|目录|链接符号\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ find . -size 1024(c)&nbsp;&nbsp;&nbsp; # 查找当前目录大小为1024个块（字节）的文件\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ find . -maxdepth 1 -name &quot;*.txt&quot;&nbsp;&nbsp;&nbsp; # 设置最大查找深入，1表示为当前目录\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ find . -a(m)time -1&nbsp;&nbsp;&nbsp; # 查找当前目录下最后24小时访问（修改）的文件\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ find . -name &quot;*.tmp&quot; -exec(-ok) rm {} \\;&nbsp;&nbsp; # 删除当前目录的所有tmp文件，-ok表示执行前先询问用户\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **TIPS1:** 如不太喜欢用-exec，也可以用 find . | while read line; do do_sth to $line; done;\r> \n> \n> \t\t**TIPS2:** 最好的参考文档莫过于man find了\n\n\t**locate****：**\n\n\tlocate命令其实是&ldquo;find -name&rdquo;的另一种写法，但是要比后者快得多，原因在于它不搜索具体目录，而是搜索一个数据库（/var/lib/locatedb），这个数据库中含有本地所有文件信息。Linux系统自动创建这个数据库，并且每天自动更新一次，所以使用locate命令查不到最新变动过的文件。为了避免这种情况，可以在使用locate之前，先使用updatedb命令，手动更新数据库。不过需要root权限。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"631\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"629\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ locate your_file\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**whereis:**\n\n\twhereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"632\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"630\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ whereis whereis\n\n\t\t\t\t\t&nbsp; whereis: /usr/bin/whereis /usr/share/man/man1/whereis.1.gz\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**which:**\n\n\twhich命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"633\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"631\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ which gcc\n\n\t\t\t\t\t&nbsp; /usr/bin/gcc\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **REFE: **以上多数文字摘抄自阮一峰的文章 - 《[Linux的五个查找命令](http://www.ruanyifeng.com/blog/2009/10/5_ways_to_search_for_files_using_the_terminal.html)》\n\n\t&nbsp;\n\n\t**2.3 ****磁盘操作**\n\n\tdu(disk usage)查看目录大小，df(disk free)查看磁盘状况。均有-h参数，代表human-readable，即数据小大会显示单位。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"634\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"632\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ du -sh .&nbsp;&nbsp;&nbsp;&nbsp; # -s summay\n\n\t\t\t\t\t&nbsp; 10G&nbsp;&nbsp;&nbsp;&nbsp; .\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ df -h\n\n\t\t\t\t\t&nbsp; Filesystem&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Size&nbsp;&nbsp; Used&nbsp;&nbsp; Avail&nbsp;&nbsp; Use%&nbsp;&nbsp; Mounted on\n\n\t\t\t\t\t&nbsp; /dev/hda1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 62G&nbsp;&nbsp;&nbsp; 21G&nbsp;&nbsp;&nbsp; 42G&nbsp;&nbsp;&nbsp; 34%&nbsp;&nbsp;&nbsp;&nbsp; /\n\n\t\t\t\t\t&nbsp; tmpfs&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 502M&nbsp;&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp; 502M&nbsp;&nbsp;&nbsp; 0%&nbsp;&nbsp;&nbsp;&nbsp; /dev/shm\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ df -ih&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # -i inode usage\n\n\t\t\t\t\t&nbsp; Filesystem&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Inodes&nbsp;&nbsp; IUsed&nbsp;&nbsp; IFree&nbsp;&nbsp; IUse%&nbsp;&nbsp; Mounted on\n\n\t\t\t\t\t&nbsp; /dev/hda1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 63M&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 197K&nbsp;&nbsp;&nbsp; 62M&nbsp;&nbsp;&nbsp; 1%&nbsp;&nbsp; /\n\n\t\t\t\t\t&nbsp; tmpfs&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 126K&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 126K&nbsp;&nbsp;&nbsp; 1%&nbsp;&nbsp; /dev/shm\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **WARNING: **这两个命令非常重要，在机器上运行大任务的同时，切忌注意磁盘空间是否充裕（我们这里规定超过85%就报警）。经常有同事撑爆服务器，上头就过来找我麻烦T_T，真的冤枉。话说，以前也因为没有估量自己任务大小，撑爆一个集群的情况出现&hellip;&hellip;\r> \n> \n> \t\t**TIPS:** df是针对整个文件系统的，它通过系统调用statfs从文件系统的超级块中获取整个文件系统的磁盘使用情况，它没有没法针对任意目录来统计，但统计磁盘大小速度更快。如果需要统计磁盘大小，可以用df代替du：df -h | grep mounted_disk | awk &#39;{print $4}&#39;\n\n\t&nbsp;\n\n\t**2.4 ****权限管理**\n\n\tchmod(change mode), chown(change owner)\n\n\t说实在的，这两个命令在非管理员的情况下一般用不到。用得多的是chmod +x file，给文件添加执行权限。其他的还有需求自行谷歌。\n\n\t&nbsp;\n\n\t**2.5 ****文件压缩、裁剪**\n\n\t压缩用的是tar命令，也有用zip的但是不多。tar的参数实在是太多了，列不过来，就说两个常用的压缩解压缩吧：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"630\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"628\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ tar zcvf file.tar.gz file&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # z 以gzip的压缩方式压缩&nbsp; c 压缩\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ tar zxvf file.tar.gz [-C untar_dir]\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n> **WARNING: **需要注意gzip压缩解压缩非常耗时且耗cpu\r> \n> \n> \t\t**TIPS: **在远程拷贝（scp）文件的时候，如果文件非常大，需要考虑拷贝中断所带来的痛苦。所以适当的将文件裁剪成多个再scp，拷贝中断带来的痛苦系数会大大减小。\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\" width=\"632\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"630\">\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ split --help\n\n\t\t\t\t\t&nbsp; Usage: split [OPTION] [INPUT [PREFIX]]\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ split -b 1024b(k)(m) filename (splited_filename)&nbsp;&nbsp; # 按大小裁剪\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ split -l 1000 filename (splited_filename)&nbsp;&nbsp; # 按行数裁剪\n\n\t\t\t\t\t&nbsp; &gt;&gt; $ cat splited_filename* &gt; filename&nbsp;&nbsp; # 合并被裁剪文件\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>","slug":"linux-file-directory-shell","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg622u005lsb8fua2jrmej"},{"title":"Les Miserables - Do You Hear the People Sing?","id":"688","date":"2013-03-05T13:41:21.000Z","_content":"\nDo you hear the people sing?\n\n\tSinging a song of angry men?\n\n\tIt is the music of a people\n\n\tWho will not be slaves again!\n\n\tWhen the beating of your heart\n\n\tEchoes the beating of the drums\n\n\tThere is a life about to start\n\n\tWhen tomorrow comes!\n\n<!--more-->\n\n\tWill you join in our crusade?\n\n\tWho will be strong and stand with me?\n\n\tBeyond the barricade\n\n\tIs there a world you long to see?\n\n\tThen join in the fight\n\n\tThat will give you the right to be free!\n\n\tDo you hear the people sing?\n\n\tSinging a song of angry men?\n\n\tIt is the music of a people\n\n\tWho will not be slaves again!\n\n\tWhen the beating of your heart\n\n\tEchoes the beating of the drums\n\n\tThere is a life about to start\n\n\tWhen tomorrow comes!\n\n\tWill you give all you can give\n\n\tSo that our banner may advance\n\n\tSome will fall and some will live\n\n\tWill you stand up and take your chance?\n\n\tThe blood of the martyrs\n\n\tWill water the meadows of France!\n\n\tDo you hear the people sing?\n\n\tSinging a song of angry men?\n\n\tIt is the music of a people\n\n\tWho will not be slaves again!\n\n\tWhen the beating of your heart\n\n\tEchoes the beating of the drums\n\n\tThere is a life about to start\n\n\tWhen tomorrow comes!\n\n\t<object classid=\"clsid:d27cdb6e-ae6d-11cf-96b8-444553540000\" codebase=\"http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0\" height=\"33\" hspace=\"0\" vspace=\"0\" width=\"257\"><param name=\"quality\" value=\"high\" /><param name=\"movie\" value=\"http://www.xiami.com/widget/8564659_1769015591/singlePlayer.swf\" /><embed height=\"33\" hspace=\"0\" pluginspage=\"http://www.macromedia.com/go/getflashplayer\" quality=\"high\" src=\"http://www.xiami.com/widget/8564659_1769015591/singlePlayer.swf\" type=\"application/x-shockwave-flash\" vspace=\"0\" width=\"257\"></embed></object>​","source":"_posts/les-miserables-lrc.md","raw":"title: Les Miserables - Do You Hear the People Sing?\ntags:\n  - 歌词\n  - 音乐\nid: 688\ncategories:\n  - 生活分享\ndate: 2013-03-05 21:41:21\n---\n\nDo you hear the people sing?\n\n\tSinging a song of angry men?\n\n\tIt is the music of a people\n\n\tWho will not be slaves again!\n\n\tWhen the beating of your heart\n\n\tEchoes the beating of the drums\n\n\tThere is a life about to start\n\n\tWhen tomorrow comes!\n\n<!--more-->\n\n\tWill you join in our crusade?\n\n\tWho will be strong and stand with me?\n\n\tBeyond the barricade\n\n\tIs there a world you long to see?\n\n\tThen join in the fight\n\n\tThat will give you the right to be free!\n\n\tDo you hear the people sing?\n\n\tSinging a song of angry men?\n\n\tIt is the music of a people\n\n\tWho will not be slaves again!\n\n\tWhen the beating of your heart\n\n\tEchoes the beating of the drums\n\n\tThere is a life about to start\n\n\tWhen tomorrow comes!\n\n\tWill you give all you can give\n\n\tSo that our banner may advance\n\n\tSome will fall and some will live\n\n\tWill you stand up and take your chance?\n\n\tThe blood of the martyrs\n\n\tWill water the meadows of France!\n\n\tDo you hear the people sing?\n\n\tSinging a song of angry men?\n\n\tIt is the music of a people\n\n\tWho will not be slaves again!\n\n\tWhen the beating of your heart\n\n\tEchoes the beating of the drums\n\n\tThere is a life about to start\n\n\tWhen tomorrow comes!\n\n\t<object classid=\"clsid:d27cdb6e-ae6d-11cf-96b8-444553540000\" codebase=\"http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=6,0,40,0\" height=\"33\" hspace=\"0\" vspace=\"0\" width=\"257\"><param name=\"quality\" value=\"high\" /><param name=\"movie\" value=\"http://www.xiami.com/widget/8564659_1769015591/singlePlayer.swf\" /><embed height=\"33\" hspace=\"0\" pluginspage=\"http://www.macromedia.com/go/getflashplayer\" quality=\"high\" src=\"http://www.xiami.com/widget/8564659_1769015591/singlePlayer.swf\" type=\"application/x-shockwave-flash\" vspace=\"0\" width=\"257\"></embed></object>​","slug":"les-miserables-lrc","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg622w005psb8frln26qp5"},{"title":"JVM内存结构","id":"270","date":"2012-02-13T05:25:40.000Z","_content":"\n**1****、JVM规定**\n\n《_The Java__ __Virtual Machine Specification_》中将JVM内存结构（又称运行时数据区Runtime Data Area）分为六部分（参看第三章）：\n\n1）The pc Register；2）Java Virtual Machine Stacks；3）Heap；4）Method Area；5）Runtime Constant Pool；6）Native Method Stacks；\n\n以上数据区的具体描述可参考规范。需要注意的是，以上只是一个规范说明，并没有规定虚拟机如何实现这些数据区。Sun JDK实现将内存空间划分为方法区、堆、本地方法栈、JVM方法栈、PC寄存器五部分。\n <!--more-->  \n\n如下图所示：\n\n[![clip_image002[6]](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0026_thumb.jpg \"clip_image002[6]\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0026.jpg)\n\n**2****、内存空间详解**\n\n**1）PC寄存器和JVM方法栈**\n\n每个线程都会拥有以及创建一个属于自己的PC寄存器和JVM方法栈，PC寄存器占用的有可能为CPU寄存器或者OS内存，而JVM栈占用的为OC内存。\n\n每运行一个方法，便会将方法的信息压入JVM方法栈中，同时将当前执行方法放入PC寄存器中（需要注意的是，如果当前方法为Native方法，PC寄存器的值为空）。可以想到，如果方法栈太深，如递归方法，便会报StackOverflowError，同样如果占用空间太多，也会报OutOfMemoryError。需要修改JVM参数设置：-Xss××k，在××中填入数字。\n\n**2）本地方法栈**\n\n同JVM方法栈一样，本地方法栈存放的是native方法的调用的状态。在Sun JDK的实现中，本地方法栈和JVM方法栈是同一个。\n\n**3）方法区**\n\n方法区存放了要加载的类的信息（名称、修饰符等）、类的静态变量、类中定义为fianl类型的常量、类中的Field信息、类中的方法信息，你用Class对象的方法，如getName()、getFields()等来获取信息时，这些数据都来自方法区。需要注意的是，Runtime Constant Pool（常量池）也存放在方法区中。\n\n方法区是被同一个JVM所有线程所共享的，在Sun JDK中这块区域对应Permanet Generation（持久代），默认最小值为16MB，最大值为64MB，可通过-XX:PermSize及-XX:MaxPermSize来指定。当方法区无法满足分配请求时，会报OutOfMemoryError。\n\n**4）堆**\n\n堆用于存放对象实例以及数组值，可以认为所有通过new来创建的对象的内存均在此分配。一般所说的GC，大部分都是对堆进行的。\n\n堆在32位操作系统上最大为2GB，在64位的则没有限制，大小通过-Xms和-Xmx来控制。-Xms为JVM启动时申请的最小堆内存，默认为物理内存的1/64但小于1GB；-Xmx为JVM可申请的最大堆内存，默认为物理内存的1/4但小于1GB，默认当空余堆内存小于40%的时候，JVM会将堆增大到-Xmx指定大小，可通过-XX:MinHeapFreeRatio=来指定比例，空余堆大于70%时，会将堆大小降到-Xms指定大小，这个参数可用-XX:MaxHeapFreeRatio=来指定。但对于运行系统来说，会避免频繁调整堆大小，会将-Xms和-Xmx的值设为一样。\n\n为了让内存回收更加高效，Sun JDK从1.2开始对堆采取了分代管理的方法，如下图：\n\n[![clip_image004[6]](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0046_thumb.jpg \"clip_image004[6]\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0046.jpg)\n\n**4.1) 新生代（New Generation）**\n\n大多数的新建对象都是从新生代中分配内存，新生代由Eden（伊甸园） Space和两块相同的Survivor Space（S0，S1或者From，To）构成。\n\n可通过-Xmn参数来指定新生代大小，-XX:SurvivorRatio来调整Eden与S Space的大小。\n\n**4.2）旧生代（Old Generation）**\n\n用于存放新生代经过多次垃圾回收仍然存活的对象，像Cache。同时新建的对象也有可能在旧生代上直接分配内存，一般来说是比较的对象，即：单一大对象以及大数组，-XX:PretenureSizeThreshold = 1024 (byte, default = 0)可用来代表单一对象超过多大即不在新生代分配。\n\n旧生代所占内存大小为-Xmx-（-Xmn）。\n\n**3****、典型JVM参数配置汇总**     <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"223\">           <p>**配置**\n         </td>          <td valign=\"top\" width=\"301\">           \n\n**解释**\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-Xss××k\n         </td>          <td valign=\"top\" width=\"301\">           \n\n方法栈深度\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-XX:PermSize\n         </td>          <td valign=\"top\" width=\"301\">           \n\n方法区内存最小值\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-XX:MaxPermSize\n         </td>          <td valign=\"top\" width=\"301\">           \n\n方法区内存最大值\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-Xms\n         </td>          <td valign=\"top\" width=\"301\">           \n\nJVM启动分配最小堆内存\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-Xmx\n         </td>          <td valign=\"top\" width=\"301\">           \n\nJVM启动分配最大堆内存\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-XX:MinHeapFreeRatio=\n         </td>          <td valign=\"top\" width=\"301\">           \n\n堆内存需扩展时，剩余内存最小比例，默认40%\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-XX:MaxHeapFreeRatio=\n         </td>          <td valign=\"top\" width=\"301\">           \n\n堆内存需收缩时，剩余内存最大比例，默认70%\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-Xmn\n         </td>          <td valign=\"top\" width=\"301\">           \n\n堆新生代内存大小\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-XX:NewRatio=\n         </td>          <td valign=\"top\" width=\"301\">           \n\n如参数为4，则新生代与旧生代比例为1：4\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-XX:SurvivorRatio=\n         </td>          <td valign=\"top\" width=\"301\">           \n\nS0/S1占新生代内存的比例\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-XX:PretenureSizeThreshold=\n         </td>          <td valign=\"top\" width=\"301\">           \n\n需要内存超过参数的对象，直接在旧生代分配\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-XX:MaxTenuringThreshold=\n         </td>          <td valign=\"top\" width=\"301\">           \n\n设置垃圾最大年龄。如果为0，新生代对象不经过S区，直接进行旧生代，值较大的话，会增加新生代对象再GC的概率。\n         </td>       </tr>     </tbody></table> </p>  \n\n**4、小结**\n\n总的来说，所有语言的内存结构都大同小异，均分为堆、栈、区，堆放动态分配（alloc）的对象，栈存放临时变量、方法过程等，区则存放编译时确定的方法签名、常量池等。\n\nJVM的内存结构需要结合GC一起学习，有兴趣的可以参考&lt;The Java™ Virtual Machine Specification&gt;以及&lt;分布式Java应用&gt;这两本书。","source":"_posts/jvm-structure.md","raw":"title: JVM内存结构\ntags:\n  - JVM\nid: 270\ncategories:\n  - 技术分享\ndate: 2012-02-13 13:25:40\n---\n\n**1****、JVM规定**\n\n《_The Java__ __Virtual Machine Specification_》中将JVM内存结构（又称运行时数据区Runtime Data Area）分为六部分（参看第三章）：\n\n1）The pc Register；2）Java Virtual Machine Stacks；3）Heap；4）Method Area；5）Runtime Constant Pool；6）Native Method Stacks；\n\n以上数据区的具体描述可参考规范。需要注意的是，以上只是一个规范说明，并没有规定虚拟机如何实现这些数据区。Sun JDK实现将内存空间划分为方法区、堆、本地方法栈、JVM方法栈、PC寄存器五部分。\n <!--more-->  \n\n如下图所示：\n\n[![clip_image002[6]](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0026_thumb.jpg \"clip_image002[6]\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0026.jpg)\n\n**2****、内存空间详解**\n\n**1）PC寄存器和JVM方法栈**\n\n每个线程都会拥有以及创建一个属于自己的PC寄存器和JVM方法栈，PC寄存器占用的有可能为CPU寄存器或者OS内存，而JVM栈占用的为OC内存。\n\n每运行一个方法，便会将方法的信息压入JVM方法栈中，同时将当前执行方法放入PC寄存器中（需要注意的是，如果当前方法为Native方法，PC寄存器的值为空）。可以想到，如果方法栈太深，如递归方法，便会报StackOverflowError，同样如果占用空间太多，也会报OutOfMemoryError。需要修改JVM参数设置：-Xss××k，在××中填入数字。\n\n**2）本地方法栈**\n\n同JVM方法栈一样，本地方法栈存放的是native方法的调用的状态。在Sun JDK的实现中，本地方法栈和JVM方法栈是同一个。\n\n**3）方法区**\n\n方法区存放了要加载的类的信息（名称、修饰符等）、类的静态变量、类中定义为fianl类型的常量、类中的Field信息、类中的方法信息，你用Class对象的方法，如getName()、getFields()等来获取信息时，这些数据都来自方法区。需要注意的是，Runtime Constant Pool（常量池）也存放在方法区中。\n\n方法区是被同一个JVM所有线程所共享的，在Sun JDK中这块区域对应Permanet Generation（持久代），默认最小值为16MB，最大值为64MB，可通过-XX:PermSize及-XX:MaxPermSize来指定。当方法区无法满足分配请求时，会报OutOfMemoryError。\n\n**4）堆**\n\n堆用于存放对象实例以及数组值，可以认为所有通过new来创建的对象的内存均在此分配。一般所说的GC，大部分都是对堆进行的。\n\n堆在32位操作系统上最大为2GB，在64位的则没有限制，大小通过-Xms和-Xmx来控制。-Xms为JVM启动时申请的最小堆内存，默认为物理内存的1/64但小于1GB；-Xmx为JVM可申请的最大堆内存，默认为物理内存的1/4但小于1GB，默认当空余堆内存小于40%的时候，JVM会将堆增大到-Xmx指定大小，可通过-XX:MinHeapFreeRatio=来指定比例，空余堆大于70%时，会将堆大小降到-Xms指定大小，这个参数可用-XX:MaxHeapFreeRatio=来指定。但对于运行系统来说，会避免频繁调整堆大小，会将-Xms和-Xmx的值设为一样。\n\n为了让内存回收更加高效，Sun JDK从1.2开始对堆采取了分代管理的方法，如下图：\n\n[![clip_image004[6]](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0046_thumb.jpg \"clip_image004[6]\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0046.jpg)\n\n**4.1) 新生代（New Generation）**\n\n大多数的新建对象都是从新生代中分配内存，新生代由Eden（伊甸园） Space和两块相同的Survivor Space（S0，S1或者From，To）构成。\n\n可通过-Xmn参数来指定新生代大小，-XX:SurvivorRatio来调整Eden与S Space的大小。\n\n**4.2）旧生代（Old Generation）**\n\n用于存放新生代经过多次垃圾回收仍然存活的对象，像Cache。同时新建的对象也有可能在旧生代上直接分配内存，一般来说是比较的对象，即：单一大对象以及大数组，-XX:PretenureSizeThreshold = 1024 (byte, default = 0)可用来代表单一对象超过多大即不在新生代分配。\n\n旧生代所占内存大小为-Xmx-（-Xmn）。\n\n**3****、典型JVM参数配置汇总**     <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"223\">           <p>**配置**\n         </td>          <td valign=\"top\" width=\"301\">           \n\n**解释**\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-Xss××k\n         </td>          <td valign=\"top\" width=\"301\">           \n\n方法栈深度\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-XX:PermSize\n         </td>          <td valign=\"top\" width=\"301\">           \n\n方法区内存最小值\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-XX:MaxPermSize\n         </td>          <td valign=\"top\" width=\"301\">           \n\n方法区内存最大值\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-Xms\n         </td>          <td valign=\"top\" width=\"301\">           \n\nJVM启动分配最小堆内存\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-Xmx\n         </td>          <td valign=\"top\" width=\"301\">           \n\nJVM启动分配最大堆内存\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-XX:MinHeapFreeRatio=\n         </td>          <td valign=\"top\" width=\"301\">           \n\n堆内存需扩展时，剩余内存最小比例，默认40%\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-XX:MaxHeapFreeRatio=\n         </td>          <td valign=\"top\" width=\"301\">           \n\n堆内存需收缩时，剩余内存最大比例，默认70%\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-Xmn\n         </td>          <td valign=\"top\" width=\"301\">           \n\n堆新生代内存大小\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-XX:NewRatio=\n         </td>          <td valign=\"top\" width=\"301\">           \n\n如参数为4，则新生代与旧生代比例为1：4\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-XX:SurvivorRatio=\n         </td>          <td valign=\"top\" width=\"301\">           \n\nS0/S1占新生代内存的比例\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-XX:PretenureSizeThreshold=\n         </td>          <td valign=\"top\" width=\"301\">           \n\n需要内存超过参数的对象，直接在旧生代分配\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"223\">           \n\n-XX:MaxTenuringThreshold=\n         </td>          <td valign=\"top\" width=\"301\">           \n\n设置垃圾最大年龄。如果为0，新生代对象不经过S区，直接进行旧生代，值较大的话，会增加新生代对象再GC的概率。\n         </td>       </tr>     </tbody></table> </p>  \n\n**4、小结**\n\n总的来说，所有语言的内存结构都大同小异，均分为堆、栈、区，堆放动态分配（alloc）的对象，栈存放临时变量、方法过程等，区则存放编译时确定的方法签名、常量池等。\n\nJVM的内存结构需要结合GC一起学习，有兴趣的可以参考&lt;The Java™ Virtual Machine Specification&gt;以及&lt;分布式Java应用&gt;这两本书。","slug":"jvm-structure","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg622x005tsb8fno1na3yx"},{"title":"Java 源码阅读 最佳实践","date":"2015-09-01T15:40:00.000Z","_content":"\n## 原则\n\n\n### 原则1：了解使用\n\n仔细查看使用文档和说明，写较为详细的 demo 程序。\n\n### 原则2：了解全局\n\n了解该产品解决了哪些问题，并了解其周边产品及优缺点。\n\n### 原则3：了解原理\n\n查看其内部架构文档，如果有了周边产品的了解，可以从周边产品推算出其实现基本原理。不过当对其它产品了解比较深刻的时候，这个原则很容易就可以达到了。\n\n<!-- more -->\n## 方式\n\n### 单步 Debug\n\n单步 Debug 是比直接阅读源码来得更加直观快速的方式，通过单步 Debug 的主要目的是了解整个源码的大概逻辑和流程。\n\n* 针对应用程序（Tomcat、Hadoop）：找启动脚本 -> 找到 main 入口 -> 开始 Debug\n* 库、框架（FastJSON、Spring）：找到关键类 -> 打断点 -> 查看堆栈\n\n### 「无法 Debug？」\n\n很多时候我们拿到的都是「无法运行」的代码，比如说构建起来很麻烦的源码、只有一个 lib 包。在这个时候只能采取一些其它手段了。\n\n* 在我看来，最有效的方式还是 Debug。如果遇到了比较难构建的源码，那么暂时放弃构建它的想法，可以直接新建一个工程并添加其 Jar 包依赖，写测试代码的方式进行 Debug。至于测试代码，可以从源码的官方文档、或者它的测试用例中找到；\n\n* 如果以上也是比较麻烦的话，那就直接强行裸看代码吧，不过裸看代码也有一些简便的方法让你更好的裸看代码，比如接下来的。\n\n\n### 梳理整个工程的类依赖关系图\n\n以 Intellij IDEA 的为例：\n\n\n* 右键 Java 类\n* 点击 Diagrams\n* 点击 Show Diagrams\n\n\n### 查找方法调用关系\n\n以 Intellij IDEA 的 Mac OS X 的快捷键为例：\n\n* Alt + F7 (Find Usage)\n* Ctrl + Alt + H (Call Hierarchy)\n\n\n### 搜索关键字\n\n这个一般在无头绪的时候才会使用的。比如出现了框架内部的错误，里面包含了特殊关键字，如错误日志或者没有堆栈的方法。\n\n这个在 Intellij IDEA 中比较好用，可以包含依赖的三方库进行全文搜索。快捷键：\n\n* Ctrl + Shift + F (Find in path)\n\n> 搜索三方库需要选择 Custom -> Project and Libraries\n\n如果是 Eclipse 的话，似乎只能是大概知道是哪个 Jar 包之后，解压 source 包再全文搜索吧 = =\n\n\n\n## 其他\n\n我好像就上面几个方法，看任何源码（Hadoop、Spring、Netty、公司内部的）都能够很快上手。如果想到啥或者有啥比较典型的实例的话，再补充吧。\n","source":"_posts/java-source-code-practice.md","raw":"title: Java 源码阅读 最佳实践\ndate: 2015-09-01 23:40:00\ncategories: 最佳实践\ntags: Java, 源码\n---\n\n## 原则\n\n\n### 原则1：了解使用\n\n仔细查看使用文档和说明，写较为详细的 demo 程序。\n\n### 原则2：了解全局\n\n了解该产品解决了哪些问题，并了解其周边产品及优缺点。\n\n### 原则3：了解原理\n\n查看其内部架构文档，如果有了周边产品的了解，可以从周边产品推算出其实现基本原理。不过当对其它产品了解比较深刻的时候，这个原则很容易就可以达到了。\n\n<!-- more -->\n## 方式\n\n### 单步 Debug\n\n单步 Debug 是比直接阅读源码来得更加直观快速的方式，通过单步 Debug 的主要目的是了解整个源码的大概逻辑和流程。\n\n* 针对应用程序（Tomcat、Hadoop）：找启动脚本 -> 找到 main 入口 -> 开始 Debug\n* 库、框架（FastJSON、Spring）：找到关键类 -> 打断点 -> 查看堆栈\n\n### 「无法 Debug？」\n\n很多时候我们拿到的都是「无法运行」的代码，比如说构建起来很麻烦的源码、只有一个 lib 包。在这个时候只能采取一些其它手段了。\n\n* 在我看来，最有效的方式还是 Debug。如果遇到了比较难构建的源码，那么暂时放弃构建它的想法，可以直接新建一个工程并添加其 Jar 包依赖，写测试代码的方式进行 Debug。至于测试代码，可以从源码的官方文档、或者它的测试用例中找到；\n\n* 如果以上也是比较麻烦的话，那就直接强行裸看代码吧，不过裸看代码也有一些简便的方法让你更好的裸看代码，比如接下来的。\n\n\n### 梳理整个工程的类依赖关系图\n\n以 Intellij IDEA 的为例：\n\n\n* 右键 Java 类\n* 点击 Diagrams\n* 点击 Show Diagrams\n\n\n### 查找方法调用关系\n\n以 Intellij IDEA 的 Mac OS X 的快捷键为例：\n\n* Alt + F7 (Find Usage)\n* Ctrl + Alt + H (Call Hierarchy)\n\n\n### 搜索关键字\n\n这个一般在无头绪的时候才会使用的。比如出现了框架内部的错误，里面包含了特殊关键字，如错误日志或者没有堆栈的方法。\n\n这个在 Intellij IDEA 中比较好用，可以包含依赖的三方库进行全文搜索。快捷键：\n\n* Ctrl + Shift + F (Find in path)\n\n> 搜索三方库需要选择 Custom -> Project and Libraries\n\n如果是 Eclipse 的话，似乎只能是大概知道是哪个 Jar 包之后，解压 source 包再全文搜索吧 = =\n\n\n\n## 其他\n\n我好像就上面几个方法，看任何源码（Hadoop、Spring、Netty、公司内部的）都能够很快上手。如果想到啥或者有啥比较典型的实例的话，再补充吧。\n","slug":"java-source-code-practice","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg622z005wsb8fm2aami3p"},{"title":"Java中随机数生成是等概率的吗？","id":"127","date":"2011-03-17T14:32:43.000Z","_content":"\n今天群里面**HJH**问了一个问题：\n> Java里的**随机数生成**是**等概率**的吗？\r> \n> \n> 例如：下面这两行代码将从0-99之间随机生成一个数\r> \n> \n> java.util.Random ran=new java.util.Random();\r> \n> \n> int ConnectID=ran.nextInt(100);\r> \n> \n> 问：生成0-99之间任意一个数字的概率是相等的吗？\n没怎么用过**Random类**，于是乎随意的浏览了一下**Random类**和**nextInt()方法**源代码，无奈水平有限，短时间内无法参透其中的奥秘啊。所以来了一个快速验证的方法，统计学中不是说过**随机事件**的概率，一般可以通过**大量重复试验**求得其近似值么。于是乎，我也通过**大量重复试验**来求求其概率吧。\n\n**<!--more-->代码**如下：\n<div class=\"dp-highlighter\">\n\n1.  <span><span>java.util.Random ran = </span><span class=\"keyword\">new</span><span> java.util.Random(); </span></span>\n2.  <span> </span><span class=\"keyword\">int</span><span> connectID; </span>\n3.  <span class=\"keyword\">int</span><span>[] ids = </span><span class=\"keyword\">new</span><span> </span><span class=\"keyword\">int</span><span>[</span><span class=\"number\">100</span><span>]; </span>\n4.  <span class=\"keyword\">for</span><span> (</span><span class=\"keyword\">int</span><span> i = </span><span class=\"number\">0</span><span>; i &lt; </span><span class=\"number\">100</span><span>; i++) { </span>\n5.  <span> ids[i] = </span><span class=\"number\">0</span><span>; </span>\n6.  <span>} </span>\n7.  <span class=\"keyword\">for</span><span> (</span><span class=\"keyword\">int</span><span> i = </span><span class=\"number\">0</span><span>; i &lt; </span><span class=\"number\">10000000</span><span>; i++) { </span>\n8.  <span> connectID = ran.nextInt(</span><span class=\"number\">100</span><span>); </span>\n9.  <span> ids[connectID]++; </span>\n10.  <span>} </span>\n11.  <span class=\"keyword\">for</span><span> (</span><span class=\"keyword\">int</span><span> i = </span><span class=\"number\">0</span><span>; i &lt; </span><span class=\"number\">100</span><span>; i++) { </span>\n12.  <span> System.out.println(i + </span><span class=\"string\">\": \"</span><span> + ids[i]); </span>\n13.  <span>} </span>\n</div>\n截一小段**结果**：\n> 0: 99127\r> \n> \n> 1: 99941\r> \n> \n> 2: 100295\r> \n> \n> 3: 100187\r> \n> \n> 4: 100255\r> \n> \n> 5: 100266\r> \n> \n> 6: 100280\r> \n> \n> 7: 99840\r> \n> \n> 8: 100466\r> \n> \n> 9: 99616\r> \n> \n> 10: 100016\n剩下的90个数出现的频率和上面的基本一致，大约为10万次。通过上面的实验，基本可以确定为**随机数生成是等概率的**。至于怎么实现的，有时间再研究研究JDK吧……","source":"_posts/java-probability.md","raw":"title: Java中随机数生成是等概率的吗？\ntags:\n  - java\nid: 127\ncategories:\n  - 技术分享\ndate: 2011-03-17 22:32:43\n---\n\n今天群里面**HJH**问了一个问题：\n> Java里的**随机数生成**是**等概率**的吗？\r> \n> \n> 例如：下面这两行代码将从0-99之间随机生成一个数\r> \n> \n> java.util.Random ran=new java.util.Random();\r> \n> \n> int ConnectID=ran.nextInt(100);\r> \n> \n> 问：生成0-99之间任意一个数字的概率是相等的吗？\n没怎么用过**Random类**，于是乎随意的浏览了一下**Random类**和**nextInt()方法**源代码，无奈水平有限，短时间内无法参透其中的奥秘啊。所以来了一个快速验证的方法，统计学中不是说过**随机事件**的概率，一般可以通过**大量重复试验**求得其近似值么。于是乎，我也通过**大量重复试验**来求求其概率吧。\n\n**<!--more-->代码**如下：\n<div class=\"dp-highlighter\">\n\n1.  <span><span>java.util.Random ran = </span><span class=\"keyword\">new</span><span> java.util.Random(); </span></span>\n2.  <span> </span><span class=\"keyword\">int</span><span> connectID; </span>\n3.  <span class=\"keyword\">int</span><span>[] ids = </span><span class=\"keyword\">new</span><span> </span><span class=\"keyword\">int</span><span>[</span><span class=\"number\">100</span><span>]; </span>\n4.  <span class=\"keyword\">for</span><span> (</span><span class=\"keyword\">int</span><span> i = </span><span class=\"number\">0</span><span>; i &lt; </span><span class=\"number\">100</span><span>; i++) { </span>\n5.  <span> ids[i] = </span><span class=\"number\">0</span><span>; </span>\n6.  <span>} </span>\n7.  <span class=\"keyword\">for</span><span> (</span><span class=\"keyword\">int</span><span> i = </span><span class=\"number\">0</span><span>; i &lt; </span><span class=\"number\">10000000</span><span>; i++) { </span>\n8.  <span> connectID = ran.nextInt(</span><span class=\"number\">100</span><span>); </span>\n9.  <span> ids[connectID]++; </span>\n10.  <span>} </span>\n11.  <span class=\"keyword\">for</span><span> (</span><span class=\"keyword\">int</span><span> i = </span><span class=\"number\">0</span><span>; i &lt; </span><span class=\"number\">100</span><span>; i++) { </span>\n12.  <span> System.out.println(i + </span><span class=\"string\">\": \"</span><span> + ids[i]); </span>\n13.  <span>} </span>\n</div>\n截一小段**结果**：\n> 0: 99127\r> \n> \n> 1: 99941\r> \n> \n> 2: 100295\r> \n> \n> 3: 100187\r> \n> \n> 4: 100255\r> \n> \n> 5: 100266\r> \n> \n> 6: 100280\r> \n> \n> 7: 99840\r> \n> \n> 8: 100466\r> \n> \n> 9: 99616\r> \n> \n> 10: 100016\n剩下的90个数出现的频率和上面的基本一致，大约为10万次。通过上面的实验，基本可以确定为**随机数生成是等概率的**。至于怎么实现的，有时间再研究研究JDK吧……","slug":"java-probability","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg62310060sb8fenovhnnj"},{"title":"Java 最佳实践","date":"2015-08-28T14:32:00.000Z","_content":"\n* [毕玄的演讲](/upload/java-at-alibaba.pptx)","source":"_posts/java-practice.md","raw":"title: Java 最佳实践\ndate: 2015-08-28 22:32:00\ncategories: 最佳实践\ntags: [Java]\n---\n\n* [毕玄的演讲](/upload/java-at-alibaba.pptx)","slug":"java-practice","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg62320063sb8fbj698zwi"},{"title":"Java装箱/拆箱技术","id":"409","date":"2012-03-03T17:07:14.000Z","_content":"\n今天群里提出了一个有趣的问题：\n<!--more--><div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span>Integer num1 = </span><span class=\"number\">128</span><span>;&#160;&#160; </span></span>\n2.  <span>Integer num2 = </span><span class=\"number\">128</span><span>;&#160;&#160; </span></span>\n3.  <span></span><span class=\"keyword\">int</span><span> num3 = </span><span class=\"number\">128</span><span>;&#160;&#160; </span></span>\n4.  <span></span><span class=\"keyword\">int</span><span> num4 = </span><span class=\"number\">128</span><span>;&#160;&#160; </span></span>\n5.  <span>System.out.println(num1 == num2);&#160;&#160; </span>\n6.  <span>System.out.println(num1 == num3);&#160;&#160; </span>\n7.  <span>System.out.println(num2 == num3);&#160;&#160; </span>\n8.  <span>System.out.println(num3 == num4);&#160;&#160; </span>\n9.  <span>System.out.println(</span><span class=\"string\">&quot;============&quot;</span><span>);&#160;&#160; </span></span>\n10.  <span>Integer num5 = </span><span class=\"number\">12</span><span>;&#160;&#160; </span></span>\n11.  <span>Integer num6 = </span><span class=\"number\">12</span><span>;&#160;&#160; </span></span>\n12.  <span></span><span class=\"keyword\">int</span><span> num7 = </span><span class=\"number\">12</span><span>;&#160;&#160; </span></span>\n13.  <span></span><span class=\"keyword\">int</span><span> num8 = </span><span class=\"number\">12</span><span>;&#160;&#160; </span></span>\n14.  <span>System.out.println(num5 == num6);&#160;&#160; </span>\n15.  <span>System.out.println(num5 == num7);&#160;&#160; </span>\n16.  <span>System.out.println(num6 == num7);&#160;&#160; </span>\n17.  <span>System.out.println(num7 == num8);&#160; </span> </div>  \n\n乍一看，好似是常量池的题目，但是运行一遍结果之后，好像有些迷糊，结果只有第一个输出为false，其它地方均为true。\n\n（num3==num4）以及（num7==num8）这个倒是没什么，常量池基本知识。\n\nInteger与int比较，以及Integer内部比较是怎么样的呢？这就涉及到自动装箱/拆箱技术了，一般来说，具有包装类的语言都有这种技术，如Objective-C、Java等，该技术只是编译器给用户提供的一些方便（编译器糖：Compiler Sugar），那么我们来看看Java是怎么实现的吧。附上字节码：\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image.png) \n\nJava的自动装箱直接调用了Integer的静态方法Integer.valueOf，实质上还是创建了一个Integer对象。\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb1.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image1.png) 而拆箱呢，有人说是将int变量先装箱，再比较。但是字节码说明了，是获得对象的值，再比较。\n\n还有一个疑问，为什么在128的时候num1 != num2，而改一个常量12就等于了呢？需要说明的是，在自动装箱时对于值从[–128, 127]之间的值，它们被装箱为Integer对象后，会在内存中被重用（装箱对象池？）。即如果创建时值位于界内，它会先判断是否存在该对象，有的话直接指向地址。如果不位于界内，则会直接创建新对象。\n\n这样的功能嘛，还是推荐使用标准的格式（=new Integer(value);），自个明白呢，以后的人也明白。不过自个私底下研究研究还是很开脑的。\n  > **P.S.: **反编译字节码命令 javap –c ClassName，不能带.class后缀","source":"_posts/java-boxing.md","raw":"title: Java装箱/拆箱技术\ntags:\n  - java\nid: 409\ncategories:\n  - 技术分享\ndate: 2012-03-04 01:07:14\n---\n\n今天群里提出了一个有趣的问题：\n<!--more--><div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span>Integer num1 = </span><span class=\"number\">128</span><span>;&#160;&#160; </span></span>\n2.  <span>Integer num2 = </span><span class=\"number\">128</span><span>;&#160;&#160; </span></span>\n3.  <span></span><span class=\"keyword\">int</span><span> num3 = </span><span class=\"number\">128</span><span>;&#160;&#160; </span></span>\n4.  <span></span><span class=\"keyword\">int</span><span> num4 = </span><span class=\"number\">128</span><span>;&#160;&#160; </span></span>\n5.  <span>System.out.println(num1 == num2);&#160;&#160; </span>\n6.  <span>System.out.println(num1 == num3);&#160;&#160; </span>\n7.  <span>System.out.println(num2 == num3);&#160;&#160; </span>\n8.  <span>System.out.println(num3 == num4);&#160;&#160; </span>\n9.  <span>System.out.println(</span><span class=\"string\">&quot;============&quot;</span><span>);&#160;&#160; </span></span>\n10.  <span>Integer num5 = </span><span class=\"number\">12</span><span>;&#160;&#160; </span></span>\n11.  <span>Integer num6 = </span><span class=\"number\">12</span><span>;&#160;&#160; </span></span>\n12.  <span></span><span class=\"keyword\">int</span><span> num7 = </span><span class=\"number\">12</span><span>;&#160;&#160; </span></span>\n13.  <span></span><span class=\"keyword\">int</span><span> num8 = </span><span class=\"number\">12</span><span>;&#160;&#160; </span></span>\n14.  <span>System.out.println(num5 == num6);&#160;&#160; </span>\n15.  <span>System.out.println(num5 == num7);&#160;&#160; </span>\n16.  <span>System.out.println(num6 == num7);&#160;&#160; </span>\n17.  <span>System.out.println(num7 == num8);&#160; </span> </div>  \n\n乍一看，好似是常量池的题目，但是运行一遍结果之后，好像有些迷糊，结果只有第一个输出为false，其它地方均为true。\n\n（num3==num4）以及（num7==num8）这个倒是没什么，常量池基本知识。\n\nInteger与int比较，以及Integer内部比较是怎么样的呢？这就涉及到自动装箱/拆箱技术了，一般来说，具有包装类的语言都有这种技术，如Objective-C、Java等，该技术只是编译器给用户提供的一些方便（编译器糖：Compiler Sugar），那么我们来看看Java是怎么实现的吧。附上字节码：\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image.png) \n\nJava的自动装箱直接调用了Integer的静态方法Integer.valueOf，实质上还是创建了一个Integer对象。\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb1.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image1.png) 而拆箱呢，有人说是将int变量先装箱，再比较。但是字节码说明了，是获得对象的值，再比较。\n\n还有一个疑问，为什么在128的时候num1 != num2，而改一个常量12就等于了呢？需要说明的是，在自动装箱时对于值从[–128, 127]之间的值，它们被装箱为Integer对象后，会在内存中被重用（装箱对象池？）。即如果创建时值位于界内，它会先判断是否存在该对象，有的话直接指向地址。如果不位于界内，则会直接创建新对象。\n\n这样的功能嘛，还是推荐使用标准的格式（=new Integer(value);），自个明白呢，以后的人也明白。不过自个私底下研究研究还是很开脑的。\n  > **P.S.: **反编译字节码命令 javap –c ClassName，不能带.class后缀","slug":"java-boxing","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg62340066sb8f1f55dv0n"},{"title":"迭代式MapReduce解决方案（一）","id":"250","date":"2012-02-08T15:11:00.000Z","_content":"\n**一、迭代式Mapreduce简介**\n\n普通的MapReduce任务是将一个任务分割成map与reduce两个阶段。map阶段负责过滤、筛选、检查输入数据，并将处理后的结果写入本地磁盘中；reduce阶段则负责远程读入map的本地输出结果，对数据进行归并、分析等处理，之后再将结果写入HDFS中。其数据流过程如下：\n <!--more-->  \n\n(k, v) -&gt; map -&gt; (k1, v1), (k1, v2), (k2,v3) -&gt; sort&amp;shuffle -&gt; (k1, list(v1, v2)), (k2, v3)\n\n而迭代式的MapReduce任务需要迭代执行以上过程多次，由于每次任务都是独立的，则需要不断的读取、写入、传输数据，如果还是按照普通的MapReduce一样运行MR任务，性能将会非常低下。\n\n本文拿PageRank做一个例子，PageRank是Google的网页排名算法，是基于网页与网页之间的链接关系计算而得，计算过程需要不断的迭代（单次MR任务），获取一个新的PR值后，再继续迭代，直到两次迭代之间的PR差值小于某一个阈值即停止。\n\nPageRank计算数据分为两个部分：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"123\">           <p>**URL**\n         </td>          <td valign=\"top\" width=\"66\">           \n\n**RANK**\n         </td>          <td valign=\"top\" width=\"76\">           \n\n         </td>          <td valign=\"top\" width=\"132\">           \n\n**URL**\n         </td>          <td valign=\"top\" width=\"123\">           \n\n**OUT_LINK**\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">           \n\nwww.a.com\n         </td>          <td valign=\"top\" width=\"66\">           \n\n1\n         </td>          <td valign=\"top\" width=\"76\">&#160;</td>          <td valign=\"top\" width=\"132\">           \n\nwww.a.com\n         </td>          <td valign=\"top\" width=\"123\">           \n\nwww.b.com\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">           \n\nwww.b.com\n         </td>          <td valign=\"top\" width=\"66\">           \n\n1\n         </td>          <td valign=\"top\" width=\"76\">&#160;</td>          <td valign=\"top\" width=\"132\">           \n\nwww.a.com\n         </td>          <td valign=\"top\" width=\"123\">           \n\nwww.c.com\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">           \n\nwww.c.com\n         </td>          <td valign=\"top\" width=\"66\">           \n\n1\n         </td>          <td valign=\"top\" width=\"76\">&#160;</td>          <td valign=\"top\" width=\"132\">           \n\nwww.b.com\n         </td>          <td valign=\"top\" width=\"123\">           \n\nwww.a.com\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">           \n\nwww.d.com\n         </td>          <td valign=\"top\" width=\"66\">           \n\n1\n         </td>          <td valign=\"top\" width=\"76\">&#160;</td>          <td valign=\"top\" width=\"132\">           \n\nwww.b.com\n         </td>          <td valign=\"top\" width=\"123\">           \n\nwww.c.com\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">&#160;</td>          <td valign=\"top\" width=\"66\">&#160;</td>          <td valign=\"top\" width=\"76\">&#160;</td>          <td valign=\"top\" width=\"132\">           \n\nwww.c.com\n         </td>          <td valign=\"top\" width=\"123\">           \n\nwww.d.com\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">&#160;</td>          <td valign=\"top\" width=\"66\">&#160;</td>          <td valign=\"top\" width=\"76\">&#160;</td>          <td valign=\"top\" width=\"132\">           \n\nwww.d.com\n         </td>          <td valign=\"top\" width=\"123\">           \n\nwww.b.com\n         </td>       </tr>     </tbody></table> </p>  \n\n_&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; PR__值表&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 网页链接关系表_\n\n**二、问题分析说明**\n\n迭代式作业的缺点很突出，在[这篇博客](http://dongxicheng.org/mapreduce/iterative-mapreduce-intro/)有详细的介绍，本篇主要需要解决的问题是：**如何减少不必要的数据传输与读写**。\n\n正如前面所示，PageRank的计算数据分为了两种：PR值表以及网页链接关系表。其中PR值是随着迭代而不断变化，称之为动态数据；而网页链接关系，在计算中，不会有任何的改变，称之为静态数据。\n\n我现在能想到的，再参考了[网上](http://blog.xebia.com/2011/09/27/wiki-pagerank-with-hadoop/)的实现方式，基本上都是将静态数据与动态数据合并成一个文件，同时读入(mapper)-&gt;写出(mapper)-&gt;传输(reducer)-&gt;写出(reducer)。\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/02/image_thumb.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/image.png)&#160;\n\n我们可以来估算一下时间，先不考虑磁盘IO，仅算静态数据传输时间一项。其中模拟实验数据为：100w个链接地址；随机生成最多1000个外链；结果数据3.22G（动态数据8.5M）；实验环境网络带宽100M；迭代次数20次。\n\n单轮迭代，3.22G的数据会从mapper中读入再全部写入到本地磁盘，reducer再从mapper中将3.22G的临时数据传输到相应的taskTracker上。100M带宽的网络，传输速率约为10M/s，计算公式即为：3.22G×1024 / 10 = 330s = 5.5min。迭代20次，5.5×20 = 110min = 1.8h。简单的估算一下，3G左右的数据，在百兆带宽的网络环境，仅静态数据传输这一项就会占去近两小时（这是最坏情况，不考虑数据在本地的情况）！而网页数据远远不止3.22G，如果到了TB乃至PB级的话，耗时应该就不是开发者所能接受的了。\n\n**三、问题解决方法**\n\n为了减少不必要数据的传输与读写，开发者就一定要做到以下几点：\n\n1、 将静态数据与动态数据分离，但需要保证在一次（以及下一次）迭代中，结合动静数据；\n\n2、 输出结果中尽量减少数据量，原则上只能有动态数据，不能包含静态数据。\n\n每次map过程中，都需要读入一行PR值表元组，同时也要读入多行对应的链接关系表元组，虽然在map中无法控制两个分离文件的读入顺序，但我们可以预先将动态数据加载进内存作为索引，读入一行后，再查找内存获取需要的数据。这样的方式很容易的就可以想到分布式缓存技术，先前我还在考虑是用Memocached还是Redis，但多看看后好像是多此一举了。MapReduce自带了Distributed Cache技术，可以参见《[Mapreduce API文档](http://hadoop.apache.org/common/docs/r0.20.203.0/api/org/apache/hadoop/filecache/DistributedCache.html)》。\n\nHaoop中自带的分布式缓存，即DistributedCache对象，可以方便map task之间或者reduce task之间共享一些信息，缓存数据会被分发到集群的所有节点上。需要注意的是，DistributedCache是read-only的。\n\n操作步骤：\n\n1\\. 将数据分发到每个节点上：\n\nDistributedCache.addCacheFile(new Path(args[0]).toUri(), conf);&#160; \n\n2\\. 在每个mapper上获取cache文件，便可加载进内存：\n\nDistributedCache.getLocalCacheFiles(conf);\n\n3\\. Reducer写出动态数据，下一次迭代中，再将新的动态数据加载至DistributedCache中。\n\n将动态数据作为缓存文件的后，整个迭代过程，只有大量减少磁盘IO，且在很大程度上减少了网络带宽负荷与无效数据传输时间。\n\n**四、总结**\n\n以上的方法理论上支持大多数迭代式Mapreduce模型，如pagerank、SSSP（Single Source Shortest Path）等。参考&lt;[董的博客](http://dongxicheng.org/mapreduce/iterative-mapreduce-intro/)&gt;，再加上自己的实践，提出以下一些问题：\n\n**（1） 每次迭代，如果所有task重复重新创建，代价将非常高。怎样重用task以提高效率（task pool）？**\n\n说明： hadoop自身提供了task JVM reuse的功能。不过该功能仅限于同一个Job内，而我们每次迭代都会重新运行一个job，故自带功能不适用（或者我还不会用）。但是我们可否考虑job复用呢？ \n\n**（2） 何时迭代终止，怎样改变编程模型，允许用户指定合适终止迭代。**\n\n说明：就PageRank来说，迭代中止的条件是每次迭代结果相差小于一个阈值，即PR结果达到平衡。我们就可以将前一次结果直接输出到Reducer中，或者可以从DistributedCache读取前一次PR值，并做判断。\n\n但是一个PR结果符合条件并不能说明任务就结束了，需要所有的（或者说大多数）的结果均满足条件才能中止任务。那么，这个大多数结果满足条件的数据该怎么存放以及读取呢？还有就是，怎么找到一个通过的编程模型去适应其它的迭代式MR任务呢？\n\n**（3）就算没有静态数据，动态数据生成也不小**\n\n100W行数据3.22G，64M的split有52个，每个2W行数据。由于是随机生成的，平均每行500个链接地址，每个连接地址都会生成一行临时结果&lt;URL_ID AER_PR&gt;，估算一下也有150M（实际140M），那么3.22数据，最后生成临时数据为7G+。\n\n如不加任何优化的话，那铁定是不行的。后面的文章再说说优化问题，在这个实验环境下，可将7G的文件压缩到不到300M。\n\n**（4）DistributedCache API的使用**\n\n一直觉得Hadoop的版本管理十分混乱，新旧API杂乱，文档不更新！所以DistributedCache API一直没用好，到时候整理一下，顺带说说如何添加第三方jar包。\n\n以上的讨论还待我的继续研究了，性能分析比较以后的文章给填上。如对迭代式MapReduce任务感兴趣的童鞋可以参考一下Apache开源项目[Mahout](http://mahout.apache.org/)，还有Google的一篇论文&lt;Pregel: A System for Large-Scale Graph Processing&gt;：[中文](http://blog.csdn.net/ae86_fc/article/details/5796640)；[英文](http://kowshik.github.com/JPregel/pregel_paper.pdf)。\n  > **参考资料：**\n> \n> [迭代式MapReduce框架介绍](http://dongxicheng.org/mapreduce/iterative-mapreduce-intro/)\n> \n> [MapReduce Tutorial](http://hadoop.apache.org/common/docs/r0.20.203.0/mapred_tutorial.html)","source":"_posts/iterative-mapred.md","raw":"title: 迭代式MapReduce解决方案（一）\ntags:\n  - Hadoop\n  - MapReduce\nid: 250\ncategories:\n  - 技术分享\ndate: 2012-02-08 23:11:00\n---\n\n**一、迭代式Mapreduce简介**\n\n普通的MapReduce任务是将一个任务分割成map与reduce两个阶段。map阶段负责过滤、筛选、检查输入数据，并将处理后的结果写入本地磁盘中；reduce阶段则负责远程读入map的本地输出结果，对数据进行归并、分析等处理，之后再将结果写入HDFS中。其数据流过程如下：\n <!--more-->  \n\n(k, v) -&gt; map -&gt; (k1, v1), (k1, v2), (k2,v3) -&gt; sort&amp;shuffle -&gt; (k1, list(v1, v2)), (k2, v3)\n\n而迭代式的MapReduce任务需要迭代执行以上过程多次，由于每次任务都是独立的，则需要不断的读取、写入、传输数据，如果还是按照普通的MapReduce一样运行MR任务，性能将会非常低下。\n\n本文拿PageRank做一个例子，PageRank是Google的网页排名算法，是基于网页与网页之间的链接关系计算而得，计算过程需要不断的迭代（单次MR任务），获取一个新的PR值后，再继续迭代，直到两次迭代之间的PR差值小于某一个阈值即停止。\n\nPageRank计算数据分为两个部分：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"123\">           <p>**URL**\n         </td>          <td valign=\"top\" width=\"66\">           \n\n**RANK**\n         </td>          <td valign=\"top\" width=\"76\">           \n\n         </td>          <td valign=\"top\" width=\"132\">           \n\n**URL**\n         </td>          <td valign=\"top\" width=\"123\">           \n\n**OUT_LINK**\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">           \n\nwww.a.com\n         </td>          <td valign=\"top\" width=\"66\">           \n\n1\n         </td>          <td valign=\"top\" width=\"76\">&#160;</td>          <td valign=\"top\" width=\"132\">           \n\nwww.a.com\n         </td>          <td valign=\"top\" width=\"123\">           \n\nwww.b.com\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">           \n\nwww.b.com\n         </td>          <td valign=\"top\" width=\"66\">           \n\n1\n         </td>          <td valign=\"top\" width=\"76\">&#160;</td>          <td valign=\"top\" width=\"132\">           \n\nwww.a.com\n         </td>          <td valign=\"top\" width=\"123\">           \n\nwww.c.com\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">           \n\nwww.c.com\n         </td>          <td valign=\"top\" width=\"66\">           \n\n1\n         </td>          <td valign=\"top\" width=\"76\">&#160;</td>          <td valign=\"top\" width=\"132\">           \n\nwww.b.com\n         </td>          <td valign=\"top\" width=\"123\">           \n\nwww.a.com\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">           \n\nwww.d.com\n         </td>          <td valign=\"top\" width=\"66\">           \n\n1\n         </td>          <td valign=\"top\" width=\"76\">&#160;</td>          <td valign=\"top\" width=\"132\">           \n\nwww.b.com\n         </td>          <td valign=\"top\" width=\"123\">           \n\nwww.c.com\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">&#160;</td>          <td valign=\"top\" width=\"66\">&#160;</td>          <td valign=\"top\" width=\"76\">&#160;</td>          <td valign=\"top\" width=\"132\">           \n\nwww.c.com\n         </td>          <td valign=\"top\" width=\"123\">           \n\nwww.d.com\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"123\">&#160;</td>          <td valign=\"top\" width=\"66\">&#160;</td>          <td valign=\"top\" width=\"76\">&#160;</td>          <td valign=\"top\" width=\"132\">           \n\nwww.d.com\n         </td>          <td valign=\"top\" width=\"123\">           \n\nwww.b.com\n         </td>       </tr>     </tbody></table> </p>  \n\n_&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; PR__值表&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 网页链接关系表_\n\n**二、问题分析说明**\n\n迭代式作业的缺点很突出，在[这篇博客](http://dongxicheng.org/mapreduce/iterative-mapreduce-intro/)有详细的介绍，本篇主要需要解决的问题是：**如何减少不必要的数据传输与读写**。\n\n正如前面所示，PageRank的计算数据分为了两种：PR值表以及网页链接关系表。其中PR值是随着迭代而不断变化，称之为动态数据；而网页链接关系，在计算中，不会有任何的改变，称之为静态数据。\n\n我现在能想到的，再参考了[网上](http://blog.xebia.com/2011/09/27/wiki-pagerank-with-hadoop/)的实现方式，基本上都是将静态数据与动态数据合并成一个文件，同时读入(mapper)-&gt;写出(mapper)-&gt;传输(reducer)-&gt;写出(reducer)。\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/02/image_thumb.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/image.png)&#160;\n\n我们可以来估算一下时间，先不考虑磁盘IO，仅算静态数据传输时间一项。其中模拟实验数据为：100w个链接地址；随机生成最多1000个外链；结果数据3.22G（动态数据8.5M）；实验环境网络带宽100M；迭代次数20次。\n\n单轮迭代，3.22G的数据会从mapper中读入再全部写入到本地磁盘，reducer再从mapper中将3.22G的临时数据传输到相应的taskTracker上。100M带宽的网络，传输速率约为10M/s，计算公式即为：3.22G×1024 / 10 = 330s = 5.5min。迭代20次，5.5×20 = 110min = 1.8h。简单的估算一下，3G左右的数据，在百兆带宽的网络环境，仅静态数据传输这一项就会占去近两小时（这是最坏情况，不考虑数据在本地的情况）！而网页数据远远不止3.22G，如果到了TB乃至PB级的话，耗时应该就不是开发者所能接受的了。\n\n**三、问题解决方法**\n\n为了减少不必要数据的传输与读写，开发者就一定要做到以下几点：\n\n1、 将静态数据与动态数据分离，但需要保证在一次（以及下一次）迭代中，结合动静数据；\n\n2、 输出结果中尽量减少数据量，原则上只能有动态数据，不能包含静态数据。\n\n每次map过程中，都需要读入一行PR值表元组，同时也要读入多行对应的链接关系表元组，虽然在map中无法控制两个分离文件的读入顺序，但我们可以预先将动态数据加载进内存作为索引，读入一行后，再查找内存获取需要的数据。这样的方式很容易的就可以想到分布式缓存技术，先前我还在考虑是用Memocached还是Redis，但多看看后好像是多此一举了。MapReduce自带了Distributed Cache技术，可以参见《[Mapreduce API文档](http://hadoop.apache.org/common/docs/r0.20.203.0/api/org/apache/hadoop/filecache/DistributedCache.html)》。\n\nHaoop中自带的分布式缓存，即DistributedCache对象，可以方便map task之间或者reduce task之间共享一些信息，缓存数据会被分发到集群的所有节点上。需要注意的是，DistributedCache是read-only的。\n\n操作步骤：\n\n1\\. 将数据分发到每个节点上：\n\nDistributedCache.addCacheFile(new Path(args[0]).toUri(), conf);&#160; \n\n2\\. 在每个mapper上获取cache文件，便可加载进内存：\n\nDistributedCache.getLocalCacheFiles(conf);\n\n3\\. Reducer写出动态数据，下一次迭代中，再将新的动态数据加载至DistributedCache中。\n\n将动态数据作为缓存文件的后，整个迭代过程，只有大量减少磁盘IO，且在很大程度上减少了网络带宽负荷与无效数据传输时间。\n\n**四、总结**\n\n以上的方法理论上支持大多数迭代式Mapreduce模型，如pagerank、SSSP（Single Source Shortest Path）等。参考&lt;[董的博客](http://dongxicheng.org/mapreduce/iterative-mapreduce-intro/)&gt;，再加上自己的实践，提出以下一些问题：\n\n**（1） 每次迭代，如果所有task重复重新创建，代价将非常高。怎样重用task以提高效率（task pool）？**\n\n说明： hadoop自身提供了task JVM reuse的功能。不过该功能仅限于同一个Job内，而我们每次迭代都会重新运行一个job，故自带功能不适用（或者我还不会用）。但是我们可否考虑job复用呢？ \n\n**（2） 何时迭代终止，怎样改变编程模型，允许用户指定合适终止迭代。**\n\n说明：就PageRank来说，迭代中止的条件是每次迭代结果相差小于一个阈值，即PR结果达到平衡。我们就可以将前一次结果直接输出到Reducer中，或者可以从DistributedCache读取前一次PR值，并做判断。\n\n但是一个PR结果符合条件并不能说明任务就结束了，需要所有的（或者说大多数）的结果均满足条件才能中止任务。那么，这个大多数结果满足条件的数据该怎么存放以及读取呢？还有就是，怎么找到一个通过的编程模型去适应其它的迭代式MR任务呢？\n\n**（3）就算没有静态数据，动态数据生成也不小**\n\n100W行数据3.22G，64M的split有52个，每个2W行数据。由于是随机生成的，平均每行500个链接地址，每个连接地址都会生成一行临时结果&lt;URL_ID AER_PR&gt;，估算一下也有150M（实际140M），那么3.22数据，最后生成临时数据为7G+。\n\n如不加任何优化的话，那铁定是不行的。后面的文章再说说优化问题，在这个实验环境下，可将7G的文件压缩到不到300M。\n\n**（4）DistributedCache API的使用**\n\n一直觉得Hadoop的版本管理十分混乱，新旧API杂乱，文档不更新！所以DistributedCache API一直没用好，到时候整理一下，顺带说说如何添加第三方jar包。\n\n以上的讨论还待我的继续研究了，性能分析比较以后的文章给填上。如对迭代式MapReduce任务感兴趣的童鞋可以参考一下Apache开源项目[Mahout](http://mahout.apache.org/)，还有Google的一篇论文&lt;Pregel: A System for Large-Scale Graph Processing&gt;：[中文](http://blog.csdn.net/ae86_fc/article/details/5796640)；[英文](http://kowshik.github.com/JPregel/pregel_paper.pdf)。\n  > **参考资料：**\n> \n> [迭代式MapReduce框架介绍](http://dongxicheng.org/mapreduce/iterative-mapreduce-intro/)\n> \n> [MapReduce Tutorial](http://hadoop.apache.org/common/docs/r0.20.203.0/mapred_tutorial.html)","slug":"iterative-mapred","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg62350069sb8fw77h4cbp"},{"title":"迭代式MapReduce解决方案（三）","id":"401","date":"2012-02-29T15:14:46.000Z","_content":"\n**1****、前言**\n\n前面两篇[（一）](http://www.hongweiyi.com/2012/02/mapred-optimize/)[（二）](http://www.hongweiyi.com/2012/02/iterative-mapred-distcache/)解决方案分别从静态数据（Invariant Data）分离以及分布式缓存来优化迭代式Mapreduce，但是由于Mapreduce天生的缺陷，再加上分布式缓存是分布存放在本地磁盘的，没有一个好的读取方案的话，就会大大提高了每个task的磁盘IO次数。这篇博客算是迭代式Mapreduce的收尾了，来整体分析一下我的解决方案和Haloop方案吧。\n\n<!--more-->\n\n**2****、现存框架的缺陷&amp;我的方案**\n\nHaloop发布的文献中，说了两个缺陷，再加上董的一个，共仨：\n\n1）动静态数据无法分离，浪费大量资源（磁盘IO，网络带宽，CPU时间），Haloop原文：The first problem is that even though much of the data may be unchanged from iteration to iteration, the data must be re-loaded and re-processed at each iteration, wasting I/O, network bandwidth, and CPU resources。\n\n我的解决方案：利用分布式缓存来缓存动态数据，可以有效的减少临时数据大小，大量的减少网络带宽压力（10G-&gt;0.25G）。但是，通过我的方案，磁盘IO虽然有所下降，但是仍然有待加强的地方，因磁盘IO主要集中在了map task的read阶段，而在坏的情况下，有可能会从其它node远程读取。Haloop修改了一下这种方式，我待会儿说方法。\n\n2）没有一个客观的停止迭代的标准，Haloop原文：The second problem is that the termination condition may involve detecting when a fixpoint has been reached。\n\n我的解决方案：这个方案没有写成博客，因为觉得太普通了。和大多数应用一样，开启一个新的任务，来计算两次迭代之间的差别，Pagerank计算两次迭代过程之间所有页面PR差之和，SSSP计算所有点的状态。但是需要注意的是，由于一个文件就会开启一个map task，所以需要动脑筋思考一下如何“合并”起来。\n\n3）每次迭代，如果所有task重复重新创建，代价将非常高。怎样重用task以提高效率（task pool）。这个缺陷是[董的博客](http://dongxicheng.org/mapreduce/iterative-mapreduce-intro/)提出的，这个虽然没有在Haloop中单独提出，但是实现中已经考虑到了。这个在现有框架下，基本是上没可能了，迭代式Mapreduce需要解决的是Job复用的问题，整个task pool就得修改框架了。\n\n**3****、Haloop解决方案**\n\n**[![clip_image002](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image002_thumb4.jpg \"clip_image002\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0024.jpg)**\n\n_Haloop__框架图_\n\n[![clip_image004](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image004_thumb3.jpg \"clip_image004\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0043.jpg)\n\n_Haloop__计算流程图_\n\nHaloop进行的改进有：\n\n**1****）提供了一套新的编程接口，以方便用户进行迭代式程序开发**\n\nHaloop提供了一些有用的方法，如下：\n  > SetFixedPointThreshold：设置两次迭代的终止条件，即距离差是否达到某一个阈值\n> \n> ResultDistance：计算两次距离的方法\n> \n> setMaxNumOfIterations：设置迭代次数\n> \n> setIterationInput：设置变化的输入数据\n> \n> AddInvariantTable：设置不变的输入数据  \n\n有了上面的方法，整个迭代式MR过程很清晰，确实提供了很大的方便。\n\n**2****） master node（jobtracker）包含一个循环控制模块，它不断的启动map-reduce计算知道满足迭代终止条件**\n\n从Haloop计算流程图可以看出，Haloop基本实现了job“复用”，只有一个job就可以了，它可以开启多个map/reduce对，而传统的每次迭代过程都需要开启一个job，且一个job只有一个map/reduce对。且迭代终止条件控制在job内部，无需再启新job来计算。\n\n**3****）设计了新的Task Scheduler，以便更好的利用data locality特性**\n\nHaloop有一个Loop-aware 任务调度机制。Haloop在首次迭代时会将不变的输入数据保存到相应计算节点上，以后每次调度task，尽量放在固定的那些节点上（locality）。这样，每次迭代，不变的数据就不必重复传输了。\n\n**4****）数据在各个task tracker会被缓存（cache）和建索引（index）**\n\nMap task的输入与输出，Reduce task的输出都会被建索引和缓存，以加快数据处理速度。这个部分在论文中占的大量份额，所以我也没有仔细看，整体来说就是和分布式缓存有异曲同工之妙。需要说明的是，缓存是指数据被写到本次磁盘，以供下一轮循环迭代时直接使用，Haloop也并没有完全存入内存，应该是担心内存不够使的。\n\n**4****、总结**\n\n迭代式Mapreduce还有待继续研究，按照董的说法，haloop模型抽象还不够高，支持计算模型有限，而现有的解决方案都不是最优的。我所提出的方案只是在不修改源码的情况下，最大限度的优化计算过程，还是不够优！不过Yahoo!要推出下一代的Mapreduce，从它发表的文章来看，解决迭代式问题好似有戏，可以参考这里：[The Next Generation of Apache Hadoop MapReduce](http://developer.yahoo.com/blogs/hadoop/posts/2011/02/mapreduce-nextgen/)。\n  > **参考资料**\n> \n> 1\\. Haloop主页：[http://code.google.com/p/haloop/](http://code.google.com/p/haloop/)\n> \n> 2\\. 董的博客：[http://dongxicheng.org/mapreduce/iterative-mapreduce-intro/](http://dongxicheng.org/mapreduce/iterative-mapreduce-intro/)","source":"_posts/iterative-mapred-summary-haloop.md","raw":"title: 迭代式MapReduce解决方案（三）\ntags:\n  - Hadoop\n  - Haloop\n  - MapReduce\nid: 401\ncategories:\n  - 技术分享\ndate: 2012-02-29 23:14:46\n---\n\n**1****、前言**\n\n前面两篇[（一）](http://www.hongweiyi.com/2012/02/mapred-optimize/)[（二）](http://www.hongweiyi.com/2012/02/iterative-mapred-distcache/)解决方案分别从静态数据（Invariant Data）分离以及分布式缓存来优化迭代式Mapreduce，但是由于Mapreduce天生的缺陷，再加上分布式缓存是分布存放在本地磁盘的，没有一个好的读取方案的话，就会大大提高了每个task的磁盘IO次数。这篇博客算是迭代式Mapreduce的收尾了，来整体分析一下我的解决方案和Haloop方案吧。\n\n<!--more-->\n\n**2****、现存框架的缺陷&amp;我的方案**\n\nHaloop发布的文献中，说了两个缺陷，再加上董的一个，共仨：\n\n1）动静态数据无法分离，浪费大量资源（磁盘IO，网络带宽，CPU时间），Haloop原文：The first problem is that even though much of the data may be unchanged from iteration to iteration, the data must be re-loaded and re-processed at each iteration, wasting I/O, network bandwidth, and CPU resources。\n\n我的解决方案：利用分布式缓存来缓存动态数据，可以有效的减少临时数据大小，大量的减少网络带宽压力（10G-&gt;0.25G）。但是，通过我的方案，磁盘IO虽然有所下降，但是仍然有待加强的地方，因磁盘IO主要集中在了map task的read阶段，而在坏的情况下，有可能会从其它node远程读取。Haloop修改了一下这种方式，我待会儿说方法。\n\n2）没有一个客观的停止迭代的标准，Haloop原文：The second problem is that the termination condition may involve detecting when a fixpoint has been reached。\n\n我的解决方案：这个方案没有写成博客，因为觉得太普通了。和大多数应用一样，开启一个新的任务，来计算两次迭代之间的差别，Pagerank计算两次迭代过程之间所有页面PR差之和，SSSP计算所有点的状态。但是需要注意的是，由于一个文件就会开启一个map task，所以需要动脑筋思考一下如何“合并”起来。\n\n3）每次迭代，如果所有task重复重新创建，代价将非常高。怎样重用task以提高效率（task pool）。这个缺陷是[董的博客](http://dongxicheng.org/mapreduce/iterative-mapreduce-intro/)提出的，这个虽然没有在Haloop中单独提出，但是实现中已经考虑到了。这个在现有框架下，基本是上没可能了，迭代式Mapreduce需要解决的是Job复用的问题，整个task pool就得修改框架了。\n\n**3****、Haloop解决方案**\n\n**[![clip_image002](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image002_thumb4.jpg \"clip_image002\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0024.jpg)**\n\n_Haloop__框架图_\n\n[![clip_image004](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image004_thumb3.jpg \"clip_image004\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0043.jpg)\n\n_Haloop__计算流程图_\n\nHaloop进行的改进有：\n\n**1****）提供了一套新的编程接口，以方便用户进行迭代式程序开发**\n\nHaloop提供了一些有用的方法，如下：\n  > SetFixedPointThreshold：设置两次迭代的终止条件，即距离差是否达到某一个阈值\n> \n> ResultDistance：计算两次距离的方法\n> \n> setMaxNumOfIterations：设置迭代次数\n> \n> setIterationInput：设置变化的输入数据\n> \n> AddInvariantTable：设置不变的输入数据  \n\n有了上面的方法，整个迭代式MR过程很清晰，确实提供了很大的方便。\n\n**2****） master node（jobtracker）包含一个循环控制模块，它不断的启动map-reduce计算知道满足迭代终止条件**\n\n从Haloop计算流程图可以看出，Haloop基本实现了job“复用”，只有一个job就可以了，它可以开启多个map/reduce对，而传统的每次迭代过程都需要开启一个job，且一个job只有一个map/reduce对。且迭代终止条件控制在job内部，无需再启新job来计算。\n\n**3****）设计了新的Task Scheduler，以便更好的利用data locality特性**\n\nHaloop有一个Loop-aware 任务调度机制。Haloop在首次迭代时会将不变的输入数据保存到相应计算节点上，以后每次调度task，尽量放在固定的那些节点上（locality）。这样，每次迭代，不变的数据就不必重复传输了。\n\n**4****）数据在各个task tracker会被缓存（cache）和建索引（index）**\n\nMap task的输入与输出，Reduce task的输出都会被建索引和缓存，以加快数据处理速度。这个部分在论文中占的大量份额，所以我也没有仔细看，整体来说就是和分布式缓存有异曲同工之妙。需要说明的是，缓存是指数据被写到本次磁盘，以供下一轮循环迭代时直接使用，Haloop也并没有完全存入内存，应该是担心内存不够使的。\n\n**4****、总结**\n\n迭代式Mapreduce还有待继续研究，按照董的说法，haloop模型抽象还不够高，支持计算模型有限，而现有的解决方案都不是最优的。我所提出的方案只是在不修改源码的情况下，最大限度的优化计算过程，还是不够优！不过Yahoo!要推出下一代的Mapreduce，从它发表的文章来看，解决迭代式问题好似有戏，可以参考这里：[The Next Generation of Apache Hadoop MapReduce](http://developer.yahoo.com/blogs/hadoop/posts/2011/02/mapreduce-nextgen/)。\n  > **参考资料**\n> \n> 1\\. Haloop主页：[http://code.google.com/p/haloop/](http://code.google.com/p/haloop/)\n> \n> 2\\. 董的博客：[http://dongxicheng.org/mapreduce/iterative-mapreduce-intro/](http://dongxicheng.org/mapreduce/iterative-mapreduce-intro/)","slug":"iterative-mapred-summary-haloop","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg6237006dsb8fi0763m4z"},{"title":"迭代式MapReduce解决方案（二） DistributedCache","id":"337","date":"2012-02-23T08:01:52.000Z","_content":"\n**1****、DistributedCache In Hadoop**\n\n此篇文章主要是[前一篇](http://www.hongweiyi.com/?p=250)的后续，主要讲Hadoop的分布式缓存机制的原理与运用。\n\n分布式缓存在MapReduce中称之为DistributedCache，它可以方便map task之间或者reduce task之间共享一些信息，同时也可以将第三方包添加到其classpath路径中去。Hadoop会将缓存数据分发到集群的所有准备启动的节点上，复制到在mapred.temp.dir中配置的目录。\n\n <!--more-->  \n\n**2****、DistributedCache的使用**\n\nDistributedCache的使用的本质其实是添加Configuraton中的属性：mapred.cache.{files|archives}。图方便的话，可以使用DistributedCache类的静态方法。\n\n不省事法：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>conf.set(&quot;mapred.cache.files&quot;, &quot;/data/data&quot;);\n\nconf.set(&quot;mapred.cache. archives&quot;, &quot;/data/data.zip&quot;);\n         </td>       </tr>     </tbody></table> </p>  \n\n省事法：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>[DistributedCache](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/filecache/DistributedCache.html). `**[addCacheFile](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/filecache/DistributedCache.html#addCacheFile(java.net.URI, org.apache.hadoop.conf.Configuration))**``([URI](http://java.sun.com/javase/6/docs/api/java/net/URI.html?is-external=true),` `[Configuration](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/conf/Configuration.html))`\n\n[DistributedCache](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/filecache/DistributedCache.html).`**[addArchiveToClassPath](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/filecache/DistributedCache.html#addArchiveToClassPath(org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem))**``([Path](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/fs/Path.html),` `[Configuration](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/conf/Configuration.html),` `[FileSystem](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/fs/FileSystem.html))`\n         </td>       </tr>     </tbody></table> </p>  \n\n需要注意的是，上面几行代码需要写在Job类初始化之前，否则在运行会中找不到文件（被折磨了很长时间），因为Job初始化时将传入Configuration对象克隆一份给了JobContext。\n\n在MapReduce的0.21版本以后的org.apache.hadoop.mapreduce均移到org.apache.hadoop.mapred包下。但文档中提供的configure方法是重写的MapReduceBase中的，而新版本中map继承于mapper，reduce继承于reducer，所以configure方法一律改成了setup。要获得cache数据，就得在map/reduce task中的setup方法中取得cache数据，再进行相应操作：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n2.  <span></span><span class=\"keyword\">protected</span><span>&#160;</span><span class=\"keyword\">void</span><span> setup(Context context) </span><span class=\"keyword\">throws</span><span> IOException,&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; InterruptedException {&#160;&#160; </span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">super</span><span>.setup(context);&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; URI[] uris = DistributedCache.getCacheFiles(context&#160;&#160; </span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; .getConfiguration());&#160;&#160; </span>\n7.  <span>&#160;&#160;&#160; Path[] paths = DistributedCache.getLocalCacheFiles(context&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; .getConfiguration());&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n10.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n而三方库的使用稍微简单，只需要将库上传至hdfs，再用代码添加至classpath即可：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>DistributedCache.addArchiveToClassPath(new Path(&quot;/data/test.jar&quot;), conf);\n         </td>       </tr>     </tbody></table> </p>  \n\n**3、symlink的使用**\n\nSymlink其实就是hdfs文件的一个快捷方式，只需要在路径名后加入#linkname，之后在task中使用linkname即使用相应文件，如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>conf.set(&quot;mapred.cache.files&quot;, &quot;/data/data#mData&quot;);\n\nconf.set(&quot;mapred.cache. archives&quot;, &quot;/data/data.zip#mDataZip&quot;);\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n2.  <span></span><span class=\"keyword\">protected</span><span>&#160;</span><span class=\"keyword\">void</span><span> setup(Context context) </span><span class=\"keyword\">throws</span><span> IOException,&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; InterruptedException {&#160;&#160; </span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">super</span><span>.setup(context);&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; FileReader reader = </span><span class=\"keyword\">new</span><span> FileReader(</span><span class=\"keyword\">new</span><span> File(</span><span class=\"string\">&quot;mData&quot;</span><span>));&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160; BufferedReader bReader = </span><span class=\"keyword\">new</span><span> BufferedReader(reader);&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n8.  <span>}&#160; </span>           </div>         </td>       </tr>     </tbody></table> </p>  \n\n在使用symlink之前，需要告知hadoop，如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>conf.set(&quot;mapred.create.symlink&quot;, &quot;yes&quot;); // 是yes，不是true\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           \n\n[DistributedCache.createSymlink(Configuration)](http://www.hongweiyi.com/wp-content/uploads/2012/02/DistributedCache.html)\n         </td>       </tr>     </tbody></table> </p>  \n\n**4、注意事项**\n\n1）缓存文件（数据、三方库）需上传至HDFS，方能使用；\n\n2）缓存较小的情况下，建议将数据全部读入相应节点内存，提高访问速度；\n\n3）缓存文件是read-only的，不能修改。若要修改得重新输出，将新输出文件作为新缓存进入下一次迭代。","source":"_posts/iterative-mapred-distcache.md","raw":"title: 迭代式MapReduce解决方案（二） DistributedCache\ntags:\n  - Hadoop\n  - MapReduce\nid: 337\ncategories:\n  - 技术分享\ndate: 2012-02-23 16:01:52\n---\n\n**1****、DistributedCache In Hadoop**\n\n此篇文章主要是[前一篇](http://www.hongweiyi.com/?p=250)的后续，主要讲Hadoop的分布式缓存机制的原理与运用。\n\n分布式缓存在MapReduce中称之为DistributedCache，它可以方便map task之间或者reduce task之间共享一些信息，同时也可以将第三方包添加到其classpath路径中去。Hadoop会将缓存数据分发到集群的所有准备启动的节点上，复制到在mapred.temp.dir中配置的目录。\n\n <!--more-->  \n\n**2****、DistributedCache的使用**\n\nDistributedCache的使用的本质其实是添加Configuraton中的属性：mapred.cache.{files|archives}。图方便的话，可以使用DistributedCache类的静态方法。\n\n不省事法：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>conf.set(&quot;mapred.cache.files&quot;, &quot;/data/data&quot;);\n\nconf.set(&quot;mapred.cache. archives&quot;, &quot;/data/data.zip&quot;);\n         </td>       </tr>     </tbody></table> </p>  \n\n省事法：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>[DistributedCache](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/filecache/DistributedCache.html). `**[addCacheFile](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/filecache/DistributedCache.html#addCacheFile(java.net.URI, org.apache.hadoop.conf.Configuration))**``([URI](http://java.sun.com/javase/6/docs/api/java/net/URI.html?is-external=true),` `[Configuration](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/conf/Configuration.html))`\n\n[DistributedCache](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/filecache/DistributedCache.html).`**[addArchiveToClassPath](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/filecache/DistributedCache.html#addArchiveToClassPath(org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FileSystem))**``([Path](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/fs/Path.html),` `[Configuration](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/conf/Configuration.html),` `[FileSystem](http://hadoop.apache.org/common/docs/current/api/org/apache/hadoop/fs/FileSystem.html))`\n         </td>       </tr>     </tbody></table> </p>  \n\n需要注意的是，上面几行代码需要写在Job类初始化之前，否则在运行会中找不到文件（被折磨了很长时间），因为Job初始化时将传入Configuration对象克隆一份给了JobContext。\n\n在MapReduce的0.21版本以后的org.apache.hadoop.mapreduce均移到org.apache.hadoop.mapred包下。但文档中提供的configure方法是重写的MapReduceBase中的，而新版本中map继承于mapper，reduce继承于reducer，所以configure方法一律改成了setup。要获得cache数据，就得在map/reduce task中的setup方法中取得cache数据，再进行相应操作：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n2.  <span></span><span class=\"keyword\">protected</span><span>&#160;</span><span class=\"keyword\">void</span><span> setup(Context context) </span><span class=\"keyword\">throws</span><span> IOException,&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; InterruptedException {&#160;&#160; </span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">super</span><span>.setup(context);&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; URI[] uris = DistributedCache.getCacheFiles(context&#160;&#160; </span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; .getConfiguration());&#160;&#160; </span>\n7.  <span>&#160;&#160;&#160; Path[] paths = DistributedCache.getLocalCacheFiles(context&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; .getConfiguration());&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n10.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n而三方库的使用稍微简单，只需要将库上传至hdfs，再用代码添加至classpath即可：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>DistributedCache.addArchiveToClassPath(new Path(&quot;/data/test.jar&quot;), conf);\n         </td>       </tr>     </tbody></table> </p>  \n\n**3、symlink的使用**\n\nSymlink其实就是hdfs文件的一个快捷方式，只需要在路径名后加入#linkname，之后在task中使用linkname即使用相应文件，如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>conf.set(&quot;mapred.cache.files&quot;, &quot;/data/data#mData&quot;);\n\nconf.set(&quot;mapred.cache. archives&quot;, &quot;/data/data.zip#mDataZip&quot;);\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n2.  <span></span><span class=\"keyword\">protected</span><span>&#160;</span><span class=\"keyword\">void</span><span> setup(Context context) </span><span class=\"keyword\">throws</span><span> IOException,&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; InterruptedException {&#160;&#160; </span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">super</span><span>.setup(context);&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; FileReader reader = </span><span class=\"keyword\">new</span><span> FileReader(</span><span class=\"keyword\">new</span><span> File(</span><span class=\"string\">&quot;mData&quot;</span><span>));&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160; BufferedReader bReader = </span><span class=\"keyword\">new</span><span> BufferedReader(reader);&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n8.  <span>}&#160; </span>           </div>         </td>       </tr>     </tbody></table> </p>  \n\n在使用symlink之前，需要告知hadoop，如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>conf.set(&quot;mapred.create.symlink&quot;, &quot;yes&quot;); // 是yes，不是true\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           \n\n[DistributedCache.createSymlink(Configuration)](http://www.hongweiyi.com/wp-content/uploads/2012/02/DistributedCache.html)\n         </td>       </tr>     </tbody></table> </p>  \n\n**4、注意事项**\n\n1）缓存文件（数据、三方库）需上传至HDFS，方能使用；\n\n2）缓存较小的情况下，建议将数据全部读入相应节点内存，提高访问速度；\n\n3）缓存文件是read-only的，不能修改。若要修改得重新输出，将新输出文件作为新缓存进入下一次迭代。","slug":"iterative-mapred-distcache","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg6238006jsb8fpf1y2gws"},{"title":"我现在就要答案 《REMOTE》","date":"2014-10-21T15:23:00.000Z","_content":"\n人人都在办公室坐着的时候，你很容易就会养成一种坏习惯：不管大事小事，不管什么时间，也不管是否会打断对方的工作，只要想起来，就会打扰对方。为何有那么多人在传统的办公室里工作效率低下，这就是关键原因。习惯了这种工作模式之后，你很难设想一个无法立即得到反馈的世界是什么模样——无论事情有多小。可是，这样的世界是存在的，而且适宜人类居住。<!--more-->\n\n首先，你需要认识到，并不是每个问题都需要立即得到解答。没有什么能比拿着一个无须立即得到答案的问题去打扰别人更傲慢的行为了。这意味着你要明白，并不是所有的事情都同样重要。\n\n一旦明白了这个道理，你就踏上醒悟和高效之路了。可以过几个小时再得到回答的问题，可以发邮件解决。几分钟内需要知道答案的问题，可以用即时消息。至于那些如天塌下来一般、不能等的急事儿，你可以使用一种老式的发明：电话。\n\n想清楚这些，你就会很快意识到，你的问题中有80%都是不着急的，而且发邮件往往比走到某人办公室前更合适。更妙的是，你得到的回答是写下来的，还能留着日后备查。\n\n接下来的50%的问题可以用即时通信工具来解决，绝大多数人懒得打那么多字，所以大家基本上都直奔主题。本来有可能耗时15分钟的工作中断，如今变成了3分钟的速战速决。\n\n最后余下5%的问题可以打电话。的确，打电话的时候看不见对方的身体语言，可以，除非你是要炒掉谁，或是主持一个棘手的面试，否则身体语言的作用没你想的那么大。\n\n想要戒掉你和其他人的“立即回复”上瘾症，肯定会遇到点阻碍。最初几天，你得头脑处在适应阶段，还在判断什么问题改用什么媒介，这时候你会有点泄气。你还要抗拒的一个诱惑是，对你选择的沟通媒介有不切实际的要求。要是别人10分钟之内没回复你的邮件，你就会冒火，那么你没法用电子邮件来处理80%的问题。\n\n然而，一旦从“立即回复”上瘾症中解脱出来，你就会对之前的工作方式感到惊讶无比：在连续不断的干扰下，你是怎么干活的啊。放开手，别抓狂，等到对方准备好协助你的时候，回答自然会朝你走来——这里面几乎蕴含着一种禅意。运用这种镇定气度，更加高效的工作吧。\n\n> 摘抄自：《REMOTE》\n","source":"_posts/i-need-an-answer-now-from-remote.md","raw":"title: 我现在就要答案 《REMOTE》\ndate: 2014-10-21 23:23:00\ncategories: 生活点滴\ntags: Remote, 书摘, 生活\n---\n\n人人都在办公室坐着的时候，你很容易就会养成一种坏习惯：不管大事小事，不管什么时间，也不管是否会打断对方的工作，只要想起来，就会打扰对方。为何有那么多人在传统的办公室里工作效率低下，这就是关键原因。习惯了这种工作模式之后，你很难设想一个无法立即得到反馈的世界是什么模样——无论事情有多小。可是，这样的世界是存在的，而且适宜人类居住。<!--more-->\n\n首先，你需要认识到，并不是每个问题都需要立即得到解答。没有什么能比拿着一个无须立即得到答案的问题去打扰别人更傲慢的行为了。这意味着你要明白，并不是所有的事情都同样重要。\n\n一旦明白了这个道理，你就踏上醒悟和高效之路了。可以过几个小时再得到回答的问题，可以发邮件解决。几分钟内需要知道答案的问题，可以用即时消息。至于那些如天塌下来一般、不能等的急事儿，你可以使用一种老式的发明：电话。\n\n想清楚这些，你就会很快意识到，你的问题中有80%都是不着急的，而且发邮件往往比走到某人办公室前更合适。更妙的是，你得到的回答是写下来的，还能留着日后备查。\n\n接下来的50%的问题可以用即时通信工具来解决，绝大多数人懒得打那么多字，所以大家基本上都直奔主题。本来有可能耗时15分钟的工作中断，如今变成了3分钟的速战速决。\n\n最后余下5%的问题可以打电话。的确，打电话的时候看不见对方的身体语言，可以，除非你是要炒掉谁，或是主持一个棘手的面试，否则身体语言的作用没你想的那么大。\n\n想要戒掉你和其他人的“立即回复”上瘾症，肯定会遇到点阻碍。最初几天，你得头脑处在适应阶段，还在判断什么问题改用什么媒介，这时候你会有点泄气。你还要抗拒的一个诱惑是，对你选择的沟通媒介有不切实际的要求。要是别人10分钟之内没回复你的邮件，你就会冒火，那么你没法用电子邮件来处理80%的问题。\n\n然而，一旦从“立即回复”上瘾症中解脱出来，你就会对之前的工作方式感到惊讶无比：在连续不断的干扰下，你是怎么干活的啊。放开手，别抓狂，等到对方准备好协助你的时候，回答自然会朝你走来——这里面几乎蕴含着一种禅意。运用这种镇定气度，更加高效的工作吧。\n\n> 摘抄自：《REMOTE》\n","slug":"i-need-an-answer-now-from-remote","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg623a006nsb8fu2bi5dhs"},{"title":"Sina APP Engine初试","id":"210","date":"2011-11-12T14:38:57.000Z","_content":"\n**一、 ****官方概述（参考：**[**Sina APP Engine**](http://sae.sina.com.cn)**）**\n\nSina App Engine（以下简称SAE）是新浪研发中心于2009年8月开始内部开发，并在2009年11月3日正式推出第一个Alpha版本的国内首个公有云计算平台（http://sae.sina.com.cn），SAE是新浪云计算战略的核心组成部分。<!--more-->\n\nSAE作为国内的公有云计算，从开发伊始借鉴吸纳Google、Amazon等国外公司的公有云计算的成功技术经验，并很快推出不同于他们的具有自身特色的云计算平台。SAE选择在国内流行最广的Web开发语言PHP作为首选的支持语言，Web开发者可以在Linux/Mac/Windows上通过SVN、[SDK](http://sae.sina.com.cn/?m=sdk)或者Web版在线代码编辑器进行开发、部署、调试，团队开发时还可以进行成员协作，不同的角色将对代码、项目拥有不同的权限；SAE提供了一系列分布式计算、存储服务供开发者使用，包括分布式文件存储、分布式数据库集群、分布式缓存、分布式定时服务等，这些服务将大大降低开发者的开发成本。同时又由于SAE整体架构的高可靠性和新浪的品牌保证，大大降低了开发者的运营风险。另外，作为典型的云计算，SAE采用“所付即所用，所付仅所用”的计费理念，通过日志和统计中心精确的计算每个应用的资源消耗（包括CPU、内存、磁盘等）。\n\n总之，SAE就是简单高效的分布式Web服务开发、运行平台。\n\n**二、 ****我的理解**\n\nSAE基本上是Google APP Engine（GAE）的一个翻版，其为Web App开发者提供稳定、快捷、透明、可控的服务化的平台，并且减少开发者的开发和维护成本。和GAE一样，它们都属于PaaS平台型云计算服务。\n\nSAE通过Web Service Tool，提供以PHP+HTTP的计算中心，类似于传统的虚拟主机，只是运行环境不同。可能由于国内业界环境不够好，SAE还不足以大量吸引开发者入驻，不过相信通过新浪的努力，SAE能够越做越大。\n\n与传统主机托管服务相比而言，传统托管面向的是硬软件设备，使用者得到的设备的使用权；而SAE面向的服务，使用者得到的是服务的使用权。开发者通过SAE可以在上面通过在线调试、日志分析、协作共享等功能进行web开发。（具体参见：附1 SAE与虚拟主机的区别）\n\n有人可能会想，单纯的一个在线调功还不足以让开发者从虚拟主机转向SAE，那么SAE更大的吸引力是什么呢？SAE最大的吸引力就是它所提供的完整的分布式web服务的解决方案。自己的服务器可能会坏，新浪高可靠性的服务器不会！有了完整的解决方案，开发者只需专注于应用的功能开发，而不必担心故障宕机、服务扩容问题，因为所有这些SAE都已经为用户完整提供。且SAE与虚拟主机采用固定计费的方式不同，SAE采用预充值方式，“所付即所用，所付仅所用”，按需付费更加灵活和节省成本，web服务的一切损耗均提供报表查询和账单汇总，用户一目了然。\n\n开发者不用关心硬件运维方面的事情，可以缩短整个项目开发周期，减少运营成本，这也是云概念提出的一个出发点，不过新浪的路还有很远。\n\n**三、 ****SAE****与GAE的比较**\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td width=\"94\" valign=\"top\"></td>\n<td width=\"184\" valign=\"top\">**Sina App Engine**</td>\n<td width=\"200\" valign=\"top\">**Google App Engine**</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**云计算模型**</td>\n<td width=\"184\" valign=\"top\">PaaS</td>\n<td width=\"200\" valign=\"top\">PaaS</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**支持语言**</td>\n<td width=\"184\" valign=\"top\">PHP</td>\n<td width=\"200\" valign=\"top\">Java、Python、Go</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**数据库支持**</td>\n<td width=\"184\" valign=\"top\">MySQL 最大5GB</td>\n<td width=\"200\" valign=\"top\">暂不支持</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**每个帐号可拥有app****数量**</td>\n<td width=\"184\" valign=\"top\">10个</td>\n<td width=\"200\" valign=\"top\">10个</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**单app****存储限额**</td>\n<td width=\"184\" valign=\"top\">最多10GB，单文件不大于4M</td>\n<td width=\"200\" valign=\"top\">1GB免费，无最大上限</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**代码大小**</td>\n<td width=\"184\" valign=\"top\">每帐户不超过100M，单app总代码不超过50M</td>\n<td width=\"200\" valign=\"top\">单app不超过150MB</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**绑定域名**</td>\n<td width=\"184\" valign=\"top\">需另行申请，备案</td>\n<td width=\"200\" valign=\"top\">支持</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**免费额度**</td>\n<td width=\"184\" valign=\"top\">各项服务通过扣除虚拟货币“云豆”实现限额。\n\n成功注册：增500云豆\n\n实名认证：增2000云豆</td>\n<td width=\"200\" valign=\"top\">每日6.5 CPU-hours，流入流出带宽各1GB，存储1GB。</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**超过免费限额的收费标准**</td>\n<td width=\"184\" valign=\"top\">1元=100云豆\n\n赠送机制对创业者帮助很大</td>\n<td width=\"200\" valign=\"top\">流入带宽：0.1美元/GB\n流出带宽：0.12美元/GB\nCPU 时间：0.1美元/CPU小时\n存储：0.15美元/GB 每月</td>\n</tr>\n</tbody>\n</table>\n**四、 ****SAE****小用感受**\n\n从开始注册，到部署一个WordPress，花了不到半个小时，比在这个空间部署方便快捷很多，而且不要钱，可以考虑将个人博客搬到Sina APP Engine之上。不过美中不足的是，SAE还不支持个人的域名绑定功能，新浪方给出的理由是国家还未出台相应的域备案政策。\n\n还有一个不足的地方，就是平台的开发语言限制。不知新浪出于何种战略考虑，抑或是技术攻关不利，只支持了Php一种语言Web App，这让很多Java、Python程序员神伤啊！\n\n**【附****】**\n\n**SAE****与虚拟主机的区别（摘自官方介绍）**\n\n传统服务托管面向的是硬件软件设备，使用者得到的也是设备的使用权；而SAE面向的服务，使用者得到的是服务的使用权。\n\n传统服务托管不面向开发者，开发者无法在其上享受到开发的乐趣；而SAE的一个重要用户就是web developer，开发者可以在其上通过在线调试、日志分析、协作共享等功能进行web开发。\n\n传统服务托管不提供分布式系统解决方案；而SAE提供的完整的分布式web服务的解决方案，其中不仅仅包括分布式数据库、分布式文件系统，更包括分布式定时器系统、网页抓取服务、图像处理服务等。\n\n传统服务托管不解决域名问题，用户往往烦恼于域名申请；而SAE的用户将自动得到在sinaapp下的二级域名，同时SAE还支持域名cname。\n\n传统服务托管无法保证SLA（Service Level Agreement），硬件故障的成本基本由使用者承担；而SAE保证用户的SLA，用户的web服务自动享有高冗余的前端服务器、享有自动负载均衡系统、服务自动扩展、服务自动收缩等功能。\n\n传统的服务托管采用预付费的方式，费用固定且和实际使用情况无直接关系；而SAE采用预充值方式，“所付即所用，所付仅所用”，web服务的一切损耗均提供报表查询和账单汇总，让用户一目了然。\n\n参考资料：[http://sae.sina.com.cn](http://sae.sina.com.cn/)","source":"_posts/hello-sae.md","raw":"title: Sina APP Engine初试\ntags:\n  - SAE\nid: 210\ncategories:\n  - 技术分享\ndate: 2011-11-12 22:38:57\n---\n\n**一、 ****官方概述（参考：**[**Sina APP Engine**](http://sae.sina.com.cn)**）**\n\nSina App Engine（以下简称SAE）是新浪研发中心于2009年8月开始内部开发，并在2009年11月3日正式推出第一个Alpha版本的国内首个公有云计算平台（http://sae.sina.com.cn），SAE是新浪云计算战略的核心组成部分。<!--more-->\n\nSAE作为国内的公有云计算，从开发伊始借鉴吸纳Google、Amazon等国外公司的公有云计算的成功技术经验，并很快推出不同于他们的具有自身特色的云计算平台。SAE选择在国内流行最广的Web开发语言PHP作为首选的支持语言，Web开发者可以在Linux/Mac/Windows上通过SVN、[SDK](http://sae.sina.com.cn/?m=sdk)或者Web版在线代码编辑器进行开发、部署、调试，团队开发时还可以进行成员协作，不同的角色将对代码、项目拥有不同的权限；SAE提供了一系列分布式计算、存储服务供开发者使用，包括分布式文件存储、分布式数据库集群、分布式缓存、分布式定时服务等，这些服务将大大降低开发者的开发成本。同时又由于SAE整体架构的高可靠性和新浪的品牌保证，大大降低了开发者的运营风险。另外，作为典型的云计算，SAE采用“所付即所用，所付仅所用”的计费理念，通过日志和统计中心精确的计算每个应用的资源消耗（包括CPU、内存、磁盘等）。\n\n总之，SAE就是简单高效的分布式Web服务开发、运行平台。\n\n**二、 ****我的理解**\n\nSAE基本上是Google APP Engine（GAE）的一个翻版，其为Web App开发者提供稳定、快捷、透明、可控的服务化的平台，并且减少开发者的开发和维护成本。和GAE一样，它们都属于PaaS平台型云计算服务。\n\nSAE通过Web Service Tool，提供以PHP+HTTP的计算中心，类似于传统的虚拟主机，只是运行环境不同。可能由于国内业界环境不够好，SAE还不足以大量吸引开发者入驻，不过相信通过新浪的努力，SAE能够越做越大。\n\n与传统主机托管服务相比而言，传统托管面向的是硬软件设备，使用者得到的设备的使用权；而SAE面向的服务，使用者得到的是服务的使用权。开发者通过SAE可以在上面通过在线调试、日志分析、协作共享等功能进行web开发。（具体参见：附1 SAE与虚拟主机的区别）\n\n有人可能会想，单纯的一个在线调功还不足以让开发者从虚拟主机转向SAE，那么SAE更大的吸引力是什么呢？SAE最大的吸引力就是它所提供的完整的分布式web服务的解决方案。自己的服务器可能会坏，新浪高可靠性的服务器不会！有了完整的解决方案，开发者只需专注于应用的功能开发，而不必担心故障宕机、服务扩容问题，因为所有这些SAE都已经为用户完整提供。且SAE与虚拟主机采用固定计费的方式不同，SAE采用预充值方式，“所付即所用，所付仅所用”，按需付费更加灵活和节省成本，web服务的一切损耗均提供报表查询和账单汇总，用户一目了然。\n\n开发者不用关心硬件运维方面的事情，可以缩短整个项目开发周期，减少运营成本，这也是云概念提出的一个出发点，不过新浪的路还有很远。\n\n**三、 ****SAE****与GAE的比较**\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td width=\"94\" valign=\"top\"></td>\n<td width=\"184\" valign=\"top\">**Sina App Engine**</td>\n<td width=\"200\" valign=\"top\">**Google App Engine**</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**云计算模型**</td>\n<td width=\"184\" valign=\"top\">PaaS</td>\n<td width=\"200\" valign=\"top\">PaaS</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**支持语言**</td>\n<td width=\"184\" valign=\"top\">PHP</td>\n<td width=\"200\" valign=\"top\">Java、Python、Go</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**数据库支持**</td>\n<td width=\"184\" valign=\"top\">MySQL 最大5GB</td>\n<td width=\"200\" valign=\"top\">暂不支持</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**每个帐号可拥有app****数量**</td>\n<td width=\"184\" valign=\"top\">10个</td>\n<td width=\"200\" valign=\"top\">10个</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**单app****存储限额**</td>\n<td width=\"184\" valign=\"top\">最多10GB，单文件不大于4M</td>\n<td width=\"200\" valign=\"top\">1GB免费，无最大上限</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**代码大小**</td>\n<td width=\"184\" valign=\"top\">每帐户不超过100M，单app总代码不超过50M</td>\n<td width=\"200\" valign=\"top\">单app不超过150MB</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**绑定域名**</td>\n<td width=\"184\" valign=\"top\">需另行申请，备案</td>\n<td width=\"200\" valign=\"top\">支持</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**免费额度**</td>\n<td width=\"184\" valign=\"top\">各项服务通过扣除虚拟货币“云豆”实现限额。\n\n成功注册：增500云豆\n\n实名认证：增2000云豆</td>\n<td width=\"200\" valign=\"top\">每日6.5 CPU-hours，流入流出带宽各1GB，存储1GB。</td>\n</tr>\n<tr>\n<td width=\"94\" valign=\"top\">**超过免费限额的收费标准**</td>\n<td width=\"184\" valign=\"top\">1元=100云豆\n\n赠送机制对创业者帮助很大</td>\n<td width=\"200\" valign=\"top\">流入带宽：0.1美元/GB\n流出带宽：0.12美元/GB\nCPU 时间：0.1美元/CPU小时\n存储：0.15美元/GB 每月</td>\n</tr>\n</tbody>\n</table>\n**四、 ****SAE****小用感受**\n\n从开始注册，到部署一个WordPress，花了不到半个小时，比在这个空间部署方便快捷很多，而且不要钱，可以考虑将个人博客搬到Sina APP Engine之上。不过美中不足的是，SAE还不支持个人的域名绑定功能，新浪方给出的理由是国家还未出台相应的域备案政策。\n\n还有一个不足的地方，就是平台的开发语言限制。不知新浪出于何种战略考虑，抑或是技术攻关不利，只支持了Php一种语言Web App，这让很多Java、Python程序员神伤啊！\n\n**【附****】**\n\n**SAE****与虚拟主机的区别（摘自官方介绍）**\n\n传统服务托管面向的是硬件软件设备，使用者得到的也是设备的使用权；而SAE面向的服务，使用者得到的是服务的使用权。\n\n传统服务托管不面向开发者，开发者无法在其上享受到开发的乐趣；而SAE的一个重要用户就是web developer，开发者可以在其上通过在线调试、日志分析、协作共享等功能进行web开发。\n\n传统服务托管不提供分布式系统解决方案；而SAE提供的完整的分布式web服务的解决方案，其中不仅仅包括分布式数据库、分布式文件系统，更包括分布式定时器系统、网页抓取服务、图像处理服务等。\n\n传统服务托管不解决域名问题，用户往往烦恼于域名申请；而SAE的用户将自动得到在sinaapp下的二级域名，同时SAE还支持域名cname。\n\n传统服务托管无法保证SLA（Service Level Agreement），硬件故障的成本基本由使用者承担；而SAE保证用户的SLA，用户的web服务自动享有高冗余的前端服务器、享有自动负载均衡系统、服务自动扩展、服务自动收缩等功能。\n\n传统的服务托管采用预付费的方式，费用固定且和实际使用情况无直接关系；而SAE采用预充值方式，“所付即所用，所付仅所用”，web服务的一切损耗均提供报表查询和账单汇总，让用户一目了然。\n\n参考资料：[http://sae.sina.com.cn](http://sae.sina.com.cn/)","slug":"hello-sae","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg623b006rsb8f6l9brp4n"},{"title":"Hadoop生态图谱","id":"413","date":"2012-03-04T16:21:13.000Z","_content":"\n当下Hadoop已经成长为一个庞大的体系，貌似只要和海量数据相关的，没有哪个领域缺少Hadoop的身影，下面是一个Hadoop生态系统的图谱，详细的列举了在Hadoop这个生态系统中出现的各种数据工具。\n<!--more-->> 1\\. 数据抓取系统 － [Nutch](http://nutch.apache.org/) \n> \n> 2\\. 海量数据怎么存，当然是用分布式文件系统 － [HDFS](http://hadoop.apache.org/hdfs/) \n> \n> 3\\. 数据怎么用呢，分析，处理 - MapReduce框架让你编写代码来实现对大数据的分析工作 \n> \n> 4\\. 非结构化数据（日志）收集处理 － [fuse](http://fuse.sourceforge.net/),[webdav](http://www.webdav.org/), [chukwa](http://incubator.apache.org/chukwa/), [flume](https://github.com/cloudera/flume/wiki), [Scribe](https://github.com/facebook/scribe) \n> \n> 5\\. 数据导入到HDFS中，至此RDBSM也可以加入HDFS的狂欢了 － [Hiho](https://github.com/sonalgoyal/hiho), [sqoop](http://www.cloudera.com/downloads/sqoop/) \n> \n> 6\\. MapReduce太麻烦，好吧，让你用熟悉的方式来操作Hadoop里的数据 – [Pig](http://pig.apache.org/), [Hive](http://hive.apache.org/), [Jaql](http://code.google.com/p/jaql/) \n> \n> 7\\. 让你的数据可见 － drilldown, [Intellicus](http://www.intellicus.com/) \n> \n> 8\\. 用高级语言管理你的任务流 – [oozie](http://yahoo.github.com/oozie/), [Cascading](http://www.cascading.org/) \n> \n> 9\\. Hadoop当然也有自己的监控管理工具 – [Hue](https://github.com/cloudera/hue), [karmasphere](http://karmasphere.com/), [eclipse plugin](http://wiki.apache.org/hadoop/EclipsePlugIn), [cacti](http://www.cacti.net/), [ganglia](http://ganglia.sourceforge.net/) \n> \n> 10\\. 数据序列化处理与任务调度 – [Avro](http://avro.apache.org/), [Zookeeper](http://zookeeper.apache.org/) \n> \n> 11\\. 更多构建在Hadoop上层的服务 – [Mahout](http://mahout.apache.org/), [Elastic map Reduce](http://aws.amazon.com/elasticmapreduce/) \n> \n> 12\\. OLTP存储系统 – [Hbase](http://hbase.apache.org/)  \n\n![](http://pic.yupoo.com/iammutex/BKBq9XAQ/POqWJ.png)\n  > 转载：\n> \n> NoSQLFan：[Hadoop生态图谱](http://blog.nosqlfan.com/html/3675.html)","source":"_posts/hadoop-related.md","raw":"title: Hadoop生态图谱\ntags:\n  - Hadoop\nid: 413\ncategories:\n  - 技术分享\ndate: 2012-03-05 00:21:13\n---\n\n当下Hadoop已经成长为一个庞大的体系，貌似只要和海量数据相关的，没有哪个领域缺少Hadoop的身影，下面是一个Hadoop生态系统的图谱，详细的列举了在Hadoop这个生态系统中出现的各种数据工具。\n<!--more-->> 1\\. 数据抓取系统 － [Nutch](http://nutch.apache.org/) \n> \n> 2\\. 海量数据怎么存，当然是用分布式文件系统 － [HDFS](http://hadoop.apache.org/hdfs/) \n> \n> 3\\. 数据怎么用呢，分析，处理 - MapReduce框架让你编写代码来实现对大数据的分析工作 \n> \n> 4\\. 非结构化数据（日志）收集处理 － [fuse](http://fuse.sourceforge.net/),[webdav](http://www.webdav.org/), [chukwa](http://incubator.apache.org/chukwa/), [flume](https://github.com/cloudera/flume/wiki), [Scribe](https://github.com/facebook/scribe) \n> \n> 5\\. 数据导入到HDFS中，至此RDBSM也可以加入HDFS的狂欢了 － [Hiho](https://github.com/sonalgoyal/hiho), [sqoop](http://www.cloudera.com/downloads/sqoop/) \n> \n> 6\\. MapReduce太麻烦，好吧，让你用熟悉的方式来操作Hadoop里的数据 – [Pig](http://pig.apache.org/), [Hive](http://hive.apache.org/), [Jaql](http://code.google.com/p/jaql/) \n> \n> 7\\. 让你的数据可见 － drilldown, [Intellicus](http://www.intellicus.com/) \n> \n> 8\\. 用高级语言管理你的任务流 – [oozie](http://yahoo.github.com/oozie/), [Cascading](http://www.cascading.org/) \n> \n> 9\\. Hadoop当然也有自己的监控管理工具 – [Hue](https://github.com/cloudera/hue), [karmasphere](http://karmasphere.com/), [eclipse plugin](http://wiki.apache.org/hadoop/EclipsePlugIn), [cacti](http://www.cacti.net/), [ganglia](http://ganglia.sourceforge.net/) \n> \n> 10\\. 数据序列化处理与任务调度 – [Avro](http://avro.apache.org/), [Zookeeper](http://zookeeper.apache.org/) \n> \n> 11\\. 更多构建在Hadoop上层的服务 – [Mahout](http://mahout.apache.org/), [Elastic map Reduce](http://aws.amazon.com/elasticmapreduce/) \n> \n> 12\\. OLTP存储系统 – [Hbase](http://hbase.apache.org/)  \n\n![](http://pic.yupoo.com/iammutex/BKBq9XAQ/POqWJ.png)\n  > 转载：\n> \n> NoSQLFan：[Hadoop生态图谱](http://blog.nosqlfan.com/html/3675.html)","slug":"hadoop-related","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg623d006vsb8fwxucqwl2"},{"title":"Hadoop Pipes编程","id":"533","date":"2012-05-12T15:04:42.000Z","_content":"\n**1****、Hadoop Pipes****简介**\n\nHadoop Pipes是Hadoop MapReduce的C++接口代称。不同于使用标准输入和输出来实现的map代码和reduce代码之间的Streaming编程，Pipes使用Socket作为TaskTracker与C++进程之间数据传输的通道，数据传输为字节流。\n\n<!--more-->\n\n**2****、Hadoop Pipes****编程初探**\n\nHadoop Pipes可供开发者编写RecordReader、Mapper、Partitioner、Reducer、RecordWriter五个组件，当然，也可以自定义Combiner。\n\n网上有一大堆Hadoop Pipes的WordCount，个人觉得最好的WordCount还是Hadoop自带的，可以参见目录：$HADOOP_HOME/src/examples/pipes/impl\n\n与Pipes相关的头文件放在了目录：\n  > $HADOOP_HOME/c++/Linux-i386oramd64-32/include/hadoop/  \n\n主要的文件为Pipes.hh，该头文件定义了一些抽象类，除去开发者需要编写的五大组件之外，还有JobConf、TaskContext、Closeable、Factory四个。\n\n**TaskContext****：**开发者可以从context中获取当前的key，value，progress和inputSplit等数据信息，当然，比较重要的就是调用emit将结果回传给Hadoop Framework。除了TaskContext，还有MapContext与ReduceContext，代码见下： \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"keyword\">class</span><span> TaskContext {&#160;&#160; </span></span>\n2.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n3.  <span>&#160; </span><span class=\"keyword\">class</span><span> Counter {&#160;&#160; </span></span>\n4.  <span>&#160; </span><span class=\"keyword\">private</span><span>:&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">int</span><span> id;&#160;&#160; </span></span>\n6.  <span>&#160; </span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160; Counter(</span><span class=\"datatypes\">int</span><span> counterId) : id(counterId) {}&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160; Counter(</span><span class=\"keyword\">const</span><span> Counter&amp; counter) : id(counter.id) {}&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">int</span><span> getId() </span><span class=\"keyword\">const</span><span> { </span><span class=\"keyword\">return</span><span> id; }&#160;&#160; </span></span>\n10.  <span>&#160; };&#160;&#160; </span>\n11.  <span>&#160;&#160;&#160;&#160; </span>\n12.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">const</span><span> JobConf* getJobConf() = 0;&#160;&#160; </span></span>\n13.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">const</span><span> std::string&amp; getInputKey() = 0;&#160;&#160;&#160; </span></span>\n14.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">const</span><span> std::string&amp; getInputValue() = 0;&#160;&#160;&#160;&#160; </span></span>\n15.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">void</span><span> emit(</span><span class=\"keyword\">const</span><span> std::string&amp; key, </span><span class=\"keyword\">const</span><span> std::string&amp; value) = 0;&#160;&#160;&#160;&#160; </span></span>\n16.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">void</span><span> progress() = 0;&#160;&#160;&#160;&#160; </span></span>\n17.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">void</span><span> setStatus(</span><span class=\"keyword\">const</span><span> std::string&amp; status) = 0;&#160;&#160; </span></span>\n18.  <span>&#160; </span><span class=\"keyword\">virtual</span><span> Counter*&#160;&#160;&#160; </span></span>\n19.  <span>getCounter(</span><span class=\"keyword\">const</span><span> std::string&amp; group, </span><span class=\"keyword\">const</span><span> std::string&amp; name) = 0;&#160;&#160; </span></span>\n20.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">void</span><span> incrementCounter(</span><span class=\"keyword\">const</span><span> Counter* counter, uint64_t amount) = 0;&#160;&#160; </span></span>\n21.  <span>&#160; </span><span class=\"keyword\">virtual</span><span> ~TaskContext() {}&#160;&#160; </span></span>\n22.  <span>};&#160;&#160; </span>\n23.  <span>&#160; </span>\n24.  <span></span><span class=\"keyword\">class</span><span> MapContext: </span><span class=\"keyword\">public</span><span> TaskContext {&#160;&#160; </span></span>\n25.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n26.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">const</span><span> std::string&amp; getInputSplit() = 0;&#160;&#160; </span></span>\n27.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">const</span><span> std::string&amp; getInputKeyClass() = 0;&#160;&#160; </span></span>\n28.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">const</span><span> std::string&amp; getInputValueClass() = 0;&#160;&#160; </span></span>\n29.  <span>};&#160;&#160; </span>\n30.  <span>&#160; </span>\n31.  <span></span><span class=\"keyword\">class</span><span> ReduceContext: </span><span class=\"keyword\">public</span><span> TaskContext {&#160;&#160; </span></span>\n32.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n33.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">bool</span><span> nextValue() = 0;&#160;&#160; </span></span>\n34.  <span>};&#160;&#160; </span> </div>    \n\n**JobConf**：开发者可以通过获得任务的属性 \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"keyword\">class</span><span> JobConf {&#160;&#160; </span></span>\n2.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n3.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">bool</span><span> hasKey(</span><span class=\"keyword\">const</span><span> std::string&amp; key) </span><span class=\"keyword\">const</span><span> = 0;&#160;&#160; </span></span>\n4.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">const</span><span> std::string&amp; get(</span><span class=\"keyword\">const</span><span> std::string&amp; key) </span><span class=\"keyword\">const</span><span> = 0;&#160;&#160; </span></span>\n5.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">int</span><span> getInt(</span><span class=\"keyword\">const</span><span> std::string&amp; key) </span><span class=\"keyword\">const</span><span> = 0;&#160;&#160; </span></span>\n6.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">float</span><span> getFloat(</span><span class=\"keyword\">const</span><span> std::string&amp; key) </span><span class=\"keyword\">const</span><span> = 0;&#160;&#160; </span></span>\n7.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">bool</span><span> getBoolean(</span><span class=\"keyword\">const</span><span> std::string&amp;key) </span><span class=\"keyword\">const</span><span> = 0;&#160;&#160; </span></span>\n8.  <span>&#160; </span><span class=\"keyword\">virtual</span><span> ~JobConf() {}&#160;&#160; </span></span>\n9.  <span>};&#160;&#160; </span> </div>    \n\n**Closeable**：这个抽象类是五大组件的基类，只有两个方法，一个close()，一个析构函数。这个设计还是挺有Java风格的。\n\n**Factory**：一个抽象工厂，用来创建五大组件的类，是模版工厂的基类。具体的可以参见TemplateFactory.hh。开发者在调用runTask时，创建相应的Factory传入即可。\n\n**3****、Hadoop Pipes****编程**\n\n有了以上的基础知识，就可以开始编写MapReduce任务了。我们可以直接从examples着手，先来看看wordcount-simple.cc。\n\n**wordcount-simple.cc -&gt; Mapper &amp; Reducer** \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"keyword\">class</span><span> WordCountMap: </span><span class=\"keyword\">public</span><span> HadoopPipes::Mapper {&#160;&#160; </span></span>\n2.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n3.  <span>&#160; HadoopPipes::TaskContext::Counter* inputWords;&#160;&#160; </span>\n4.  <span>&#160;&#160;&#160;&#160; </span>\n5.  <span>&#160; WordCountMap(HadoopPipes::TaskContext&amp; context) {&#160;&#160; </span>\n6.  <span>&#160;&#160;&#160; inputWords = context.getCounter(WORDCOUNT, INPUT_WORDS);&#160;&#160; </span>\n7.  <span>&#160; }&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160; </span>\n9.  <span>&#160; </span><span class=\"keyword\">void</span><span> map(HadoopPipes::MapContext&amp; context) {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160; std::vector&lt;std::string&gt; words =&#160;&#160;&#160; </span>\n11.  <span>&#160;&#160;&#160;&#160;&#160; HadoopUtils::splitString(context.getInputValue(), </span><span class=\"string\">&quot; &quot;</span><span>);&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">for</span><span>(unsigned </span><span class=\"datatypes\">int</span><span> i=0; i &lt; words.size(); ++i) {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160; context.emit(words[i], </span><span class=\"string\">&quot;1&quot;</span><span>);&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160; context.incrementCounter(inputWords, words.size());&#160;&#160; </span>\n16.  <span>&#160; }&#160;&#160; </span>\n17.  <span>};&#160;&#160; </span>\n18.  <span>&#160; </span>\n19.  <span></span><span class=\"keyword\">class</span><span> WordCountReduce: </span><span class=\"keyword\">public</span><span> HadoopPipes::Reducer {&#160;&#160; </span></span>\n20.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n21.  <span>&#160; HadoopPipes::TaskContext::Counter* outputWords;&#160;&#160; </span>\n22.  <span>&#160; </span>\n23.  <span>&#160; WordCountReduce(HadoopPipes::TaskContext&amp; context) {&#160;&#160; </span>\n24.  <span>&#160;&#160;&#160; outputWords = context.getCounter(WORDCOUNT, OUTPUT_WORDS);&#160;&#160; </span>\n25.  <span>&#160; }&#160;&#160; </span>\n26.  <span>&#160; </span>\n27.  <span>&#160; </span><span class=\"keyword\">void</span><span> reduce(HadoopPipes::ReduceContext&amp; context) {&#160;&#160; </span></span>\n28.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">int</span><span> sum = 0;&#160;&#160; </span></span>\n29.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">while</span><span> (context.nextValue()) {&#160;&#160; </span></span>\n30.  <span>&#160;&#160;&#160;&#160;&#160; sum += HadoopUtils::toInt(context.getInputValue());&#160;&#160; </span>\n31.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n32.  <span>&#160;&#160;&#160; context.emit(context.getInputKey(), HadoopUtils::toString(sum));&#160;&#160; </span>\n33.  <span>&#160;&#160;&#160; context.incrementCounter(outputWords, 1);&#160;&#160;&#160; </span>\n34.  <span>&#160; }&#160;&#160; </span>\n35.  <span>};&#160; </span> </div>    \n\n该任务编写了两个主要组件，mapper与reducer。要实现这两个组件需要继承相应的基类。基类声明如下： \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"keyword\">class</span><span> Mapper: </span><span class=\"keyword\">public</span><span> Closable {&#160;&#160; </span></span>\n2.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n3.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">void</span><span> map(MapContext&amp; context) = 0;&#160;&#160; </span></span>\n4.  <span>};&#160;&#160; </span>\n5.  <span>&#160; </span>\n6.  <span></span><span class=\"keyword\">class</span><span> Reducer: </span><span class=\"keyword\">public</span><span> Closable {&#160;&#160; </span></span>\n7.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n8.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">void</span><span> reduce(ReduceContext&amp; context) = 0;&#160;&#160; </span></span>\n9.  <span>};&#160;&#160; </span> </div>    \n\n继承了相应的基类，就可以大胆的通过context获得key/value实现自己的逻辑了，结果处理完毕后，需要通过context.emit(key, value)将结果发送到下一阶段。\n\n注：\n\n1）由于Factory创建对象需要传入Context对象，所以还需要实现一个构造函数，参数为TaskContext。\n\n2）Hadoop Pipes内部规定，map与reduce的key/value均为Text类型，在C++中表现为string类型。不过，Hadoop还是做得比较贴心，有专门的方法负责处理string，具体可以参见StringUtils.hh。\n\n3）Counter可以称之为统计器，可供开发者统计一些需要的数据，如读入行数、处理字节数等。任务完毕后，可以在web控制参看结果。\n\n**wordcount-part.cc -&gt; Partitioner** \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"keyword\">class</span><span> WordCountPartitioner: </span><span class=\"keyword\">public</span><span> HadoopPipes::Partitioner {&#160;&#160; </span></span>2.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>3.  <span>&#160; WordCountPartitioner(HadoopPipes::TaskContext&amp; context){}&#160;&#160; </span>4.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">int</span><span> partition(</span><span class=\"keyword\">const</span><span> std::string&amp; key, </span><span class=\"datatypes\">int</span><span> numOfReduces) {&#160;&#160; </span></span>5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> 0;&#160;&#160; </span></span>6.  <span>&#160; }&#160;&#160; </span>7.  <span>};&#160;&#160; </span> </div>    \n\n该实例在提供简单Mapper与Reducer方法的同时，还提供了Partitioner，实例实现较为简单，直接返回了第一个reduce位置。开发者自定义的Partitioner同mapper/reducer一致，需要继承其基类HadoopPipes:: RecordWriter，也需要提供一个传入TaskContext的构造函数，它的声明如下： \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"keyword\">class</span><span> Partitioner {&#160;&#160; </span></span>2.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>3.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">int</span><span> partition(</span><span class=\"keyword\">const</span><span> std::string&amp; key, </span><span class=\"datatypes\">int</span><span> numOfReduces) = 0;&#160;&#160; </span></span>4.  <span>&#160; </span><span class=\"keyword\">virtual</span><span> ~Partitioner() {}&#160;&#160; </span></span>5.  <span>};&#160; </span> </div>    \n\nPartitioner编写方法与Java的一致，对于partition方法，框架会自动为它传入两个参数，分别为key值和reduce task的个数numOfReduces，用户只需返回一个0~ numOfReduces-1的值即可。\n\n**wordcount-nopipe.cc -&gt; RecordReader &amp; RecordWriter**\n\n这个实例的命名让我思考了很久，是nopipe还是nopart呢？该实例没有实现Partitioner，实现了RecordReader与RecordWriter。框架在运行之初，检查到开发者没有使用Java内置的RecordWriter，所以就只将InputSplit信息通过Pipes发送给C++ Task，由Task实现自身的Record读方法。同样，在Record写数据时任务也没走Pipes，直接将数据写到了相应的位置，写临时文件会直接写到磁盘，写HDFS则需要通过libhdfs进行写操作。具体Pipes运行流程，请参见下篇博文。\n\nRecordReader/RecordWriter实现较长，这里就不贴了，贴一下这俩的基类： \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"keyword\">class</span><span> RecordReader: </span><span class=\"keyword\">public</span><span> Closable {&#160;&#160; </span></span>2.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>3.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">bool</span><span> next(std::string&amp; key, std::string&amp; value) = 0;&#160;&#160; </span></span>4.  <span>&#160; </span><span class=\"comment\">// 读进度 </span><span>&#160; </span></span>5.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">float</span><span> getProgress() = 0;&#160;&#160; </span></span>6.  <span>};&#160;&#160; </span>7.  <span>&#160; </span>8.  <span></span><span class=\"keyword\">class</span><span> RecordWriter: </span><span class=\"keyword\">public</span><span> Closable {&#160;&#160; </span></span>9.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>10.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">void</span><span> emit(</span><span class=\"keyword\">const</span><span> std::string&amp; key,&#160;&#160; </span></span>11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">const</span><span> std::string&amp; value) = 0;&#160;&#160; </span></span>12.  <span>};&#160; </span> </div>    \n\n对于RecordReader，用户自定义的构造函数需携带类型为HadoopPipes::MapContext的参数（而不能是TaskContext），通过该参数的getInputSplit()的方法，用户可以获取经过序列化的InpuSplit对象，Java端采用不同的InputFormat可导致InputSplit对象格式不同，但对于大多数InpuSplit对象，它们可以提供至少三个信息：当前要处理的InputSplit所在的文件名，所在文件中的偏移量，它的长度。用户获取这三个信息后，可使用libhdfs库读取文件，以实现next方法。\n\n用户自定的RecordWriter的构造函数需携带参数TaskContext，通过该参数的getJobConf()可获取一个HadoopPipes::JobConf的对象，用户可从该对象中获取该reduce task的各种参数，如：该reduce task的编号（这对于确定输出文件名有用），reduce task的输出目录等。同时实现emit方法，将数据写入文件。\n\n**4****、Hadoop Pipes****任务提交**\n\nHadoop Pipes任务提交命令根据Hadoop版本而不一，主体的命令有如下：\n\nhadoop pipes [-conf &lt;path&gt;] [-D &lt;key=value&gt;, &lt;key=value&gt;, ...] [-input &lt;path&gt;] [-output &lt;path&gt;] [-jar &lt;jar file&gt;] [-inputformat &lt;class&gt;] [-map &lt;class&gt;] [-partitioner &lt;class&gt;] [-reduce &lt;class&gt;] [-writer &lt;class&gt;] [-program &lt;executable&gt;]    <table border=\"0\" cellspacing=\"1\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"254\">           <p>**命**** ****令**\n         </td>          <td valign=\"top\" width=\"292\">           \n\n**描**** ****述**\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-conf &lt;path&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\n任务配置文件\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-D &lt;key=value&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\n添加单独的配置\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-input &lt;path&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\n输入数据目录\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-output &lt;path&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\n输出数据目录\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-jar &lt;jar file&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\n应用程序jar包\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-inputformat class\n         </td>          <td valign=\"top\" width=\"292\">           \n\n#Java版的InputFormat\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-map &lt;class&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\nJava版的Mapper\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-partitioner &lt;class&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\nJava版的Partitioner\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-reduce &lt;class&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\nJava版的Reducer\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-writer &lt;class&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\nJava版的 RecordWriter\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-program &lt;executable&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\nC++可执行程序\n         </td>       </tr>     </tbody></table> </p>  \n\n想使用其它静态数据的话，还可以使用-files命令，该命令就是DistributedCache，直接将静态数据分发到所有datanode上。具体机制参见：[DistributedCache](http://www.hongweiyi.com/2012/02/iterative-mapred-distcache/)。使用如下：\n  > **shell**: bin/hadoop pipes … -files dict.txt\n> \n> **c**: file = fopen(“dict.txt”, “r”); // 直接根据文件名读取  \n\n**5****、小结**\n\n本篇博文简要了说了一下Hadoop Pipes的使用方法，下篇博文会对Hadoop Pipes的运行机制进行一个深入的讲解。\n\n在这里贴一下董的优化意见：为了提高系能，RecordReader和RecordWriter最好采用Java代码实现（或者重用Hadoop中自带的），这是因为Hadoop自带的C++库libhdfs采用JNI实现，底层还是要调用Java相关接口，效率很低，此外，如果要处理的文件为二进制文件或者其他非文本文件，libhdfs可能不好处理。\n\n&#160;\n  > **参考资料：**\n> \n> 董的博客: [Hadoop pipes编程](http://dongxicheng.org/mapreduce/hadoop-pipes-programming/)\n> \n> 《Hadoop权威指南》","source":"_posts/hadoop-pipes.md","raw":"title: Hadoop Pipes编程\ntags:\n  - Hadoop\n  - Hadoop Pipes\n  - MapReduce\nid: 533\ncategories:\n  - 技术分享\ndate: 2012-05-12 23:04:42\n---\n\n**1****、Hadoop Pipes****简介**\n\nHadoop Pipes是Hadoop MapReduce的C++接口代称。不同于使用标准输入和输出来实现的map代码和reduce代码之间的Streaming编程，Pipes使用Socket作为TaskTracker与C++进程之间数据传输的通道，数据传输为字节流。\n\n<!--more-->\n\n**2****、Hadoop Pipes****编程初探**\n\nHadoop Pipes可供开发者编写RecordReader、Mapper、Partitioner、Reducer、RecordWriter五个组件，当然，也可以自定义Combiner。\n\n网上有一大堆Hadoop Pipes的WordCount，个人觉得最好的WordCount还是Hadoop自带的，可以参见目录：$HADOOP_HOME/src/examples/pipes/impl\n\n与Pipes相关的头文件放在了目录：\n  > $HADOOP_HOME/c++/Linux-i386oramd64-32/include/hadoop/  \n\n主要的文件为Pipes.hh，该头文件定义了一些抽象类，除去开发者需要编写的五大组件之外，还有JobConf、TaskContext、Closeable、Factory四个。\n\n**TaskContext****：**开发者可以从context中获取当前的key，value，progress和inputSplit等数据信息，当然，比较重要的就是调用emit将结果回传给Hadoop Framework。除了TaskContext，还有MapContext与ReduceContext，代码见下： \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"keyword\">class</span><span> TaskContext {&#160;&#160; </span></span>\n2.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n3.  <span>&#160; </span><span class=\"keyword\">class</span><span> Counter {&#160;&#160; </span></span>\n4.  <span>&#160; </span><span class=\"keyword\">private</span><span>:&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">int</span><span> id;&#160;&#160; </span></span>\n6.  <span>&#160; </span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160; Counter(</span><span class=\"datatypes\">int</span><span> counterId) : id(counterId) {}&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160; Counter(</span><span class=\"keyword\">const</span><span> Counter&amp; counter) : id(counter.id) {}&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">int</span><span> getId() </span><span class=\"keyword\">const</span><span> { </span><span class=\"keyword\">return</span><span> id; }&#160;&#160; </span></span>\n10.  <span>&#160; };&#160;&#160; </span>\n11.  <span>&#160;&#160;&#160;&#160; </span>\n12.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">const</span><span> JobConf* getJobConf() = 0;&#160;&#160; </span></span>\n13.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">const</span><span> std::string&amp; getInputKey() = 0;&#160;&#160;&#160; </span></span>\n14.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">const</span><span> std::string&amp; getInputValue() = 0;&#160;&#160;&#160;&#160; </span></span>\n15.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">void</span><span> emit(</span><span class=\"keyword\">const</span><span> std::string&amp; key, </span><span class=\"keyword\">const</span><span> std::string&amp; value) = 0;&#160;&#160;&#160;&#160; </span></span>\n16.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">void</span><span> progress() = 0;&#160;&#160;&#160;&#160; </span></span>\n17.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">void</span><span> setStatus(</span><span class=\"keyword\">const</span><span> std::string&amp; status) = 0;&#160;&#160; </span></span>\n18.  <span>&#160; </span><span class=\"keyword\">virtual</span><span> Counter*&#160;&#160;&#160; </span></span>\n19.  <span>getCounter(</span><span class=\"keyword\">const</span><span> std::string&amp; group, </span><span class=\"keyword\">const</span><span> std::string&amp; name) = 0;&#160;&#160; </span></span>\n20.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">void</span><span> incrementCounter(</span><span class=\"keyword\">const</span><span> Counter* counter, uint64_t amount) = 0;&#160;&#160; </span></span>\n21.  <span>&#160; </span><span class=\"keyword\">virtual</span><span> ~TaskContext() {}&#160;&#160; </span></span>\n22.  <span>};&#160;&#160; </span>\n23.  <span>&#160; </span>\n24.  <span></span><span class=\"keyword\">class</span><span> MapContext: </span><span class=\"keyword\">public</span><span> TaskContext {&#160;&#160; </span></span>\n25.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n26.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">const</span><span> std::string&amp; getInputSplit() = 0;&#160;&#160; </span></span>\n27.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">const</span><span> std::string&amp; getInputKeyClass() = 0;&#160;&#160; </span></span>\n28.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">const</span><span> std::string&amp; getInputValueClass() = 0;&#160;&#160; </span></span>\n29.  <span>};&#160;&#160; </span>\n30.  <span>&#160; </span>\n31.  <span></span><span class=\"keyword\">class</span><span> ReduceContext: </span><span class=\"keyword\">public</span><span> TaskContext {&#160;&#160; </span></span>\n32.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n33.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">bool</span><span> nextValue() = 0;&#160;&#160; </span></span>\n34.  <span>};&#160;&#160; </span> </div>    \n\n**JobConf**：开发者可以通过获得任务的属性 \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"keyword\">class</span><span> JobConf {&#160;&#160; </span></span>\n2.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n3.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">bool</span><span> hasKey(</span><span class=\"keyword\">const</span><span> std::string&amp; key) </span><span class=\"keyword\">const</span><span> = 0;&#160;&#160; </span></span>\n4.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">const</span><span> std::string&amp; get(</span><span class=\"keyword\">const</span><span> std::string&amp; key) </span><span class=\"keyword\">const</span><span> = 0;&#160;&#160; </span></span>\n5.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">int</span><span> getInt(</span><span class=\"keyword\">const</span><span> std::string&amp; key) </span><span class=\"keyword\">const</span><span> = 0;&#160;&#160; </span></span>\n6.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">float</span><span> getFloat(</span><span class=\"keyword\">const</span><span> std::string&amp; key) </span><span class=\"keyword\">const</span><span> = 0;&#160;&#160; </span></span>\n7.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">bool</span><span> getBoolean(</span><span class=\"keyword\">const</span><span> std::string&amp;key) </span><span class=\"keyword\">const</span><span> = 0;&#160;&#160; </span></span>\n8.  <span>&#160; </span><span class=\"keyword\">virtual</span><span> ~JobConf() {}&#160;&#160; </span></span>\n9.  <span>};&#160;&#160; </span> </div>    \n\n**Closeable**：这个抽象类是五大组件的基类，只有两个方法，一个close()，一个析构函数。这个设计还是挺有Java风格的。\n\n**Factory**：一个抽象工厂，用来创建五大组件的类，是模版工厂的基类。具体的可以参见TemplateFactory.hh。开发者在调用runTask时，创建相应的Factory传入即可。\n\n**3****、Hadoop Pipes****编程**\n\n有了以上的基础知识，就可以开始编写MapReduce任务了。我们可以直接从examples着手，先来看看wordcount-simple.cc。\n\n**wordcount-simple.cc -&gt; Mapper &amp; Reducer** \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"keyword\">class</span><span> WordCountMap: </span><span class=\"keyword\">public</span><span> HadoopPipes::Mapper {&#160;&#160; </span></span>\n2.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n3.  <span>&#160; HadoopPipes::TaskContext::Counter* inputWords;&#160;&#160; </span>\n4.  <span>&#160;&#160;&#160;&#160; </span>\n5.  <span>&#160; WordCountMap(HadoopPipes::TaskContext&amp; context) {&#160;&#160; </span>\n6.  <span>&#160;&#160;&#160; inputWords = context.getCounter(WORDCOUNT, INPUT_WORDS);&#160;&#160; </span>\n7.  <span>&#160; }&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160; </span>\n9.  <span>&#160; </span><span class=\"keyword\">void</span><span> map(HadoopPipes::MapContext&amp; context) {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160; std::vector&lt;std::string&gt; words =&#160;&#160;&#160; </span>\n11.  <span>&#160;&#160;&#160;&#160;&#160; HadoopUtils::splitString(context.getInputValue(), </span><span class=\"string\">&quot; &quot;</span><span>);&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">for</span><span>(unsigned </span><span class=\"datatypes\">int</span><span> i=0; i &lt; words.size(); ++i) {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160; context.emit(words[i], </span><span class=\"string\">&quot;1&quot;</span><span>);&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160; context.incrementCounter(inputWords, words.size());&#160;&#160; </span>\n16.  <span>&#160; }&#160;&#160; </span>\n17.  <span>};&#160;&#160; </span>\n18.  <span>&#160; </span>\n19.  <span></span><span class=\"keyword\">class</span><span> WordCountReduce: </span><span class=\"keyword\">public</span><span> HadoopPipes::Reducer {&#160;&#160; </span></span>\n20.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n21.  <span>&#160; HadoopPipes::TaskContext::Counter* outputWords;&#160;&#160; </span>\n22.  <span>&#160; </span>\n23.  <span>&#160; WordCountReduce(HadoopPipes::TaskContext&amp; context) {&#160;&#160; </span>\n24.  <span>&#160;&#160;&#160; outputWords = context.getCounter(WORDCOUNT, OUTPUT_WORDS);&#160;&#160; </span>\n25.  <span>&#160; }&#160;&#160; </span>\n26.  <span>&#160; </span>\n27.  <span>&#160; </span><span class=\"keyword\">void</span><span> reduce(HadoopPipes::ReduceContext&amp; context) {&#160;&#160; </span></span>\n28.  <span>&#160;&#160;&#160; </span><span class=\"datatypes\">int</span><span> sum = 0;&#160;&#160; </span></span>\n29.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">while</span><span> (context.nextValue()) {&#160;&#160; </span></span>\n30.  <span>&#160;&#160;&#160;&#160;&#160; sum += HadoopUtils::toInt(context.getInputValue());&#160;&#160; </span>\n31.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n32.  <span>&#160;&#160;&#160; context.emit(context.getInputKey(), HadoopUtils::toString(sum));&#160;&#160; </span>\n33.  <span>&#160;&#160;&#160; context.incrementCounter(outputWords, 1);&#160;&#160;&#160; </span>\n34.  <span>&#160; }&#160;&#160; </span>\n35.  <span>};&#160; </span> </div>    \n\n该任务编写了两个主要组件，mapper与reducer。要实现这两个组件需要继承相应的基类。基类声明如下： \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"keyword\">class</span><span> Mapper: </span><span class=\"keyword\">public</span><span> Closable {&#160;&#160; </span></span>\n2.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n3.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">void</span><span> map(MapContext&amp; context) = 0;&#160;&#160; </span></span>\n4.  <span>};&#160;&#160; </span>\n5.  <span>&#160; </span>\n6.  <span></span><span class=\"keyword\">class</span><span> Reducer: </span><span class=\"keyword\">public</span><span> Closable {&#160;&#160; </span></span>\n7.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>\n8.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">void</span><span> reduce(ReduceContext&amp; context) = 0;&#160;&#160; </span></span>\n9.  <span>};&#160;&#160; </span> </div>    \n\n继承了相应的基类，就可以大胆的通过context获得key/value实现自己的逻辑了，结果处理完毕后，需要通过context.emit(key, value)将结果发送到下一阶段。\n\n注：\n\n1）由于Factory创建对象需要传入Context对象，所以还需要实现一个构造函数，参数为TaskContext。\n\n2）Hadoop Pipes内部规定，map与reduce的key/value均为Text类型，在C++中表现为string类型。不过，Hadoop还是做得比较贴心，有专门的方法负责处理string，具体可以参见StringUtils.hh。\n\n3）Counter可以称之为统计器，可供开发者统计一些需要的数据，如读入行数、处理字节数等。任务完毕后，可以在web控制参看结果。\n\n**wordcount-part.cc -&gt; Partitioner** \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"keyword\">class</span><span> WordCountPartitioner: </span><span class=\"keyword\">public</span><span> HadoopPipes::Partitioner {&#160;&#160; </span></span>2.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>3.  <span>&#160; WordCountPartitioner(HadoopPipes::TaskContext&amp; context){}&#160;&#160; </span>4.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">int</span><span> partition(</span><span class=\"keyword\">const</span><span> std::string&amp; key, </span><span class=\"datatypes\">int</span><span> numOfReduces) {&#160;&#160; </span></span>5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> 0;&#160;&#160; </span></span>6.  <span>&#160; }&#160;&#160; </span>7.  <span>};&#160;&#160; </span> </div>    \n\n该实例在提供简单Mapper与Reducer方法的同时，还提供了Partitioner，实例实现较为简单，直接返回了第一个reduce位置。开发者自定义的Partitioner同mapper/reducer一致，需要继承其基类HadoopPipes:: RecordWriter，也需要提供一个传入TaskContext的构造函数，它的声明如下： \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"keyword\">class</span><span> Partitioner {&#160;&#160; </span></span>2.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>3.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">int</span><span> partition(</span><span class=\"keyword\">const</span><span> std::string&amp; key, </span><span class=\"datatypes\">int</span><span> numOfReduces) = 0;&#160;&#160; </span></span>4.  <span>&#160; </span><span class=\"keyword\">virtual</span><span> ~Partitioner() {}&#160;&#160; </span></span>5.  <span>};&#160; </span> </div>    \n\nPartitioner编写方法与Java的一致，对于partition方法，框架会自动为它传入两个参数，分别为key值和reduce task的个数numOfReduces，用户只需返回一个0~ numOfReduces-1的值即可。\n\n**wordcount-nopipe.cc -&gt; RecordReader &amp; RecordWriter**\n\n这个实例的命名让我思考了很久，是nopipe还是nopart呢？该实例没有实现Partitioner，实现了RecordReader与RecordWriter。框架在运行之初，检查到开发者没有使用Java内置的RecordWriter，所以就只将InputSplit信息通过Pipes发送给C++ Task，由Task实现自身的Record读方法。同样，在Record写数据时任务也没走Pipes，直接将数据写到了相应的位置，写临时文件会直接写到磁盘，写HDFS则需要通过libhdfs进行写操作。具体Pipes运行流程，请参见下篇博文。\n\nRecordReader/RecordWriter实现较长，这里就不贴了，贴一下这俩的基类： \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"keyword\">class</span><span> RecordReader: </span><span class=\"keyword\">public</span><span> Closable {&#160;&#160; </span></span>2.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>3.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">bool</span><span> next(std::string&amp; key, std::string&amp; value) = 0;&#160;&#160; </span></span>4.  <span>&#160; </span><span class=\"comment\">// 读进度 </span><span>&#160; </span></span>5.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"datatypes\">float</span><span> getProgress() = 0;&#160;&#160; </span></span>6.  <span>};&#160;&#160; </span>7.  <span>&#160; </span>8.  <span></span><span class=\"keyword\">class</span><span> RecordWriter: </span><span class=\"keyword\">public</span><span> Closable {&#160;&#160; </span></span>9.  <span></span><span class=\"keyword\">public</span><span>:&#160;&#160; </span></span>10.  <span>&#160; </span><span class=\"keyword\">virtual</span><span>&#160;</span><span class=\"keyword\">void</span><span> emit(</span><span class=\"keyword\">const</span><span> std::string&amp; key,&#160;&#160; </span></span>11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">const</span><span> std::string&amp; value) = 0;&#160;&#160; </span></span>12.  <span>};&#160; </span> </div>    \n\n对于RecordReader，用户自定义的构造函数需携带类型为HadoopPipes::MapContext的参数（而不能是TaskContext），通过该参数的getInputSplit()的方法，用户可以获取经过序列化的InpuSplit对象，Java端采用不同的InputFormat可导致InputSplit对象格式不同，但对于大多数InpuSplit对象，它们可以提供至少三个信息：当前要处理的InputSplit所在的文件名，所在文件中的偏移量，它的长度。用户获取这三个信息后，可使用libhdfs库读取文件，以实现next方法。\n\n用户自定的RecordWriter的构造函数需携带参数TaskContext，通过该参数的getJobConf()可获取一个HadoopPipes::JobConf的对象，用户可从该对象中获取该reduce task的各种参数，如：该reduce task的编号（这对于确定输出文件名有用），reduce task的输出目录等。同时实现emit方法，将数据写入文件。\n\n**4****、Hadoop Pipes****任务提交**\n\nHadoop Pipes任务提交命令根据Hadoop版本而不一，主体的命令有如下：\n\nhadoop pipes [-conf &lt;path&gt;] [-D &lt;key=value&gt;, &lt;key=value&gt;, ...] [-input &lt;path&gt;] [-output &lt;path&gt;] [-jar &lt;jar file&gt;] [-inputformat &lt;class&gt;] [-map &lt;class&gt;] [-partitioner &lt;class&gt;] [-reduce &lt;class&gt;] [-writer &lt;class&gt;] [-program &lt;executable&gt;]    <table border=\"0\" cellspacing=\"1\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"254\">           <p>**命**** ****令**\n         </td>          <td valign=\"top\" width=\"292\">           \n\n**描**** ****述**\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-conf &lt;path&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\n任务配置文件\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-D &lt;key=value&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\n添加单独的配置\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-input &lt;path&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\n输入数据目录\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-output &lt;path&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\n输出数据目录\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-jar &lt;jar file&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\n应用程序jar包\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-inputformat class\n         </td>          <td valign=\"top\" width=\"292\">           \n\n#Java版的InputFormat\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-map &lt;class&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\nJava版的Mapper\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-partitioner &lt;class&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\nJava版的Partitioner\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-reduce &lt;class&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\nJava版的Reducer\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-writer &lt;class&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\nJava版的 RecordWriter\n         </td>       </tr>        <tr>         <td valign=\"top\" width=\"254\">           \n\n-program &lt;executable&gt;\n         </td>          <td valign=\"top\" width=\"292\">           \n\nC++可执行程序\n         </td>       </tr>     </tbody></table> </p>  \n\n想使用其它静态数据的话，还可以使用-files命令，该命令就是DistributedCache，直接将静态数据分发到所有datanode上。具体机制参见：[DistributedCache](http://www.hongweiyi.com/2012/02/iterative-mapred-distcache/)。使用如下：\n  > **shell**: bin/hadoop pipes … -files dict.txt\n> \n> **c**: file = fopen(“dict.txt”, “r”); // 直接根据文件名读取  \n\n**5****、小结**\n\n本篇博文简要了说了一下Hadoop Pipes的使用方法，下篇博文会对Hadoop Pipes的运行机制进行一个深入的讲解。\n\n在这里贴一下董的优化意见：为了提高系能，RecordReader和RecordWriter最好采用Java代码实现（或者重用Hadoop中自带的），这是因为Hadoop自带的C++库libhdfs采用JNI实现，底层还是要调用Java相关接口，效率很低，此外，如果要处理的文件为二进制文件或者其他非文本文件，libhdfs可能不好处理。\n\n&#160;\n  > **参考资料：**\n> \n> 董的博客: [Hadoop pipes编程](http://dongxicheng.org/mapreduce/hadoop-pipes-programming/)\n> \n> 《Hadoop权威指南》","slug":"hadoop-pipes","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg623f006ysb8fcmqm2fr2"},{"title":"Hadoop Pipes运行机制","id":"541","date":"2012-05-13T06:20:19.000Z","_content":"\n**1****、前言**\n\nHadoop Pipes可供C++开发者开发MapReduce任务。文献与书籍上也写了，C++与Java是通过Socket通信，但是具体的运行机制是什么还是得参考源码。\n\n这篇博文主要从源码角度来讲解Hadoop Pipes运行机制以及设计原理，实际的Hadoop Pipes编程请参见：**[Hadoop Pipes编程](http://www.hongweiyi.com/2012/05/hadoop-pipes/)**\n\n<!--more-->\n\n**2****、Hadoop Pipes****运行图解**\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/05/image_thumb.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/05/image.png) \n\n**3****、Hadoop****运行机制**\n\nHadoop端主要类均在org.apache.hadoop.mapred.pipes包下，见下图。\n\n其中，Application是JVM中主要运行程序，PipesMapRunner、PipesReducer、PipesPartitioner、PipesNonJavaInputFormat分别对应C++版的Mapper、Reducer、Partitioner、RecordReader，由于重写RecordWriter后，C++会直接写文件，这里就没有对应的类了。DownwardProtocol/BinaryProtocol、UpwardProtocol/OutputProtocol是Java与C++交互的接口代理类。\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/05/image_thumb1.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/05/image1.png)\n\n开发者通过$HADOOP_HOME/bin/hadoop pipes将作业提交到了包下的Submitter类。运行过程就直接贴文字了，可以结合代码一起看：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>1 解析命令行参数\n\n2 setupPipes(job)\n\n2.1 设置Mapper，Partitioner，Reducer，RecordWriter，如果不是java编写的，则用PipesMapRunner，PipesPartitioner，PipesReducer，NullOutputFormat（所有输出均输出到/dev/null中）；\n\n2.2 设置map/reduce的key/value class，均为Text.class；\n\n2.3 设置RecordReader，如果不是java编写的，则用PipesNonJavaInputFormat；\n\n2.4 获得运行程序，debug脚本以及缓存文件；\n\n3 JobClient.submitJob(job);\n         </td>       </tr>     </tbody></table> </p>  \n\nJobClient提交任务和非Pipes编程提交过程一致，进行Task调度分配之后，就会在分配的TaskTracker上开启JVM进程，运行Runner。这里解析一下PipesMapRunner的运行机制：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>1 创建Application\n\n1.1 创建ServerSocket\n\n1.2 设置环境（临时文件位置、命令端口等）\n\n1.3 获得执行文件，并设置执行权限（chmod +x）\n\n1.4 执行任务，通过java.lang.ProcessBuilder\n\n1.5 创建任务交互代理，DownwardProcotol对象。\n\n1.5.1 创建接收交互代理，UplinkReaderThread对象\n\n1.5.2 循环接受客户端的请求\n\n1.6 downlink.start()，发送消息，客户端可以开始运行\n\n2 如果不是Java编写的RecordReader，直接发送一个InputSplit（注：只是Split的信息，不包括文件数据）给客户端；反之，发送InputSplit之后，再循环读取split，将record格式化之后，将KVP发给客户端。\n         </td>       </tr>     </tbody></table> </p>  \n\nPipesReducer与PipesMapRunner运行机制一致，见下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>1 创建Application，与Map一致；\n\n2 向客户端发送key，之后循环发送value。\n         </td>       </tr>     </tbody></table> </p>  \n\n以上是Hadoop端的运行机制，C++端的与Java的也基本一致，源文件在$HADOOP_HOME/src/c++/pipes/impl/HadoopPipes.cc\n\n在组件运行时，会用ProcessBuilder运行C++可执行文件，可执行文件的main程序基本上都是这样写的： \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"datatypes\">int</span><span> main(</span><span class=\"datatypes\">int</span><span> argc, </span><span class=\"datatypes\">char</span><span> *argv[]) {&#160;&#160; </span></span>2.  <span>&#160; </span><span class=\"keyword\">return</span><span> HadoopPipes::runTask(HadoopPipes::TemplateFactory&lt;WordCountMap,&#160;&#160;&#160; </span></span>3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; WordCountReduce&gt;());&#160;&#160; </span>4.  <span>}&#160;&#160; </span> </div>    \n\n调用了HadoopUtils::runTask(factory)方法，运行机制如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>1 创建运行环境；\n\n2 获得socket端口，如果有端口，则创建socket，并获得其输入输出流。如果没有端口，则获得文件输出输入流；\n\n3 创建ping线程，该线程每隔5s发送一次心跳信息；\n\n4 等待接受任务；\n\n5 循环获得任务消息，直到结束（done）；\n\n6 通知Hadoop完成任务，关闭流\n         </td>       </tr>     </tbody></table> </p>  \n\n**4****、Hadoop Pipes****浅析**\n\nHadoop Pipes采用类RPC机制，封装了Hadoop端与C++端的调用接口。Hadoop调用C++的协议为DownwardProtocol，C++调用Hadoop的为UpwardProtocol。同时也封装了传输数据序列化的接口（SerialUtils.cc），代码结构十分清晰。\n\n但是实际使用中也有一定缺陷，调试起来十分麻烦。C++端挂了之后，Hadoop也就接受不到的心跳消息，所以错误一律为：Pipes Broken。Apache的维基上有一个条目：[howToDebugMapReducePrograms](http://wiki.apache.org/hadoop/HowToDebugMapReducePrograms)，改天得好好研究一下。\n\n&#160;\n\n  > **参考资料：**\n> \n> [董的博客](http://dongxicheng.org/mapreduce/hadoop-pipes-architecture/)\n> \n> Hadoop源码","source":"_posts/hadoop-pipes-src.md","raw":"title: Hadoop Pipes运行机制\ntags:\n  - Hadoop\n  - Hadoop Pipes\n  - MapReduce\nid: 541\ncategories:\n  - 技术分享\ndate: 2012-05-13 14:20:19\n---\n\n**1****、前言**\n\nHadoop Pipes可供C++开发者开发MapReduce任务。文献与书籍上也写了，C++与Java是通过Socket通信，但是具体的运行机制是什么还是得参考源码。\n\n这篇博文主要从源码角度来讲解Hadoop Pipes运行机制以及设计原理，实际的Hadoop Pipes编程请参见：**[Hadoop Pipes编程](http://www.hongweiyi.com/2012/05/hadoop-pipes/)**\n\n<!--more-->\n\n**2****、Hadoop Pipes****运行图解**\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/05/image_thumb.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/05/image.png) \n\n**3****、Hadoop****运行机制**\n\nHadoop端主要类均在org.apache.hadoop.mapred.pipes包下，见下图。\n\n其中，Application是JVM中主要运行程序，PipesMapRunner、PipesReducer、PipesPartitioner、PipesNonJavaInputFormat分别对应C++版的Mapper、Reducer、Partitioner、RecordReader，由于重写RecordWriter后，C++会直接写文件，这里就没有对应的类了。DownwardProtocol/BinaryProtocol、UpwardProtocol/OutputProtocol是Java与C++交互的接口代理类。\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/05/image_thumb1.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/05/image1.png)\n\n开发者通过$HADOOP_HOME/bin/hadoop pipes将作业提交到了包下的Submitter类。运行过程就直接贴文字了，可以结合代码一起看：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>1 解析命令行参数\n\n2 setupPipes(job)\n\n2.1 设置Mapper，Partitioner，Reducer，RecordWriter，如果不是java编写的，则用PipesMapRunner，PipesPartitioner，PipesReducer，NullOutputFormat（所有输出均输出到/dev/null中）；\n\n2.2 设置map/reduce的key/value class，均为Text.class；\n\n2.3 设置RecordReader，如果不是java编写的，则用PipesNonJavaInputFormat；\n\n2.4 获得运行程序，debug脚本以及缓存文件；\n\n3 JobClient.submitJob(job);\n         </td>       </tr>     </tbody></table> </p>  \n\nJobClient提交任务和非Pipes编程提交过程一致，进行Task调度分配之后，就会在分配的TaskTracker上开启JVM进程，运行Runner。这里解析一下PipesMapRunner的运行机制：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>1 创建Application\n\n1.1 创建ServerSocket\n\n1.2 设置环境（临时文件位置、命令端口等）\n\n1.3 获得执行文件，并设置执行权限（chmod +x）\n\n1.4 执行任务，通过java.lang.ProcessBuilder\n\n1.5 创建任务交互代理，DownwardProcotol对象。\n\n1.5.1 创建接收交互代理，UplinkReaderThread对象\n\n1.5.2 循环接受客户端的请求\n\n1.6 downlink.start()，发送消息，客户端可以开始运行\n\n2 如果不是Java编写的RecordReader，直接发送一个InputSplit（注：只是Split的信息，不包括文件数据）给客户端；反之，发送InputSplit之后，再循环读取split，将record格式化之后，将KVP发给客户端。\n         </td>       </tr>     </tbody></table> </p>  \n\nPipesReducer与PipesMapRunner运行机制一致，见下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>1 创建Application，与Map一致；\n\n2 向客户端发送key，之后循环发送value。\n         </td>       </tr>     </tbody></table> </p>  \n\n以上是Hadoop端的运行机制，C++端的与Java的也基本一致，源文件在$HADOOP_HOME/src/c++/pipes/impl/HadoopPipes.cc\n\n在组件运行时，会用ProcessBuilder运行C++可执行文件，可执行文件的main程序基本上都是这样写的： \n  <div class=\"dp-highlighter\">   <div class=\"bar\"></div>    \n\n1.  <span><span class=\"datatypes\">int</span><span> main(</span><span class=\"datatypes\">int</span><span> argc, </span><span class=\"datatypes\">char</span><span> *argv[]) {&#160;&#160; </span></span>2.  <span>&#160; </span><span class=\"keyword\">return</span><span> HadoopPipes::runTask(HadoopPipes::TemplateFactory&lt;WordCountMap,&#160;&#160;&#160; </span></span>3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; WordCountReduce&gt;());&#160;&#160; </span>4.  <span>}&#160;&#160; </span> </div>    \n\n调用了HadoopUtils::runTask(factory)方法，运行机制如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>1 创建运行环境；\n\n2 获得socket端口，如果有端口，则创建socket，并获得其输入输出流。如果没有端口，则获得文件输出输入流；\n\n3 创建ping线程，该线程每隔5s发送一次心跳信息；\n\n4 等待接受任务；\n\n5 循环获得任务消息，直到结束（done）；\n\n6 通知Hadoop完成任务，关闭流\n         </td>       </tr>     </tbody></table> </p>  \n\n**4****、Hadoop Pipes****浅析**\n\nHadoop Pipes采用类RPC机制，封装了Hadoop端与C++端的调用接口。Hadoop调用C++的协议为DownwardProtocol，C++调用Hadoop的为UpwardProtocol。同时也封装了传输数据序列化的接口（SerialUtils.cc），代码结构十分清晰。\n\n但是实际使用中也有一定缺陷，调试起来十分麻烦。C++端挂了之后，Hadoop也就接受不到的心跳消息，所以错误一律为：Pipes Broken。Apache的维基上有一个条目：[howToDebugMapReducePrograms](http://wiki.apache.org/hadoop/HowToDebugMapReducePrograms)，改天得好好研究一下。\n\n&#160;\n\n  > **参考资料：**\n> \n> [董的博客](http://dongxicheng.org/mapreduce/hadoop-pipes-architecture/)\n> \n> Hadoop源码","slug":"hadoop-pipes-src","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg623g0074sb8f021yhjoc"},{"title":"Hadoop源码 - ipc.Server","id":"387","date":"2012-02-27T04:57:25.000Z","_content":"\n**1****、前言**\n\n昨天分析了ipc包下的RPC、Client类，今天来分析下ipc.Server。Server类因为是Hadoop自己使用，所以代码结构以及流程都很清晰，可以清楚的看到实例化、停止、运行等过程。\n\n<!--more-->\n\n**2****、Server类结构**\n\n上面是Server的五个内部类，分别介绍一下：\n\n**1****）Call**\n\n用以存储客户端发来的请求，这个请求会放入一个BlockQueue中；\n\n**2****）Listener**\n\n监听类，用以监听客户端发来的请求。同时Listener下面还有一个静态类，Listener.Reader，当监听器监听到用户请求，便用让Reader读取用户请求。\n\n**3****）Responder**\n\n响应RPC请求类，请求处理完毕，由Responder发送给请求客户端。\n\n**4****）Connection**\n\n连接类，真正的客户端请求读取逻辑在这个类中。\n\n**5****）Handler**\n\n请求（blockQueueCall）处理类，会循环阻塞读取callQueue中的call对象，并对其进行操作。\n\n**3****、Server初始化**\n\n第一篇[博客](http://www.hongweiyi.com/2012/02/hadoop-ipc-rpc/)说了，Server的初始化入口在RPC.getServer中，getServer其实是调用的RPC.Server静态类中的构造方法，我们看看Namenode创建RPCServer的方法和RPC.Server构造方法代码：     <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">private</span><span>&#160;</span><span class=\"keyword\">void</span><span> initialize(Configuration conf) </span><span class=\"keyword\">throws</span><span> IOException {&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160; …&#160;&#160; </span>\n3.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.serviceRpcServer = RPC.getServer(</span><span class=\"keyword\">this</span><span>, dnSocketAddr.getHostName(),&#160;&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; dnSocketAddr.getPort(), serviceHandlerCount,&#160;&#160; </span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">false</span><span>, conf, namesystem.getDelegationTokenSecretManager());&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.serviceRpcServer.start(); </span><span class=\"comment\">// 运行服务器 </span><span>&#160; </span></span>\n7.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">public</span><span> Server(Object instance, Configuration conf, String bindAddress,&#160; </span><span class=\"keyword\">int</span><span> port,&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> numHandlers, </span><span class=\"keyword\">boolean</span><span> verbose,&#160;&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; SecretManager&lt;? </span><span class=\"keyword\">extends</span><span> TokenIdentifier&gt; secretManager)&#160;&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throws</span><span> IOException {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">super</span><span>(bindAddress, port, Invocation.</span><span class=\"keyword\">class</span><span>, numHandlers, conf,&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; classNameBase(instance.getClass().getName()), secretManager);&#160;&#160; </span>\n7.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.instance = instance;&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.verbose = verbose;&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160; }&#160;&#160; </span>           </div>            <p>\n         </td>       </tr>     </tbody></table> </p>  \n\n该方法调用了父类的构造方法，如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">protected</span><span> Server(String bindAddress, </span><span class=\"keyword\">int</span><span> port,&#160;&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; Class&lt;? </span><span class=\"keyword\">extends</span><span> Writable&gt; paramClass, </span><span class=\"keyword\">int</span><span> handlerCount,&#160;&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; Configuration conf, String serverName, SecretManager&lt;? </span><span class=\"keyword\">extends</span><span> TokenIdentifier&gt; secretManager)&#160;&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">throws</span><span> IOException {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.bindAddress = bindAddress;&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.conf = conf;&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.port = port;&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.paramClass = paramClass;&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.handlerCount = handlerCount;&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.socketSendBufferSize = </span><span class=\"number\">0</span><span>;&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.maxQueueSize = handlerCount * conf.getInt(&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; IPC_SERVER_HANDLER_QUEUE_SIZE_KEY,&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; IPC_SERVER_HANDLER_QUEUE_SIZE_DEFAULT);&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.maxRespSize = conf.getInt(IPC_SERVER_RPC_MAX_RESPONSE_SIZE_KEY,&#160;&#160; </span></span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; IPC_SERVER_RPC_MAX_RESPONSE_SIZE_DEFAULT);&#160;&#160; </span>\n16.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.readThreads = conf.getInt(&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; IPC_SERVER_RPC_READ_THREADS_KEY,&#160;&#160; </span>\n18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; IPC_SERVER_RPC_READ_THREADS_DEFAULT);&#160;&#160; </span>\n19.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.callQueue&#160; = </span><span class=\"keyword\">new</span><span> LinkedBlockingQueue&lt;Call&gt;(maxQueueSize);&#160;&#160;&#160; </span></span>\n20.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.maxIdleTime = </span><span class=\"number\">2</span><span>*conf.getInt(</span><span class=\"string\">&quot;ipc.client.connection.maxidletime&quot;</span><span>, </span><span class=\"number\">1000</span><span>);&#160;&#160; </span></span>\n21.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.maxConnectionsToNuke = conf.getInt(</span><span class=\"string\">&quot;ipc.client.kill.max&quot;</span><span>, </span><span class=\"number\">10</span><span>);&#160;&#160; </span></span>\n22.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.thresholdIdleConnections = conf.getInt(</span><span class=\"string\">&quot;ipc.client.idlethreshold&quot;</span><span>, </span><span class=\"number\">4000</span><span>);&#160;&#160; </span></span>\n23.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.secretManager = (SecretManager&lt;TokenIdentifier&gt;) secretManager;&#160;&#160; </span></span>\n24.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.authorize =&#160;&#160;&#160; </span></span>\n25.  <span>&#160;&#160;&#160;&#160;&#160; conf.getBoolean(HADOOP_SECURITY_AUTHORIZATION, </span><span class=\"keyword\">false</span><span>);&#160;&#160; </span></span>\n26.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.isSecurityEnabled = UserGroupInformation.isSecurityEnabled();&#160;&#160; </span></span>\n27.  <span>&#160;&#160;&#160;&#160;&#160;&#160; </span>\n28.  <span>&#160;&#160;&#160; </span><span class=\"comment\">// Start the listener here and let it bind to the port </span><span>&#160; </span></span>\n29.  <span>&#160;&#160;&#160; listener = </span><span class=\"keyword\">new</span><span> Listener();&#160;&#160; </span></span>\n30.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.port = listener.getAddress().getPort();&#160;&#160;&#160;&#160;&#160;&#160; </span></span>\n31.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.rpcMetrics = RpcInstrumentation.create(serverName, </span><span class=\"keyword\">this</span><span>.port);&#160;&#160; </span></span>\n32.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.tcpNoDelay = conf.getBoolean(</span><span class=\"string\">&quot;ipc.server.tcpnodelay&quot;</span><span>, </span><span class=\"keyword\">false</span><span>);&#160;&#160; </span></span>\n33.  <span>&#160; </span>\n34.  <span>&#160;&#160;&#160; </span><span class=\"comment\">// Create the responder here </span><span>&#160; </span></span>\n35.  <span>&#160;&#160;&#160; responder = </span><span class=\"keyword\">new</span><span> Responder();&#160;&#160; </span></span>\n36.  <span>&#160;&#160;&#160;&#160;&#160;&#160; </span>\n37.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (isSecurityEnabled) {&#160;&#160; </span></span>\n38.  <span>&#160;&#160;&#160;&#160;&#160; SaslRpcServer.init(conf);&#160;&#160; </span>\n39.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n40.  <span>&#160; }&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n不难看出，父类的构造方法就初始化了一些配置和变量。\n\n**4、Server运行**\n\n在上面第一段代码中，还有一句RpcServer.start()的方法，在调用构造函数初始化一些变量之后，Server就可以正式运行起来了：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">synchronized</span><span>&#160;</span><span class=\"keyword\">void</span><span> start() {&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160; responder.start();&#160;&#160; </span>\n3.  <span>&#160;&#160;&#160; listener.start();&#160;&#160; </span>\n4.  <span>&#160;&#160;&#160; handlers = </span><span class=\"keyword\">new</span><span> Handler[handlerCount];&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160; </span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">for</span><span> (</span><span class=\"keyword\">int</span><span> i = </span><span class=\"number\">0</span><span>; i &lt; handlerCount; i++) {&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160; handlers[i] = </span><span class=\"keyword\">new</span><span> Handler(i);&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160; handlers[i].start();&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n10.  <span>&#160; }&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\nresponder、listener、handlers三个对象的线程均阻塞了，前两个阻塞在selector.select()方法上，handler阻塞在callQueue.take()方法，都在等待客户端请求。Responder设置了超时时间，为15分钟。而listener还开启了Reader线程，该线程也阻塞了。\n\n**4、Server接受请求流程**\n\n**1****）监听到请求**\n\nListener监听到请求，获得所有请求的SelectionKey，执行doAccept(key)方法，该方法将所有的连接对象放入list中，并将connection对象与key绑定，以供reader使用。初始化玩所有的conne对象之后，就可以激活Reader线程了。    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">void</span><span> doAccept(SelectionKey key) </span><span class=\"keyword\">throws</span><span> IOException,&#160; OutOfMemoryError {&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160;&#160;&#160; Connection c = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160; ServerSocketChannel server = (ServerSocketChannel) key.channel();&#160;&#160; </span>\n4.  <span>&#160;&#160;&#160;&#160;&#160; SocketChannel channel;&#160;&#160; </span>\n5.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">while</span><span> ((channel = server.accept()) != </span><span class=\"keyword\">null</span><span>) {&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; channel.configureBlocking(</span><span class=\"keyword\">false</span><span>);&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; channel.socket().setTcpNoDelay(tcpNoDelay);&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Reader reader = getReader();&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">try</span><span> {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; reader.startAdd();&#160; </span><span class=\"comment\">// 激活readSelector，设置adding为true </span><span>&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; SelectionKey readKey = reader.registerChannel(channel);&#160;&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; c = </span><span class=\"keyword\">new</span><span> Connection(readKey, channel, System.currentTimeMillis());&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; readKey.attach(c);&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">synchronized</span><span> (connectionList) {&#160;&#160; </span></span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; connectionList.add(numConnections, c);&#160;&#160; </span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; numConnections++;&#160;&#160; </span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n19.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">finally</span><span> {&#160;&#160; </span></span>\n20.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; reader.finishAdd(); </span><span class=\"comment\">// add完毕，设置adding为false，Reader开始工作 </span><span>&#160; </span></span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n22.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n23.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n**2****）接收请求**\n\nReader的run方法和Listener基本一致，也是获得所有的SelectionKey，再执行doRead(key)方法。该方法获得key中绑定的connection，并执行conection的readAndProcess()方法：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">void</span><span> doRead(SelectionKey key) </span><span class=\"keyword\">throws</span><span> InterruptedException {&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> count = </span><span class=\"number\">0</span><span>;&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160; Connection c = (Connection)key.attachment(); </span><span class=\"comment\">// 获得连接对象 </span><span>&#160; </span></span>\n4.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (c == </span><span class=\"keyword\">null</span><span>) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>;&#160;&#160;&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n7.  <span>&#160;&#160;&#160;&#160;&#160; c.setLastContact(System.currentTimeMillis());&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">try</span><span> {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; count = c.readAndProcess(); </span><span class=\"comment\">// 接受并处理请求 </span><span>&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">catch</span><span> (InterruptedException ieo) {&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (count &lt; </span><span class=\"number\">0</span><span>) {&#160;&#160; </span></span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; closeConnection(c);&#160;&#160; </span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; c = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n19.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n20.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; c.setLastContact(System.currentTimeMillis());&#160;&#160; </span>\n21.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n22.  <span>&#160;&#160;&#160; }&#160;&#160; </span>           </div>         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">int</span><span> readAndProcess() </span><span class=\"keyword\">throws</span><span> IOException, InterruptedException {&#160;&#160; </span></span>\n2.  <span></span><span class=\"comment\">// 一次最多读取一次RPC请求，如果头没读完，继续迭代直到 </span><span>&#160; </span></span>\n3.  <span></span><span class=\"comment\">// 读完所有请求数据&#160;&#160; </span><span>&#160; </span></span>\n4.  <span></span><span class=\"keyword\">while</span><span> (</span><span class=\"keyword\">true</span><span>) {&#160;&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> count = -</span><span class=\"number\">1</span><span>;&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (dataLengthBuffer.remaining() &gt; </span><span class=\"number\">0</span><span>) {&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; count = channelRead(channel, dataLengthBuffer);&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (!rpcHeaderRead) {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">//读取请求头. </span><span>&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (rpcHeaderBuffer == </span><span class=\"keyword\">null</span><span>) {&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; rpcHeaderBuffer = ByteBuffer.allocate(</span><span class=\"number\">2</span><span>);&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; count = channelRead(channel, rpcHeaderBuffer);&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (count &lt; </span><span class=\"number\">0</span><span> || rpcHeaderBuffer.remaining() &gt; </span><span class=\"number\">0</span><span>) {&#160;&#160; </span></span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> count;&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 读取请求版本号 </span><span>&#160; </span></span>\n19.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> version = rpcHeaderBuffer.get(</span><span class=\"number\">0</span><span>);&#160;&#160; </span></span>\n20.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">byte</span><span>[] method = </span><span class=\"keyword\">new</span><span>&#160;</span><span class=\"keyword\">byte</span><span>[] {rpcHeaderBuffer.get(</span><span class=\"number\">1</span><span>)};&#160;&#160; </span></span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; authMethod = AuthMethod.read(</span><span class=\"keyword\">new</span><span> DataInputStream(&#160;&#160; </span></span>\n22.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">new</span><span> ByteArrayInputStream(method)));&#160;&#160; </span></span>\n23.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; dataLengthBuffer.flip();&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n24.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n25.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; dataLengthBuffer.clear();&#160;&#160; </span>\n26.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n27.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n28.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; rpcHeaderBuffer = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>\n29.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; rpcHeaderRead = </span><span class=\"keyword\">true</span><span>;&#160;&#160; </span></span>\n30.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">continue</span><span>;&#160;&#160; </span></span>\n31.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160;&#160; </span>\n32.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n33.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; data = ByteBuffer.allocate(dataLength);&#160;&#160; </span>\n34.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n35.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n36.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 读取请求 </span><span>&#160; </span></span>\n37.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; count = channelRead(channel, data);&#160;&#160; </span>\n38.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n39.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (data.remaining() == </span><span class=\"number\">0</span><span>) {&#160;&#160; </span></span>\n40.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n41.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (useSasl) {&#160;&#160; </span></span>\n42.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; saslReadAndProcess(data.array());&#160;&#160; </span>\n43.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n44.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 执行RPC请求，先解析header请求，下次循环解析param请求 </span><span>&#160; </span></span>\n45.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; processOneRpc(data.array());&#160;&#160; </span>\n46.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n47.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n48.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160;&#160; </span>\n49.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> count;&#160;&#160; </span></span>\n50.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n51.  <span>&#160;&#160;&#160; }&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n**3****）获得call请求**\n\n在Connection中解析param请求中，解析了请求数据，并构造Call对象，将其加入callQueue。    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">private</span><span>&#160;</span><span class=\"keyword\">void</span><span> processData(</span><span class=\"keyword\">byte</span><span>[] buf) </span><span class=\"keyword\">throws</span><span>&#160; IOException, InterruptedException {&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160;&#160;&#160; DataInputStream dis =&#160;&#160; </span>\n3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">new</span><span> DataInputStream(</span><span class=\"keyword\">new</span><span> ByteArrayInputStream(buf));&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> id = dis.readInt();&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 读取请求id </span><span>&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n6.  <span>&#160; </span>\n7.  <span>&#160;&#160;&#160;&#160;&#160; Writable param = ReflectionUtils.newInstance(paramClass, conf);</span><span class=\"comment\">// 获取参数，paramClass是参数的实体类，在构造Server对象的时候传入 </span><span>&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160; param.readFields(dis);&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n10.  <span>&#160;&#160;&#160;&#160;&#160; Call call = </span><span class=\"keyword\">new</span><span> Call(id, param, </span><span class=\"keyword\">this</span><span>);&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160; callQueue.put(call);&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 添加进阻塞队列，不过队列有max限制，有可能也会阻塞 </span><span>&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160; incRpcCount();&#160;&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160; }&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n**4****）处理call对象**\n\nConnection给callQueue添加了call对象，阻塞的Handler可以继续运行了，拿出一个call对象，并调用RPC.Call方法    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"comment\">// 关键代码 </span><span>&#160; </span></span>\n2.  <span></span><span class=\"keyword\">while</span><span> (running) {&#160;&#160; </span></span>\n3.  <span></span><span class=\"keyword\">final</span><span> Call call = callQueue.take(); </span><span class=\"comment\">// 弹出call对象 </span><span>&#160; </span></span>\n4.  <span>CurCall.set(call);&#160;&#160; </span>\n5.  <span>&#160;&#160;&#160;&#160; value = call(call.connection.protocol, call.param,&#160;&#160;&#160; </span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; call.timestamp); </span><span class=\"comment\">// 调用RPC.Server中的call </span><span>&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160; CurCall.set(</span><span class=\"keyword\">null</span><span>);&#160;&#160; </span></span>\n8.  <span>&#160; </span>\n9.  <span></span><span class=\"keyword\">synchronized</span><span> (call.connection.responseQueue) {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; setupResponse(buf, call,&#160;&#160;&#160; </span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; (error == </span><span class=\"keyword\">null</span><span>) ? Status.SUCCESS : Status.ERROR,&#160;&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; value, errorClass, error);&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; responder.doRespond(call);&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n16.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n**5）响应请求**\n\n上面代码中的setupResponse将call的id和状态发送回去，再设置了call中的response:ByteBuffer，之后就开始responder.doRespond(call)了，processResponse以及Responder.run()没太弄明白，就先不说了。    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">void</span><span> doRespond(Call call) </span><span class=\"keyword\">throws</span><span> IOException {&#160;&#160; </span></span>2.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">synchronized</span><span> (call.connection.responseQueue) {&#160;&#160; </span></span>3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 这行没懂 </span><span>&#160; </span></span>4.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; call.connection.responseQueue.addLast(call);&#160;&#160; </span>5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (call.connection.responseQueue.size() == </span><span class=\"number\">1</span><span>) {&#160;&#160; </span></span>6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 返回响应结果，并激活writeSelector </span><span>&#160; </span></span>7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; processResponse(call.connection.responseQueue, </span><span class=\"keyword\">true</span><span>);&#160;&#160; </span></span>8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>9.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>10.  <span>&#160;&#160;&#160; }&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n**6、总结**\n\nServer用的标准的Java TCP/IP NIO通信，同时请求的超时使用基于BlockingQueue以及wait/notify机制实现。使用的模式是reactor模式，关于nio和reactor可以参考这个**[博客](http://www.cnblogs.com/ericchen/archive/2011/05/08/2036993.html)**。\n\n对于服务器端接收多个连接请求的需求，Server采用Listener来监听连接的事件，并用Listener.Reader来监听网络流读以及Responder监听写的事件，当有实际的网络流读写时间发生之后，解析了请求Call之后，添加进阻塞队列，并交由多个Handlers来处理请求。\n\n这个方法比TCP/IP BIO好处就是可接受很多的连接，而这些连接只在真实的请求时才会创建线程处理，称之为一请求一处理。但是，连接上的请求发送非常频繁时，TCP/IP NIO的方法并不会带来太大的优势。\n\n但是Hadoop实际场景中，通常是服务器端支持大量的连接数（Namenode连上几千个Datanode），但是连接发送的请求并不会太多（heartbeat、blockreport都有较长间隔）。这样就造成了Hadoop不适合实时的、多请求的运算，带来的代价是模型、实现简单，但是这也为以后的扩展埋下了祸根。\n\nP.S.: 以上分析基于稳定版0.20.203.0rc1。","source":"_posts/hadoop-ipc-server.md","raw":"title: Hadoop源码 - ipc.Server\ntags:\n  - Hadoop\n  - RPC\nid: 387\ncategories:\n  - 技术分享\ndate: 2012-02-27 12:57:25\n---\n\n**1****、前言**\n\n昨天分析了ipc包下的RPC、Client类，今天来分析下ipc.Server。Server类因为是Hadoop自己使用，所以代码结构以及流程都很清晰，可以清楚的看到实例化、停止、运行等过程。\n\n<!--more-->\n\n**2****、Server类结构**\n\n上面是Server的五个内部类，分别介绍一下：\n\n**1****）Call**\n\n用以存储客户端发来的请求，这个请求会放入一个BlockQueue中；\n\n**2****）Listener**\n\n监听类，用以监听客户端发来的请求。同时Listener下面还有一个静态类，Listener.Reader，当监听器监听到用户请求，便用让Reader读取用户请求。\n\n**3****）Responder**\n\n响应RPC请求类，请求处理完毕，由Responder发送给请求客户端。\n\n**4****）Connection**\n\n连接类，真正的客户端请求读取逻辑在这个类中。\n\n**5****）Handler**\n\n请求（blockQueueCall）处理类，会循环阻塞读取callQueue中的call对象，并对其进行操作。\n\n**3****、Server初始化**\n\n第一篇[博客](http://www.hongweiyi.com/2012/02/hadoop-ipc-rpc/)说了，Server的初始化入口在RPC.getServer中，getServer其实是调用的RPC.Server静态类中的构造方法，我们看看Namenode创建RPCServer的方法和RPC.Server构造方法代码：     <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">private</span><span>&#160;</span><span class=\"keyword\">void</span><span> initialize(Configuration conf) </span><span class=\"keyword\">throws</span><span> IOException {&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160; …&#160;&#160; </span>\n3.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.serviceRpcServer = RPC.getServer(</span><span class=\"keyword\">this</span><span>, dnSocketAddr.getHostName(),&#160;&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; dnSocketAddr.getPort(), serviceHandlerCount,&#160;&#160; </span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">false</span><span>, conf, namesystem.getDelegationTokenSecretManager());&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.serviceRpcServer.start(); </span><span class=\"comment\">// 运行服务器 </span><span>&#160; </span></span>\n7.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">public</span><span> Server(Object instance, Configuration conf, String bindAddress,&#160; </span><span class=\"keyword\">int</span><span> port,&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> numHandlers, </span><span class=\"keyword\">boolean</span><span> verbose,&#160;&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; SecretManager&lt;? </span><span class=\"keyword\">extends</span><span> TokenIdentifier&gt; secretManager)&#160;&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throws</span><span> IOException {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">super</span><span>(bindAddress, port, Invocation.</span><span class=\"keyword\">class</span><span>, numHandlers, conf,&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; classNameBase(instance.getClass().getName()), secretManager);&#160;&#160; </span>\n7.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.instance = instance;&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.verbose = verbose;&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160; }&#160;&#160; </span>           </div>            <p>\n         </td>       </tr>     </tbody></table> </p>  \n\n该方法调用了父类的构造方法，如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">protected</span><span> Server(String bindAddress, </span><span class=\"keyword\">int</span><span> port,&#160;&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; Class&lt;? </span><span class=\"keyword\">extends</span><span> Writable&gt; paramClass, </span><span class=\"keyword\">int</span><span> handlerCount,&#160;&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; Configuration conf, String serverName, SecretManager&lt;? </span><span class=\"keyword\">extends</span><span> TokenIdentifier&gt; secretManager)&#160;&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">throws</span><span> IOException {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.bindAddress = bindAddress;&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.conf = conf;&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.port = port;&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.paramClass = paramClass;&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.handlerCount = handlerCount;&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.socketSendBufferSize = </span><span class=\"number\">0</span><span>;&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.maxQueueSize = handlerCount * conf.getInt(&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; IPC_SERVER_HANDLER_QUEUE_SIZE_KEY,&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; IPC_SERVER_HANDLER_QUEUE_SIZE_DEFAULT);&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.maxRespSize = conf.getInt(IPC_SERVER_RPC_MAX_RESPONSE_SIZE_KEY,&#160;&#160; </span></span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; IPC_SERVER_RPC_MAX_RESPONSE_SIZE_DEFAULT);&#160;&#160; </span>\n16.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.readThreads = conf.getInt(&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; IPC_SERVER_RPC_READ_THREADS_KEY,&#160;&#160; </span>\n18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; IPC_SERVER_RPC_READ_THREADS_DEFAULT);&#160;&#160; </span>\n19.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.callQueue&#160; = </span><span class=\"keyword\">new</span><span> LinkedBlockingQueue&lt;Call&gt;(maxQueueSize);&#160;&#160;&#160; </span></span>\n20.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.maxIdleTime = </span><span class=\"number\">2</span><span>*conf.getInt(</span><span class=\"string\">&quot;ipc.client.connection.maxidletime&quot;</span><span>, </span><span class=\"number\">1000</span><span>);&#160;&#160; </span></span>\n21.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.maxConnectionsToNuke = conf.getInt(</span><span class=\"string\">&quot;ipc.client.kill.max&quot;</span><span>, </span><span class=\"number\">10</span><span>);&#160;&#160; </span></span>\n22.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.thresholdIdleConnections = conf.getInt(</span><span class=\"string\">&quot;ipc.client.idlethreshold&quot;</span><span>, </span><span class=\"number\">4000</span><span>);&#160;&#160; </span></span>\n23.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.secretManager = (SecretManager&lt;TokenIdentifier&gt;) secretManager;&#160;&#160; </span></span>\n24.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.authorize =&#160;&#160;&#160; </span></span>\n25.  <span>&#160;&#160;&#160;&#160;&#160; conf.getBoolean(HADOOP_SECURITY_AUTHORIZATION, </span><span class=\"keyword\">false</span><span>);&#160;&#160; </span></span>\n26.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.isSecurityEnabled = UserGroupInformation.isSecurityEnabled();&#160;&#160; </span></span>\n27.  <span>&#160;&#160;&#160;&#160;&#160;&#160; </span>\n28.  <span>&#160;&#160;&#160; </span><span class=\"comment\">// Start the listener here and let it bind to the port </span><span>&#160; </span></span>\n29.  <span>&#160;&#160;&#160; listener = </span><span class=\"keyword\">new</span><span> Listener();&#160;&#160; </span></span>\n30.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.port = listener.getAddress().getPort();&#160;&#160;&#160;&#160;&#160;&#160; </span></span>\n31.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.rpcMetrics = RpcInstrumentation.create(serverName, </span><span class=\"keyword\">this</span><span>.port);&#160;&#160; </span></span>\n32.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.tcpNoDelay = conf.getBoolean(</span><span class=\"string\">&quot;ipc.server.tcpnodelay&quot;</span><span>, </span><span class=\"keyword\">false</span><span>);&#160;&#160; </span></span>\n33.  <span>&#160; </span>\n34.  <span>&#160;&#160;&#160; </span><span class=\"comment\">// Create the responder here </span><span>&#160; </span></span>\n35.  <span>&#160;&#160;&#160; responder = </span><span class=\"keyword\">new</span><span> Responder();&#160;&#160; </span></span>\n36.  <span>&#160;&#160;&#160;&#160;&#160;&#160; </span>\n37.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (isSecurityEnabled) {&#160;&#160; </span></span>\n38.  <span>&#160;&#160;&#160;&#160;&#160; SaslRpcServer.init(conf);&#160;&#160; </span>\n39.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n40.  <span>&#160; }&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n不难看出，父类的构造方法就初始化了一些配置和变量。\n\n**4、Server运行**\n\n在上面第一段代码中，还有一句RpcServer.start()的方法，在调用构造函数初始化一些变量之后，Server就可以正式运行起来了：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">synchronized</span><span>&#160;</span><span class=\"keyword\">void</span><span> start() {&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160; responder.start();&#160;&#160; </span>\n3.  <span>&#160;&#160;&#160; listener.start();&#160;&#160; </span>\n4.  <span>&#160;&#160;&#160; handlers = </span><span class=\"keyword\">new</span><span> Handler[handlerCount];&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160; </span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">for</span><span> (</span><span class=\"keyword\">int</span><span> i = </span><span class=\"number\">0</span><span>; i &lt; handlerCount; i++) {&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160; handlers[i] = </span><span class=\"keyword\">new</span><span> Handler(i);&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160; handlers[i].start();&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n10.  <span>&#160; }&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\nresponder、listener、handlers三个对象的线程均阻塞了，前两个阻塞在selector.select()方法上，handler阻塞在callQueue.take()方法，都在等待客户端请求。Responder设置了超时时间，为15分钟。而listener还开启了Reader线程，该线程也阻塞了。\n\n**4、Server接受请求流程**\n\n**1****）监听到请求**\n\nListener监听到请求，获得所有请求的SelectionKey，执行doAccept(key)方法，该方法将所有的连接对象放入list中，并将connection对象与key绑定，以供reader使用。初始化玩所有的conne对象之后，就可以激活Reader线程了。    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">void</span><span> doAccept(SelectionKey key) </span><span class=\"keyword\">throws</span><span> IOException,&#160; OutOfMemoryError {&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160;&#160;&#160; Connection c = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160; ServerSocketChannel server = (ServerSocketChannel) key.channel();&#160;&#160; </span>\n4.  <span>&#160;&#160;&#160;&#160;&#160; SocketChannel channel;&#160;&#160; </span>\n5.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">while</span><span> ((channel = server.accept()) != </span><span class=\"keyword\">null</span><span>) {&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; channel.configureBlocking(</span><span class=\"keyword\">false</span><span>);&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; channel.socket().setTcpNoDelay(tcpNoDelay);&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Reader reader = getReader();&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">try</span><span> {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; reader.startAdd();&#160; </span><span class=\"comment\">// 激活readSelector，设置adding为true </span><span>&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; SelectionKey readKey = reader.registerChannel(channel);&#160;&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; c = </span><span class=\"keyword\">new</span><span> Connection(readKey, channel, System.currentTimeMillis());&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; readKey.attach(c);&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">synchronized</span><span> (connectionList) {&#160;&#160; </span></span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; connectionList.add(numConnections, c);&#160;&#160; </span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; numConnections++;&#160;&#160; </span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n19.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">finally</span><span> {&#160;&#160; </span></span>\n20.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; reader.finishAdd(); </span><span class=\"comment\">// add完毕，设置adding为false，Reader开始工作 </span><span>&#160; </span></span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n22.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n23.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n**2****）接收请求**\n\nReader的run方法和Listener基本一致，也是获得所有的SelectionKey，再执行doRead(key)方法。该方法获得key中绑定的connection，并执行conection的readAndProcess()方法：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">void</span><span> doRead(SelectionKey key) </span><span class=\"keyword\">throws</span><span> InterruptedException {&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> count = </span><span class=\"number\">0</span><span>;&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160; Connection c = (Connection)key.attachment(); </span><span class=\"comment\">// 获得连接对象 </span><span>&#160; </span></span>\n4.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (c == </span><span class=\"keyword\">null</span><span>) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>;&#160;&#160;&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n7.  <span>&#160;&#160;&#160;&#160;&#160; c.setLastContact(System.currentTimeMillis());&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">try</span><span> {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; count = c.readAndProcess(); </span><span class=\"comment\">// 接受并处理请求 </span><span>&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">catch</span><span> (InterruptedException ieo) {&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (count &lt; </span><span class=\"number\">0</span><span>) {&#160;&#160; </span></span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; closeConnection(c);&#160;&#160; </span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; c = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n19.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n20.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; c.setLastContact(System.currentTimeMillis());&#160;&#160; </span>\n21.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n22.  <span>&#160;&#160;&#160; }&#160;&#160; </span>           </div>         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">int</span><span> readAndProcess() </span><span class=\"keyword\">throws</span><span> IOException, InterruptedException {&#160;&#160; </span></span>\n2.  <span></span><span class=\"comment\">// 一次最多读取一次RPC请求，如果头没读完，继续迭代直到 </span><span>&#160; </span></span>\n3.  <span></span><span class=\"comment\">// 读完所有请求数据&#160;&#160; </span><span>&#160; </span></span>\n4.  <span></span><span class=\"keyword\">while</span><span> (</span><span class=\"keyword\">true</span><span>) {&#160;&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> count = -</span><span class=\"number\">1</span><span>;&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (dataLengthBuffer.remaining() &gt; </span><span class=\"number\">0</span><span>) {&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; count = channelRead(channel, dataLengthBuffer);&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (!rpcHeaderRead) {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">//读取请求头. </span><span>&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (rpcHeaderBuffer == </span><span class=\"keyword\">null</span><span>) {&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; rpcHeaderBuffer = ByteBuffer.allocate(</span><span class=\"number\">2</span><span>);&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; count = channelRead(channel, rpcHeaderBuffer);&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (count &lt; </span><span class=\"number\">0</span><span> || rpcHeaderBuffer.remaining() &gt; </span><span class=\"number\">0</span><span>) {&#160;&#160; </span></span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> count;&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 读取请求版本号 </span><span>&#160; </span></span>\n19.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> version = rpcHeaderBuffer.get(</span><span class=\"number\">0</span><span>);&#160;&#160; </span></span>\n20.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">byte</span><span>[] method = </span><span class=\"keyword\">new</span><span>&#160;</span><span class=\"keyword\">byte</span><span>[] {rpcHeaderBuffer.get(</span><span class=\"number\">1</span><span>)};&#160;&#160; </span></span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; authMethod = AuthMethod.read(</span><span class=\"keyword\">new</span><span> DataInputStream(&#160;&#160; </span></span>\n22.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">new</span><span> ByteArrayInputStream(method)));&#160;&#160; </span></span>\n23.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; dataLengthBuffer.flip();&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n24.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n25.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; dataLengthBuffer.clear();&#160;&#160; </span>\n26.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n27.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n28.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; rpcHeaderBuffer = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>\n29.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; rpcHeaderRead = </span><span class=\"keyword\">true</span><span>;&#160;&#160; </span></span>\n30.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">continue</span><span>;&#160;&#160; </span></span>\n31.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160;&#160; </span>\n32.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n33.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; data = ByteBuffer.allocate(dataLength);&#160;&#160; </span>\n34.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n35.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n36.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 读取请求 </span><span>&#160; </span></span>\n37.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; count = channelRead(channel, data);&#160;&#160; </span>\n38.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n39.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (data.remaining() == </span><span class=\"number\">0</span><span>) {&#160;&#160; </span></span>\n40.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n41.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (useSasl) {&#160;&#160; </span></span>\n42.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; saslReadAndProcess(data.array());&#160;&#160; </span>\n43.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n44.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 执行RPC请求，先解析header请求，下次循环解析param请求 </span><span>&#160; </span></span>\n45.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; processOneRpc(data.array());&#160;&#160; </span>\n46.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n47.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n48.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160;&#160; </span>\n49.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> count;&#160;&#160; </span></span>\n50.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n51.  <span>&#160;&#160;&#160; }&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n**3****）获得call请求**\n\n在Connection中解析param请求中，解析了请求数据，并构造Call对象，将其加入callQueue。    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">private</span><span>&#160;</span><span class=\"keyword\">void</span><span> processData(</span><span class=\"keyword\">byte</span><span>[] buf) </span><span class=\"keyword\">throws</span><span>&#160; IOException, InterruptedException {&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160;&#160;&#160; DataInputStream dis =&#160;&#160; </span>\n3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">new</span><span> DataInputStream(</span><span class=\"keyword\">new</span><span> ByteArrayInputStream(buf));&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> id = dis.readInt();&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 读取请求id </span><span>&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n6.  <span>&#160; </span>\n7.  <span>&#160;&#160;&#160;&#160;&#160; Writable param = ReflectionUtils.newInstance(paramClass, conf);</span><span class=\"comment\">// 获取参数，paramClass是参数的实体类，在构造Server对象的时候传入 </span><span>&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160; param.readFields(dis);&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n10.  <span>&#160;&#160;&#160;&#160;&#160; Call call = </span><span class=\"keyword\">new</span><span> Call(id, param, </span><span class=\"keyword\">this</span><span>);&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160; callQueue.put(call);&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 添加进阻塞队列，不过队列有max限制，有可能也会阻塞 </span><span>&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160; incRpcCount();&#160;&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160; }&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n**4****）处理call对象**\n\nConnection给callQueue添加了call对象，阻塞的Handler可以继续运行了，拿出一个call对象，并调用RPC.Call方法    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"comment\">// 关键代码 </span><span>&#160; </span></span>\n2.  <span></span><span class=\"keyword\">while</span><span> (running) {&#160;&#160; </span></span>\n3.  <span></span><span class=\"keyword\">final</span><span> Call call = callQueue.take(); </span><span class=\"comment\">// 弹出call对象 </span><span>&#160; </span></span>\n4.  <span>CurCall.set(call);&#160;&#160; </span>\n5.  <span>&#160;&#160;&#160;&#160; value = call(call.connection.protocol, call.param,&#160;&#160;&#160; </span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; call.timestamp); </span><span class=\"comment\">// 调用RPC.Server中的call </span><span>&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160; CurCall.set(</span><span class=\"keyword\">null</span><span>);&#160;&#160; </span></span>\n8.  <span>&#160; </span>\n9.  <span></span><span class=\"keyword\">synchronized</span><span> (call.connection.responseQueue) {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; setupResponse(buf, call,&#160;&#160;&#160; </span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; (error == </span><span class=\"keyword\">null</span><span>) ? Status.SUCCESS : Status.ERROR,&#160;&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; value, errorClass, error);&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; responder.doRespond(call);&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n16.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n**5）响应请求**\n\n上面代码中的setupResponse将call的id和状态发送回去，再设置了call中的response:ByteBuffer，之后就开始responder.doRespond(call)了，processResponse以及Responder.run()没太弄明白，就先不说了。    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">void</span><span> doRespond(Call call) </span><span class=\"keyword\">throws</span><span> IOException {&#160;&#160; </span></span>2.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">synchronized</span><span> (call.connection.responseQueue) {&#160;&#160; </span></span>3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 这行没懂 </span><span>&#160; </span></span>4.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; call.connection.responseQueue.addLast(call);&#160;&#160; </span>5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (call.connection.responseQueue.size() == </span><span class=\"number\">1</span><span>) {&#160;&#160; </span></span>6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 返回响应结果，并激活writeSelector </span><span>&#160; </span></span>7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; processResponse(call.connection.responseQueue, </span><span class=\"keyword\">true</span><span>);&#160;&#160; </span></span>8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>9.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>10.  <span>&#160;&#160;&#160; }&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n**6、总结**\n\nServer用的标准的Java TCP/IP NIO通信，同时请求的超时使用基于BlockingQueue以及wait/notify机制实现。使用的模式是reactor模式，关于nio和reactor可以参考这个**[博客](http://www.cnblogs.com/ericchen/archive/2011/05/08/2036993.html)**。\n\n对于服务器端接收多个连接请求的需求，Server采用Listener来监听连接的事件，并用Listener.Reader来监听网络流读以及Responder监听写的事件，当有实际的网络流读写时间发生之后，解析了请求Call之后，添加进阻塞队列，并交由多个Handlers来处理请求。\n\n这个方法比TCP/IP BIO好处就是可接受很多的连接，而这些连接只在真实的请求时才会创建线程处理，称之为一请求一处理。但是，连接上的请求发送非常频繁时，TCP/IP NIO的方法并不会带来太大的优势。\n\n但是Hadoop实际场景中，通常是服务器端支持大量的连接数（Namenode连上几千个Datanode），但是连接发送的请求并不会太多（heartbeat、blockreport都有较长间隔）。这样就造成了Hadoop不适合实时的、多请求的运算，带来的代价是模型、实现简单，但是这也为以后的扩展埋下了祸根。\n\nP.S.: 以上分析基于稳定版0.20.203.0rc1。","slug":"hadoop-ipc-server","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg623i0079sb8fnzgje88k"},{"title":"Hadoop源码 - ipc.RPC","id":"380","date":"2012-02-25T15:00:23.000Z","_content":"\n**1、前言**\n\nHadoop是典型的单元数据服务器模型，它将控制流与数据流分离开来，同时两种流的通信机制也不一样，分别为RPC和流式通信，这篇博客主要介绍Hadoop的RPC流程……。关于RPC的简介可以参考：[百度百科](http://baike.baidu.com/view/32726.htm)。\n  <!--more-->\n\nHadoop的RPC主要是通过Java的动态代理（Dynamic Proxy）与反射（Reflect）实现，源代码在org.apache.hadoop.ipc下，有以下几个主要类：\n\nClient：RPC服务的客户端\n\nRPC：实现了一个简单的RPC模型\n\nServer：服务端的抽象类\n\nRPC.Server：服务端的具体类\n\nVersionedProtocol：所有的使用RPC服务的类都要实现该接口，在创建代理时，用来判断代理对象是否创建正确。\n\n**2、通信发生在？**\n\nHadoop是master-slave模型，master只会接受请求并相应，slave在发送请求的同时，也有可能会接受其它请求，其它请求来自slave伙伴或者client。\n\nVersionedProtocol说了，所有要使用RPC服务的类都要实现该接口，我们可以来看一下有哪些接口继承了该接口。\n\n[![clip_image002](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image002_thumb3.jpg \"clip_image002\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0023.jpg)\n\n**1****）HDFS相关**\n\n**ClientDatanodeProtocol**：client与datanode交互的接口，操作不多，只有一个block恢复的方法。那么，其它数据请求的方法呢？client与datanode主要交互是通过流式的socket实现，源码在DataXceiver，在这里先不说了；\n\n**ClientProtocol**：client与Namenode交互的接口，所有控制流的请求均在这里，如：创建文件、删除文件等；\n\n**DatanodeProtocol**：Datanode与Namenode交互的接口，如心跳、blockreport等；\n\n**NamenodeProtocol**：SecondaryNode与Namenode交互的接口。\n\n**2****）Mapreduce相关**\n\n**InterDatanodeProtocol**：Datanode内部交互的接口，用来更新block的元数据；\n\n**InnerTrackerProtocol**：TaskTracker与JobTracker交互的接口，功能与DatanodeProtocol相似；\n\n**JobSubmissionProtocol**：JobClient与JobTracker交互的接口，用来提交Job、获得Job等与Job相关的操作；\n\n**TaskUmbilicalProtocol**：Task中子进程与母进程交互的接口，子进程即map、reduce等操作，母进程即TaskTracker，该接口可以回报子进程的运行状态（词汇扫盲: umbilical 脐带的, 关系亲密的） 。\n\n**3****）其它**\n\n**AdminOperationProtocol**：不用用户操作的接口，提供一些管理操作，如刷新JobTracker的node列表；\n\n**RefreshAuthorizationPolicyProtocol****，RefreshUserMappingsProtocol：**暂不明白。\n\n**3****、RPC方法**\n\nRPC提供了一个简单的RPC机制，提供以下几种静态方法：\n\n[![clip_image004](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image004_thumb2.jpg \"clip_image004\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0042.jpg)\n\n**1）***Proxy**\n\nwaitForProxy、getProxy、stopProxy均是与代理有关的方法，其中wait需要保证namenode启动正常且连接正常，主要由SecondayNode、Datanode、JobTracker使用。\n\nstop方法即停止代理。\n\nget则是一般的获取代理的方法， 创建代理实例，获得代理实例的versioncode，再与getProxy方法传入的versioncode做对比，相同返回代理，不同抛出VersionMismatch异常。\n\n**2）getServer**\n\n创建并返回一个Server实例，由TaskTracker、JobTracker、NameNode、DataNode使用。\n\n**3）call**\n\n静态方法，向一系列服务器发送一系列请求，在源码中没见到那个类使用该方法。但注释提到了：Expert，应该是给系统管理员使用的接口。\n\n**4****、RPC静态类**\n\nRPC方法仅仅提到了方法的作用，但是具体实现没说，具体实现就涉及到了RPC的静态类了，RPC类中有5个静态内部类，分别为：\n\n**RPC.ClientCache****：**用来缓存Client对象；\n\n**RPC.Invocation****：**每次RPC调用传的参数实体类，其中Invocation包括了调用方法（Method）和配置文件；\n\n**RPC.Invoker****：**具体的调用类，采用Java的动态代理机制，继承自InvocationHandler，有remoteId和client成员，id用以标识异步请求对象，client用以调用实现代码；\n\n**RPC.Server****：**org.apache.hadoop.ipc.Server的具体类，实现了抽象类的call方法，获得传入参数的call实例，再获取method方法，调用即可。用的是反射机制，反射很绝，再没使用之前，完全不知道该代码会怎么执行；\n\n**RPC. ****VersionMismatch****：**版本不匹配异常。\n\n**5、小结**\n\n以上是org.apache.hadoop.ipc.RPC类的实现分析，接下来再分析ipc包下的Server与Client类吧！","source":"_posts/hadoop-ipc-rpc.md","raw":"title: Hadoop源码 - ipc.RPC\ntags:\n  - Hadoop\n  - RPC\nid: 380\ncategories:\n  - 技术分享\ndate: 2012-02-25 23:00:23\n---\n\n**1、前言**\n\nHadoop是典型的单元数据服务器模型，它将控制流与数据流分离开来，同时两种流的通信机制也不一样，分别为RPC和流式通信，这篇博客主要介绍Hadoop的RPC流程……。关于RPC的简介可以参考：[百度百科](http://baike.baidu.com/view/32726.htm)。\n  <!--more-->\n\nHadoop的RPC主要是通过Java的动态代理（Dynamic Proxy）与反射（Reflect）实现，源代码在org.apache.hadoop.ipc下，有以下几个主要类：\n\nClient：RPC服务的客户端\n\nRPC：实现了一个简单的RPC模型\n\nServer：服务端的抽象类\n\nRPC.Server：服务端的具体类\n\nVersionedProtocol：所有的使用RPC服务的类都要实现该接口，在创建代理时，用来判断代理对象是否创建正确。\n\n**2、通信发生在？**\n\nHadoop是master-slave模型，master只会接受请求并相应，slave在发送请求的同时，也有可能会接受其它请求，其它请求来自slave伙伴或者client。\n\nVersionedProtocol说了，所有要使用RPC服务的类都要实现该接口，我们可以来看一下有哪些接口继承了该接口。\n\n[![clip_image002](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image002_thumb3.jpg \"clip_image002\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0023.jpg)\n\n**1****）HDFS相关**\n\n**ClientDatanodeProtocol**：client与datanode交互的接口，操作不多，只有一个block恢复的方法。那么，其它数据请求的方法呢？client与datanode主要交互是通过流式的socket实现，源码在DataXceiver，在这里先不说了；\n\n**ClientProtocol**：client与Namenode交互的接口，所有控制流的请求均在这里，如：创建文件、删除文件等；\n\n**DatanodeProtocol**：Datanode与Namenode交互的接口，如心跳、blockreport等；\n\n**NamenodeProtocol**：SecondaryNode与Namenode交互的接口。\n\n**2****）Mapreduce相关**\n\n**InterDatanodeProtocol**：Datanode内部交互的接口，用来更新block的元数据；\n\n**InnerTrackerProtocol**：TaskTracker与JobTracker交互的接口，功能与DatanodeProtocol相似；\n\n**JobSubmissionProtocol**：JobClient与JobTracker交互的接口，用来提交Job、获得Job等与Job相关的操作；\n\n**TaskUmbilicalProtocol**：Task中子进程与母进程交互的接口，子进程即map、reduce等操作，母进程即TaskTracker，该接口可以回报子进程的运行状态（词汇扫盲: umbilical 脐带的, 关系亲密的） 。\n\n**3****）其它**\n\n**AdminOperationProtocol**：不用用户操作的接口，提供一些管理操作，如刷新JobTracker的node列表；\n\n**RefreshAuthorizationPolicyProtocol****，RefreshUserMappingsProtocol：**暂不明白。\n\n**3****、RPC方法**\n\nRPC提供了一个简单的RPC机制，提供以下几种静态方法：\n\n[![clip_image004](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image004_thumb2.jpg \"clip_image004\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0042.jpg)\n\n**1）***Proxy**\n\nwaitForProxy、getProxy、stopProxy均是与代理有关的方法，其中wait需要保证namenode启动正常且连接正常，主要由SecondayNode、Datanode、JobTracker使用。\n\nstop方法即停止代理。\n\nget则是一般的获取代理的方法， 创建代理实例，获得代理实例的versioncode，再与getProxy方法传入的versioncode做对比，相同返回代理，不同抛出VersionMismatch异常。\n\n**2）getServer**\n\n创建并返回一个Server实例，由TaskTracker、JobTracker、NameNode、DataNode使用。\n\n**3）call**\n\n静态方法，向一系列服务器发送一系列请求，在源码中没见到那个类使用该方法。但注释提到了：Expert，应该是给系统管理员使用的接口。\n\n**4****、RPC静态类**\n\nRPC方法仅仅提到了方法的作用，但是具体实现没说，具体实现就涉及到了RPC的静态类了，RPC类中有5个静态内部类，分别为：\n\n**RPC.ClientCache****：**用来缓存Client对象；\n\n**RPC.Invocation****：**每次RPC调用传的参数实体类，其中Invocation包括了调用方法（Method）和配置文件；\n\n**RPC.Invoker****：**具体的调用类，采用Java的动态代理机制，继承自InvocationHandler，有remoteId和client成员，id用以标识异步请求对象，client用以调用实现代码；\n\n**RPC.Server****：**org.apache.hadoop.ipc.Server的具体类，实现了抽象类的call方法，获得传入参数的call实例，再获取method方法，调用即可。用的是反射机制，反射很绝，再没使用之前，完全不知道该代码会怎么执行；\n\n**RPC. ****VersionMismatch****：**版本不匹配异常。\n\n**5、小结**\n\n以上是org.apache.hadoop.ipc.RPC类的实现分析，接下来再分析ipc包下的Server与Client类吧！","slug":"hadoop-ipc-rpc","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg623k007esb8f7ggt3fom"},{"title":"Hadoop源码 - ipc.Client","id":"384","date":"2012-02-25T15:06:42.000Z","_content":"\n**1****、前言**\n\n上篇博客分析了ipc包下的RPC类，这篇博客来看看Client类吧。\n  <!--more-->\n\nHadoop的RPC机制还是挺简单的，简述如下：\n\n1）创建代理对象；\n\n2）代理对象调用相应方法（invoke()）；\n\n3）invoke调用client对象的call方法，向服务器发送请求（参数、方法）；\n\n4）再等待call方法的完成；\n\n5）返回请求结果。\n\n具体是怎么实现的，下面来看看吧。\n\n**2****、Client类分析**\n\n有了RPC大致分析，Client我就挑重要的分析了。\n\n**1）connections**\n\nRPC中就有了ClientCache类，那么client可以复用，所以一个client对象会有多个连接对象，实现中是用HashTable&lt;ConnectionId, Connection&gt;存储的连接对象。\n\n其中，ConnectionId是用来唯一标识连接的ID，主要由客户端地址、时间戳再结合一个素数生成；Connection是Client中的静态内部类，用以处理远程连接对象。\n\n**2）Call**\n\n客户端方法调用的实体类，存放了id、参数、返回值等。需要注意的是，Call类中有callComplete()方法，在一次call调用完毕之后调用，并调用notify()通知client接收完毕。\n\n**3）call(Writable param, ConnectionId remoteId)**     <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">public</span><span> Object invoke(Object proxy, Method method, Object[] args)&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throws</span><span> Throwable {&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n4.  <span>&#160; </span>\n5.  <span>&#160;&#160;&#160;&#160;&#160; ObjectWritable value = (ObjectWritable)&#160;&#160; </span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; client.call(</span><span class=\"keyword\">new</span><span> Invocation(method, args), remoteId); </span><span class=\"comment\">// 调用方法 </span><span>&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> value.get();&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160; }&#160;&#160; </span>           </div>         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"comment\">// client请求方法 </span><span>&#160; </span></span>\n2.  <span></span><span class=\"keyword\">public</span><span> Writable call(Writable param, ConnectionId remoteId)&#160;&#160;&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throws</span><span> InterruptedException, IOException {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; Call call = </span><span class=\"keyword\">new</span><span> Call(param);&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; Connection connection = getConnection(remoteId, call); </span><span class=\"comment\">// 获得连接对象 </span><span>&#160; </span></span>\n6.  <span>&#160;&#160;&#160; connection.sendParam(call);&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 发送参数 </span><span>&#160; </span></span>\n7.  <span>&#160;&#160;&#160; …&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">synchronized</span><span> (call) {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">while</span><span> (!call.done) {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">try</span><span> {&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; call.wait();&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 等待response </span><span>&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">catch</span><span> (InterruptedException ie) {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; interrupted = </span><span class=\"keyword\">true</span><span>;&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n16.  <span>&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n17.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> call.value;&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n19.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n20.  <span>&#160; }&#160;&#160; </span>           </div>         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"comment\">// Connection线程，等待服务器响应 </span><span>&#160; </span></span>\n2.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> run() {&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (LOG.isDebugEnabled())&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; LOG.debug(getName() + </span><span class=\"string\">&quot;: starting, having connections &quot;</span><span>&#160;&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; + connections.size());&#160;&#160; </span>\n6.  <span>&#160; </span>\n7.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">while</span><span> (waitForWork()) {</span><span class=\"comment\">// 等待工作，主要依据是calls是否为空 </span><span>&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; receiveResponse();&#160; </span><span class=\"comment\">// 接收响应 </span><span>&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n11.  <span>&#160;&#160;&#160;&#160;&#160; close();&#160;&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>           </div>         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">private</span><span>&#160;</span><span class=\"keyword\">void</span><span> receiveResponse() {&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n4.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">try</span><span> {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> id = in.readInt();&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// try to read an id </span><span>&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Call call = calls.get(id);&#160;&#160; </span>\n8.  <span>&#160; </span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> state = in.readInt();&#160;&#160;&#160;&#160; </span><span class=\"comment\">// read call status </span><span>&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (state == Status.SUCCESS.state) {&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; Writable value = ReflectionUtils.newInstance(valueClass, conf);&#160;&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; value.readFields(in);&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// read value </span><span>&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; call.setValue(value);&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; calls.remove(id);&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160;&#160; </span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n17.  <span>&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">catch</span><span> (IOException e) {&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; markClosed(e);&#160;&#160; </span>\n19.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n20.  <span>&#160;&#160;&#160; }&#160;&#160; </span>           </div>         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">synchronized</span><span>&#160;</span><span class=\"keyword\">void</span><span> setValue(Writable value) {&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.value = value;&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160; callComplete();&#160;&#160; </span>\n4.  <span>}&#160;&#160; </span>\n5.  <span></span><span class=\"keyword\">protected</span><span>&#160;</span><span class=\"keyword\">synchronized</span><span>&#160;</span><span class=\"keyword\">void</span><span> callComplete() {&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.done = </span><span class=\"keyword\">true</span><span>;&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160; notify();&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// notify caller </span><span>&#160; </span></span>\n8.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n该方法由invoker调用，调用过程如下：\n\nA、构建Call对象\n\nB、 用remoteId获得connection对象\n\n&#160;&#160;&#160; a) 如果connections中有remoteId，取得该connection；反之，创建一个，并添加进connections；\n\n&#160;&#160;&#160; b) connection.setupIOstreams()连接到服务器，并配置好连接对象，发送协议头，接着运行connection线程，等待接收工作（waitForWork()）；\n\nC、 调用connection.sendParam发送协议体，等待接收响应，call.wait();；\n\n&#160;&#160;&#160; a) receiveResponse()，依次读入call的值（id，value）；\n\n&#160;&#160;&#160; b) 标记接收结束（markClosed），同时notifyAll()；\n\nD、 获得返回值，返回调用者。\n\n**3、异步/同步模型**\n\nHadoop的RPC对外的接口其实是同步的，但是，RPC的内部实现其实是异步消息机制。hadoop用线程wait/notify机制实现异步转同步，发送请求（call）之后wait请求处理完毕，接收完响应（connection.receiveResponse()）之后notify，notify()方法在call.setValue中。\n\n但现在有一个问题，一个connection有多个call。可能同时有多个call在等待接收消息，那么是当client接收到response后，怎样确认它到底是之前哪个request的response呢？这个就是依靠的connection中的一个HashTable&lt;Integer, Call&gt;了，其中的Integer是用来标识Call，这样就可以将request和response对应上了。\n\n**4、小结**\n\n今天先休息一下了，吃坏东西了，悲催。\n  > **参考资料：**\n> \n> [智障大师的专栏](http://blog.csdn.net/historyasamirror/article/details/6159248)","source":"_posts/hadoop-ipc-client.md","raw":"title: Hadoop源码 - ipc.Client\ntags:\n  - Hadoop\n  - RPC\nid: 384\ncategories:\n  - 技术分享\ndate: 2012-02-25 23:06:42\n---\n\n**1****、前言**\n\n上篇博客分析了ipc包下的RPC类，这篇博客来看看Client类吧。\n  <!--more-->\n\nHadoop的RPC机制还是挺简单的，简述如下：\n\n1）创建代理对象；\n\n2）代理对象调用相应方法（invoke()）；\n\n3）invoke调用client对象的call方法，向服务器发送请求（参数、方法）；\n\n4）再等待call方法的完成；\n\n5）返回请求结果。\n\n具体是怎么实现的，下面来看看吧。\n\n**2****、Client类分析**\n\n有了RPC大致分析，Client我就挑重要的分析了。\n\n**1）connections**\n\nRPC中就有了ClientCache类，那么client可以复用，所以一个client对象会有多个连接对象，实现中是用HashTable&lt;ConnectionId, Connection&gt;存储的连接对象。\n\n其中，ConnectionId是用来唯一标识连接的ID，主要由客户端地址、时间戳再结合一个素数生成；Connection是Client中的静态内部类，用以处理远程连接对象。\n\n**2）Call**\n\n客户端方法调用的实体类，存放了id、参数、返回值等。需要注意的是，Call类中有callComplete()方法，在一次call调用完毕之后调用，并调用notify()通知client接收完毕。\n\n**3）call(Writable param, ConnectionId remoteId)**     <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">public</span><span> Object invoke(Object proxy, Method method, Object[] args)&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throws</span><span> Throwable {&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n4.  <span>&#160; </span>\n5.  <span>&#160;&#160;&#160;&#160;&#160; ObjectWritable value = (ObjectWritable)&#160;&#160; </span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; client.call(</span><span class=\"keyword\">new</span><span> Invocation(method, args), remoteId); </span><span class=\"comment\">// 调用方法 </span><span>&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> value.get();&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160; }&#160;&#160; </span>           </div>         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"comment\">// client请求方法 </span><span>&#160; </span></span>\n2.  <span></span><span class=\"keyword\">public</span><span> Writable call(Writable param, ConnectionId remoteId)&#160;&#160;&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throws</span><span> InterruptedException, IOException {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; Call call = </span><span class=\"keyword\">new</span><span> Call(param);&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; Connection connection = getConnection(remoteId, call); </span><span class=\"comment\">// 获得连接对象 </span><span>&#160; </span></span>\n6.  <span>&#160;&#160;&#160; connection.sendParam(call);&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 发送参数 </span><span>&#160; </span></span>\n7.  <span>&#160;&#160;&#160; …&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">synchronized</span><span> (call) {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">while</span><span> (!call.done) {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">try</span><span> {&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; call.wait();&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 等待response </span><span>&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">catch</span><span> (InterruptedException ie) {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; interrupted = </span><span class=\"keyword\">true</span><span>;&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n16.  <span>&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n17.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> call.value;&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n19.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n20.  <span>&#160; }&#160;&#160; </span>           </div>         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"comment\">// Connection线程，等待服务器响应 </span><span>&#160; </span></span>\n2.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> run() {&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (LOG.isDebugEnabled())&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; LOG.debug(getName() + </span><span class=\"string\">&quot;: starting, having connections &quot;</span><span>&#160;&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; + connections.size());&#160;&#160; </span>\n6.  <span>&#160; </span>\n7.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">while</span><span> (waitForWork()) {</span><span class=\"comment\">// 等待工作，主要依据是calls是否为空 </span><span>&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; receiveResponse();&#160; </span><span class=\"comment\">// 接收响应 </span><span>&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n11.  <span>&#160;&#160;&#160;&#160;&#160; close();&#160;&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>           </div>         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">private</span><span>&#160;</span><span class=\"keyword\">void</span><span> receiveResponse() {&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n3.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n4.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">try</span><span> {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> id = in.readInt();&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// try to read an id </span><span>&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Call call = calls.get(id);&#160;&#160; </span>\n8.  <span>&#160; </span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> state = in.readInt();&#160;&#160;&#160;&#160; </span><span class=\"comment\">// read call status </span><span>&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (state == Status.SUCCESS.state) {&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; Writable value = ReflectionUtils.newInstance(valueClass, conf);&#160;&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; value.readFields(in);&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// read value </span><span>&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; call.setValue(value);&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; calls.remove(id);&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160;&#160; </span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; …&#160;&#160; </span>\n17.  <span>&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">catch</span><span> (IOException e) {&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; markClosed(e);&#160;&#160; </span>\n19.  <span>&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n20.  <span>&#160;&#160;&#160; }&#160;&#160; </span>           </div>         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">synchronized</span><span>&#160;</span><span class=\"keyword\">void</span><span> setValue(Writable value) {&#160;&#160; </span></span>\n2.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.value = value;&#160;&#160; </span></span>\n3.  <span>&#160;&#160;&#160;&#160;&#160; callComplete();&#160;&#160; </span>\n4.  <span>}&#160;&#160; </span>\n5.  <span></span><span class=\"keyword\">protected</span><span>&#160;</span><span class=\"keyword\">synchronized</span><span>&#160;</span><span class=\"keyword\">void</span><span> callComplete() {&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.done = </span><span class=\"keyword\">true</span><span>;&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160; notify();&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// notify caller </span><span>&#160; </span></span>\n8.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n该方法由invoker调用，调用过程如下：\n\nA、构建Call对象\n\nB、 用remoteId获得connection对象\n\n&#160;&#160;&#160; a) 如果connections中有remoteId，取得该connection；反之，创建一个，并添加进connections；\n\n&#160;&#160;&#160; b) connection.setupIOstreams()连接到服务器，并配置好连接对象，发送协议头，接着运行connection线程，等待接收工作（waitForWork()）；\n\nC、 调用connection.sendParam发送协议体，等待接收响应，call.wait();；\n\n&#160;&#160;&#160; a) receiveResponse()，依次读入call的值（id，value）；\n\n&#160;&#160;&#160; b) 标记接收结束（markClosed），同时notifyAll()；\n\nD、 获得返回值，返回调用者。\n\n**3、异步/同步模型**\n\nHadoop的RPC对外的接口其实是同步的，但是，RPC的内部实现其实是异步消息机制。hadoop用线程wait/notify机制实现异步转同步，发送请求（call）之后wait请求处理完毕，接收完响应（connection.receiveResponse()）之后notify，notify()方法在call.setValue中。\n\n但现在有一个问题，一个connection有多个call。可能同时有多个call在等待接收消息，那么是当client接收到response后，怎样确认它到底是之前哪个request的response呢？这个就是依靠的connection中的一个HashTable&lt;Integer, Call&gt;了，其中的Integer是用来标识Call，这样就可以将request和response对应上了。\n\n**4、小结**\n\n今天先休息一下了，吃坏东西了，悲催。\n  > **参考资料：**\n> \n> [智障大师的专栏](http://blog.csdn.net/historyasamirror/article/details/6159248)","slug":"hadoop-ipc-client","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg623p007isb8f5uodzpij"},{"title":"Hadoop默认配置和常用配置","id":"508","date":"2012-04-20T12:48:18.000Z","_content":"\n**获取默认配置**\n\n配置hadoop，主要是配置core-site.xml，hdfs-site.xml，mapred-site.xml三个配置文件，默认下来，这些配置文件都是空的，所以很难知道这些配置文件有哪些配置可以生效，上网找的配置可能因为各个hadoop版本不同，导致无法生效。浏览更多的配置，有两个方法：\n\n1.选择相应版本的hadoop，下载解压后，找到core-default.xml，hdfs-default.xml，mapred-default.xml。这些分别在hadoop/src/{core | hdfs | mapred}下面。这些就是默认配置，可以参考这些配置的说明和key，配置hadoop集群。\n\n<!--more-->\n\n2.浏览apache官网，三个配置文件链接如下：\n\n[http://hadoop.apache.org/common/docs/r0.20.2/core-default.html](http://hadoop.apache.org/common/docs/r0.20.2/core-default.html)\n\n[http://hadoop.apache.org/common/docs/r0.20.2/hdfs-default.html](http://hadoop.apache.org/common/docs/r0.20.2/hdfs-default.html)\n\n[http://hadoop.apache.org/common/docs/r0.20.2/mapred-default.html](http://hadoop.apache.org/common/docs/r0.20.2/mapred-default.html)\n\n这里是浏览hadoop当前版本号的默认配置文件，其他版本号，要另外去官网找。其中第一个方法找到默认的配置是最好的，因为每个属性都有说明，可以直接使用。另外，core-site.xml是全局配置，hdfs-site.xml和mapred-site.xml分别是hdfs和mapred的局部配置。\n\n**常用的端口配置**\n\n**HDFS****端口**\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td>**参数**</td>\n<td>**描述**</td>\n<td>**默认**</td>\n<td>**例子值**</td>\n</tr>\n<tr>\n<td>fs.default.name</td>\n<td>namenode RPC交互端口</td>\n<td>8020</td>\n<td>hdfs：//master：8020/</td>\n</tr>\n<tr>\n<td>dfs.http.address</td>\n<td>NameNode web管理端口</td>\n<td>50070</td>\n<td>0.0.0.0：50070</td>\n</tr>\n<tr>\n<td>dfs.datanode.address</td>\n<td>datanode 控制端口</td>\n<td>50010</td>\n<td>0.0.0.0：50010</td>\n</tr>\n<tr>\n<td>dfs.datanode.ipc.address</td>\n<td>datanode的RPC服务器地址和端口</td>\n<td>50020</td>\n<td>0.0.0.0：50020</td>\n</tr>\n<tr>\n<td>dfs.datanode.http.address</td>\n<td>datanode的HTTP服务器和端口</td>\n<td>50075</td>\n<td>0.0.0.0：50075</td>\n</tr>\n</tbody>\n</table>\n**MR****端口**\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td>**参数**</td>\n<td>**描述**</td>\n<td>**默认**</td>\n<td>**例子值**</td>\n</tr>\n<tr>\n<td>mapred.job.tracker</td>\n<td>job tracker交互端口</td>\n<td>8021</td>\n<td>hdfs：//master：8021/</td>\n</tr>\n<tr>\n<td>mapred.job.tracker.http.address</td>\n<td>job tracker的web管理端口</td>\n<td>50030</td>\n<td>0.0.0.0：50030</td>\n</tr>\n<tr>\n<td>mapred.task.tracker.http.address</td>\n<td>task tracker的HTTP端口</td>\n<td>50060</td>\n<td>0.0.0.0：50060</td>\n</tr>\n</tbody>\n</table>\n**其他端口**\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td>**参数**</td>\n<td>**描述 **</td>\n<td>**默认 **</td>\n<td>**例子值**</td>\n</tr>\n<tr>\n<td>dfs.secondary.http.address</td>\n<td>secondary NameNode web管理端口</td>\n<td>50090</td>\n<td>0.0.0.0：28680</td>\n</tr>\n</tbody>\n</table>\n**集群目录配置**\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td>**参数**</td>\n<td>**描述 **</td>\n<td>**默认 **</td>\n<td>**例子值**</td>\n</tr>\n<tr>\n<td>dfs.name.dir</td>\n<td>name node的元数据，以，号隔开，hdfs会把元数据冗余复制到这些目录，一般这些目录是不同的块设备，不存在的目录会被忽略掉</td>\n<td>{hadoop.tmp.dir}\n\n/dfs/name</td>\n<td>/hadoop/hdfs/name</td>\n</tr>\n<tr>\n<td>dfs.name.edits.dir</td>\n<td>node node的事务文件存储的目录，以，号隔开，hdfs会把事务文件冗余复制到这些目录，一般这些目录是不同的块设备，不存在的目录会被忽略掉</td>\n<td>${dfs.name.dir}</td>\n<td>${dfs.name.dir}</td>\n</tr>\n<tr>\n<td>fs.checkpoint.dir</td>\n<td>secondary NameNode的元数据以，号隔开，hdfs会把元数据冗余复制到这些目录，一般这些目录是不同的块设备，不存在的目录会被忽略掉</td>\n<td>${hadoop.tmp.dir}\n\n/dfs/namesecondary</td>\n<td>/hadoop/hdfs/\n\nnamesecondary</td>\n</tr>\n<tr>\n<td>fs.checkpoint.edits\n\n.dir</td>\n<td>secondary NameNode的事务文件存储的目录，以，号隔开，hdfs会把事务文件冗余复制到这些目录</td>\n<td>${fs.checkpoint.dir}</td>\n<td>${fs.checkpoint.dir}</td>\n</tr>\n<tr>\n<td>hadoop.tmp.dir</td>\n<td>临时目录，其他临时目录的父目录</td>\n<td>/tmp/hadoop-${user.name}</td>\n<td>/hadoop/tmp/hadoop-\n\n${user.name}</td>\n</tr>\n<tr>\n<td>dfs.data.dir</td>\n<td>data node的数据目录，以，号隔开，hdfs会把数据存在这些目录下，一般这些目录是不同的块设备，不存在的目录会被忽略掉</td>\n<td>${hadoop.tmp.dir}\n\n/dfs/data</td>\n<td>/hadoop/hdfs/data1/data\n\n/hadoop/hdfs/data2/data</td>\n</tr>\n<tr>\n<td>mapred.local.dir</td>\n<td>MapReduce产生的中间数据存放目录，以，号隔开，hdfs会把数据存在这些目录下，一般这些目录是不同的块设备，不存在的目录会被忽略掉</td>\n<td>${hadoop.tmp.dir}\n\n/mapred/local</td>\n<td>/hadoop/hdfs/data1/\n\nmapred/local\n\n/hadoop/hdfs/data2/\n\nmapred/local</td>\n</tr>\n<tr>\n<td>mapred.system.dir</td>\n<td>MapReduce的控制文件</td>\n<td>${hadoop.tmp.dir}\n\n/mapred/system</td>\n<td>/hadoop/hdfs/data1/system</td>\n</tr>\n</tbody>\n</table>\n**其他配置**\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td>**参数**</td>\n<td>**描述 **</td>\n<td>**默认 **</td>\n<td>**例子值**</td>\n</tr>\n<tr>\n<td>dfs.support.append</td>\n<td>支持文件append，主要是支持hbase</td>\n<td>false</td>\n<td>true</td>\n</tr>\n<tr>\n<td>dfs.replication</td>\n<td>文件复制的副本数，如果创建时不指定这个参数，就使用这个默认值作为复制的副本数</td>\n<td>3</td>\n<td>2</td>\n</tr>\n</tbody>\n</table>\n&nbsp;\n> 转载：\r> \n> \n> [http://www.cnblogs.com/ggjucheng/archive/2012/04/17/2454590.html](http://www.cnblogs.com/ggjucheng/archive/2012/04/17/2454590.html)","source":"_posts/hadoop-default-conf.md","raw":"title: Hadoop默认配置和常用配置\ntags:\n  - Hadoop\nid: 508\ncategories:\n  - 技术分享\ndate: 2012-04-20 20:48:18\n---\n\n**获取默认配置**\n\n配置hadoop，主要是配置core-site.xml，hdfs-site.xml，mapred-site.xml三个配置文件，默认下来，这些配置文件都是空的，所以很难知道这些配置文件有哪些配置可以生效，上网找的配置可能因为各个hadoop版本不同，导致无法生效。浏览更多的配置，有两个方法：\n\n1.选择相应版本的hadoop，下载解压后，找到core-default.xml，hdfs-default.xml，mapred-default.xml。这些分别在hadoop/src/{core | hdfs | mapred}下面。这些就是默认配置，可以参考这些配置的说明和key，配置hadoop集群。\n\n<!--more-->\n\n2.浏览apache官网，三个配置文件链接如下：\n\n[http://hadoop.apache.org/common/docs/r0.20.2/core-default.html](http://hadoop.apache.org/common/docs/r0.20.2/core-default.html)\n\n[http://hadoop.apache.org/common/docs/r0.20.2/hdfs-default.html](http://hadoop.apache.org/common/docs/r0.20.2/hdfs-default.html)\n\n[http://hadoop.apache.org/common/docs/r0.20.2/mapred-default.html](http://hadoop.apache.org/common/docs/r0.20.2/mapred-default.html)\n\n这里是浏览hadoop当前版本号的默认配置文件，其他版本号，要另外去官网找。其中第一个方法找到默认的配置是最好的，因为每个属性都有说明，可以直接使用。另外，core-site.xml是全局配置，hdfs-site.xml和mapred-site.xml分别是hdfs和mapred的局部配置。\n\n**常用的端口配置**\n\n**HDFS****端口**\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td>**参数**</td>\n<td>**描述**</td>\n<td>**默认**</td>\n<td>**例子值**</td>\n</tr>\n<tr>\n<td>fs.default.name</td>\n<td>namenode RPC交互端口</td>\n<td>8020</td>\n<td>hdfs：//master：8020/</td>\n</tr>\n<tr>\n<td>dfs.http.address</td>\n<td>NameNode web管理端口</td>\n<td>50070</td>\n<td>0.0.0.0：50070</td>\n</tr>\n<tr>\n<td>dfs.datanode.address</td>\n<td>datanode 控制端口</td>\n<td>50010</td>\n<td>0.0.0.0：50010</td>\n</tr>\n<tr>\n<td>dfs.datanode.ipc.address</td>\n<td>datanode的RPC服务器地址和端口</td>\n<td>50020</td>\n<td>0.0.0.0：50020</td>\n</tr>\n<tr>\n<td>dfs.datanode.http.address</td>\n<td>datanode的HTTP服务器和端口</td>\n<td>50075</td>\n<td>0.0.0.0：50075</td>\n</tr>\n</tbody>\n</table>\n**MR****端口**\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td>**参数**</td>\n<td>**描述**</td>\n<td>**默认**</td>\n<td>**例子值**</td>\n</tr>\n<tr>\n<td>mapred.job.tracker</td>\n<td>job tracker交互端口</td>\n<td>8021</td>\n<td>hdfs：//master：8021/</td>\n</tr>\n<tr>\n<td>mapred.job.tracker.http.address</td>\n<td>job tracker的web管理端口</td>\n<td>50030</td>\n<td>0.0.0.0：50030</td>\n</tr>\n<tr>\n<td>mapred.task.tracker.http.address</td>\n<td>task tracker的HTTP端口</td>\n<td>50060</td>\n<td>0.0.0.0：50060</td>\n</tr>\n</tbody>\n</table>\n**其他端口**\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td>**参数**</td>\n<td>**描述 **</td>\n<td>**默认 **</td>\n<td>**例子值**</td>\n</tr>\n<tr>\n<td>dfs.secondary.http.address</td>\n<td>secondary NameNode web管理端口</td>\n<td>50090</td>\n<td>0.0.0.0：28680</td>\n</tr>\n</tbody>\n</table>\n**集群目录配置**\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td>**参数**</td>\n<td>**描述 **</td>\n<td>**默认 **</td>\n<td>**例子值**</td>\n</tr>\n<tr>\n<td>dfs.name.dir</td>\n<td>name node的元数据，以，号隔开，hdfs会把元数据冗余复制到这些目录，一般这些目录是不同的块设备，不存在的目录会被忽略掉</td>\n<td>{hadoop.tmp.dir}\n\n/dfs/name</td>\n<td>/hadoop/hdfs/name</td>\n</tr>\n<tr>\n<td>dfs.name.edits.dir</td>\n<td>node node的事务文件存储的目录，以，号隔开，hdfs会把事务文件冗余复制到这些目录，一般这些目录是不同的块设备，不存在的目录会被忽略掉</td>\n<td>${dfs.name.dir}</td>\n<td>${dfs.name.dir}</td>\n</tr>\n<tr>\n<td>fs.checkpoint.dir</td>\n<td>secondary NameNode的元数据以，号隔开，hdfs会把元数据冗余复制到这些目录，一般这些目录是不同的块设备，不存在的目录会被忽略掉</td>\n<td>${hadoop.tmp.dir}\n\n/dfs/namesecondary</td>\n<td>/hadoop/hdfs/\n\nnamesecondary</td>\n</tr>\n<tr>\n<td>fs.checkpoint.edits\n\n.dir</td>\n<td>secondary NameNode的事务文件存储的目录，以，号隔开，hdfs会把事务文件冗余复制到这些目录</td>\n<td>${fs.checkpoint.dir}</td>\n<td>${fs.checkpoint.dir}</td>\n</tr>\n<tr>\n<td>hadoop.tmp.dir</td>\n<td>临时目录，其他临时目录的父目录</td>\n<td>/tmp/hadoop-${user.name}</td>\n<td>/hadoop/tmp/hadoop-\n\n${user.name}</td>\n</tr>\n<tr>\n<td>dfs.data.dir</td>\n<td>data node的数据目录，以，号隔开，hdfs会把数据存在这些目录下，一般这些目录是不同的块设备，不存在的目录会被忽略掉</td>\n<td>${hadoop.tmp.dir}\n\n/dfs/data</td>\n<td>/hadoop/hdfs/data1/data\n\n/hadoop/hdfs/data2/data</td>\n</tr>\n<tr>\n<td>mapred.local.dir</td>\n<td>MapReduce产生的中间数据存放目录，以，号隔开，hdfs会把数据存在这些目录下，一般这些目录是不同的块设备，不存在的目录会被忽略掉</td>\n<td>${hadoop.tmp.dir}\n\n/mapred/local</td>\n<td>/hadoop/hdfs/data1/\n\nmapred/local\n\n/hadoop/hdfs/data2/\n\nmapred/local</td>\n</tr>\n<tr>\n<td>mapred.system.dir</td>\n<td>MapReduce的控制文件</td>\n<td>${hadoop.tmp.dir}\n\n/mapred/system</td>\n<td>/hadoop/hdfs/data1/system</td>\n</tr>\n</tbody>\n</table>\n**其他配置**\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"0\">\n<tbody>\n<tr>\n<td>**参数**</td>\n<td>**描述 **</td>\n<td>**默认 **</td>\n<td>**例子值**</td>\n</tr>\n<tr>\n<td>dfs.support.append</td>\n<td>支持文件append，主要是支持hbase</td>\n<td>false</td>\n<td>true</td>\n</tr>\n<tr>\n<td>dfs.replication</td>\n<td>文件复制的副本数，如果创建时不指定这个参数，就使用这个默认值作为复制的副本数</td>\n<td>3</td>\n<td>2</td>\n</tr>\n</tbody>\n</table>\n&nbsp;\n> 转载：\r> \n> \n> [http://www.cnblogs.com/ggjucheng/archive/2012/04/17/2454590.html](http://www.cnblogs.com/ggjucheng/archive/2012/04/17/2454590.html)","slug":"hadoop-default-conf","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg623q007msb8f3y9e9qh8"},{"title":"发现Hadoop小bug一枚","id":"584","date":"2012-09-18T13:52:55.000Z","_content":"\n最近在做一个任务，合并大小文本文件，每个不到5M，合并之后再进行统计分析。但是统计分析结果不对，本来只有60w个文件，但是最后的结果竟然到了200w了，断断续续debug了几天，从合并、map过程、combine过程、reduce过程，都一一过了一遍。最后发现在map过程中的数据就有重复，而且重复的形式很奇怪。\n<!--more-->  \n\n举例来说，SequenceFile中两个记录一个4M一个为1M，map第一个4M的记录没出现问题，但是map第二个1M的记录出问题了，记录大小为1M，但是getBytes()之后会获得4M的数据，前面1M是正常数据，而后面3M是非法的前一个记录的后3M数据。\n\n开始以为是jvm没有将内存给销毁，但是觉着不对劲，就直接跟进代码瞅了瞅几眼。原来在map过程中，每次获得的key和value均会复用，而不会销毁，而Text的数据均存在了一个bytes数组，Text对象不销毁，bytes数组也不会销毁。可以参见：LineRecordReader or SequenceFileRecordReader的nextKeyValue()方法，该方法由Mapper的run方法间接调用。\n\n继续刚才的那个问题，我在读取Text中的数据时，会调用text.getBytes()方法，逻辑上它应该是要返回length长度的bytes给开发者，但是它却将整个bytes数组返回了。\n\n心想着可以提交一个patch，但后来翻了一下新版本的源码，发现hadoop已经提供了一种解决方案——copyBytes()。具体实现见下图：\n\n[![Image](http://www.hongweiyi.com/wp-content/uploads/2012/09/Image_thumb.png \"Image\")](http://www.hongweiyi.com/wp-content/uploads/2012/09/Image.png)\n\n**P.S.:** Hadoop会在不变动原有逻辑的基础上进行修改，这样的话可以最大限度的减少对用户的影响，并且可以往下兼容。值得学习啊，给我的话，就直接修改getBytes()方法了。\n\n**P.P.S.:** 我是基于0.20.203.0做的实验，这个问题在0.22之后的版本均提供了解决方案。","source":"_posts/hadoop-bug-in-text.md","raw":"title: 发现Hadoop小bug一枚\ntags:\n  - Hadoop\nid: 584\ncategories:\n  - 技术分享\ndate: 2012-09-18 21:52:55\n---\n\n最近在做一个任务，合并大小文本文件，每个不到5M，合并之后再进行统计分析。但是统计分析结果不对，本来只有60w个文件，但是最后的结果竟然到了200w了，断断续续debug了几天，从合并、map过程、combine过程、reduce过程，都一一过了一遍。最后发现在map过程中的数据就有重复，而且重复的形式很奇怪。\n<!--more-->  \n\n举例来说，SequenceFile中两个记录一个4M一个为1M，map第一个4M的记录没出现问题，但是map第二个1M的记录出问题了，记录大小为1M，但是getBytes()之后会获得4M的数据，前面1M是正常数据，而后面3M是非法的前一个记录的后3M数据。\n\n开始以为是jvm没有将内存给销毁，但是觉着不对劲，就直接跟进代码瞅了瞅几眼。原来在map过程中，每次获得的key和value均会复用，而不会销毁，而Text的数据均存在了一个bytes数组，Text对象不销毁，bytes数组也不会销毁。可以参见：LineRecordReader or SequenceFileRecordReader的nextKeyValue()方法，该方法由Mapper的run方法间接调用。\n\n继续刚才的那个问题，我在读取Text中的数据时，会调用text.getBytes()方法，逻辑上它应该是要返回length长度的bytes给开发者，但是它却将整个bytes数组返回了。\n\n心想着可以提交一个patch，但后来翻了一下新版本的源码，发现hadoop已经提供了一种解决方案——copyBytes()。具体实现见下图：\n\n[![Image](http://www.hongweiyi.com/wp-content/uploads/2012/09/Image_thumb.png \"Image\")](http://www.hongweiyi.com/wp-content/uploads/2012/09/Image.png)\n\n**P.S.:** Hadoop会在不变动原有逻辑的基础上进行修改，这样的话可以最大限度的减少对用户的影响，并且可以往下兼容。值得学习啊，给我的话，就直接修改getBytes()方法了。\n\n**P.P.S.:** 我是基于0.20.203.0做的实验，这个问题在0.22之后的版本均提供了解决方案。","slug":"hadoop-bug-in-text","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg623r007psb8fxi147iu8"},{"title":"Google Doodle for Turing","id":"564","date":"2012-06-23T13:29:27.000Z","_content":"\n[![clip_image001](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image001_thumb.jpg \"clip_image001\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image001.jpg)\n\n今天是图灵的诞辰100周年，Google又推出了有意思的doodle。今天的doodle主要是围绕着图灵机来的，需要完成多个图灵机规则表的选择，共有6关，每完成一关Google就亮一个字母，直到所有字母都亮起来为止。我就直接贴结果了，想知道原理的可以Google一下“图灵 doodle”或者“图灵机”。游戏截图参见文尾。\n<!--more-->  \n\n**P.S.: **6盘通关后，还会出现更进阶的版本，这篇并没提到。\n\n**P.P.S. : **谷奥的这篇介绍得不错。[猛击](http://www.guao.hk/posts/alan-mathison-turings-birthday-2012.html)…\n\n&#160;\n\n玩到最后，让我最感兴趣不是图灵机，而是Google所对应的6个二进制串是怎么来的？{01011, 00011, 00011, 01011, 01001, 10000}\n\n看到G/g与o/o对应的串是相同的，可以猜想这六个串不是随机得出的。对二进制排序、取反、求十进制、比较ascii码，均没发现任何规律。还是得Google一下，最后竟然发现这几个串对应的是**国际电报****2****号码：ITA2****（International Telegraph Alphabet Number 2****，国际电报2****号码）**又称**博多码（****Baudot code****）**。有一种被玩了的感觉 &gt;_&lt;…\n\n在后面游戏replay的时候，点击图下的红圈处，会有一个彩蛋。彩蛋所出来的图看着我头疼了，搜了一下说是Rabbit Sequence，应该就是斐波拉奇数列。有兴趣的童鞋可以仔细地研究研究最后的Rabbit图灵机……\n\n[![clip_image003](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image003_thumb.jpg \"clip_image003\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image003.jpg)\n\n[![clip_image005](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image005_thumb.jpg \"clip_image005\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image005.jpg)\n\n**Rabbit Sequence**\n\n**第一轮游戏截图：**\n\n[![clip_image007](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image007_thumb.jpg \"clip_image007\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image007.jpg)\n\n[![clip_image009](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image009_thumb.jpg \"clip_image009\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image009.jpg)\n\n[![clip_image011](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image011_thumb.jpg \"clip_image011\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image011.jpg)\n\n[![clip_image013](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image013_thumb.jpg \"clip_image013\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image013.jpg)\n\n[![clip_image015](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image015_thumb.jpg \"clip_image015\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image015.jpg)\n\n[![clip_image017](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image017_thumb.jpg \"clip_image017\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image017.jpg)","source":"_posts/google-doodle-for-turing.md","raw":"title: Google Doodle for Turing\ntags:\n  - Google\nid: 564\ncategories:\n  - 生活分享\ndate: 2012-06-23 21:29:27\n---\n\n[![clip_image001](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image001_thumb.jpg \"clip_image001\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image001.jpg)\n\n今天是图灵的诞辰100周年，Google又推出了有意思的doodle。今天的doodle主要是围绕着图灵机来的，需要完成多个图灵机规则表的选择，共有6关，每完成一关Google就亮一个字母，直到所有字母都亮起来为止。我就直接贴结果了，想知道原理的可以Google一下“图灵 doodle”或者“图灵机”。游戏截图参见文尾。\n<!--more-->  \n\n**P.S.: **6盘通关后，还会出现更进阶的版本，这篇并没提到。\n\n**P.P.S. : **谷奥的这篇介绍得不错。[猛击](http://www.guao.hk/posts/alan-mathison-turings-birthday-2012.html)…\n\n&#160;\n\n玩到最后，让我最感兴趣不是图灵机，而是Google所对应的6个二进制串是怎么来的？{01011, 00011, 00011, 01011, 01001, 10000}\n\n看到G/g与o/o对应的串是相同的，可以猜想这六个串不是随机得出的。对二进制排序、取反、求十进制、比较ascii码，均没发现任何规律。还是得Google一下，最后竟然发现这几个串对应的是**国际电报****2****号码：ITA2****（International Telegraph Alphabet Number 2****，国际电报2****号码）**又称**博多码（****Baudot code****）**。有一种被玩了的感觉 &gt;_&lt;…\n\n在后面游戏replay的时候，点击图下的红圈处，会有一个彩蛋。彩蛋所出来的图看着我头疼了，搜了一下说是Rabbit Sequence，应该就是斐波拉奇数列。有兴趣的童鞋可以仔细地研究研究最后的Rabbit图灵机……\n\n[![clip_image003](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image003_thumb.jpg \"clip_image003\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image003.jpg)\n\n[![clip_image005](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image005_thumb.jpg \"clip_image005\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image005.jpg)\n\n**Rabbit Sequence**\n\n**第一轮游戏截图：**\n\n[![clip_image007](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image007_thumb.jpg \"clip_image007\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image007.jpg)\n\n[![clip_image009](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image009_thumb.jpg \"clip_image009\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image009.jpg)\n\n[![clip_image011](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image011_thumb.jpg \"clip_image011\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image011.jpg)\n\n[![clip_image013](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image013_thumb.jpg \"clip_image013\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image013.jpg)\n\n[![clip_image015](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image015_thumb.jpg \"clip_image015\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image015.jpg)\n\n[![clip_image017](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image017_thumb.jpg \"clip_image017\")](http://www.hongweiyi.com/wp-content/uploads/2012/06/clip_image017.jpg)","slug":"google-doodle-for-turing","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg623t007ssb8fyghfif6h"},{"title":"GIT 最佳实践","date":"2015-08-28T14:32:00.000Z","_content":"\n以下是我整理的自己使用及见过比较好的 GIT 实践，草草总结如下，有空会详细描述各项内容：\n<!--more-->\n\n## Labels\n\n* BUG\n* P0\n* P1\n* P2\n* TIPS\n* TODO\n* 功能Label\n\t* 交互\n\t* 视觉\n\t* ...\n* 子功能Label\n    * 业务1\n    * 业务2\n\t* ...\n\n\n## Branch\n\n* 方式1: [Git版本控制与工作流](http://www.jianshu.com/p/67afe711c731)\n\t* master\n\t* release\n\t* develop\n\t* feature/*\n\t* hotfix\n* 方式2\n\t* master\n\t* name-dev\n\n## Issue\n\n* 命名\n\t* XX1-XX2-Description\n\t* XX1: 功能\n\t* XX2: 子功能\n* Push\n\t* comment 中添加 #{Issue Id}\n\n## Push\n\n* 最小功能提交原则\n\n\n## Milestone\n\n### 常规\n\n* 命名\n\t* v1.0.0\n\t* v1.0.1\n\t* ...\n* 内容\n\t* 基本描述\n\t* 版本负责人\n\n### 其它\n\n* Application Talk\n\t* 针对 Application 的讨论与展望\n\t* 同时也可以发设计文档\n\n## 其它实践\n\n* 可以建立 project-management 分支\n\t* 更多的关注项目管理的内容\n\t\t* 文档\n\t\t* 项目管理 issue\n\t* 如果有些 issue 同时涉及多个不同子工程，可以将这些写在这里面\n","source":"_posts/git-practice.md","raw":"title: GIT 最佳实践\ndate: 2015-08-28 22:32:00\ncategories: 最佳实践\ntags: GIT\n---\n\n以下是我整理的自己使用及见过比较好的 GIT 实践，草草总结如下，有空会详细描述各项内容：\n<!--more-->\n\n## Labels\n\n* BUG\n* P0\n* P1\n* P2\n* TIPS\n* TODO\n* 功能Label\n\t* 交互\n\t* 视觉\n\t* ...\n* 子功能Label\n    * 业务1\n    * 业务2\n\t* ...\n\n\n## Branch\n\n* 方式1: [Git版本控制与工作流](http://www.jianshu.com/p/67afe711c731)\n\t* master\n\t* release\n\t* develop\n\t* feature/*\n\t* hotfix\n* 方式2\n\t* master\n\t* name-dev\n\n## Issue\n\n* 命名\n\t* XX1-XX2-Description\n\t* XX1: 功能\n\t* XX2: 子功能\n* Push\n\t* comment 中添加 #{Issue Id}\n\n## Push\n\n* 最小功能提交原则\n\n\n## Milestone\n\n### 常规\n\n* 命名\n\t* v1.0.0\n\t* v1.0.1\n\t* ...\n* 内容\n\t* 基本描述\n\t* 版本负责人\n\n### 其它\n\n* Application Talk\n\t* 针对 Application 的讨论与展望\n\t* 同时也可以发设计文档\n\n## 其它实践\n\n* 可以建立 project-management 分支\n\t* 更多的关注项目管理的内容\n\t\t* 文档\n\t\t* 项目管理 issue\n\t* 如果有些 issue 同时涉及多个不同子工程，可以将这些写在这里面\n","slug":"git-practice","published":1,"updated":"2015-12-29T13:45:58.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg623u007wsb8fb145hlx7"},{"title":"有求皆苦、无欲则刚","date":"2014-04-13T15:48:00.000Z","_content":"\n\n最近会听到不少周围朋友负能量的东西，无外乎是升职、加薪、倒挂之类与经济利益挂钩的事情。当然，也会听到一些情感的负能量，不过这个应该算是占少数吧，毕竟我对这个不太感冒。正如前女友所说：「天底下像你一样的程序员屌丝男真的不多。」「像我哪样了」「不寂寞，不要女朋友的」，忧桑。\n\n<!--more-->\n\n最近几周和老同学聚的比较多，可能是同学的缘故，大家也不会藏着掖着，有啥话都会直接说。\n\n> 「擦，我那老大太变态了，需求一天一个变」\n> 「哎，这特么升P又卡住了，还得面试」\n> 「你知道那谁不，不到一年老大特批给升了」\n\n嗯，顺带也听了不少坊间八卦。与他们沟通具体情况时，发现公司其他部门情况（主要是业务部门）与我想像中的大相径庭，各种勾心斗角尔虞我诈。但是奇怪的是，我在这里也待了一年了，并没有发现类似的情况出现，一切都是那么的和谐，是我想简单了么？\n\n不过，在众多负能量中也有一些正能量的出现。有趣的是，在这个正能量的主人身上很少听到负能量的东西：\n\n> 「老大让我好好准备下5月份的晋升」\n\n所以，我又在想：是他们主动产生了正/负能量，还是客观的正/负能量影响了他们，抑或是相辅相成的，搞不明白了。我一直都会说，计算机艺术相较于人的艺术是那么的简单。看样子不仅仅是简单那么简单了，应该改成：「计算机艺术相较于人的艺术是那么的小儿科」\n\n对于升职加薪之类的，我确实也挺想的，谁不想呢。但是我会尽可能保持一种「有求皆苦、无欲则刚」的态度，这八个字在去年这个时候我还不太理解，在入职培训的时候，和爱好佛学的@湛然同学请教过这个，能稍微有点参悟。大致对话回忆如下：\n\n> 「菩萨不是说要救苦救难，普度众生啥的，这不算是欲么？」\n> 「就是这样，他才是菩萨。观音菩萨要普度众生，地藏菩萨要地狱没有鬼魂，这都是欲，当无欲了才能称之为佛。佛讲究无欲，并不是无所诉求，而是不会将诉求放在口中、心上。如你努力工作，不把欲望挂在心中，你就会得到你所要的东西」\n\n嗯，希望我也能继续保持这种态度吧，尽可能广/多/快的汲取周边的营养让自己得到快速的成长（这也算欲吧？我还是比较贪的，嗯）。\n","source":"_posts/forget-your-lusts.md","raw":"title: 有求皆苦、无欲则刚\ndate: 2014-04-13 23:48:00\ncategories: 生活点滴\ntags: 价值观, 生活\n---\n\n\n最近会听到不少周围朋友负能量的东西，无外乎是升职、加薪、倒挂之类与经济利益挂钩的事情。当然，也会听到一些情感的负能量，不过这个应该算是占少数吧，毕竟我对这个不太感冒。正如前女友所说：「天底下像你一样的程序员屌丝男真的不多。」「像我哪样了」「不寂寞，不要女朋友的」，忧桑。\n\n<!--more-->\n\n最近几周和老同学聚的比较多，可能是同学的缘故，大家也不会藏着掖着，有啥话都会直接说。\n\n> 「擦，我那老大太变态了，需求一天一个变」\n> 「哎，这特么升P又卡住了，还得面试」\n> 「你知道那谁不，不到一年老大特批给升了」\n\n嗯，顺带也听了不少坊间八卦。与他们沟通具体情况时，发现公司其他部门情况（主要是业务部门）与我想像中的大相径庭，各种勾心斗角尔虞我诈。但是奇怪的是，我在这里也待了一年了，并没有发现类似的情况出现，一切都是那么的和谐，是我想简单了么？\n\n不过，在众多负能量中也有一些正能量的出现。有趣的是，在这个正能量的主人身上很少听到负能量的东西：\n\n> 「老大让我好好准备下5月份的晋升」\n\n所以，我又在想：是他们主动产生了正/负能量，还是客观的正/负能量影响了他们，抑或是相辅相成的，搞不明白了。我一直都会说，计算机艺术相较于人的艺术是那么的简单。看样子不仅仅是简单那么简单了，应该改成：「计算机艺术相较于人的艺术是那么的小儿科」\n\n对于升职加薪之类的，我确实也挺想的，谁不想呢。但是我会尽可能保持一种「有求皆苦、无欲则刚」的态度，这八个字在去年这个时候我还不太理解，在入职培训的时候，和爱好佛学的@湛然同学请教过这个，能稍微有点参悟。大致对话回忆如下：\n\n> 「菩萨不是说要救苦救难，普度众生啥的，这不算是欲么？」\n> 「就是这样，他才是菩萨。观音菩萨要普度众生，地藏菩萨要地狱没有鬼魂，这都是欲，当无欲了才能称之为佛。佛讲究无欲，并不是无所诉求，而是不会将诉求放在口中、心上。如你努力工作，不把欲望挂在心中，你就会得到你所要的东西」\n\n嗯，希望我也能继续保持这种态度吧，尽可能广/多/快的汲取周边的营养让自己得到快速的成长（这也算欲吧？我还是比较贪的，嗯）。\n","slug":"forget-your-lusts","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg623v0080sb8fve7w65dn"},{"title":"有求皆苦、无欲则刚","id":"1044","date":"2014-04-13T15:48:24.000Z","_content":"\n最近会听到不少周围朋友负能量的东西，无外乎是升职、加薪、倒挂之类与经济利益挂钩的事情。当然，也会听到一些情感的负能量，不过这个应该算是占少数吧，毕竟我对这个不太感冒。正如前女友所说：「天底下像你一样的程序员屌丝男真的不多。」「像我哪样了」「不寂寞，不要女朋友的」，忧桑。\n\n<!--more-->\n\n* * *\n\n\t最近几周和老同学聚的比较多，可能是同学的缘故，大家也不会藏着掖着，有啥话都会直接说。\n\n> 「擦，我那老大太变态了，需求一天一个变」\n> \n> \t「哎，这特么升P又卡住了，还得面试」\n> \n> \t「你知道那谁不，不到一年老大特批给升了」\n\n\t嗯，顺带也听了不少坊间八卦。与他们沟通具体情况时，发现公司其他部门情况（主要是业务部门）与我想像中的大相径庭，各种勾心斗角尔虞我诈。但是奇怪的是，我在这里也待了一年了，并没有发现类似的情况出现，一切都是那么的和谐，是我想简单了么？\n\n\t不过，在众多负能量中也有一些正能量的出现。有趣的是，在这个正能量的主人身上很少听到负能量的东西：\n\n> 「老大让我好好准备下5月份的晋升」\n\n\t所以，我又在想：是他们主动产生了正/负能量，还是客观的<span style=\"font-size: 13px;\">正/负能量影响了他们</span>，抑或是相辅相成的，搞不明白了。我一直都会说，计算机艺术相较于人的艺术是那么的简单。看样子不仅仅是简单那么简单了，应该改成：**「计算机艺术相较于人的艺术是那么的小儿科」**\n\n\t对于升职加薪之类的，我确实也挺想的，谁不想呢。但是我会尽可能保持一种**「有求皆苦、无欲则刚」**的态度，这八个字在去年这个时候我还不太理解，在入职培训的时候，和爱好佛学的[@湛然](http://weibo.com/hhbl)同学请教过这个，能稍微有点参悟。大致对话回忆如下：\n\n> 「菩萨不是说要救苦救难，普度众生啥的，这不算是欲么？」\n\n> 「就是这样，他才是菩萨。观音菩萨要普度众生，地藏菩萨要地狱没有鬼魂，这都是欲，当无欲了才能称之为佛。佛讲究无欲，并不是无所诉求，而是不会将诉求放在口中、心上。如你努力工作，不把欲望挂在心中，你就会得到你所要的东西」\n\n\t嗯，希望我也能继续保持这种态度吧，尽可能广/多/快的汲取周边的营养让自己得到快速的成长（这也算欲吧？我还是比较贪的，嗯）。_BTW，楼下一妹子哭的老凄惨了，吓死个人。_","source":"_posts/forget-your-lusts-1.md","raw":"title: 有求皆苦、无欲则刚\ntags:\n  - 价值观\n  - 生活\nid: 1044\ncategories:\n  - 生活分享\ndate: 2014-04-13 23:48:24\n---\n\n最近会听到不少周围朋友负能量的东西，无外乎是升职、加薪、倒挂之类与经济利益挂钩的事情。当然，也会听到一些情感的负能量，不过这个应该算是占少数吧，毕竟我对这个不太感冒。正如前女友所说：「天底下像你一样的程序员屌丝男真的不多。」「像我哪样了」「不寂寞，不要女朋友的」，忧桑。\n\n<!--more-->\n\n* * *\n\n\t最近几周和老同学聚的比较多，可能是同学的缘故，大家也不会藏着掖着，有啥话都会直接说。\n\n> 「擦，我那老大太变态了，需求一天一个变」\n> \n> \t「哎，这特么升P又卡住了，还得面试」\n> \n> \t「你知道那谁不，不到一年老大特批给升了」\n\n\t嗯，顺带也听了不少坊间八卦。与他们沟通具体情况时，发现公司其他部门情况（主要是业务部门）与我想像中的大相径庭，各种勾心斗角尔虞我诈。但是奇怪的是，我在这里也待了一年了，并没有发现类似的情况出现，一切都是那么的和谐，是我想简单了么？\n\n\t不过，在众多负能量中也有一些正能量的出现。有趣的是，在这个正能量的主人身上很少听到负能量的东西：\n\n> 「老大让我好好准备下5月份的晋升」\n\n\t所以，我又在想：是他们主动产生了正/负能量，还是客观的<span style=\"font-size: 13px;\">正/负能量影响了他们</span>，抑或是相辅相成的，搞不明白了。我一直都会说，计算机艺术相较于人的艺术是那么的简单。看样子不仅仅是简单那么简单了，应该改成：**「计算机艺术相较于人的艺术是那么的小儿科」**\n\n\t对于升职加薪之类的，我确实也挺想的，谁不想呢。但是我会尽可能保持一种**「有求皆苦、无欲则刚」**的态度，这八个字在去年这个时候我还不太理解，在入职培训的时候，和爱好佛学的[@湛然](http://weibo.com/hhbl)同学请教过这个，能稍微有点参悟。大致对话回忆如下：\n\n> 「菩萨不是说要救苦救难，普度众生啥的，这不算是欲么？」\n\n> 「就是这样，他才是菩萨。观音菩萨要普度众生，地藏菩萨要地狱没有鬼魂，这都是欲，当无欲了才能称之为佛。佛讲究无欲，并不是无所诉求，而是不会将诉求放在口中、心上。如你努力工作，不把欲望挂在心中，你就会得到你所要的东西」\n\n\t嗯，希望我也能继续保持这种态度吧，尽可能广/多/快的汲取周边的营养让自己得到快速的成长（这也算欲吧？我还是比较贪的，嗯）。_BTW，楼下一妹子哭的老凄惨了，吓死个人。_","slug":"forget-your-lusts-1","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg623x0084sb8f3nfkrqoc"},{"title":"那些英语标点怎么读","id":"115","date":"2011-03-08T07:52:59.000Z","_content":"\n+　 plus　加号；正号\n-　 minus　减号；负号\n±　plus or minus　正负号\n×　is multiplied by　乘号\n÷　is divided by　除号\n＝　is equal to　等于号\n≠　is not equal to　不等于号\n≡　is equivalent to　全等于号\n≌　is equal to or approximately equal to　等于或约等于号\n≈　is approximately equal to　约等于号\n＜　is less than　小于号\n＞　is greater than　大于号\n≮　is not less than　不小于号\n≯　is not more than　不大于号\n≤　is less than or equal to　小于或等于号\n≥　is more than or equal to　大于或等于号\n<!--more-->%　 per cent　百分之…\n‰　per mill　千分之…\n∞　infinity　无限大号\n∝　varies as　与…成比例\n√　(square) root　平方根\n∵　since; because　因为\n∴　hence　所以\n∷　equals, as (proportion)　等于，成比例\n∠　angle　角\n⌒　semicircle　半圆\n⊙　circle　圆\n○　circumference　圆周\nπ　pi 圆周率\n△　triangle　三角形\n⊥　perpendicular to　垂直于\n∪　union of　并，合集\n∩　intersection of 交，通集\n∫　the integral of …的积分\n∑　(sigma) summation of　总和\n°　degree　度\n′　minute　分\n″　second　秒\n℃　Celsius system　摄氏度\n{　open brace, open curly　左花括号\n}　close brace, close curly　右花括号\n(　open parenthesis, open paren　左圆括号\n)　close parenthesis, close paren　右圆括号\n() brakets/ parentheses　括号\n[　open bracket 左方括号\n]　close bracket 右方括号\n[] square brackets　方括号\n.　period, dot　句号，点\n|　vertical bar, vertical virgule　竖线\n&amp;　ampersand, and, reference, ref　和，引用\n*　asterisk, multiply, star, pointer　星号，乘号，星，指针\n/　slash, divide, oblique 斜线，斜杠，除号\n//　slash-slash, comment 双斜线，注释符\n#　pound　井号\n\\　backslash, sometimes escape　反斜线转义符，有时表示转义符或续行符\n~　tilde　波浪符\n.　full stop　句号\n,　comma　逗号\n:　colon　冒号\n;　semicolon　分号\n?　question mark　问号\n!　exclamation mark (英式英语) exclamation point (美式英语)\n'　apostrophe　撇号\n-　hyphen　连字号\n-- dash 破折号\n...　dots/ ellipsis　省略号\n\"　single quotation marks 单引号\n\"\"　double quotation marks 双引号\n‖ parallel 双线号\n&amp;　ampersand = and\n～　swung dash 代字号\n§　section; division 分节号\n→　arrow 箭号；参见号\n\n原文链接：http://blog.sina.com.cn/s/blog_515dc9340100gy95.html","source":"_posts/english-punctuate.md","raw":"title: 那些英语标点怎么读\ntags:\n  - 英语\nid: 115\ncategories:\n  - 生活分享\ndate: 2011-03-08 15:52:59\n---\n\n+　 plus　加号；正号\n-　 minus　减号；负号\n±　plus or minus　正负号\n×　is multiplied by　乘号\n÷　is divided by　除号\n＝　is equal to　等于号\n≠　is not equal to　不等于号\n≡　is equivalent to　全等于号\n≌　is equal to or approximately equal to　等于或约等于号\n≈　is approximately equal to　约等于号\n＜　is less than　小于号\n＞　is greater than　大于号\n≮　is not less than　不小于号\n≯　is not more than　不大于号\n≤　is less than or equal to　小于或等于号\n≥　is more than or equal to　大于或等于号\n<!--more-->%　 per cent　百分之…\n‰　per mill　千分之…\n∞　infinity　无限大号\n∝　varies as　与…成比例\n√　(square) root　平方根\n∵　since; because　因为\n∴　hence　所以\n∷　equals, as (proportion)　等于，成比例\n∠　angle　角\n⌒　semicircle　半圆\n⊙　circle　圆\n○　circumference　圆周\nπ　pi 圆周率\n△　triangle　三角形\n⊥　perpendicular to　垂直于\n∪　union of　并，合集\n∩　intersection of 交，通集\n∫　the integral of …的积分\n∑　(sigma) summation of　总和\n°　degree　度\n′　minute　分\n″　second　秒\n℃　Celsius system　摄氏度\n{　open brace, open curly　左花括号\n}　close brace, close curly　右花括号\n(　open parenthesis, open paren　左圆括号\n)　close parenthesis, close paren　右圆括号\n() brakets/ parentheses　括号\n[　open bracket 左方括号\n]　close bracket 右方括号\n[] square brackets　方括号\n.　period, dot　句号，点\n|　vertical bar, vertical virgule　竖线\n&amp;　ampersand, and, reference, ref　和，引用\n*　asterisk, multiply, star, pointer　星号，乘号，星，指针\n/　slash, divide, oblique 斜线，斜杠，除号\n//　slash-slash, comment 双斜线，注释符\n#　pound　井号\n\\　backslash, sometimes escape　反斜线转义符，有时表示转义符或续行符\n~　tilde　波浪符\n.　full stop　句号\n,　comma　逗号\n:　colon　冒号\n;　semicolon　分号\n?　question mark　问号\n!　exclamation mark (英式英语) exclamation point (美式英语)\n'　apostrophe　撇号\n-　hyphen　连字号\n-- dash 破折号\n...　dots/ ellipsis　省略号\n\"　single quotation marks 单引号\n\"\"　double quotation marks 双引号\n‖ parallel 双线号\n&amp;　ampersand = and\n～　swung dash 代字号\n§　section; division 分节号\n→　arrow 箭号；参见号\n\n原文链接：http://blog.sina.com.cn/s/blog_515dc9340100gy95.html","slug":"english-punctuate","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg623y0088sb8f9zxg4am1"},{"title":"Eclipse插件卸载","id":"140","date":"2011-05-02T15:41:05.000Z","_content":"\nJava开发工具一直用的是MyEclipse，ME虽然方便，但是总觉着大材小用。而且开启启动的插件忒多了，又要收费，所以开始慢慢转向ME的爸爸Eclipse上来了。\n\n今天在配置ADT环境，不小心多装了几个插件，找卸载按钮找了老久，最后在About里面找到了，太折腾人了，留日志Mark一下。\n\nHelp –&gt; About Eclipse SDK –&gt; Installation Details –&gt; 选择插件Uninstall –&gt; Restart –&gt; Done.\n\n顺带说句，Eclipse版本为3.6.1。","source":"_posts/eclipse-plugin-unintall.md","raw":"title: Eclipse插件卸载\ntags:\n  - Eclipse\n  - java\nid: 140\ncategories:\n  - 技术分享\ndate: 2011-05-02 23:41:05\n---\n\nJava开发工具一直用的是MyEclipse，ME虽然方便，但是总觉着大材小用。而且开启启动的插件忒多了，又要收费，所以开始慢慢转向ME的爸爸Eclipse上来了。\n\n今天在配置ADT环境，不小心多装了几个插件，找卸载按钮找了老久，最后在About里面找到了，太折腾人了，留日志Mark一下。\n\nHelp –&gt; About Eclipse SDK –&gt; Installation Details –&gt; 选择插件Uninstall –&gt; Restart –&gt; Done.\n\n顺带说句，Eclipse版本为3.6.1。","slug":"eclipse-plugin-unintall","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg6241008csb8f15ct5jre"},{"title":"Docker 插件 - Volume plugins","date":"2015-10-14T14:05:00.000Z","_content":"\n## Docker 插件是什么\n\ndocker 插件是 docker 提供出来的扩展机制，目前 docker 支持 volume 和 network 两种插件，由于 network 插件比较复杂而且没有好的开源项目，这里主要介绍 volume 插件。\n\n插件是一个独立的进程和 docker daemon 运行在同一台 host 上，通过 Plugin Discovery 的机制进行插件发现，插件有几个要求：\n\n* 插件名要求是小写\n* 插件可以运行在容器内也可以运行在容器外，不过现阶段建议运行在容器外\n\n<!-- more -->\n\n## 插件发现\n\n插件发现机制需要插件将自己的地址文件放在固定目录，方便 docker 发现插件进程，有三种文件可以设置：\n\n* `.sock` 文件是 UNIX domain sockets\n* `.spec` 文本文件内包含了一个 URL，比如：`unix:///other.sock`\n* `.json` 文本文件包含了插件的完整 JSON 描述\n\nUNIX domain socket 文件必须放在 `/run/docker/plugins` 目录，但是 `.spec`，`.json` 文件则可以放在 `/etc/docker/plugins` 或者 `/usr/lib/docker/plugins` 中。\n\n无后缀的文件名决定了插件的名字，比如 `/run/docker/plugins/myplugin.sock` 的插件名就是 `myplugin`。你可以在子目录中放置地址文件，比如 `/run/docker/plugins/myplugin/myplugin.sock`。\n\ndocker 优先搜索 `/run/docker/plugins` 目录，如果没有 unix socket 的话才会去搜索 `/etc/docker/plugins` 和 `/usr/lib/docker/plugins`，如果根据指定插件名搜到了插件就会立马停止搜索。\n\n### `.json`\n\nJSON 格式文件示例：\n\n```\n{\n  \"Name\": \"plugin-example\",\n  \"Addr\": \"https://example.com/docker/plugin\",\n  \"TLSConfig\": {\n    \"InsecureSkipVerify\": false,\n    \"CAFile\": \"/usr/shared/docker/certs/example-ca.pem\",\n    \"CertFile\": \"/usr/shared/docker/certs/example-cert.pem\",\n    \"KeyFile\": \"/usr/shared/docker/certs/example-key.pem\",\n  }\n}\n```\n\n## 插件生命周期\n\n* 启动插件\n* 启动 docker\n* 停止 docker\n* 停止插件\n\n\n## 插件激活\n\n运行命令 `docker run --volume-driver=foo` 即可以激活名为 `foo` 的 volume 插件，需要注意的是，插件是按需加载机制，只有被使用到了才会被激活。\n\n## volume 插件使用\n\n示例：\n\n```\n$ docker run -ti -v volumename:/data --volume-driver=flocker busybox sh\n```\n\n上面表示的意思是，使用 flocker 插件将 voluemname 挂载到容器的 /data 目录。\n\n注意：volumename 一定不能以 `/` 开头。（文档说的，没看 docker 源码，我实现一个以 `/` 开头好像也没问题，应该是规范吧）\n\n## 插件 API 设计\n\n插件是 API 是基于 HTTP 的 JSON POST 请求，所以插件需要实现一个 HTTP 服务器并且将其 bind 到一个 UNIX socket 上。API 的版本设置在了 HTTP\n头里面，现在这个头的固定值为：`application/vnd.docker.plugins.v1+json`\n\n不过 docker 的开发人员已经提供了一个比较好的 docker volume 的扩展 API 代码，可以参考：[docker-volume-extension-api](https://github.com/calavera/dkvolume)\n\n### `/Plugin.Activate`\n\n请求：空\n\n响应：\n\n```json\n{\n  \"Implements:\" [\"VolumeDriver\"]\n}\n```\n\n返回插件实现，表示是 volume 插件\n\n### `/VolumeDriver.Create`\n\n请求：\n\n```\n{\n    \"Name\": \"volume_name\"\n}\n```\n\n告诉插件用户想要创建一个 volume，并将用户输入的 volume 名传给插件。插件在这个时候可以不用理会这个请求，会有真正挂载的请求。\n\n响应：\n\n```\n{\n    \"Err\": null\n}\n```\n\n如果出错返回错误字符串。\n\n### `/VolumeDriver.Remove`\n\n与 Create 相对应。\n\n请求：\n\n```\n{\n    \"Name\": \"volume_name\"\n}\n```\n\n响应：\n\n```\n{\n    \"Err\": null\n}\n```\n\n\n### `/VolumeDriver.Mount`\n\n请求：\n\n```\n{\n    \"Name\": \"volume_name\"\n}\n```\n\n用户请求挂载某个文件，这个请求仅会在容器启动时发送一次。\n\n响应：\n\n```\n{\n   \"Mountpoint\": \"/path/to/directory/on/host\",\n   \"Err\": null\n}\n```\n\n将 volume_name 挂载的真正挂载点返回给 docker，如果出错则返回错误字符串。\n\n\n### `/VolumeDriver.Path`\n\n请求：\n\n```\n{\n    \"Name\": \"volume_name\"\n}\n```\n\n响应：\n\n```\n{\n   \"Mountpoint\": \"/path/to/directory/on/host\",\n   \"Err\": null\n}\n```\n\n插件需要管理 volume_name 的真正挂载地址，这个请求需要将 volume_name 挂载的真正挂载点返回给 docker，如果出错则返回错误字符串。\n\n### `/VolumeDriver.Unmount`\n\n请求：\n\n```\n{\n    \"Name\": \"volume_name\"\n}\n```\n\n表示 docker 已经不需要这个 volume 了，插件需要安全的将这个挂载从挂载点卸载。\n\n响应：\n\n```\n{\n    \"Err\": null\n}\n```\n\n\n> 参考地址：[Understand Docker plugins](https://docs.docker.com/extend/plugins/)\n","source":"_posts/docker-volume-plugin.md","raw":"title: Docker 插件 - Volume plugins\ndate: 2015-10-14 22:05:00\ncategories: 自学资料\ntags: [Docker, Docker plugins, Docker volume]\n---\n\n## Docker 插件是什么\n\ndocker 插件是 docker 提供出来的扩展机制，目前 docker 支持 volume 和 network 两种插件，由于 network 插件比较复杂而且没有好的开源项目，这里主要介绍 volume 插件。\n\n插件是一个独立的进程和 docker daemon 运行在同一台 host 上，通过 Plugin Discovery 的机制进行插件发现，插件有几个要求：\n\n* 插件名要求是小写\n* 插件可以运行在容器内也可以运行在容器外，不过现阶段建议运行在容器外\n\n<!-- more -->\n\n## 插件发现\n\n插件发现机制需要插件将自己的地址文件放在固定目录，方便 docker 发现插件进程，有三种文件可以设置：\n\n* `.sock` 文件是 UNIX domain sockets\n* `.spec` 文本文件内包含了一个 URL，比如：`unix:///other.sock`\n* `.json` 文本文件包含了插件的完整 JSON 描述\n\nUNIX domain socket 文件必须放在 `/run/docker/plugins` 目录，但是 `.spec`，`.json` 文件则可以放在 `/etc/docker/plugins` 或者 `/usr/lib/docker/plugins` 中。\n\n无后缀的文件名决定了插件的名字，比如 `/run/docker/plugins/myplugin.sock` 的插件名就是 `myplugin`。你可以在子目录中放置地址文件，比如 `/run/docker/plugins/myplugin/myplugin.sock`。\n\ndocker 优先搜索 `/run/docker/plugins` 目录，如果没有 unix socket 的话才会去搜索 `/etc/docker/plugins` 和 `/usr/lib/docker/plugins`，如果根据指定插件名搜到了插件就会立马停止搜索。\n\n### `.json`\n\nJSON 格式文件示例：\n\n```\n{\n  \"Name\": \"plugin-example\",\n  \"Addr\": \"https://example.com/docker/plugin\",\n  \"TLSConfig\": {\n    \"InsecureSkipVerify\": false,\n    \"CAFile\": \"/usr/shared/docker/certs/example-ca.pem\",\n    \"CertFile\": \"/usr/shared/docker/certs/example-cert.pem\",\n    \"KeyFile\": \"/usr/shared/docker/certs/example-key.pem\",\n  }\n}\n```\n\n## 插件生命周期\n\n* 启动插件\n* 启动 docker\n* 停止 docker\n* 停止插件\n\n\n## 插件激活\n\n运行命令 `docker run --volume-driver=foo` 即可以激活名为 `foo` 的 volume 插件，需要注意的是，插件是按需加载机制，只有被使用到了才会被激活。\n\n## volume 插件使用\n\n示例：\n\n```\n$ docker run -ti -v volumename:/data --volume-driver=flocker busybox sh\n```\n\n上面表示的意思是，使用 flocker 插件将 voluemname 挂载到容器的 /data 目录。\n\n注意：volumename 一定不能以 `/` 开头。（文档说的，没看 docker 源码，我实现一个以 `/` 开头好像也没问题，应该是规范吧）\n\n## 插件 API 设计\n\n插件是 API 是基于 HTTP 的 JSON POST 请求，所以插件需要实现一个 HTTP 服务器并且将其 bind 到一个 UNIX socket 上。API 的版本设置在了 HTTP\n头里面，现在这个头的固定值为：`application/vnd.docker.plugins.v1+json`\n\n不过 docker 的开发人员已经提供了一个比较好的 docker volume 的扩展 API 代码，可以参考：[docker-volume-extension-api](https://github.com/calavera/dkvolume)\n\n### `/Plugin.Activate`\n\n请求：空\n\n响应：\n\n```json\n{\n  \"Implements:\" [\"VolumeDriver\"]\n}\n```\n\n返回插件实现，表示是 volume 插件\n\n### `/VolumeDriver.Create`\n\n请求：\n\n```\n{\n    \"Name\": \"volume_name\"\n}\n```\n\n告诉插件用户想要创建一个 volume，并将用户输入的 volume 名传给插件。插件在这个时候可以不用理会这个请求，会有真正挂载的请求。\n\n响应：\n\n```\n{\n    \"Err\": null\n}\n```\n\n如果出错返回错误字符串。\n\n### `/VolumeDriver.Remove`\n\n与 Create 相对应。\n\n请求：\n\n```\n{\n    \"Name\": \"volume_name\"\n}\n```\n\n响应：\n\n```\n{\n    \"Err\": null\n}\n```\n\n\n### `/VolumeDriver.Mount`\n\n请求：\n\n```\n{\n    \"Name\": \"volume_name\"\n}\n```\n\n用户请求挂载某个文件，这个请求仅会在容器启动时发送一次。\n\n响应：\n\n```\n{\n   \"Mountpoint\": \"/path/to/directory/on/host\",\n   \"Err\": null\n}\n```\n\n将 volume_name 挂载的真正挂载点返回给 docker，如果出错则返回错误字符串。\n\n\n### `/VolumeDriver.Path`\n\n请求：\n\n```\n{\n    \"Name\": \"volume_name\"\n}\n```\n\n响应：\n\n```\n{\n   \"Mountpoint\": \"/path/to/directory/on/host\",\n   \"Err\": null\n}\n```\n\n插件需要管理 volume_name 的真正挂载地址，这个请求需要将 volume_name 挂载的真正挂载点返回给 docker，如果出错则返回错误字符串。\n\n### `/VolumeDriver.Unmount`\n\n请求：\n\n```\n{\n    \"Name\": \"volume_name\"\n}\n```\n\n表示 docker 已经不需要这个 volume 了，插件需要安全的将这个挂载从挂载点卸载。\n\n响应：\n\n```\n{\n    \"Err\": null\n}\n```\n\n\n> 参考地址：[Understand Docker plugins](https://docs.docker.com/extend/plugins/)\n","slug":"docker-volume-plugin","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg6243008hsb8fta1bt7k9"},{"title":"Docker Compose 最佳实践","date":"2015-10-08T12:00:00.000Z","_content":"\n## docker-compose 小功能\n\n* daemon 模式\n\n`docker-compose up -d`\n\n* 设置 container 的名字\n\n显式设置 container 的名字：[Issue 讨论](https://github.com/docker/compose/pull/1711), [yml.md: container_name](https://github.com/docker/compose/blob/master/docs/yml.md#container_name)\n\n    * 设置了这个的话，scale 能力就无法使用了\n    * container 名字默认格式：${PROJECT}-${NAME}-${sacle_num}\n\n## docker-compose 的问题\n\n* 无法给 yml 传递参数 [Issue 讨论](https://github.com/docker/compose/issues/1377)，好像有[解决方案](https://github.com/docker/compose/blob/master/docs/yml.md#variable-substitution)，不过不好用\n* 无法给 container 之间加依赖 [Issue](https://github.com/docker/compose/issues/374)\n* 仅能控制多个 container 的启动和关系，如果有初始化任务（如DB 初始化），还需要额外写脚本文件\n* docker-compose 和 docker-swarm 集成还在开发中：https://github.com/docker/compose/blob/master/SWARM.md\n","source":"_posts/docker-compose-pratice.md","raw":"title: Docker Compose 最佳实践\ndate: 2015-10-08 20:00:00\ncategories: 最佳实践\ntags: [Docker, Docker Compose]\n---\n\n## docker-compose 小功能\n\n* daemon 模式\n\n`docker-compose up -d`\n\n* 设置 container 的名字\n\n显式设置 container 的名字：[Issue 讨论](https://github.com/docker/compose/pull/1711), [yml.md: container_name](https://github.com/docker/compose/blob/master/docs/yml.md#container_name)\n\n    * 设置了这个的话，scale 能力就无法使用了\n    * container 名字默认格式：${PROJECT}-${NAME}-${sacle_num}\n\n## docker-compose 的问题\n\n* 无法给 yml 传递参数 [Issue 讨论](https://github.com/docker/compose/issues/1377)，好像有[解决方案](https://github.com/docker/compose/blob/master/docs/yml.md#variable-substitution)，不过不好用\n* 无法给 container 之间加依赖 [Issue](https://github.com/docker/compose/issues/374)\n* 仅能控制多个 container 的启动和关系，如果有初始化任务（如DB 初始化），还需要额外写脚本文件\n* docker-compose 和 docker-swarm 集成还在开发中：https://github.com/docker/compose/blob/master/SWARM.md\n","slug":"docker-compose-pratice","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg6247008qsb8fmkuz8kqu"},{"title":"数码产品屏幕分辨率汇总","id":"141","date":"2011-06-07T15:12:59.000Z","_content":"\n### VGA\n\nVGA(Video Graphics Array)是IBM在1987年随PS／2机一起推出的一种视频传输标准，具有分辨率高、显示速率快、颜色丰富等优点，在彩色显示器领域得到了广泛的应用。一般来说，分辨率为640×480。\n\n<!--more-->**QVGA**\n\n**QVGA**即“**Q**uarter **VGA**”。顾名思义即VGA的四分之一尺寸，亦即在液晶屏幕（LCD）上输出的分辨率是320×240像素。\n\n### HVGA\n\n**HVGA**即“**H**alf-size **VGA**”，是VGA(640*480)的一半，分辨率为(480*320)，(3:2宽高比)。\n\n### WQVGA\n\n**WQVGA**即“**W**ide **Q**uarter **VGA**”，数码产品屏幕分辨率的一种，代表480X272（宽高比16：9）或者400X240（宽高比5：3）的屏幕分辨率，而不是国内厂商标称的480X240。\n\n### WVGA\n\n**WVGA**即“**W**ide **VGA**”，是数码产品屏幕分辨率的一种，比VGA分辨率高。WVGA的分辨率达到了800×480像素。\n\n### FWVGA\n\n**FWVGA**即“**F**ull **W**ide **VGA**”，数码产品屏幕材质的一种，VGA的另一种形式，比WVGA分辨率高，其分辨率为854×480象素(16:9)。是扩大了WVGA（800×480)的分辨率(15:9)。应用于PDA和Android手机等，专为手提设备浏览网页设计,是未来手持设备的分辨率的大趋势。\n> 参考资料：[百度百科](http://baike.baidu.com)","source":"_posts/ditital-screen.md","raw":"title: 数码产品屏幕分辨率汇总\ntags:\n  - 数码\nid: 141\ncategories:\n  - 技术分享\n  - 生活分享\ndate: 2011-06-07 23:12:59\n---\n\n### VGA\n\nVGA(Video Graphics Array)是IBM在1987年随PS／2机一起推出的一种视频传输标准，具有分辨率高、显示速率快、颜色丰富等优点，在彩色显示器领域得到了广泛的应用。一般来说，分辨率为640×480。\n\n<!--more-->**QVGA**\n\n**QVGA**即“**Q**uarter **VGA**”。顾名思义即VGA的四分之一尺寸，亦即在液晶屏幕（LCD）上输出的分辨率是320×240像素。\n\n### HVGA\n\n**HVGA**即“**H**alf-size **VGA**”，是VGA(640*480)的一半，分辨率为(480*320)，(3:2宽高比)。\n\n### WQVGA\n\n**WQVGA**即“**W**ide **Q**uarter **VGA**”，数码产品屏幕分辨率的一种，代表480X272（宽高比16：9）或者400X240（宽高比5：3）的屏幕分辨率，而不是国内厂商标称的480X240。\n\n### WVGA\n\n**WVGA**即“**W**ide **VGA**”，是数码产品屏幕分辨率的一种，比VGA分辨率高。WVGA的分辨率达到了800×480像素。\n\n### FWVGA\n\n**FWVGA**即“**F**ull **W**ide **VGA**”，数码产品屏幕材质的一种，VGA的另一种形式，比WVGA分辨率高，其分辨率为854×480象素(16:9)。是扩大了WVGA（800×480)的分辨率(15:9)。应用于PDA和Android手机等，专为手提设备浏览网页设计,是未来手持设备的分辨率的大趋势。\n> 参考资料：[百度百科](http://baike.baidu.com)","slug":"ditital-screen","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg6249008vsb8ftjncozzm"},{"title":"分布式文件系统元数据服务器模型","id":"163","date":"2011-10-01T02:21:35.000Z","_content":"\n随着非结构化数据的爆炸，分布式文件系统进入了发展的黄金时期，从高性能计算到数据中心，从数据共享到互联网应用，已经渗透到数据应用的各方各面。对于大多数分布式文件系统(或集群文件系统，或并行文件系统)而言，通常将元数据与数据两者独立开来，即控制流与数据流进行分离，从而获得更高的系统扩展性和I/O并发性。因而，元数据管理模型显得至关重要，直接影响到系统的扩展性、性能、可靠性和稳定性等。存储系统要具有很高的Scale-Out特性，最大的挑战之一就是记录数据逻辑与物理位置的映像关系即数据元数据，还包括诸如属性和访问权限等信息。特别是对于海量小文件的应用，元数据问题是个非常大的挑战。总体来说，分布式文件系统的元数据管理方式大致可以分为三种模型，即集中式元数据服务模型、分布式元数据服务模型和无元数据服务模型。在学术界和工业界，这三种模型一直存在争议，各有优势和不足之处，实际系统实现中也难分优劣。实际上，设计出一个能够适用各种数据应用负载的通用分布式文件系统，这种想法本来就是不现实的。从这个意义上看，这三种元数据服务模型都有各自存在的理由，至少是在它适用的数据存储应用领域之内。\n\n<!--more-->\n\n**集中式元数据服务模型**\n\n分布式文件系统中，数据和I/O访问负载被分散到多个物理独立的存储和计算节点，从而实现系统的高扩展性和高性能。对于一组文件，如果以文件为单位进行调度，则不同的文件会存储在不同的节点上；或者以Stripe方式进行存储，则一个文件会分成多个部分存放在多个节点。显然，我们面临的一个关键问题就是如何确保对数据进行正确定位和访问，元数据服务正是用来解决这个问题的。元数据服务记录数据逻辑名字与物理信息的映射关系，包含文件访问控制所需要的所有元数据，对文件进行访问时，先向元数据服务请求查询对应的元数据，然后通过获得的元数据进行后续的文件读写等I/O操作。\n\n出于简化系统设计复杂性的考虑，并且由于大量的历史遗留系统等原因，大多数分布式文件系统采用了集中式的元数据服务，如Lustre, PVFS, StorNext, GFS等。集中式元数据服务模型，通常提供一个中央元数据服务器负责元数据的存储和客户端查询请求，它提供统一的文件系统命名空间，并处理名字解析和数据定位等访问控制功能。传统的NAS系统中，I/O数据流需要经过服务器，而分布式文件系统中，I/O数据流不需要经过元数据服务器，由客户端与存储节点直接交互。这个架构上的变革，使得控制流与数据流分离开来，元数据服务器和存储服务器各司其职，系统扩展性和性能上获得了极大的提升。显而易见，集中式元数据服务模型的最大优点就是设计实现简单，本质上相当于设计一个单机应用程序，对外提供网络访问接口即可，如Socket, RPC, HTTP REST或SOAP等。元数据服务设计实现的关键是OPS吞吐量，即单位时间处理的操作数，这对集中式元数据服务模型尤其关键，因为会受到系统Scale-Up方面的限制。为了优化OPS，该模型对CPU、内存、磁盘要求较高，条件允许的情况下尽量使用高性能CPU、大内存和高速磁盘，甚至后端存储可考虑使用高端磁盘阵列或SSD。在软件架构方面设计，应该考虑多进程/线程(池)、异步通信、Cache、事件驱动等实现机制。至于分布式文件系统名字空间的设计实现，请参考“[分布式文件系统名字空间实现研究](http://blog.csdn.net/liuben/article/details/5993604)”一文，这里不再讨论。实际上，集中式元数据服务模型的缺点同样突出，其中两个最为关键的是性能瓶颈和单点故障问题。\n\n性能瓶颈，这种模型下元数据服务器在负载不断增大时将很快成为整个系统性能的瓶颈。根据Amdahl定律，系统性能加速比最终受制于串行部分的比重，这决定了系统使用并行手段所能改进性能的潜力。这里，元数据服务器就是串行的部分，它直接决定着系统的扩展规模和性能。文件元数据的基本特性要求它必须同步地进行维护和更新，任何时候对文件数据或元数据进行操作时，都需要同步更新元数据。例如，文件的访问时间，即使是读操作或列目录都需要对它进行更新。客户端访问分布式文件系统时，都需要先与元数据服务器进行交互，这包括命名空间解析、数据定位、访问控制等，然后才直接与存储节点进行I/O交互。随着系统规模不断扩大，存储节点、磁盘数量、文件数量、客户端数据、文件操作数量等都将急剧增加，而运行元数据服务器的物理服务器性能毕竟终究有限，因此集中式元数据服务器将最终成为性能瓶颈。对于众所周知的LOSF(Lots of Small Files)应用，文件数量众多而且文件很小，通常都是几KB至几十KB的小文件，比如CDN和生命科学DNA数据应用，集中式元数据服务模型的性能瓶颈问题更加严重。LOSF应用主要是大量的元数据操作，元数据服务器一旦出现性能问题，直接导致极低的OPS和I/O吞吐量。目前，以这种模型实现的分布式文件系统都不适合LOSF应用，比如Lustre, PVFS, GFS。\n\n实际上，性能瓶颈问题没有想像中的那么严重，Lustre, StorNext, GFS等在大文件应用下性能极高，StorNext甚至在小文件应该下性能也表现良好。一方面，首先应该尽量避免应用于LOSF，除非对性能要求极低。其次，对于大文件应用，更加强调I/O数据吞吐量，元数据操作所占比例非常小。文件很大时，元数据数量将显著降低，而且系统更多时间是在进行数据传输，元数据服务器压力大幅下降。这种情形下，基本上不存在性能瓶颈问题了。再者，如果出现性能瓶颈问题，在系统可以承载的最大负载前提下，可以对元数据服务器进行性能优化。优化最为直接的方法是升级硬件，比如CPU、内存、存储、网络，摩尔定律目前仍然是有效的。系统级优化通常也是有效的，包括OS裁剪和参数优化，这方面有很大提升空间。元数据服务器设计本身的优化才是最为关键的，它可以帮助用户节约成本、简化维护和管理，优化的方法主要包括数据局部性、Cache、异步I/O等，旨在提高并发性、减少磁盘I/O访问、降低请求处理时间。因此，在非常多的数据应用下，集中式元数据服务器的性能并不是大问题，或者通过性能优化可以解决的。\n\n单点故障(SPOF，Single Point of Failure)，这个问题看上去要比性能瓶颈更加严重。整个系统严重依赖于元数据服务器，一旦出现问题，系统将变得完全不可用，直接导致应用 中断并影响业务连续性。物理服务器所涉及的网络、计算和存储部件以及软件都有可能发生故障，因此单点故障问题潜在的，采用更优的硬件和软件只能降低发生的概率而无法避免。目前，SPOF问题主要是采用HA机制来解决，根据可用性要求的高低，镜像一个或多个元数据服务器(逻辑的或物理的均可)，构成一个元数据服务HA集群。集群中一台作为主元数据服务器，接受和处理来自客户端的请求，并与其他服务器保持同步。当主元数据服务器发生问题时，自动选择一台可用服务器作为新的主服务器，这一过程对上层应用是透明的，不会产生业务中断。HA机制能够解决SPOF问题，但同时增加了成本开销，只有主服务器是活动的，其他服务器均处于非活动状态，对性能提升没有任何帮助。\n\n**分布式元数据服务模型**\n\n自然地有人提出了分布式元数据服务模型，顾名思义就是使用多台服务器构成集群协同为分布式文件系统提供元数据服务，从而消除集中式元数据服务模型的性能瓶颈和单点故障问题。这种模型可以细分为两类，一为全对等模式，即集群中的每个元数据服务器是完全对等的，每个都可以独立对外提供元数据服务，然后集群内部进行元数据同步，保持数据一致性，比如ISILON、LoongStore、CZSS等。另一类为全分布模式，集群中的每个元数据服务器负责部分元数据服务(分区可以重叠)，共同构成完整的元数据服务，比如PanFS, GPFS, Ceph等。分布式元数据服务模型，将负载分散到多台服务器解决了性能瓶颈问题，利用对等的服务器或冗余元数据服务分区解决了单点故障问题。分布式看似非常完善，然而它大大增加了设计实现上的复杂性，同时可能会引入了新的问题，即性能开销和数据一致性问题。\n\n性能开销，分布式系统通常会引由于节点之间的数据同步而引入额外开销，这是因为同步过程中需要使用各种锁和同步机制，以保证数据一致性。如果节点同步问题处理不当，性能开销将对系统扩展性和性能产生较大影响，和集中式元数据模型一样形成性能瓶颈，这就对分布式元数据服务器的设计提出了更高的要求。这种性能开销会抵消一部分采用分布式所带来的性能提升，而且随着元数据服务器数量、文件数量、文件操作、存储系统规模、磁盘数量、文件大小变小、I/O操作随机性等增加而加剧。另外，元数据服务器规模较大时，高并发性元数据访问会导致同步性能开销更加显著。目前，一些分布式文件系统采用高性能网络(如InfiniBand, GibE等)、SSD固态硬盘或SAN磁盘阵列、分布式共享内存(SMP或ccNUMA)等技术进行集群内部的元数据同步和通信。这的确可以明显提高系统性能以抵消同步开销，不过成本方面也徒然增加许多。\n\n数据一致性，这是分布式系统必须面对的难题。分布式元数据服务模型同样面临潜在的系统发生错误的风险，虽然一部分元数据节点发生故障不会致使整个系统宕机，但却可能影响整个系统正常运行或出现访问错误。为了保证高可用性，元数据会被复制到多个节点位置，维护多个副本之间的同步具有很高的风险。如果元数据没有及时同步或者遭受意外破坏，同一个文件的元数据就会出现不一致，从而导致访问文件数据的不一致，直接影响到上层数据应用的正确性。这种风险发生的概率随着系统规模的扩大而大幅增加，因此分布式元数据的同步和并发访问是个巨大的挑战。使用同步方法对元数据进行同步，再结合事务或日志，自然可以解决数据一致性问题，然而这大大降低了系统的并发性，违背了分布式系统的设计初衷。在保证元数据一致性的前提下，尽可能地提高并发性，这就对同步机制和算法设计方面提出了严格要求，复杂性和挑战性不言而喻。\n\n**无元数据服务模型**\n\n既然集中式或分布式元数据服务模型都不能彻底地解决问题，那么直接去掉元数据服务器，是否就可以避免这些问题呢？理论上，无元数据服务模型是完全可行的，寻找到元数据查询定位的替代方法即可。理想情况下，这种模型消除了元数据的性能瓶颈、单点故障、数据一致性等一系列相关问题，系统扩展性显著提高，系统并发性和性能将实现线性扩展增长。目前，基于无元数据服务模型的分布式文件系统可谓凤毛麟角，Glusterfs是其中最为典型的代表。\n\n对于分布式系统而言，元数据处理是决定系统扩展性、性能以及稳定性的关键。GlusterFS另辟蹊径，彻底摒弃了元数据服务，使用弹性哈希算法代替传统分布式文件系统中的集中或分布式元数据服务。这根本性解决了元数据这一难题，从而获得了接近线性的高扩展性，同时也提高了系统性能和可靠性。GlusterFS使用算法进行数据定位，集群中的任何服务器和客户端只需根据路径和文件名就可以对数据进行定位和读写访问。换句话说，GlusterFS不需要将元数据与数据进行分离，因为文件定位可独立并行化进行。GlusterFS独特地采用无元数据服务的设计，取而代之使用算法来定位文件，元数据和数据没有分离而是一起存储。集群中的所有存储系统服务器都可以智能地对文件数据分片进行定位，仅仅根据文件名和路径并运用算法即可，而不需要查询索引或者其他服务器。这使得数据访问完全并行化，从而实现真正的线性性能扩展。无元数据服务器极大提高了GlusterFS的性能、可靠性和稳定性。(Glusterfs更深入地分析请参考“[Glusterfs集群文件系统研究](http://blog.csdn.net/liuben/article/details/6284551)”一文)。\n\n无元数据服务器设计的好处是没有单点故障和性能瓶颈问题，可提高系统扩展性、性能、可靠性和稳定性。对于海量小文件应用，这种设计能够有效解决元数据的难点问题。它的负面影响是，数据一致问题更加复杂，文件目录遍历操作效率低下，缺乏全局监控管理功能。同时也导致客户端承担了更多的职能，比如文件定位、名字空间缓存、逻辑卷视图维护等等，这些都增加了客户端的负载，占用相当的CPU和内存。\n\n**三种元数据服务模型比较**\n\n对Scale-Out存储系统而言，最大的挑战之一就是记录数据逻辑与物理位置的映像关系，即数据元数据。传统分布式存储系统使用集中式或布式元数据服务来维护元数据，集中式元数据服务会导致单点故障和性能瓶颈问题，而分布式元数据服务存在性能开销、元数据同步一致性和设计复杂性等问题。无元数据服务模型，消除了元数据访问问题，但同时增加了数据本身管理的复杂性，缺乏全局监控管理功能，并增加了客户端的负载。由此可见，这三种模型都不是完美的，分别有各自的优点和不足，没有绝对的优劣与好坏之分，实际选型要根据具体情况选择合适的模型，并想方设法完善其不足之处，从而提高分布式文件系统的扩展性、高性能、可用性等特性。集中式元数据服务模型的代表是Lustre, StorNext, GFS等，分布式元数据服务模型的典型案例有ISILON, GPFS, Ceph等，Glustrefs是无元数据服务模型的经典。以上这些都是非常强大的分布式文件系统，它们是非常好的设计典范。这也足以说明，架构固然非常关键，但具体实现技术却往往决定最后的结局。\n\n**补充阅读**\n[1] Ceph, [http://www.ibm.com/developerworks/cn/linux/l-ceph/index.html?ca=drs-](http://www.ibm.com/developerworks/cn/linux/l-ceph/index.html?ca=drs-)\n[2] Glusterfs, [http://blog.csdn.net/liuben/article/details/6284551](http://blog.csdn.net/liuben/article/details/6284551)\n[3] 集群NAS技术架构，[http://blog.csdn.net/liuben/article/details/6422700](http://blog.csdn.net/liuben/article/details/6422700)\n> **转载：**[**刘爱贵的专栏**](http://blog.csdn.net/liuben/article/details/6749188)","source":"_posts/dist-filesystem-metadata-server.md","raw":"title: 分布式文件系统元数据服务器模型\ntags:\n  - 分布式\nid: 163\ncategories:\n  - 技术分享\ndate: 2011-10-01 10:21:35\n---\n\n随着非结构化数据的爆炸，分布式文件系统进入了发展的黄金时期，从高性能计算到数据中心，从数据共享到互联网应用，已经渗透到数据应用的各方各面。对于大多数分布式文件系统(或集群文件系统，或并行文件系统)而言，通常将元数据与数据两者独立开来，即控制流与数据流进行分离，从而获得更高的系统扩展性和I/O并发性。因而，元数据管理模型显得至关重要，直接影响到系统的扩展性、性能、可靠性和稳定性等。存储系统要具有很高的Scale-Out特性，最大的挑战之一就是记录数据逻辑与物理位置的映像关系即数据元数据，还包括诸如属性和访问权限等信息。特别是对于海量小文件的应用，元数据问题是个非常大的挑战。总体来说，分布式文件系统的元数据管理方式大致可以分为三种模型，即集中式元数据服务模型、分布式元数据服务模型和无元数据服务模型。在学术界和工业界，这三种模型一直存在争议，各有优势和不足之处，实际系统实现中也难分优劣。实际上，设计出一个能够适用各种数据应用负载的通用分布式文件系统，这种想法本来就是不现实的。从这个意义上看，这三种元数据服务模型都有各自存在的理由，至少是在它适用的数据存储应用领域之内。\n\n<!--more-->\n\n**集中式元数据服务模型**\n\n分布式文件系统中，数据和I/O访问负载被分散到多个物理独立的存储和计算节点，从而实现系统的高扩展性和高性能。对于一组文件，如果以文件为单位进行调度，则不同的文件会存储在不同的节点上；或者以Stripe方式进行存储，则一个文件会分成多个部分存放在多个节点。显然，我们面临的一个关键问题就是如何确保对数据进行正确定位和访问，元数据服务正是用来解决这个问题的。元数据服务记录数据逻辑名字与物理信息的映射关系，包含文件访问控制所需要的所有元数据，对文件进行访问时，先向元数据服务请求查询对应的元数据，然后通过获得的元数据进行后续的文件读写等I/O操作。\n\n出于简化系统设计复杂性的考虑，并且由于大量的历史遗留系统等原因，大多数分布式文件系统采用了集中式的元数据服务，如Lustre, PVFS, StorNext, GFS等。集中式元数据服务模型，通常提供一个中央元数据服务器负责元数据的存储和客户端查询请求，它提供统一的文件系统命名空间，并处理名字解析和数据定位等访问控制功能。传统的NAS系统中，I/O数据流需要经过服务器，而分布式文件系统中，I/O数据流不需要经过元数据服务器，由客户端与存储节点直接交互。这个架构上的变革，使得控制流与数据流分离开来，元数据服务器和存储服务器各司其职，系统扩展性和性能上获得了极大的提升。显而易见，集中式元数据服务模型的最大优点就是设计实现简单，本质上相当于设计一个单机应用程序，对外提供网络访问接口即可，如Socket, RPC, HTTP REST或SOAP等。元数据服务设计实现的关键是OPS吞吐量，即单位时间处理的操作数，这对集中式元数据服务模型尤其关键，因为会受到系统Scale-Up方面的限制。为了优化OPS，该模型对CPU、内存、磁盘要求较高，条件允许的情况下尽量使用高性能CPU、大内存和高速磁盘，甚至后端存储可考虑使用高端磁盘阵列或SSD。在软件架构方面设计，应该考虑多进程/线程(池)、异步通信、Cache、事件驱动等实现机制。至于分布式文件系统名字空间的设计实现，请参考“[分布式文件系统名字空间实现研究](http://blog.csdn.net/liuben/article/details/5993604)”一文，这里不再讨论。实际上，集中式元数据服务模型的缺点同样突出，其中两个最为关键的是性能瓶颈和单点故障问题。\n\n性能瓶颈，这种模型下元数据服务器在负载不断增大时将很快成为整个系统性能的瓶颈。根据Amdahl定律，系统性能加速比最终受制于串行部分的比重，这决定了系统使用并行手段所能改进性能的潜力。这里，元数据服务器就是串行的部分，它直接决定着系统的扩展规模和性能。文件元数据的基本特性要求它必须同步地进行维护和更新，任何时候对文件数据或元数据进行操作时，都需要同步更新元数据。例如，文件的访问时间，即使是读操作或列目录都需要对它进行更新。客户端访问分布式文件系统时，都需要先与元数据服务器进行交互，这包括命名空间解析、数据定位、访问控制等，然后才直接与存储节点进行I/O交互。随着系统规模不断扩大，存储节点、磁盘数量、文件数量、客户端数据、文件操作数量等都将急剧增加，而运行元数据服务器的物理服务器性能毕竟终究有限，因此集中式元数据服务器将最终成为性能瓶颈。对于众所周知的LOSF(Lots of Small Files)应用，文件数量众多而且文件很小，通常都是几KB至几十KB的小文件，比如CDN和生命科学DNA数据应用，集中式元数据服务模型的性能瓶颈问题更加严重。LOSF应用主要是大量的元数据操作，元数据服务器一旦出现性能问题，直接导致极低的OPS和I/O吞吐量。目前，以这种模型实现的分布式文件系统都不适合LOSF应用，比如Lustre, PVFS, GFS。\n\n实际上，性能瓶颈问题没有想像中的那么严重，Lustre, StorNext, GFS等在大文件应用下性能极高，StorNext甚至在小文件应该下性能也表现良好。一方面，首先应该尽量避免应用于LOSF，除非对性能要求极低。其次，对于大文件应用，更加强调I/O数据吞吐量，元数据操作所占比例非常小。文件很大时，元数据数量将显著降低，而且系统更多时间是在进行数据传输，元数据服务器压力大幅下降。这种情形下，基本上不存在性能瓶颈问题了。再者，如果出现性能瓶颈问题，在系统可以承载的最大负载前提下，可以对元数据服务器进行性能优化。优化最为直接的方法是升级硬件，比如CPU、内存、存储、网络，摩尔定律目前仍然是有效的。系统级优化通常也是有效的，包括OS裁剪和参数优化，这方面有很大提升空间。元数据服务器设计本身的优化才是最为关键的，它可以帮助用户节约成本、简化维护和管理，优化的方法主要包括数据局部性、Cache、异步I/O等，旨在提高并发性、减少磁盘I/O访问、降低请求处理时间。因此，在非常多的数据应用下，集中式元数据服务器的性能并不是大问题，或者通过性能优化可以解决的。\n\n单点故障(SPOF，Single Point of Failure)，这个问题看上去要比性能瓶颈更加严重。整个系统严重依赖于元数据服务器，一旦出现问题，系统将变得完全不可用，直接导致应用 中断并影响业务连续性。物理服务器所涉及的网络、计算和存储部件以及软件都有可能发生故障，因此单点故障问题潜在的，采用更优的硬件和软件只能降低发生的概率而无法避免。目前，SPOF问题主要是采用HA机制来解决，根据可用性要求的高低，镜像一个或多个元数据服务器(逻辑的或物理的均可)，构成一个元数据服务HA集群。集群中一台作为主元数据服务器，接受和处理来自客户端的请求，并与其他服务器保持同步。当主元数据服务器发生问题时，自动选择一台可用服务器作为新的主服务器，这一过程对上层应用是透明的，不会产生业务中断。HA机制能够解决SPOF问题，但同时增加了成本开销，只有主服务器是活动的，其他服务器均处于非活动状态，对性能提升没有任何帮助。\n\n**分布式元数据服务模型**\n\n自然地有人提出了分布式元数据服务模型，顾名思义就是使用多台服务器构成集群协同为分布式文件系统提供元数据服务，从而消除集中式元数据服务模型的性能瓶颈和单点故障问题。这种模型可以细分为两类，一为全对等模式，即集群中的每个元数据服务器是完全对等的，每个都可以独立对外提供元数据服务，然后集群内部进行元数据同步，保持数据一致性，比如ISILON、LoongStore、CZSS等。另一类为全分布模式，集群中的每个元数据服务器负责部分元数据服务(分区可以重叠)，共同构成完整的元数据服务，比如PanFS, GPFS, Ceph等。分布式元数据服务模型，将负载分散到多台服务器解决了性能瓶颈问题，利用对等的服务器或冗余元数据服务分区解决了单点故障问题。分布式看似非常完善，然而它大大增加了设计实现上的复杂性，同时可能会引入了新的问题，即性能开销和数据一致性问题。\n\n性能开销，分布式系统通常会引由于节点之间的数据同步而引入额外开销，这是因为同步过程中需要使用各种锁和同步机制，以保证数据一致性。如果节点同步问题处理不当，性能开销将对系统扩展性和性能产生较大影响，和集中式元数据模型一样形成性能瓶颈，这就对分布式元数据服务器的设计提出了更高的要求。这种性能开销会抵消一部分采用分布式所带来的性能提升，而且随着元数据服务器数量、文件数量、文件操作、存储系统规模、磁盘数量、文件大小变小、I/O操作随机性等增加而加剧。另外，元数据服务器规模较大时，高并发性元数据访问会导致同步性能开销更加显著。目前，一些分布式文件系统采用高性能网络(如InfiniBand, GibE等)、SSD固态硬盘或SAN磁盘阵列、分布式共享内存(SMP或ccNUMA)等技术进行集群内部的元数据同步和通信。这的确可以明显提高系统性能以抵消同步开销，不过成本方面也徒然增加许多。\n\n数据一致性，这是分布式系统必须面对的难题。分布式元数据服务模型同样面临潜在的系统发生错误的风险，虽然一部分元数据节点发生故障不会致使整个系统宕机，但却可能影响整个系统正常运行或出现访问错误。为了保证高可用性，元数据会被复制到多个节点位置，维护多个副本之间的同步具有很高的风险。如果元数据没有及时同步或者遭受意外破坏，同一个文件的元数据就会出现不一致，从而导致访问文件数据的不一致，直接影响到上层数据应用的正确性。这种风险发生的概率随着系统规模的扩大而大幅增加，因此分布式元数据的同步和并发访问是个巨大的挑战。使用同步方法对元数据进行同步，再结合事务或日志，自然可以解决数据一致性问题，然而这大大降低了系统的并发性，违背了分布式系统的设计初衷。在保证元数据一致性的前提下，尽可能地提高并发性，这就对同步机制和算法设计方面提出了严格要求，复杂性和挑战性不言而喻。\n\n**无元数据服务模型**\n\n既然集中式或分布式元数据服务模型都不能彻底地解决问题，那么直接去掉元数据服务器，是否就可以避免这些问题呢？理论上，无元数据服务模型是完全可行的，寻找到元数据查询定位的替代方法即可。理想情况下，这种模型消除了元数据的性能瓶颈、单点故障、数据一致性等一系列相关问题，系统扩展性显著提高，系统并发性和性能将实现线性扩展增长。目前，基于无元数据服务模型的分布式文件系统可谓凤毛麟角，Glusterfs是其中最为典型的代表。\n\n对于分布式系统而言，元数据处理是决定系统扩展性、性能以及稳定性的关键。GlusterFS另辟蹊径，彻底摒弃了元数据服务，使用弹性哈希算法代替传统分布式文件系统中的集中或分布式元数据服务。这根本性解决了元数据这一难题，从而获得了接近线性的高扩展性，同时也提高了系统性能和可靠性。GlusterFS使用算法进行数据定位，集群中的任何服务器和客户端只需根据路径和文件名就可以对数据进行定位和读写访问。换句话说，GlusterFS不需要将元数据与数据进行分离，因为文件定位可独立并行化进行。GlusterFS独特地采用无元数据服务的设计，取而代之使用算法来定位文件，元数据和数据没有分离而是一起存储。集群中的所有存储系统服务器都可以智能地对文件数据分片进行定位，仅仅根据文件名和路径并运用算法即可，而不需要查询索引或者其他服务器。这使得数据访问完全并行化，从而实现真正的线性性能扩展。无元数据服务器极大提高了GlusterFS的性能、可靠性和稳定性。(Glusterfs更深入地分析请参考“[Glusterfs集群文件系统研究](http://blog.csdn.net/liuben/article/details/6284551)”一文)。\n\n无元数据服务器设计的好处是没有单点故障和性能瓶颈问题，可提高系统扩展性、性能、可靠性和稳定性。对于海量小文件应用，这种设计能够有效解决元数据的难点问题。它的负面影响是，数据一致问题更加复杂，文件目录遍历操作效率低下，缺乏全局监控管理功能。同时也导致客户端承担了更多的职能，比如文件定位、名字空间缓存、逻辑卷视图维护等等，这些都增加了客户端的负载，占用相当的CPU和内存。\n\n**三种元数据服务模型比较**\n\n对Scale-Out存储系统而言，最大的挑战之一就是记录数据逻辑与物理位置的映像关系，即数据元数据。传统分布式存储系统使用集中式或布式元数据服务来维护元数据，集中式元数据服务会导致单点故障和性能瓶颈问题，而分布式元数据服务存在性能开销、元数据同步一致性和设计复杂性等问题。无元数据服务模型，消除了元数据访问问题，但同时增加了数据本身管理的复杂性，缺乏全局监控管理功能，并增加了客户端的负载。由此可见，这三种模型都不是完美的，分别有各自的优点和不足，没有绝对的优劣与好坏之分，实际选型要根据具体情况选择合适的模型，并想方设法完善其不足之处，从而提高分布式文件系统的扩展性、高性能、可用性等特性。集中式元数据服务模型的代表是Lustre, StorNext, GFS等，分布式元数据服务模型的典型案例有ISILON, GPFS, Ceph等，Glustrefs是无元数据服务模型的经典。以上这些都是非常强大的分布式文件系统，它们是非常好的设计典范。这也足以说明，架构固然非常关键，但具体实现技术却往往决定最后的结局。\n\n**补充阅读**\n[1] Ceph, [http://www.ibm.com/developerworks/cn/linux/l-ceph/index.html?ca=drs-](http://www.ibm.com/developerworks/cn/linux/l-ceph/index.html?ca=drs-)\n[2] Glusterfs, [http://blog.csdn.net/liuben/article/details/6284551](http://blog.csdn.net/liuben/article/details/6284551)\n[3] 集群NAS技术架构，[http://blog.csdn.net/liuben/article/details/6422700](http://blog.csdn.net/liuben/article/details/6422700)\n> **转载：**[**刘爱贵的专栏**](http://blog.csdn.net/liuben/article/details/6749188)","slug":"dist-filesystem-metadata-server","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg624b0090sb8fgn7hmnzm"},{"title":"设计模式 - 单例模式","id":"224","date":"2011-12-17T14:52:21.000Z","_content":"\n**GOF****定义：**\n\n_“Prototype Pattern Ensure a class only has one instance, and provide a global point of access to it.” _\n\n_“保证一个类仅有一个实例，并提供一个访问它的全局访问点。”_\n <!--more-->  \n\n如定义所说，单例模式确保了在同一时间内内存中又有类的一个实例，并提供了全局的访问方法。\n\n节省内存是单例普遍认为的优点，那还有其它优点吗？当然还有，如果应用中存在多个（过多个）实例可能会引发程序（逻辑）错误时，也可以考虑用单例模式。比如说单一实例为池化对象，或唯一标识生成器等。\n\n&#160;\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.singleton;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Singleton {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">private</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">final</span><span> Singleton mySingletonObj = </span><span class=\"keyword\">new</span><span> Singleton();&#160;&#160; </span></span>\n5.  <span>&#160; </span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"comment\">// 不能直接创建实例 </span><span>&#160; </span></span>\n7.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">private</span><span> Singleton() {&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n9.  <span>&#160; </span>\n10.  <span>&#160;&#160;&#160; </span><span class=\"comment\">// 直接返回实例 </span><span>&#160; </span></span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">synchronized</span><span>&#160;</span><span class=\"keyword\">static</span><span> Singleton getInstance() {&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> mySingletonObj;&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>","source":"_posts/design-pattern-singleton.md","raw":"title: 设计模式 - 单例模式\ntags:\n  - 设计模式\nid: 224\ncategories:\n  - 技术分享\ndate: 2011-12-17 22:52:21\n---\n\n**GOF****定义：**\n\n_“Prototype Pattern Ensure a class only has one instance, and provide a global point of access to it.” _\n\n_“保证一个类仅有一个实例，并提供一个访问它的全局访问点。”_\n <!--more-->  \n\n如定义所说，单例模式确保了在同一时间内内存中又有类的一个实例，并提供了全局的访问方法。\n\n节省内存是单例普遍认为的优点，那还有其它优点吗？当然还有，如果应用中存在多个（过多个）实例可能会引发程序（逻辑）错误时，也可以考虑用单例模式。比如说单一实例为池化对象，或唯一标识生成器等。\n\n&#160;\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.singleton;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Singleton {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">private</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">final</span><span> Singleton mySingletonObj = </span><span class=\"keyword\">new</span><span> Singleton();&#160;&#160; </span></span>\n5.  <span>&#160; </span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"comment\">// 不能直接创建实例 </span><span>&#160; </span></span>\n7.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">private</span><span> Singleton() {&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n9.  <span>&#160; </span>\n10.  <span>&#160;&#160;&#160; </span><span class=\"comment\">// 直接返回实例 </span><span>&#160; </span></span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">synchronized</span><span>&#160;</span><span class=\"keyword\">static</span><span> Singleton getInstance() {&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> mySingletonObj;&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>","slug":"design-pattern-singleton","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg624c0094sb8fswg0jbic"},{"title":"设计模式 - 代理模式","id":"233","date":"2011-12-25T15:37:24.000Z","_content":"\n**GOF****定义：**\n\n_“Provide a surrogate or placeholder for another object to control access to it.” _\n\n_“为其它对象提供一种代理以控制对这个对象的访问。”_\n <!--more-->  \n\n为什么需要使用代理模式：\n\n1、 如果不同用户对同一对象有不同的访问权利；\n\n2、 如果某个用户不能直接操作某个对象，但是又必须和那个对象有所依赖。\n\n有不同的访问权利，即定义中的控制对象访问，我们很容易就可以想到权限控制，比如说下载文件，交了钱的人才能下载，没交的没门。被下载文件有如下操作：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.proxy;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">interface</span><span> FileOps {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">void</span><span> download();&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">void</span><span> del();&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">void</span><span> modify();&#160;&#160; </span></span>\n7.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n实际文件操作类如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.proxy;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> RealFileOps </span><span class=\"keyword\">implements</span><span> FileOps {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> download() {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n6.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n7.  <span>&#160; </span>\n8.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> del() {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n10.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n11.  <span>&#160; </span>\n12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> modify() {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n文件操作代理类如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.proxy;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> FileProxy </span><span class=\"keyword\">implements</span><span> FileOps {&#160;&#160; </span></span>\n4.  <span>&#160; </span>\n5.  <span>&#160;&#160;&#160; FileOps file;&#160;&#160; </span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> permission;&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">final</span><span>&#160;</span><span class=\"keyword\">int</span><span> PERMISSION_USER = </span><span class=\"number\">100</span><span>;&#160;&#160; </span></span>\n8.  <span>&#160; </span>\n9.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> FileProxy(</span><span class=\"keyword\">int</span><span> permission, FileOps file) {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// FIXME </span><span>&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.file = file;&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.permission = permission;&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>&#160; </span>\n15.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n16.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> download() {&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (PERMISSION_USER == permission) {&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.file.download();&#160;&#160; </span></span>\n19.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n20.  <span></span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n22.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n23.  <span>&#160; </span>\n24.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n25.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> del() {&#160;&#160; </span></span>\n26.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n27.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n28.  <span>&#160; </span>\n29.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n30.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> modify() {&#160;&#160; </span></span>\n31.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n32.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n33.  <span>}&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n优点：\n\n1、 职责清晰\n\n最大的优点就是职责清晰，真正的角色只需要实现实际的业务逻辑（本文的下载逻辑），而不用关心其它的非本职责的事务（权限管理）。\n\n2、 高可扩展性\n\n显而易见，在本文中，实际下载文件类实现了接口，需要添加新的实现时，只要将需要的新实例对象传入代理中即可。","source":"_posts/design-pattern-proxy.md","raw":"title: 设计模式 - 代理模式\ntags:\n  - 设计模式\nid: 233\ncategories:\n  - 技术分享\ndate: 2011-12-25 23:37:24\n---\n\n**GOF****定义：**\n\n_“Provide a surrogate or placeholder for another object to control access to it.” _\n\n_“为其它对象提供一种代理以控制对这个对象的访问。”_\n <!--more-->  \n\n为什么需要使用代理模式：\n\n1、 如果不同用户对同一对象有不同的访问权利；\n\n2、 如果某个用户不能直接操作某个对象，但是又必须和那个对象有所依赖。\n\n有不同的访问权利，即定义中的控制对象访问，我们很容易就可以想到权限控制，比如说下载文件，交了钱的人才能下载，没交的没门。被下载文件有如下操作：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.proxy;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">interface</span><span> FileOps {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">void</span><span> download();&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">void</span><span> del();&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">void</span><span> modify();&#160;&#160; </span></span>\n7.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n实际文件操作类如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.proxy;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> RealFileOps </span><span class=\"keyword\">implements</span><span> FileOps {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> download() {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n6.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n7.  <span>&#160; </span>\n8.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> del() {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n10.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n11.  <span>&#160; </span>\n12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> modify() {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n文件操作代理类如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.proxy;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> FileProxy </span><span class=\"keyword\">implements</span><span> FileOps {&#160;&#160; </span></span>\n4.  <span>&#160; </span>\n5.  <span>&#160;&#160;&#160; FileOps file;&#160;&#160; </span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> permission;&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">final</span><span>&#160;</span><span class=\"keyword\">int</span><span> PERMISSION_USER = </span><span class=\"number\">100</span><span>;&#160;&#160; </span></span>\n8.  <span>&#160; </span>\n9.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> FileProxy(</span><span class=\"keyword\">int</span><span> permission, FileOps file) {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// FIXME </span><span>&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.file = file;&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.permission = permission;&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>&#160; </span>\n15.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n16.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> download() {&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (PERMISSION_USER == permission) {&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.file.download();&#160;&#160; </span></span>\n19.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n20.  <span></span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n22.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n23.  <span>&#160; </span>\n24.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n25.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> del() {&#160;&#160; </span></span>\n26.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n27.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n28.  <span>&#160; </span>\n29.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n30.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> modify() {&#160;&#160; </span></span>\n31.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n32.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n33.  <span>}&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n优点：\n\n1、 职责清晰\n\n最大的优点就是职责清晰，真正的角色只需要实现实际的业务逻辑（本文的下载逻辑），而不用关心其它的非本职责的事务（权限管理）。\n\n2、 高可扩展性\n\n显而易见，在本文中，实际下载文件类实现了接口，需要添加新的实现时，只要将需要的新实例对象传入代理中即可。","slug":"design-pattern-proxy","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg624e0098sb8fozf07zx5"},{"title":"设计模式 - 观察者模式","id":"225","date":"2011-12-18T13:17:41.000Z","_content":"\n**GOF****定义：**\n\n_“Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically” _\n\n_“定义对象间的一种一对多的依赖关系，当一个对象的状态发生变化时，所有依赖于它的对象都得到通知并被自动更新。”_\n <!--more-->  \n\n写过桌面的程序的人一定不会陌生Listener这个东东，添加一个组件就得添加一个相应的XXXListener，这也是观察者模式一个比较常见的应用领域了。\n\n先看监听器（观察者）的实现，实现中只有事件发生时调用的接口方法声明：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\">&#160;</div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.observer.listener;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"comment\">/** </span>&#160;</span>4.  <span><span class=\"comment\">*&#160; </span>&#160;</span>5.  <span><span class=\"comment\">* 监听器（观察者）接口，具体实现由使用者实现 </span>&#160;</span>6.  <span><span class=\"comment\">*&#160; </span>&#160;</span>7.  <span><span class=\"comment\">* @author Wikie </span>&#160;</span>8.  <span><span class=\"comment\">*/</span><span>&#160; </span></span>\n9.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span>&#160;</span><span class=\"keyword\">class</span><span> SendListener{&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span>&#160;</span><span class=\"keyword\">void</span><span> onMsgSended(String msg);&#160;&#160; </span></span>\n11.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n应用组件，即被观察者：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.observer.listener;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Sender {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"comment\">// 监听器（观察者） </span><span>&#160; </span></span>\n5.  <span>&#160;&#160;&#160; SendListener sendListener;&#160;&#160; </span>\n6.  <span>&#160; </span>\n7.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>8.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 添加（注册）一个监听器 </span>&#160;</span>9.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @param l 监听器 </span>&#160;</span>10.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> addSendListener(SendListener l) {&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (l == </span><span class=\"keyword\">null</span><span>) {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throw</span><span>&#160;</span><span class=\"keyword\">new</span><span> NullPointerException();&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.sendListener = l;&#160;&#160; </span></span>\n16.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n17.  <span>&#160; </span>\n18.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>19.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 发送消息 </span>&#160;</span>20.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 同时通知监听器 </span>&#160;</span>21.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @param msg </span>&#160;</span>22.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n23.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> sendMsg(String msg) {&#160;&#160; </span></span>\n24.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; doSth();&#160;&#160; </span>\n25.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; sendListener.onMsgSended(msg);&#160;&#160; </span>\n26.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n27.  <span>&#160; </span>\n28.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">private</span><span>&#160;</span><span class=\"keyword\">void</span><span> doSth() {&#160;&#160; </span></span>\n29.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO Auto-generated method stubO </span><span>&#160; </span></span>\n30.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n31.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n最后应用程序使用时，只需要在组件中注册一个监听器即可：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.observer.listener;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Application {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">void</span><span> main(String[] args) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Sender sender = </span><span class=\"keyword\">new</span><span> Sender();&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; sender.addSendListener(</span><span class=\"keyword\">new</span><span> SendListener() {&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> onMsgSended(String msg) {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(</span><span class=\"string\">&quot;Msg is: &quot;</span><span> + msg);&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; });&#160;&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; sender.sendMsg(</span><span class=\"string\">&quot;Hello World&quot;</span><span>);&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>}&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n观察者模式也不仅仅局限于界面监听器，系统实时推送更新消息也可以考虑使用该模式。\n\n需要注意的是，java中已经有现成的观察者模式了，即使用Observer接口与Observable类。不过出于线程安全的考虑，Sun JDK的实现可能会出现两个不太好的情况：1、新加入的观察者会丢失消息；2、新删除的观察者会收到之前的消息。对这个要求较高的建议重写吧，一般来说，我们还是可以使用它的。\n\n他们俩内部实现和上面的代码差不多，Observer接口中只有一个update方法声明，而Observable中有一个存放Observer的Vector对象，可以给一个Observable对象注册多个Observer，同时发生事件后调用notifyObservers(obj)即可通知所有的Observer。\n\n将上面代码改一下，就成了这个样子：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.observer;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">import</span><span> java.util.Observable;&#160;&#160; </span></span>\n4.  <span></span><span class=\"keyword\">import</span><span> java.util.Observer;&#160;&#160; </span></span>\n5.  <span>&#160; </span>\n6.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> SendObserver </span><span class=\"keyword\">implements</span><span> Observer {&#160;&#160; </span></span>\n7.  <span>&#160; </span>\n8.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>9.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 事件处理方法 </span>&#160;</span>10.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @param o: 发生事件的被观察者 </span>&#160;</span>11.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @param arg: 参数 </span>&#160;</span>12.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n13.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n14.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> update(Observable o, Object arg) {&#160;&#160; </span></span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (arg </span><span class=\"keyword\">instanceof</span><span> String) {&#160;&#160; </span></span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(</span><span class=\"string\">&quot;Msg is: &quot;</span><span> + arg);&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n18.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n19.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.observer;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">import</span><span> java.util.Observable;&#160;&#160; </span></span>\n4.  <span>&#160; </span>\n5.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Sender </span><span class=\"keyword\">extends</span><span> Observable {&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> sendMsg(String msg) {&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; setChanged();&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; notifyObservers(msg);&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n10.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.observer;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Application {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">void</span><span> main(String[] args) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Sender sender = </span><span class=\"keyword\">new</span><span> Sender();&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; sender.addObserver(</span><span class=\"keyword\">new</span><span> SendObserver());&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; sender.sendMsg(</span><span class=\"string\">&quot;Hello world&quot;</span><span>);&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n9.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>","source":"_posts/design-pattern-observer.md","raw":"title: 设计模式 - 观察者模式\ntags:\n  - 设计模式\nid: 225\ncategories:\n  - 技术分享\ndate: 2011-12-18 21:17:41\n---\n\n**GOF****定义：**\n\n_“Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically” _\n\n_“定义对象间的一种一对多的依赖关系，当一个对象的状态发生变化时，所有依赖于它的对象都得到通知并被自动更新。”_\n <!--more-->  \n\n写过桌面的程序的人一定不会陌生Listener这个东东，添加一个组件就得添加一个相应的XXXListener，这也是观察者模式一个比较常见的应用领域了。\n\n先看监听器（观察者）的实现，实现中只有事件发生时调用的接口方法声明：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\">&#160;</div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.observer.listener;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"comment\">/** </span>&#160;</span>4.  <span><span class=\"comment\">*&#160; </span>&#160;</span>5.  <span><span class=\"comment\">* 监听器（观察者）接口，具体实现由使用者实现 </span>&#160;</span>6.  <span><span class=\"comment\">*&#160; </span>&#160;</span>7.  <span><span class=\"comment\">* @author Wikie </span>&#160;</span>8.  <span><span class=\"comment\">*/</span><span>&#160; </span></span>\n9.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span>&#160;</span><span class=\"keyword\">class</span><span> SendListener{&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span>&#160;</span><span class=\"keyword\">void</span><span> onMsgSended(String msg);&#160;&#160; </span></span>\n11.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n应用组件，即被观察者：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.observer.listener;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Sender {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"comment\">// 监听器（观察者） </span><span>&#160; </span></span>\n5.  <span>&#160;&#160;&#160; SendListener sendListener;&#160;&#160; </span>\n6.  <span>&#160; </span>\n7.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>8.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 添加（注册）一个监听器 </span>&#160;</span>9.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @param l 监听器 </span>&#160;</span>10.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> addSendListener(SendListener l) {&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (l == </span><span class=\"keyword\">null</span><span>) {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throw</span><span>&#160;</span><span class=\"keyword\">new</span><span> NullPointerException();&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.sendListener = l;&#160;&#160; </span></span>\n16.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n17.  <span>&#160; </span>\n18.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>19.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 发送消息 </span>&#160;</span>20.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 同时通知监听器 </span>&#160;</span>21.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @param msg </span>&#160;</span>22.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n23.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> sendMsg(String msg) {&#160;&#160; </span></span>\n24.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; doSth();&#160;&#160; </span>\n25.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; sendListener.onMsgSended(msg);&#160;&#160; </span>\n26.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n27.  <span>&#160; </span>\n28.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">private</span><span>&#160;</span><span class=\"keyword\">void</span><span> doSth() {&#160;&#160; </span></span>\n29.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO Auto-generated method stubO </span><span>&#160; </span></span>\n30.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n31.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n最后应用程序使用时，只需要在组件中注册一个监听器即可：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.observer.listener;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Application {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">void</span><span> main(String[] args) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Sender sender = </span><span class=\"keyword\">new</span><span> Sender();&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; sender.addSendListener(</span><span class=\"keyword\">new</span><span> SendListener() {&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> onMsgSended(String msg) {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(</span><span class=\"string\">&quot;Msg is: &quot;</span><span> + msg);&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; });&#160;&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; sender.sendMsg(</span><span class=\"string\">&quot;Hello World&quot;</span><span>);&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>}&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n观察者模式也不仅仅局限于界面监听器，系统实时推送更新消息也可以考虑使用该模式。\n\n需要注意的是，java中已经有现成的观察者模式了，即使用Observer接口与Observable类。不过出于线程安全的考虑，Sun JDK的实现可能会出现两个不太好的情况：1、新加入的观察者会丢失消息；2、新删除的观察者会收到之前的消息。对这个要求较高的建议重写吧，一般来说，我们还是可以使用它的。\n\n他们俩内部实现和上面的代码差不多，Observer接口中只有一个update方法声明，而Observable中有一个存放Observer的Vector对象，可以给一个Observable对象注册多个Observer，同时发生事件后调用notifyObservers(obj)即可通知所有的Observer。\n\n将上面代码改一下，就成了这个样子：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.observer;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">import</span><span> java.util.Observable;&#160;&#160; </span></span>\n4.  <span></span><span class=\"keyword\">import</span><span> java.util.Observer;&#160;&#160; </span></span>\n5.  <span>&#160; </span>\n6.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> SendObserver </span><span class=\"keyword\">implements</span><span> Observer {&#160;&#160; </span></span>\n7.  <span>&#160; </span>\n8.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>9.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 事件处理方法 </span>&#160;</span>10.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @param o: 发生事件的被观察者 </span>&#160;</span>11.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @param arg: 参数 </span>&#160;</span>12.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n13.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n14.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> update(Observable o, Object arg) {&#160;&#160; </span></span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (arg </span><span class=\"keyword\">instanceof</span><span> String) {&#160;&#160; </span></span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(</span><span class=\"string\">&quot;Msg is: &quot;</span><span> + arg);&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n18.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n19.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.observer;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">import</span><span> java.util.Observable;&#160;&#160; </span></span>\n4.  <span>&#160; </span>\n5.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Sender </span><span class=\"keyword\">extends</span><span> Observable {&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> sendMsg(String msg) {&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; setChanged();&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; notifyObservers(msg);&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n10.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.observer;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Application {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">void</span><span> main(String[] args) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Sender sender = </span><span class=\"keyword\">new</span><span> Sender();&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; sender.addObserver(</span><span class=\"keyword\">new</span><span> SendObserver());&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; sender.sendMsg(</span><span class=\"string\">&quot;Hello world&quot;</span><span>);&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n9.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>","slug":"design-pattern-observer","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg624f009bsb8fu6r73978"},{"title":"设计模式 - 工厂模式","id":"213","date":"2011-12-15T16:47:04.000Z","_content":"\n**GOF定义：**\n\n“_Define an interface for creating an object, but let subclasses decide which class to instantiate. Factory Method lets a class defer instantiation to subclasses._”\n\n“_定义一个用于创建对象的接口，让子类决定实例化哪一个类。Factory Method使一个类的实例化延迟到其子类。_”\n <!--more-->如果我们经常需要实例化很多对象，如：A a = new A(); B b = new B();     \n\n如果在开发过程中，我们发现，类A、B的方法是那么的一致，但是具体实现却大不太一样。\n\n这个时候就可以开始考虑使用工厂模式了。工厂模式提供一个封装机制来隔离出a、b对象的具体实现，提炼出一致的接口，从而保持了系统中其它依赖这些接口的对象不会随着需求的改变而改变，即解耦。用户无需知道a、b对象具体是怎么创建的，只管用即可。\n\n程序猿对数据库一定不会陌生，近几年流行一种新的数据库——NoSQL，NoSQL中又流行Key/Value内存数据库。故名思议，数据库中存放的都是一些键值对。\n\n一般来说，操作键值对就两个方法：get(key)与set(key,value)。这两个方法应对简单结构的数据库足够了，但是有丰富数据结构的就不行了，如redis。虽然说具体实现不太一样，但是接口名基本上是一致的，还是get与set，只是传入的参数个数不同。那么就可以抽出有这样两个方法的接口：get(String[])与set(String[])。\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.factory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">interface</span><span> Command {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>5.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 根据参数取得值 </span>&#160;</span>6.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @param args 参数数组 </span>&#160;</span>7.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @return 值 </span>&#160;</span>8.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n9.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> String get(String[] args);&#160;&#160; </span></span>\n10.  <span>&#160; </span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>12.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 根据参数设置值 </span>&#160;</span>13.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @param args 参数数组 </span>&#160;</span>14.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @return 影响条数，-1为失败 </span>&#160;</span>15.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n16.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">int</span><span> set(String[] args);&#160;&#160; </span></span>\n17.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n同时，有一些类实现了这个接口，本文简单的使用了HashCommand与SimpleCommand：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.factory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"comment\">/** </span>&#160;</span>4.  <span><span class=\"comment\">*&#160; </span>&#160;</span>5.  <span><span class=\"comment\">* 对Redis的Hash结构进行操作的类 </span>&#160;</span>6.  <span><span class=\"comment\">*&#160; </span>&#160;</span>7.  <span><span class=\"comment\">* @author 易鸿伟 Wikie </span>&#160;</span>8.  <span><span class=\"comment\">* @date 2011-12-15 </span>&#160;</span>9.  <span><span class=\"comment\">*/</span><span>&#160; </span></span>\n10.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> HashCommand </span><span class=\"keyword\">implements</span><span> Command {&#160;&#160; </span></span>\n11.  <span>&#160; </span>\n12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">private</span><span>&#160;</span><span class=\"keyword\">static</span><span> String KEY = </span><span class=\"string\">&quot;default_key&quot;</span><span>;&#160;&#160; </span></span>\n13.  <span>&#160; </span>\n14.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n15.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> String get(String[] args) {&#160;&#160; </span></span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String key, field, value = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (</span><span class=\"number\">2</span><span> == args.length) {&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; key = args[</span><span class=\"number\">0</span><span>];&#160;&#160; </span></span>\n19.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; field = args[</span><span class=\"number\">1</span><span>];&#160;&#160; </span></span>\n20.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span>&#160;</span><span class=\"keyword\">if</span><span> (</span><span class=\"number\">1</span><span> == args.length) {&#160;&#160; </span></span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; key = KEY;&#160;&#160; </span>\n22.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; field = args[</span><span class=\"number\">0</span><span>];&#160;&#160; </span></span>\n23.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n24.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throw</span><span>&#160;</span><span class=\"keyword\">new</span><span> IllegalArgumentException(</span><span class=\"string\">&quot;参数输入不对&quot;</span><span>);&#160;&#160; </span></span>\n25.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n26.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 获得client对象，获得数据 </span><span>&#160; </span></span>\n27.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// sample: value = conn.get.....; </span><span>&#160; </span></span>\n28.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> value;&#160;&#160; </span></span>\n29.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n30.  <span>&#160; </span>\n31.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n32.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">int</span><span> set(String[] args) {&#160;&#160; </span></span>\n33.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String key, field, value;&#160;&#160; </span>\n34.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> result = -</span><span class=\"number\">1</span><span>;&#160;&#160; </span></span>\n35.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (</span><span class=\"number\">3</span><span> == args.length) {&#160;&#160; </span></span>\n36.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; key = args[</span><span class=\"number\">0</span><span>];&#160;&#160; </span></span>\n37.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; field = args[</span><span class=\"number\">1</span><span>];&#160;&#160; </span></span>\n38.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; value = args[</span><span class=\"number\">2</span><span>];&#160;&#160; </span></span>\n39.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span>&#160;</span><span class=\"keyword\">if</span><span> (</span><span class=\"number\">2</span><span> == args.length) {&#160;&#160; </span></span>\n40.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; key = KEY;&#160;&#160; </span>\n41.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; field = args[</span><span class=\"number\">0</span><span>];&#160;&#160; </span></span>\n42.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; value = args[</span><span class=\"number\">1</span><span>];&#160;&#160; </span></span>\n43.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n44.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throw</span><span>&#160;</span><span class=\"keyword\">new</span><span> IllegalArgumentException(</span><span class=\"string\">&quot;参数输入不对&quot;</span><span>);&#160;&#160; </span></span>\n45.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n46.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 获得client对象，设置数据 </span><span>&#160; </span></span>\n47.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// sample: result = conn.set.....; </span><span>&#160; </span></span>\n48.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> result;&#160;&#160; </span></span>\n49.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n50.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.factory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"comment\">/** </span>&#160;</span>4.  <span><span class=\"comment\">*&#160; </span>&#160;</span>5.  <span><span class=\"comment\">* 对Redis的普通结构（Key/Value）进行操作的类 </span>&#160;</span>6.  <span><span class=\"comment\">*&#160; </span>&#160;</span>7.  <span><span class=\"comment\">*&#160; </span>&#160;</span>8.  <span><span class=\"comment\">* @author 易鸿伟 Wikie </span>&#160;</span>9.  <span><span class=\"comment\">* @date 2011-12-15 </span>&#160;</span>10.  <span><span class=\"comment\">*/</span><span>&#160; </span></span>\n11.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> SimpleCommand </span><span class=\"keyword\">implements</span><span> Command {&#160;&#160; </span></span>\n12.  <span>&#160; </span>\n13.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> String get(String[] args) {&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String key, value = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (</span><span class=\"number\">1</span><span> == args.length) {&#160;&#160; </span></span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; key = args[</span><span class=\"number\">0</span><span>];&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throw</span><span>&#160;</span><span class=\"keyword\">new</span><span> IllegalArgumentException(</span><span class=\"string\">&quot;参数输入不对&quot;</span><span>);&#160;&#160; </span></span>\n19.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n20.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 获得client对象，获得数据 </span><span>&#160; </span></span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// sample: value = conn.get.....; </span><span>&#160; </span></span>\n22.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> value;&#160;&#160; </span></span>\n23.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n24.  <span>&#160; </span>\n25.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">int</span><span> set(String[] args) {&#160;&#160; </span></span>\n26.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String key, value;&#160;&#160; </span>\n27.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> result = -</span><span class=\"number\">1</span><span>;&#160;&#160; </span></span>\n28.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (</span><span class=\"number\">2</span><span> == args.length) {&#160;&#160; </span></span>\n29.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; key = args[</span><span class=\"number\">0</span><span>];&#160;&#160; </span></span>\n30.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; value = args[</span><span class=\"number\">1</span><span>];&#160;&#160; </span></span>\n31.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n32.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throw</span><span>&#160;</span><span class=\"keyword\">new</span><span> IllegalArgumentException(</span><span class=\"string\">&quot;参数输入不对&quot;</span><span>);&#160;&#160; </span></span>\n33.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n34.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 获得client对象，设置数据 </span><span>&#160; </span></span>\n35.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// sample: result = conn.set.....; </span><span>&#160; </span></span>\n36.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> result;&#160;&#160; </span></span>\n37.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n38.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n工厂类实现就比较简单了，只需要有一个静态create方法即可。\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.factory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> CommandFactory {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span> Command create(String className) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Command cmd = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">try</span><span> {&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; cmd = (Command) Class.forName(className).newInstance();&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">catch</span><span> (InstantiationException e) {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TOOD 实例化出错，即传入的不是具体类名 </span><span>&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">catch</span><span> (IllegalAccessException e) {&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TOOD 定义的具体类有问题 </span><span>&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">catch</span><span> (ClassNotFoundException e) {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TOOD 具体类无法找到 </span><span>&#160; </span></span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> cmd;&#160;&#160; </span></span>\n16.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n17.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n在最后的程序中，用户只需要定义一个接口，再将需要实例化的类名传给工厂即可。其中类名常量存在了一个Utils类中，为了减少篇幅就不添加进来了。\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"bar\"></div>          <div class=\"dp-highlighter\">           \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.factory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Application {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">void</span><span> main(String[] args) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String[] hGetArgs = {</span><span class=\"string\">&quot;key&quot;</span><span>, </span><span class=\"string\">&quot;field&quot;</span><span>};&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String[] hSetArgs = {</span><span class=\"string\">&quot;key&quot;</span><span>, </span><span class=\"string\">&quot;field&quot;</span><span>, </span><span class=\"string\">&quot;value&quot;</span><span>};&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String[] sGetArgs = {</span><span class=\"string\">&quot;key&quot;</span><span>};&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String[] sSetArgs = {</span><span class=\"string\">&quot;key&quot;</span><span>, </span><span class=\"string\">&quot;value&quot;</span><span>};&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Command cmd = CommandFactory.create(Utils.CLASS_HASH);&#160;&#160; </span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; cmd.set(hSetArgs);&#160;&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; cmd.get(hGetArgs);&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; cmd = CommandFactory.create(Utils.CLASS_SIMPLE);&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; cmd.set(sSetArgs);&#160;&#160; </span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; cmd.get(sGetArgs);&#160;&#160; </span>\n17.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n18.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>","source":"_posts/design-pattern-factory.md","raw":"title: 设计模式 - 工厂模式\ntags:\n  - 设计模式\nid: 213\ncategories:\n  - 技术分享\ndate: 2011-12-16 00:47:04\n---\n\n**GOF定义：**\n\n“_Define an interface for creating an object, but let subclasses decide which class to instantiate. Factory Method lets a class defer instantiation to subclasses._”\n\n“_定义一个用于创建对象的接口，让子类决定实例化哪一个类。Factory Method使一个类的实例化延迟到其子类。_”\n <!--more-->如果我们经常需要实例化很多对象，如：A a = new A(); B b = new B();     \n\n如果在开发过程中，我们发现，类A、B的方法是那么的一致，但是具体实现却大不太一样。\n\n这个时候就可以开始考虑使用工厂模式了。工厂模式提供一个封装机制来隔离出a、b对象的具体实现，提炼出一致的接口，从而保持了系统中其它依赖这些接口的对象不会随着需求的改变而改变，即解耦。用户无需知道a、b对象具体是怎么创建的，只管用即可。\n\n程序猿对数据库一定不会陌生，近几年流行一种新的数据库——NoSQL，NoSQL中又流行Key/Value内存数据库。故名思议，数据库中存放的都是一些键值对。\n\n一般来说，操作键值对就两个方法：get(key)与set(key,value)。这两个方法应对简单结构的数据库足够了，但是有丰富数据结构的就不行了，如redis。虽然说具体实现不太一样，但是接口名基本上是一致的，还是get与set，只是传入的参数个数不同。那么就可以抽出有这样两个方法的接口：get(String[])与set(String[])。\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.factory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">interface</span><span> Command {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>5.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 根据参数取得值 </span>&#160;</span>6.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @param args 参数数组 </span>&#160;</span>7.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @return 值 </span>&#160;</span>8.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n9.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> String get(String[] args);&#160;&#160; </span></span>\n10.  <span>&#160; </span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>12.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 根据参数设置值 </span>&#160;</span>13.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @param args 参数数组 </span>&#160;</span>14.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @return 影响条数，-1为失败 </span>&#160;</span>15.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n16.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">int</span><span> set(String[] args);&#160;&#160; </span></span>\n17.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n同时，有一些类实现了这个接口，本文简单的使用了HashCommand与SimpleCommand：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.factory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"comment\">/** </span>&#160;</span>4.  <span><span class=\"comment\">*&#160; </span>&#160;</span>5.  <span><span class=\"comment\">* 对Redis的Hash结构进行操作的类 </span>&#160;</span>6.  <span><span class=\"comment\">*&#160; </span>&#160;</span>7.  <span><span class=\"comment\">* @author 易鸿伟 Wikie </span>&#160;</span>8.  <span><span class=\"comment\">* @date 2011-12-15 </span>&#160;</span>9.  <span><span class=\"comment\">*/</span><span>&#160; </span></span>\n10.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> HashCommand </span><span class=\"keyword\">implements</span><span> Command {&#160;&#160; </span></span>\n11.  <span>&#160; </span>\n12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">private</span><span>&#160;</span><span class=\"keyword\">static</span><span> String KEY = </span><span class=\"string\">&quot;default_key&quot;</span><span>;&#160;&#160; </span></span>\n13.  <span>&#160; </span>\n14.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n15.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> String get(String[] args) {&#160;&#160; </span></span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String key, field, value = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (</span><span class=\"number\">2</span><span> == args.length) {&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; key = args[</span><span class=\"number\">0</span><span>];&#160;&#160; </span></span>\n19.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; field = args[</span><span class=\"number\">1</span><span>];&#160;&#160; </span></span>\n20.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span>&#160;</span><span class=\"keyword\">if</span><span> (</span><span class=\"number\">1</span><span> == args.length) {&#160;&#160; </span></span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; key = KEY;&#160;&#160; </span>\n22.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; field = args[</span><span class=\"number\">0</span><span>];&#160;&#160; </span></span>\n23.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n24.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throw</span><span>&#160;</span><span class=\"keyword\">new</span><span> IllegalArgumentException(</span><span class=\"string\">&quot;参数输入不对&quot;</span><span>);&#160;&#160; </span></span>\n25.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n26.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 获得client对象，获得数据 </span><span>&#160; </span></span>\n27.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// sample: value = conn.get.....; </span><span>&#160; </span></span>\n28.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> value;&#160;&#160; </span></span>\n29.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n30.  <span>&#160; </span>\n31.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n32.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">int</span><span> set(String[] args) {&#160;&#160; </span></span>\n33.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String key, field, value;&#160;&#160; </span>\n34.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> result = -</span><span class=\"number\">1</span><span>;&#160;&#160; </span></span>\n35.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (</span><span class=\"number\">3</span><span> == args.length) {&#160;&#160; </span></span>\n36.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; key = args[</span><span class=\"number\">0</span><span>];&#160;&#160; </span></span>\n37.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; field = args[</span><span class=\"number\">1</span><span>];&#160;&#160; </span></span>\n38.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; value = args[</span><span class=\"number\">2</span><span>];&#160;&#160; </span></span>\n39.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span>&#160;</span><span class=\"keyword\">if</span><span> (</span><span class=\"number\">2</span><span> == args.length) {&#160;&#160; </span></span>\n40.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; key = KEY;&#160;&#160; </span>\n41.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; field = args[</span><span class=\"number\">0</span><span>];&#160;&#160; </span></span>\n42.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; value = args[</span><span class=\"number\">1</span><span>];&#160;&#160; </span></span>\n43.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n44.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throw</span><span>&#160;</span><span class=\"keyword\">new</span><span> IllegalArgumentException(</span><span class=\"string\">&quot;参数输入不对&quot;</span><span>);&#160;&#160; </span></span>\n45.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n46.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 获得client对象，设置数据 </span><span>&#160; </span></span>\n47.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// sample: result = conn.set.....; </span><span>&#160; </span></span>\n48.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> result;&#160;&#160; </span></span>\n49.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n50.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.factory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"comment\">/** </span>&#160;</span>4.  <span><span class=\"comment\">*&#160; </span>&#160;</span>5.  <span><span class=\"comment\">* 对Redis的普通结构（Key/Value）进行操作的类 </span>&#160;</span>6.  <span><span class=\"comment\">*&#160; </span>&#160;</span>7.  <span><span class=\"comment\">*&#160; </span>&#160;</span>8.  <span><span class=\"comment\">* @author 易鸿伟 Wikie </span>&#160;</span>9.  <span><span class=\"comment\">* @date 2011-12-15 </span>&#160;</span>10.  <span><span class=\"comment\">*/</span><span>&#160; </span></span>\n11.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> SimpleCommand </span><span class=\"keyword\">implements</span><span> Command {&#160;&#160; </span></span>\n12.  <span>&#160; </span>\n13.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> String get(String[] args) {&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String key, value = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (</span><span class=\"number\">1</span><span> == args.length) {&#160;&#160; </span></span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; key = args[</span><span class=\"number\">0</span><span>];&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throw</span><span>&#160;</span><span class=\"keyword\">new</span><span> IllegalArgumentException(</span><span class=\"string\">&quot;参数输入不对&quot;</span><span>);&#160;&#160; </span></span>\n19.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n20.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 获得client对象，获得数据 </span><span>&#160; </span></span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// sample: value = conn.get.....; </span><span>&#160; </span></span>\n22.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> value;&#160;&#160; </span></span>\n23.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n24.  <span>&#160; </span>\n25.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">int</span><span> set(String[] args) {&#160;&#160; </span></span>\n26.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String key, value;&#160;&#160; </span>\n27.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> result = -</span><span class=\"number\">1</span><span>;&#160;&#160; </span></span>\n28.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (</span><span class=\"number\">2</span><span> == args.length) {&#160;&#160; </span></span>\n29.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; key = args[</span><span class=\"number\">0</span><span>];&#160;&#160; </span></span>\n30.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; value = args[</span><span class=\"number\">1</span><span>];&#160;&#160; </span></span>\n31.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n32.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throw</span><span>&#160;</span><span class=\"keyword\">new</span><span> IllegalArgumentException(</span><span class=\"string\">&quot;参数输入不对&quot;</span><span>);&#160;&#160; </span></span>\n33.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n34.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 获得client对象，设置数据 </span><span>&#160; </span></span>\n35.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// sample: result = conn.set.....; </span><span>&#160; </span></span>\n36.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> result;&#160;&#160; </span></span>\n37.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n38.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n工厂类实现就比较简单了，只需要有一个静态create方法即可。\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.factory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> CommandFactory {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span> Command create(String className) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Command cmd = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">try</span><span> {&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; cmd = (Command) Class.forName(className).newInstance();&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">catch</span><span> (InstantiationException e) {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TOOD 实例化出错，即传入的不是具体类名 </span><span>&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">catch</span><span> (IllegalAccessException e) {&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TOOD 定义的具体类有问题 </span><span>&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">catch</span><span> (ClassNotFoundException e) {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TOOD 具体类无法找到 </span><span>&#160; </span></span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> cmd;&#160;&#160; </span></span>\n16.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n17.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n在最后的程序中，用户只需要定义一个接口，再将需要实例化的类名传给工厂即可。其中类名常量存在了一个Utils类中，为了减少篇幅就不添加进来了。\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"bar\"></div>          <div class=\"dp-highlighter\">           \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.factory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Application {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">void</span><span> main(String[] args) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String[] hGetArgs = {</span><span class=\"string\">&quot;key&quot;</span><span>, </span><span class=\"string\">&quot;field&quot;</span><span>};&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String[] hSetArgs = {</span><span class=\"string\">&quot;key&quot;</span><span>, </span><span class=\"string\">&quot;field&quot;</span><span>, </span><span class=\"string\">&quot;value&quot;</span><span>};&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String[] sGetArgs = {</span><span class=\"string\">&quot;key&quot;</span><span>};&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String[] sSetArgs = {</span><span class=\"string\">&quot;key&quot;</span><span>, </span><span class=\"string\">&quot;value&quot;</span><span>};&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Command cmd = CommandFactory.create(Utils.CLASS_HASH);&#160;&#160; </span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; cmd.set(hSetArgs);&#160;&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; cmd.get(hGetArgs);&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; cmd = CommandFactory.create(Utils.CLASS_SIMPLE);&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; cmd.set(sSetArgs);&#160;&#160; </span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; cmd.get(sGetArgs);&#160;&#160; </span>\n17.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n18.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>","slug":"design-pattern-factory","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg624h009esb8f5h4jcnon"},{"title":"设计模式 - 抽象工厂模式","id":"215","date":"2011-12-15T16:58:38.000Z","_content":"\n**GOF定义：**\n\n_“Provide an interface for creating familiesof related or dependent objects withoutspecifying their concrete classes.”_\n\n_“提供一个创建一系列相互依赖对象的接口，而无需指定它们具体的类。”_\n <!--more-->  \n\n如果我们需要实例化很多对象，而且这些对象之间有一定的关系；\n\n如果由于需求的变化，需要创建更多系列的对象。\n\n这个时候就可以开始考虑使用抽象工厂模式了。这种模式提供一种“封装机制”来避免客户程序和这种“多系列具体对象创建工作”的紧耦合。\n\n接上一篇工厂的数据库访问例子，原访问接口只有get与set两个方法，但是后面数据库更新了，发现还有一个自增长（incrby）的方法。这下该怎么做呢？修改原来的Command接口，这个不行，违背了开闭原则。既然不能修改原有的代码，那就只能扩展上层的代码了。\n\n那么，在原有的代码基础上，新增Incrable接口：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.abstractfactory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">interface</span><span> Incrable {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>5.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 自增长某个字段 </span>&#160;</span>6.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @param args 参数数组 </span>&#160;</span>7.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @param step 增长步长 </span>&#160;</span>8.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @return 增长后的长度 </span>&#160;</span>9.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n10.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">int</span><span> incrby(String[] args, </span><span class=\"keyword\">int</span><span> step);&#160;&#160; </span></span>\n11.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n且分别写两个实现类，HashIncrable与SimpleIncrable：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.abstractfactory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> HashIncrable </span><span class=\"keyword\">implements</span><span> Incrable {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">int</span><span> incrby(String[] args, </span><span class=\"keyword\">int</span><span> step) {&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String key, field;&#160;&#160; </span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> result = -</span><span class=\"number\">1</span><span>;&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (</span><span class=\"number\">2</span><span> == args.length) {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; key = args[</span><span class=\"number\">0</span><span>];&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; field = args[</span><span class=\"number\">1</span><span>];&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throw</span><span>&#160;</span><span class=\"keyword\">new</span><span> IllegalArgumentException(</span><span class=\"string\">&quot;参数输入不对&quot;</span><span>);&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 获得client对象，增长相应值 </span><span>&#160; </span></span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// sample: result = conn.incrby.....; </span><span>&#160; </span></span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> result;&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n18.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>      <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.abstractfactory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> SimpleIncrable </span><span class=\"keyword\">implements</span><span> Incrable {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">int</span><span> incrby(String[] args, </span><span class=\"keyword\">int</span><span> step) {&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String key;&#160;&#160; </span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> result = -</span><span class=\"number\">1</span><span>;&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (</span><span class=\"number\">1</span><span> == args.length) {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; key = args[</span><span class=\"number\">0</span><span>];&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throw</span><span>&#160;</span><span class=\"keyword\">new</span><span> IllegalArgumentException(</span><span class=\"string\">&quot;参数输入不对&quot;</span><span>);&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 获得client对象，增长相应值 </span><span>&#160; </span></span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// sample: result = conn.incrby.....; </span><span>&#160; </span></span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> result;&#160;&#160; </span></span>\n16.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n17.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n新增一个AbstactFactory的抽象类：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.abstractfactory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"comment\">/** </span>&#160;</span>4.  <span><span class=\"comment\">*&#160; </span>&#160;</span>5.  <span><span class=\"comment\">* 抽象工厂类，可生产相应的对象 </span>&#160;</span>6.  <span><span class=\"comment\">*&#160; </span>&#160;</span>7.  <span><span class=\"comment\">* @author 易鸿伟 Wikie </span>&#160;</span>8.  <span><span class=\"comment\">* @date 2011-12-15 </span>&#160;</span>9.  <span><span class=\"comment\">*/</span><span>&#160; </span></span>\n10.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span>&#160;</span><span class=\"keyword\">class</span><span> AbstractFactory {&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span> Command createCmd();&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span> Incrable createIncrable();&#160;&#160; </span></span>\n13.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n分别写两个类，实现AbstractFactory抽象类：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.abstractfactory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"comment\">/** </span>&#160;</span>4.  <span><span class=\"comment\">*&#160; </span>&#160;</span>5.  <span><span class=\"comment\">* Hash工厂，可以创建操作Hash结构的对象 </span>&#160;</span>6.  <span><span class=\"comment\">*&#160; </span>&#160;</span>7.  <span><span class=\"comment\">* @author 易鸿伟 Wikie </span>&#160;</span>8.  <span><span class=\"comment\">* @date 2011-12-15 </span>&#160;</span>9.  <span><span class=\"comment\">*/</span><span>&#160; </span></span>\n10.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> HashFactory </span><span class=\"keyword\">extends</span><span> AbstractFactory {&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> Command createCmd() {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">new</span><span> HashCommand();&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n16.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> Incrable createIncrable() {&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">new</span><span> HashIncrable();&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n19.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.abstractfactory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"comment\">/** </span>&#160;</span>4.  <span><span class=\"comment\">*&#160; </span>&#160;</span>5.  <span><span class=\"comment\">* Simple工厂，可以创建操作Simple结构的对象 </span>&#160;</span>6.  <span><span class=\"comment\">*&#160; </span>&#160;</span>7.  <span><span class=\"comment\">* @author 易鸿伟 Wikie </span>&#160;</span>8.  <span><span class=\"comment\">* @date 2011-12-15 </span>&#160;</span>9.  <span><span class=\"comment\">*/</span><span>&#160; </span></span>\n10.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> SimpleFactory </span><span class=\"keyword\">extends</span><span> AbstractFactory {&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> Command createCmd() {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">new</span><span> SimpleCommand();&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n16.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> Incrable createIncrable() {&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">new</span><span> SimpleIncrable();&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n19.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n最后就这样使用它：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.abstractfactory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Application {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">void</span><span> main(String[] args) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; AbstractFactory factory = </span><span class=\"keyword\">new</span><span> HashFactory();&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Command cmd = factory.createCmd();&#160;&#160; </span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Incrable incrable = factory.createIncrable();&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// cmd.get(args); </span><span>&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// cmd.set(args); </span><span>&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// incrable.incrby(args, step); </span><span>&#160; </span></span>\n11.  <span>&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; factory = </span><span class=\"keyword\">new</span><span> SimpleFactory();&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; cmd = factory.createCmd();&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; incrable = factory.createIncrable();&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// cmd.get(args); </span><span>&#160; </span></span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// cmd.set(args); </span><span>&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// incrable.incrby(args, step); </span><span>&#160; </span></span>\n18.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n19.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n关于工厂模式与抽象工厂模式的比较，等到主要设计模式总结完后，再一起比较吧。","source":"_posts/design-pattern-factory-abs.md","raw":"title: 设计模式 - 抽象工厂模式\ntags:\n  - 设计模式\nid: 215\ncategories:\n  - 技术分享\ndate: 2011-12-16 00:58:38\n---\n\n**GOF定义：**\n\n_“Provide an interface for creating familiesof related or dependent objects withoutspecifying their concrete classes.”_\n\n_“提供一个创建一系列相互依赖对象的接口，而无需指定它们具体的类。”_\n <!--more-->  \n\n如果我们需要实例化很多对象，而且这些对象之间有一定的关系；\n\n如果由于需求的变化，需要创建更多系列的对象。\n\n这个时候就可以开始考虑使用抽象工厂模式了。这种模式提供一种“封装机制”来避免客户程序和这种“多系列具体对象创建工作”的紧耦合。\n\n接上一篇工厂的数据库访问例子，原访问接口只有get与set两个方法，但是后面数据库更新了，发现还有一个自增长（incrby）的方法。这下该怎么做呢？修改原来的Command接口，这个不行，违背了开闭原则。既然不能修改原有的代码，那就只能扩展上层的代码了。\n\n那么，在原有的代码基础上，新增Incrable接口：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.abstractfactory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">interface</span><span> Incrable {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>5.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 自增长某个字段 </span>&#160;</span>6.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @param args 参数数组 </span>&#160;</span>7.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @param step 增长步长 </span>&#160;</span>8.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @return 增长后的长度 </span>&#160;</span>9.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n10.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">int</span><span> incrby(String[] args, </span><span class=\"keyword\">int</span><span> step);&#160;&#160; </span></span>\n11.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n且分别写两个实现类，HashIncrable与SimpleIncrable：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.abstractfactory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> HashIncrable </span><span class=\"keyword\">implements</span><span> Incrable {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">int</span><span> incrby(String[] args, </span><span class=\"keyword\">int</span><span> step) {&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String key, field;&#160;&#160; </span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> result = -</span><span class=\"number\">1</span><span>;&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (</span><span class=\"number\">2</span><span> == args.length) {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; key = args[</span><span class=\"number\">0</span><span>];&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; field = args[</span><span class=\"number\">1</span><span>];&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throw</span><span>&#160;</span><span class=\"keyword\">new</span><span> IllegalArgumentException(</span><span class=\"string\">&quot;参数输入不对&quot;</span><span>);&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 获得client对象，增长相应值 </span><span>&#160; </span></span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// sample: result = conn.incrby.....; </span><span>&#160; </span></span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> result;&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n18.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>      <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.abstractfactory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> SimpleIncrable </span><span class=\"keyword\">implements</span><span> Incrable {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">int</span><span> incrby(String[] args, </span><span class=\"keyword\">int</span><span> step) {&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; String key;&#160;&#160; </span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">int</span><span> result = -</span><span class=\"number\">1</span><span>;&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (</span><span class=\"number\">1</span><span> == args.length) {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; key = args[</span><span class=\"number\">0</span><span>];&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">throw</span><span>&#160;</span><span class=\"keyword\">new</span><span> IllegalArgumentException(</span><span class=\"string\">&quot;参数输入不对&quot;</span><span>);&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// 获得client对象，增长相应值 </span><span>&#160; </span></span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// sample: result = conn.incrby.....; </span><span>&#160; </span></span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> result;&#160;&#160; </span></span>\n16.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n17.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n新增一个AbstactFactory的抽象类：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.abstractfactory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"comment\">/** </span>&#160;</span>4.  <span><span class=\"comment\">*&#160; </span>&#160;</span>5.  <span><span class=\"comment\">* 抽象工厂类，可生产相应的对象 </span>&#160;</span>6.  <span><span class=\"comment\">*&#160; </span>&#160;</span>7.  <span><span class=\"comment\">* @author 易鸿伟 Wikie </span>&#160;</span>8.  <span><span class=\"comment\">* @date 2011-12-15 </span>&#160;</span>9.  <span><span class=\"comment\">*/</span><span>&#160; </span></span>\n10.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span>&#160;</span><span class=\"keyword\">class</span><span> AbstractFactory {&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span> Command createCmd();&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span> Incrable createIncrable();&#160;&#160; </span></span>\n13.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n分别写两个类，实现AbstractFactory抽象类：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.abstractfactory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"comment\">/** </span>&#160;</span>4.  <span><span class=\"comment\">*&#160; </span>&#160;</span>5.  <span><span class=\"comment\">* Hash工厂，可以创建操作Hash结构的对象 </span>&#160;</span>6.  <span><span class=\"comment\">*&#160; </span>&#160;</span>7.  <span><span class=\"comment\">* @author 易鸿伟 Wikie </span>&#160;</span>8.  <span><span class=\"comment\">* @date 2011-12-15 </span>&#160;</span>9.  <span><span class=\"comment\">*/</span><span>&#160; </span></span>\n10.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> HashFactory </span><span class=\"keyword\">extends</span><span> AbstractFactory {&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> Command createCmd() {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">new</span><span> HashCommand();&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n16.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> Incrable createIncrable() {&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">new</span><span> HashIncrable();&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n19.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.abstractfactory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"comment\">/** </span>&#160;</span>4.  <span><span class=\"comment\">*&#160; </span>&#160;</span>5.  <span><span class=\"comment\">* Simple工厂，可以创建操作Simple结构的对象 </span>&#160;</span>6.  <span><span class=\"comment\">*&#160; </span>&#160;</span>7.  <span><span class=\"comment\">* @author 易鸿伟 Wikie </span>&#160;</span>8.  <span><span class=\"comment\">* @date 2011-12-15 </span>&#160;</span>9.  <span><span class=\"comment\">*/</span><span>&#160; </span></span>\n10.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> SimpleFactory </span><span class=\"keyword\">extends</span><span> AbstractFactory {&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> Command createCmd() {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">new</span><span> SimpleCommand();&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n16.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> Incrable createIncrable() {&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">new</span><span> SimpleIncrable();&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n19.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n最后就这样使用它：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.abstractfactory;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Application {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">void</span><span> main(String[] args) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; AbstractFactory factory = </span><span class=\"keyword\">new</span><span> HashFactory();&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Command cmd = factory.createCmd();&#160;&#160; </span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Incrable incrable = factory.createIncrable();&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// cmd.get(args); </span><span>&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// cmd.set(args); </span><span>&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// incrable.incrby(args, step); </span><span>&#160; </span></span>\n11.  <span>&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; factory = </span><span class=\"keyword\">new</span><span> SimpleFactory();&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; cmd = factory.createCmd();&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; incrable = factory.createIncrable();&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// cmd.get(args); </span><span>&#160; </span></span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// cmd.set(args); </span><span>&#160; </span></span>\n17.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// incrable.incrby(args, step); </span><span>&#160; </span></span>\n18.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n19.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n关于工厂模式与抽象工厂模式的比较，等到主要设计模式总结完后，再一起比较吧。","slug":"design-pattern-factory-abs","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg624j009hsb8fkbe0qon7"},{"title":"设计模式 - 门面模式","id":"235","date":"2011-12-26T12:29:00.000Z","_content":"\n**GOF****定义：**\n\n_“Provide a unified interface to a set of interfaces in a subsystem. Facade defines a higher-level interface that makes the subsystem easier to use.” _\n <!--more-->  \n\n_“要求一个子系统的外部与其内部的通信必须通过一个统一的对象进行。门面模式提供了一个高层次的接口，使得子系统更易于使用。”_\n\n门面模式给用户提供了一个使用子系统的接口（或者说界面），让用户只能通过这个接口来访问子系统。即门面对象是外界访问子系统内部的唯一通道。\n\n每个应用程序其实都是一个门面，我们只能通过界面组件来访问系统内部资源，用起来非常简单的同时我们也不需要知道内部是怎么使用的（也不应该让用户深入内部）。\n\n如用户管理子系统：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.facade;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> UserFacade {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">private</span><span> LoginModule loginModule = </span><span class=\"keyword\">new</span><span> LoginModule();&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">private</span><span> RegModule regModule = </span><span class=\"keyword\">new</span><span> RegModule();&#160;&#160; </span></span>\n6.  <span>&#160; </span>\n7.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> reg(String name, String pwd, String info) {&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; regModule.reg(name, pwd, info);&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n10.  <span>&#160; </span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> login(String name, String pwd) {&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; loginModule.login(name, pwd);&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n在LoginModule以及RegModule中分别实现了login以及reg的逻辑。\n\n门面模式的优缺点：\n\n**1、 减少系统的相互依赖**\n\n减少了用户或者其它子系统与子系统之间的依赖关系，让它们依赖的是门面，而不是子系统本身。\n\n**2、 提供了灵活性**\n\n减少依赖关系，灵活性自然就提高了。无论子系统内部如何变化，只要门面没有变，外部就没有影响。\n\n**3、 提高安全性**\n\n用户不知道内部实现的逻辑，也不能访问到内部实现，提高了安全性。\n\n门面模式的缺点也显而易见，不符合开闭原则。如果还有功能需要添加的话，继承复用均没用，只能修改门面的代码。所以使用之前，需要多思考思考。","source":"_posts/design-pattern-facade.md","raw":"title: 设计模式 - 门面模式\ntags:\n  - 设计模式\nid: 235\ncategories:\n  - 技术分享\ndate: 2011-12-26 20:29:00\n---\n\n**GOF****定义：**\n\n_“Provide a unified interface to a set of interfaces in a subsystem. Facade defines a higher-level interface that makes the subsystem easier to use.” _\n <!--more-->  \n\n_“要求一个子系统的外部与其内部的通信必须通过一个统一的对象进行。门面模式提供了一个高层次的接口，使得子系统更易于使用。”_\n\n门面模式给用户提供了一个使用子系统的接口（或者说界面），让用户只能通过这个接口来访问子系统。即门面对象是外界访问子系统内部的唯一通道。\n\n每个应用程序其实都是一个门面，我们只能通过界面组件来访问系统内部资源，用起来非常简单的同时我们也不需要知道内部是怎么使用的（也不应该让用户深入内部）。\n\n如用户管理子系统：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.facade;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> UserFacade {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">private</span><span> LoginModule loginModule = </span><span class=\"keyword\">new</span><span> LoginModule();&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">private</span><span> RegModule regModule = </span><span class=\"keyword\">new</span><span> RegModule();&#160;&#160; </span></span>\n6.  <span>&#160; </span>\n7.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> reg(String name, String pwd, String info) {&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; regModule.reg(name, pwd, info);&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n10.  <span>&#160; </span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> login(String name, String pwd) {&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; loginModule.login(name, pwd);&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n在LoginModule以及RegModule中分别实现了login以及reg的逻辑。\n\n门面模式的优缺点：\n\n**1、 减少系统的相互依赖**\n\n减少了用户或者其它子系统与子系统之间的依赖关系，让它们依赖的是门面，而不是子系统本身。\n\n**2、 提供了灵活性**\n\n减少依赖关系，灵活性自然就提高了。无论子系统内部如何变化，只要门面没有变，外部就没有影响。\n\n**3、 提高安全性**\n\n用户不知道内部实现的逻辑，也不能访问到内部实现，提高了安全性。\n\n门面模式的缺点也显而易见，不符合开闭原则。如果还有功能需要添加的话，继承复用均没用，只能修改门面的代码。所以使用之前，需要多思考思考。","slug":"design-pattern-facade","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg624k009ksb8fhdbgg0za"},{"title":"设计模式 - 装饰模式","id":"234","date":"2011-12-25T15:41:03.000Z","_content":"\n**GOF****定义：**\n\n_“Attach additional responsibilities to an object dynamically keeping the same interface. Decorators provide a flexible alternative to subclassing for extending functionality.” _\n\n_“动态地给一个对象添加一些额外的职责，就增加功能来说，装饰模式相比生成子类更为灵活。”_\n <!--more-->  \n\n如果你想给某个类添加一个功能，但是觉得没有到继承的地步；如果直接修改新增方法，那么新增方法对子类的影响大不大，这个也不太好说。最好的方法就是通过新增一个Decorator类来修饰该类。\n\n设计一个Mp3播放器：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.decorator;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> MP3PlayerComponent </span><span class=\"keyword\">implements</span><span> Component {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> operate() {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(</span><span class=\"string\">&quot;Play a mp3 now!&quot;</span><span>);&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n8.  <span>}&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n使用一段时间后，发现还想添加一些功能，比如说播放歌词，让修改吧，不符合开闭原则。继承吧，MP3PlayerWithLrcComponent，怎么看怎么怪。直接用一个修饰器是最方便的：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.decorator;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span>&#160;</span><span class=\"keyword\">class</span><span> Decorator </span><span class=\"keyword\">implements</span><span> Component {&#160;&#160; </span></span>\n4.  <span>&#160; </span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">private</span><span> Component component = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>\n6.  <span>&#160; </span>\n7.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> Decorator(Component component) {&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.component = component;&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n10.  <span>&#160; </span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> operate() {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.component.operate();&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>}&#160; </span>           </div>         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.decorator;&#160;&#160; </span></span>2.  <span>&#160; </span>3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> MP3Decorator </span><span class=\"keyword\">extends</span><span> Decorator {&#160;&#160; </span></span>4.  <span>&#160; </span>5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> MP3Decorator(Component component) {&#160;&#160; </span></span>6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">super</span><span>(component);&#160;&#160; </span></span>7.  <span>&#160;&#160;&#160; }&#160;&#160; </span>8.  <span>&#160; </span>9.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>10.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 自己的装饰方法 显示歌词 </span>&#160;</span>11.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> showLrc() {&#160;&#160; </span></span>13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>15.  <span>&#160; </span>16.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>17.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> operate() {&#160;&#160; </span></span>18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">super</span><span>.operate();&#160;&#160; </span></span>19.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.showLrc();&#160;&#160; </span></span>20.  <span>&#160;&#160;&#160; }&#160;&#160; </span>21.  <span>}&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n优点：\n\n**1、 ****装饰器与被装饰类解耦**\n\n装饰器在扩展类的功能的时候，与被装饰类完全解耦，独立运行。\n\n**2、 ****符合合成复用原则**","source":"_posts/design-pattern-decorate.md","raw":"title: 设计模式 - 装饰模式\ntags:\n  - 设计模式\nid: 234\ncategories:\n  - 技术分享\ndate: 2011-12-25 23:41:03\n---\n\n**GOF****定义：**\n\n_“Attach additional responsibilities to an object dynamically keeping the same interface. Decorators provide a flexible alternative to subclassing for extending functionality.” _\n\n_“动态地给一个对象添加一些额外的职责，就增加功能来说，装饰模式相比生成子类更为灵活。”_\n <!--more-->  \n\n如果你想给某个类添加一个功能，但是觉得没有到继承的地步；如果直接修改新增方法，那么新增方法对子类的影响大不大，这个也不太好说。最好的方法就是通过新增一个Decorator类来修饰该类。\n\n设计一个Mp3播放器：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.decorator;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> MP3PlayerComponent </span><span class=\"keyword\">implements</span><span> Component {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> operate() {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(</span><span class=\"string\">&quot;Play a mp3 now!&quot;</span><span>);&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n8.  <span>}&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n使用一段时间后，发现还想添加一些功能，比如说播放歌词，让修改吧，不符合开闭原则。继承吧，MP3PlayerWithLrcComponent，怎么看怎么怪。直接用一个修饰器是最方便的：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.decorator;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span>&#160;</span><span class=\"keyword\">class</span><span> Decorator </span><span class=\"keyword\">implements</span><span> Component {&#160;&#160; </span></span>\n4.  <span>&#160; </span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">private</span><span> Component component = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>\n6.  <span>&#160; </span>\n7.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> Decorator(Component component) {&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.component = component;&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n10.  <span>&#160; </span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> operate() {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.component.operate();&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>}&#160; </span>           </div>         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.decorator;&#160;&#160; </span></span>2.  <span>&#160; </span>3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> MP3Decorator </span><span class=\"keyword\">extends</span><span> Decorator {&#160;&#160; </span></span>4.  <span>&#160; </span>5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> MP3Decorator(Component component) {&#160;&#160; </span></span>6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">super</span><span>(component);&#160;&#160; </span></span>7.  <span>&#160;&#160;&#160; }&#160;&#160; </span>8.  <span>&#160; </span>9.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>10.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 自己的装饰方法 显示歌词 </span>&#160;</span>11.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> showLrc() {&#160;&#160; </span></span>13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>15.  <span>&#160; </span>16.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>17.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> operate() {&#160;&#160; </span></span>18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">super</span><span>.operate();&#160;&#160; </span></span>19.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">this</span><span>.showLrc();&#160;&#160; </span></span>20.  <span>&#160;&#160;&#160; }&#160;&#160; </span>21.  <span>}&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n优点：\n\n**1、 ****装饰器与被装饰类解耦**\n\n装饰器在扩展类的功能的时候，与被装饰类完全解耦，独立运行。\n\n**2、 ****符合合成复用原则**","slug":"design-pattern-decorate","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg624l009nsb8fayiwbpg6"},{"title":"设计模式 - 责任链模式","id":"229","date":"2011-12-22T02:51:28.000Z","_content":"\n**GOF****定义：**\n\n_“Avoid coupling thesender of a request to its receiver by giving more than one object a chance to handle the request. Chain the receiving objects and pass the request along the chain until an object handles it” _\n\n_“使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它为止。”_\n <!--more-->  \n\n如果你有多个类似的处理逻辑，但是事先不知道到底应该由哪一个处理，你可以考虑使用一下责任链模式。\n\n用户将请求发到责任链的起始对象，如果该对象无法解决问题，则将请求发往链的下一个对象，依此迭代，直到有对象处理请求或者无人处理直接返回。不过在一个纯的责任链模式中，不会出现无人处理的情况，一个请求必须被某一个处理对象所接受。\n\n想象一下腾讯的等级加速情况，普通用户以及VIP1-6（听说快出7了），每个等级都有自己的天数加速策略。我们可以模拟一下，下面这个是加速器抽象类：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.chainofresponsibility;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span>&#160;</span><span class=\"keyword\">class</span><span> Speeder {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">protected</span><span> Speeder next;&#160;&#160; </span></span>\n5.  <span>&#160; </span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> setNext(Speeder next) {&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Speeder tmp = </span><span class=\"keyword\">this</span><span>;&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">while</span><span> (</span><span class=\"keyword\">null</span><span> != tmp.next) {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; tmp = tmp.next;&#160;&#160; </span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; tmp.next = next;&#160;&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; tmp = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>&#160; </span>\n15.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>16.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 判断是否还有下一个结点 </span>&#160;</span>17.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; *&#160; </span>&#160;</span>18.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @return </span>&#160;</span>19.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n20.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">boolean</span><span> hasNext() {&#160;&#160; </span></span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (</span><span class=\"keyword\">null</span><span> != next) {&#160;&#160; </span></span>\n22.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">true</span><span>;&#160;&#160; </span></span>\n23.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n24.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">false</span><span>;&#160;&#160; </span></span>\n25.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n26.  <span>&#160; </span>\n27.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span>&#160;</span><span class=\"keyword\">void</span><span> speed(User user);&#160;&#160; </span></span>\n28.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span>&#160;</span><span class=\"keyword\">boolean</span><span> canHandle(User user);&#160;&#160; </span></span>\n29.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n普通用户加速器：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.chainofresponsibility;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> SimpleSpeeder </span><span class=\"keyword\">extends</span><span> Speeder {&#160;&#160; </span></span>\n4.  <span>&#160; </span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> speed(User user) {&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (canHandle(user)) {&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (hasNext()) {&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; next.speed(user);&#160;&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>&#160; </span>\n16.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n17.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">boolean</span><span> canHandle(User user) {&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (!user.isVIP) {&#160;&#160; </span></span>\n19.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">true</span><span>;&#160;&#160; </span></span>\n20.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">false</span><span>;&#160;&#160; </span></span>\n22.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n23.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\nVIP1加速器：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.chainofresponsibility;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> VIP1Speeder </span><span class=\"keyword\">extends</span><span> Speeder {&#160;&#160; </span></span>\n4.  <span>&#160; </span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">int</span><span> LEVEL = </span><span class=\"number\">1</span><span>;&#160;&#160; </span></span>\n6.  <span>&#160; </span>\n7.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n8.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> speed(User user) {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (canHandle(user)) {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(</span><span class=\"number\">1</span><span>+</span><span class=\"string\">&quot;&quot;</span><span>);&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (hasNext()) {&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; next.speed(user);&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n17.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n18.  <span>&#160; </span>\n19.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n20.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">boolean</span><span> canHandle(User user) {&#160;&#160; </span></span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (LEVEL == user.levelVIP) {&#160;&#160; </span></span>\n22.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">true</span><span>;&#160;&#160; </span></span>\n23.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n24.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">false</span><span>;&#160;&#160; </span></span>\n25.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n26.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\nVIP2同上，就只修改了LEVEL常量。\n\n使用的时候：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.chainofresponsibility;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Application {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">void</span><span> main(String[] args) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; User user = </span><span class=\"keyword\">new</span><span> User();&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; user.isVIP = </span><span class=\"keyword\">true</span><span>;&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; user.levelVIP = </span><span class=\"number\">2</span><span>;&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Speeder speeder = </span><span class=\"keyword\">new</span><span> SimpleSpeeder();&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; speeder.setNext(</span><span class=\"keyword\">new</span><span> VIP1Speeder());&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; speeder.setNext(</span><span class=\"keyword\">new</span><span> VIP2Speeder());&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; speeder.speed(user);&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n这个只是用责任链模式简单模拟了一下QQ等级加速的情况，并不代表现实情况。\n\n显然，VIP6加速就得往下传递6次，有点浪费资源，但是如果腾讯再推出一个VIP7，又有不同的speed策略怎么办呢？用责任链的话，只需要添加一个VIP7Speeder类，在speeder链中加入这个结点即可。在原来的基础之上，不需要修改，只需要在应用中添加一行代码，符合开闭原则。同理，在设计之初，也可以加入删除的接口。","source":"_posts/design-pattern-cor.md","raw":"title: 设计模式 - 责任链模式\ntags:\n  - 设计模式\nid: 229\ncategories:\n  - 技术分享\ndate: 2011-12-22 10:51:28\n---\n\n**GOF****定义：**\n\n_“Avoid coupling thesender of a request to its receiver by giving more than one object a chance to handle the request. Chain the receiving objects and pass the request along the chain until an object handles it” _\n\n_“使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它为止。”_\n <!--more-->  \n\n如果你有多个类似的处理逻辑，但是事先不知道到底应该由哪一个处理，你可以考虑使用一下责任链模式。\n\n用户将请求发到责任链的起始对象，如果该对象无法解决问题，则将请求发往链的下一个对象，依此迭代，直到有对象处理请求或者无人处理直接返回。不过在一个纯的责任链模式中，不会出现无人处理的情况，一个请求必须被某一个处理对象所接受。\n\n想象一下腾讯的等级加速情况，普通用户以及VIP1-6（听说快出7了），每个等级都有自己的天数加速策略。我们可以模拟一下，下面这个是加速器抽象类：\n  <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>     <tr>       <td valign=\"top\" width=\"568\">         <div class=\"dp-highlighter\">           <div class=\"bar\"></div>            \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.chainofresponsibility;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span>&#160;</span><span class=\"keyword\">class</span><span> Speeder {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">protected</span><span> Speeder next;&#160;&#160; </span></span>\n5.  <span>&#160; </span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> setNext(Speeder next) {&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Speeder tmp = </span><span class=\"keyword\">this</span><span>;&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">while</span><span> (</span><span class=\"keyword\">null</span><span> != tmp.next) {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; tmp = tmp.next;&#160;&#160; </span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; tmp.next = next;&#160;&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; tmp = </span><span class=\"keyword\">null</span><span>;&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>&#160; </span>\n15.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>16.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 判断是否还有下一个结点 </span>&#160;</span>17.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; *&#160; </span>&#160;</span>18.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * @return </span>&#160;</span>19.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n20.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">boolean</span><span> hasNext() {&#160;&#160; </span></span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (</span><span class=\"keyword\">null</span><span> != next) {&#160;&#160; </span></span>\n22.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">true</span><span>;&#160;&#160; </span></span>\n23.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n24.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">false</span><span>;&#160;&#160; </span></span>\n25.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n26.  <span>&#160; </span>\n27.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span>&#160;</span><span class=\"keyword\">void</span><span> speed(User user);&#160;&#160; </span></span>\n28.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">abstract</span><span>&#160;</span><span class=\"keyword\">boolean</span><span> canHandle(User user);&#160;&#160; </span></span>\n29.  <span>}&#160;&#160; </span>         </div>       </td>     </tr>   </tbody></table>  \n\n普通用户加速器：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.chainofresponsibility;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> SimpleSpeeder </span><span class=\"keyword\">extends</span><span> Speeder {&#160;&#160; </span></span>\n4.  <span>&#160; </span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n6.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> speed(User user) {&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (canHandle(user)) {&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (hasNext()) {&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; next.speed(user);&#160;&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>&#160; </span>\n16.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n17.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">boolean</span><span> canHandle(User user) {&#160;&#160; </span></span>\n18.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (!user.isVIP) {&#160;&#160; </span></span>\n19.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">true</span><span>;&#160;&#160; </span></span>\n20.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">false</span><span>;&#160;&#160; </span></span>\n22.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n23.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\nVIP1加速器：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.chainofresponsibility;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> VIP1Speeder </span><span class=\"keyword\">extends</span><span> Speeder {&#160;&#160; </span></span>\n4.  <span>&#160; </span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">int</span><span> LEVEL = </span><span class=\"number\">1</span><span>;&#160;&#160; </span></span>\n6.  <span>&#160; </span>\n7.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n8.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">void</span><span> speed(User user) {&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (canHandle(user)) {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"comment\">// TODO </span><span>&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(</span><span class=\"number\">1</span><span>+</span><span class=\"string\">&quot;&quot;</span><span>);&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; } </span><span class=\"keyword\">else</span><span> {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (hasNext()) {&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; next.speed(user);&#160;&#160; </span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n17.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n18.  <span>&#160; </span>\n19.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n20.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">boolean</span><span> canHandle(User user) {&#160;&#160; </span></span>\n21.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">if</span><span> (LEVEL == user.levelVIP) {&#160;&#160; </span></span>\n22.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">true</span><span>;&#160;&#160; </span></span>\n23.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; }&#160;&#160; </span>\n24.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span>&#160;</span><span class=\"keyword\">false</span><span>;&#160;&#160; </span></span>\n25.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n26.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\nVIP2同上，就只修改了LEVEL常量。\n\n使用的时候：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.chainofresponsibility;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Application {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">void</span><span> main(String[] args) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; User user = </span><span class=\"keyword\">new</span><span> User();&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; user.isVIP = </span><span class=\"keyword\">true</span><span>;&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; user.levelVIP = </span><span class=\"number\">2</span><span>;&#160;&#160; </span></span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Speeder speeder = </span><span class=\"keyword\">new</span><span> SimpleSpeeder();&#160;&#160; </span></span>\n9.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; speeder.setNext(</span><span class=\"keyword\">new</span><span> VIP1Speeder());&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; speeder.setNext(</span><span class=\"keyword\">new</span><span> VIP2Speeder());&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; speeder.speed(user);&#160;&#160; </span>\n13.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n14.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n这个只是用责任链模式简单模拟了一下QQ等级加速的情况，并不代表现实情况。\n\n显然，VIP6加速就得往下传递6次，有点浪费资源，但是如果腾讯再推出一个VIP7，又有不同的speed策略怎么办呢？用责任链的话，只需要添加一个VIP7Speeder类，在speeder链中加入这个结点即可。在原来的基础之上，不需要修改，只需要在应用中添加一行代码，符合开闭原则。同理，在设计之初，也可以加入删除的接口。","slug":"design-pattern-cor","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg624n009qsb8fgrc69ec1"},{"title":"设计模式 - 优点总结（补）","id":"232","date":"2011-12-25T15:36:59.000Z","_content":"\n之前写的模式（工厂、抽象工厂、单例、观察者、责任链）没有总结优点，在这里补上。\n <!--more-->  \n\n至于缺点总结嘛，抄书没意思，自己写又缺乏经验，还是不总结了吧。\n\n● **工厂模式**\n\n1、 良好的封装性，代码结构清晰\n\n完全屏蔽了实现类，将所有的实现封装起来，用户不需要知道怎么创建的，只需要知道类名即可，降低模块间的耦合。\n\n2、 扩展性非常优秀\n\n在增加新的产品类的时候，只需要增加一个具体的产品类。如前面的例子，Redis中还有set类型的数据结构，只需要实现一个SetCommand的具体类即可，工程类不需要做任何修改。\n\n3、 典型的解耦框架\n\n使用者只需要知道使用对象的接口即可，符合开闭原则，扩展性好；符合迪米特法则，不会去和无关的类做交流；符合依赖倒置原则，只依赖于接口（抽象）。\n\n● **抽象工厂模式**\n\n1、 有工厂模式的所有优点\n\n2、 易于交换产品\n\n当产品需求改变的时候，只需要更改相应的工厂即可。\n\n● **单例模式：**\n\n1、 节省内存，减少系统开销\n\n典型的优点，避免了系统中存在多个这样的实例，且减少了频繁地创建销毁时的系统开销。\n\n2、 避免对资源的多重占用\n\n如写文件操作，只有一个实例的话，就不会有多个文件的读写操作了。\n\n3、 设置全局访问点\n\n前面也说到了，即应用中存在多个（过多个）实例可能会引发程序（逻辑）错误时，设置一个全局访问点（单例），可以很好的解决这个问题。\n\n● **观察者模式：**\n\n1、 观察者与被观察者之间的解耦\n\n观察者与被观察者之间解耦得很彻底，都可以非常容易的扩展开来。如监听器模式中，组件与监听器之间，完全的解耦。\n\n2、 支持广播通信\n\n添加多个观察者后，可以有广播通知。\n\n● **责任链模式：**\n\n1、 请求与处理解耦\n\n用户无需知道是哪个对象处理的请求，处理对象也不需要知道请求的全貌，两者解耦。\n\n2、 可动态添加删除处理对象\n\n如链表一样，可动态添加删除处理对象，而原有代码无需修改。","source":"_posts/design-pattern-additional.md","raw":"title: 设计模式 - 优点总结（补）\ntags:\n  - 设计模式\nid: 232\ncategories:\n  - 技术分享\ndate: 2011-12-25 23:36:59\n---\n\n之前写的模式（工厂、抽象工厂、单例、观察者、责任链）没有总结优点，在这里补上。\n <!--more-->  \n\n至于缺点总结嘛，抄书没意思，自己写又缺乏经验，还是不总结了吧。\n\n● **工厂模式**\n\n1、 良好的封装性，代码结构清晰\n\n完全屏蔽了实现类，将所有的实现封装起来，用户不需要知道怎么创建的，只需要知道类名即可，降低模块间的耦合。\n\n2、 扩展性非常优秀\n\n在增加新的产品类的时候，只需要增加一个具体的产品类。如前面的例子，Redis中还有set类型的数据结构，只需要实现一个SetCommand的具体类即可，工程类不需要做任何修改。\n\n3、 典型的解耦框架\n\n使用者只需要知道使用对象的接口即可，符合开闭原则，扩展性好；符合迪米特法则，不会去和无关的类做交流；符合依赖倒置原则，只依赖于接口（抽象）。\n\n● **抽象工厂模式**\n\n1、 有工厂模式的所有优点\n\n2、 易于交换产品\n\n当产品需求改变的时候，只需要更改相应的工厂即可。\n\n● **单例模式：**\n\n1、 节省内存，减少系统开销\n\n典型的优点，避免了系统中存在多个这样的实例，且减少了频繁地创建销毁时的系统开销。\n\n2、 避免对资源的多重占用\n\n如写文件操作，只有一个实例的话，就不会有多个文件的读写操作了。\n\n3、 设置全局访问点\n\n前面也说到了，即应用中存在多个（过多个）实例可能会引发程序（逻辑）错误时，设置一个全局访问点（单例），可以很好的解决这个问题。\n\n● **观察者模式：**\n\n1、 观察者与被观察者之间的解耦\n\n观察者与被观察者之间解耦得很彻底，都可以非常容易的扩展开来。如监听器模式中，组件与监听器之间，完全的解耦。\n\n2、 支持广播通信\n\n添加多个观察者后，可以有广播通知。\n\n● **责任链模式：**\n\n1、 请求与处理解耦\n\n用户无需知道是哪个对象处理的请求，处理对象也不需要知道请求的全貌，两者解耦。\n\n2、 可动态添加删除处理对象\n\n如链表一样，可动态添加删除处理对象，而原有代码无需修改。","slug":"design-pattern-additional","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg624o009tsb8f05k3y3ne"},{"title":"设计模式 - 适配器模式","id":"238","date":"2011-12-26T14:31:00.000Z","_content":"\n**GOF****定义：**\n\n_“Convert the interface of a class into another interface clients expect. Adapter lets classed work together thar couldn’t otherwise because of incompatible interfaces.” _\n\n_“将一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口不匹配而无法在一起工作的两个类能够在一起工作。”_\n <!--more-->  \n\n国外用的电压和国内的不一样，有110V的330V的，为了让水货电器更好的适配大陆地区，需要额外附加一个适配器。这个和我们所说的适配器模式差不多，都是在不变更对象的情况下，让原本不适合的对象适配起来。\n\n如系统升级的时候，需要考虑到新系统的兼容性，就需要有一个适配器，接受低版本的请求；写多客户端或者多语言的项目的时候，也需要添加适配器，能够处理不同的请求；Android开发中为了让数据能够显示在界面上，也大量用到了适配器模式。\n\n如做一个查询系统，有IBasicInfo以及IEducationInfo两个接口，分别获得用户的基本信息以及教育信息。    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.adapter;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> BasicInfo </span><span class=\"keyword\">implements</span><span> IBasicInfo {&#160;&#160; </span></span>\n4.  <span>&#160; </span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>6.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 获得基本信息 </span>&#160;</span>7.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n8.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n9.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> Map&lt;String, String&gt; getBasicInfo() {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Map&lt;String, String&gt; map = </span><span class=\"keyword\">new</span><span> HashMap&lt;String, String&gt;();&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; map.put(</span><span class=\"string\">&quot;Name&quot;</span><span>, </span><span class=\"string\">&quot;Wikie&quot;</span><span>);&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; map.put(</span><span class=\"string\">&quot;Gender&quot;</span><span>, </span><span class=\"string\">&quot;male&quot;</span><span>);&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> map;&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.adapter;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">import</span><span> java.util.HashMap;&#160;&#160; </span></span>\n4.  <span></span><span class=\"keyword\">import</span><span> java.util.Map;&#160;&#160; </span></span>\n5.  <span>&#160; </span>\n6.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> EducationInfo </span><span class=\"keyword\">implements</span><span> IEducationInfo {&#160;&#160; </span></span>\n7.  <span>&#160; </span>\n8.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>9.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 获得教育信息 </span>&#160;</span>10.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> Map&lt;String, String&gt; getEducationInfo() {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Map&lt;String, String&gt; map = </span><span class=\"keyword\">new</span><span> HashMap&lt;String, String&gt;();&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; map.put(</span><span class=\"string\">&quot;Master&quot;</span><span>, </span><span class=\"string\">&quot;BUAA&quot;</span><span>);&#160;&#160; </span></span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; map.put(</span><span class=\"string\">&quot;Major&quot;</span><span>, </span><span class=\"string\">&quot;Software Engineering&quot;</span><span>);&#160;&#160; </span></span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> map;&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n18.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n使用的时候就比较简单了，    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.adapter;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Application {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">void</span><span> main(String[] args) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; IBasicInfo basicInfo = </span><span class=\"keyword\">new</span><span> BasicInfo();&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; IEducationInfo educationInfo = </span><span class=\"keyword\">new</span><span> EducationInfo();&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(basicInfo.getBasicInfo());&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(educationInfo.getEducationInfo());&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n10.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n但是后面一拍脑袋，还有工作信息，家庭信息等等等，再继续创建接口与实现类？继续创建吧，但是如果我还想要获得所有信息呢？单独创建每个对象，再单独获得信息，这个就比较麻烦了，不过直接写一个适配器吧！    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.adapter;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Application {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">void</span><span> main(String[] args) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; IBasicInfo basicInfo = </span><span class=\"keyword\">new</span><span> BasicInfo();&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; IEducationInfo educationInfo = </span><span class=\"keyword\">new</span><span> EducationInfo();&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(basicInfo.getBasicInfo());&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(educationInfo.getEducationInfo());&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n10.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n使用的时候：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.adapter;&#160;&#160; </span></span>2.  <span>&#160; </span>3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Application {&#160;&#160; </span></span>4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">void</span><span> main(String[] args) {&#160;&#160; </span></span>5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; IInfoAdapter infoAdapter = </span><span class=\"keyword\">new</span><span> InfoAdapter();&#160;&#160; </span></span>6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(infoAdapter.getInfo());&#160;&#160; </span>7.  <span>&#160;&#160;&#160; }&#160;&#160; </span>8.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n最开始的时候我在想：如果设计之初就设计一个IInfo接口，那么什么麻烦都没有。但是设计总是会有纰漏的，适配器模式就是一个“补缺”的工具，用来解决接口不相容的问题。\n\n适配器的优点：\n\n**1、 ****关联不同的类**\n\n只要你愿意，你就可以让任何两个没有一点关系的类一起运行，只要适配器写得好。\n\n**2、 ****提高了复用度**\n\n原有的代码还能在原来的系统中用，新增的功能也很好的使用到了旧代码，很好的提高了代码复用度。\n\n**3、 ****非常灵活**\n\n适配器可以任意添加删除，对系统没有任何影响。","source":"_posts/design-pattern-adapter.md","raw":"title: 设计模式 - 适配器模式\ntags:\n  - 设计模式\nid: 238\ncategories:\n  - 技术分享\ndate: 2011-12-26 22:31:00\n---\n\n**GOF****定义：**\n\n_“Convert the interface of a class into another interface clients expect. Adapter lets classed work together thar couldn’t otherwise because of incompatible interfaces.” _\n\n_“将一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口不匹配而无法在一起工作的两个类能够在一起工作。”_\n <!--more-->  \n\n国外用的电压和国内的不一样，有110V的330V的，为了让水货电器更好的适配大陆地区，需要额外附加一个适配器。这个和我们所说的适配器模式差不多，都是在不变更对象的情况下，让原本不适合的对象适配起来。\n\n如系统升级的时候，需要考虑到新系统的兼容性，就需要有一个适配器，接受低版本的请求；写多客户端或者多语言的项目的时候，也需要添加适配器，能够处理不同的请求；Android开发中为了让数据能够显示在界面上，也大量用到了适配器模式。\n\n如做一个查询系统，有IBasicInfo以及IEducationInfo两个接口，分别获得用户的基本信息以及教育信息。    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.adapter;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> BasicInfo </span><span class=\"keyword\">implements</span><span> IBasicInfo {&#160;&#160; </span></span>\n4.  <span>&#160; </span>\n5.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>6.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 获得基本信息 </span>&#160;</span>7.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n8.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n9.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> Map&lt;String, String&gt; getBasicInfo() {&#160;&#160; </span></span>\n10.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Map&lt;String, String&gt; map = </span><span class=\"keyword\">new</span><span> HashMap&lt;String, String&gt;();&#160;&#160; </span></span>\n11.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; map.put(</span><span class=\"string\">&quot;Name&quot;</span><span>, </span><span class=\"string\">&quot;Wikie&quot;</span><span>);&#160;&#160; </span></span>\n12.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; map.put(</span><span class=\"string\">&quot;Gender&quot;</span><span>, </span><span class=\"string\">&quot;male&quot;</span><span>);&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> map;&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n15.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>        <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.adapter;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">import</span><span> java.util.HashMap;&#160;&#160; </span></span>\n4.  <span></span><span class=\"keyword\">import</span><span> java.util.Map;&#160;&#160; </span></span>\n5.  <span>&#160; </span>\n6.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> EducationInfo </span><span class=\"keyword\">implements</span><span> IEducationInfo {&#160;&#160; </span></span>\n7.  <span>&#160; </span>\n8.  <span>&#160;&#160;&#160; </span><span class=\"comment\">/** </span>&#160;</span>9.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; * 获得教育信息 </span>&#160;</span>10.  <span><span class=\"comment\">&#160;&#160;&#160;&#160; */</span><span>&#160; </span></span>\n11.  <span>&#160;&#160;&#160; </span><span class=\"annotation\">@Override</span><span>&#160; </span></span>\n12.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span> Map&lt;String, String&gt; getEducationInfo() {&#160;&#160; </span></span>\n13.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; Map&lt;String, String&gt; map = </span><span class=\"keyword\">new</span><span> HashMap&lt;String, String&gt;();&#160;&#160; </span></span>\n14.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; map.put(</span><span class=\"string\">&quot;Master&quot;</span><span>, </span><span class=\"string\">&quot;BUAA&quot;</span><span>);&#160;&#160; </span></span>\n15.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; map.put(</span><span class=\"string\">&quot;Major&quot;</span><span>, </span><span class=\"string\">&quot;Software Engineering&quot;</span><span>);&#160;&#160; </span></span>\n16.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; </span><span class=\"keyword\">return</span><span> map;&#160;&#160; </span></span>\n17.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n18.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n使用的时候就比较简单了，    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.adapter;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Application {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">void</span><span> main(String[] args) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; IBasicInfo basicInfo = </span><span class=\"keyword\">new</span><span> BasicInfo();&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; IEducationInfo educationInfo = </span><span class=\"keyword\">new</span><span> EducationInfo();&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(basicInfo.getBasicInfo());&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(educationInfo.getEducationInfo());&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n10.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n但是后面一拍脑袋，还有工作信息，家庭信息等等等，再继续创建接口与实现类？继续创建吧，但是如果我还想要获得所有信息呢？单独创建每个对象，再单独获得信息，这个就比较麻烦了，不过直接写一个适配器吧！    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.adapter;&#160;&#160; </span></span>\n2.  <span>&#160; </span>\n3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Application {&#160;&#160; </span></span>\n4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">void</span><span> main(String[] args) {&#160;&#160; </span></span>\n5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; IBasicInfo basicInfo = </span><span class=\"keyword\">new</span><span> BasicInfo();&#160;&#160; </span></span>\n6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; IEducationInfo educationInfo = </span><span class=\"keyword\">new</span><span> EducationInfo();&#160;&#160; </span></span>\n7.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(basicInfo.getBasicInfo());&#160;&#160; </span>\n8.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(educationInfo.getEducationInfo());&#160;&#160; </span>\n9.  <span>&#160;&#160;&#160; }&#160;&#160; </span>\n10.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n使用的时候：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <div class=\"dp-highlighter\">             <div class=\"bar\"></div>              \n\n1.  <span><span class=\"keyword\">package</span><span> com.wikieno.adapter;&#160;&#160; </span></span>2.  <span>&#160; </span>3.  <span></span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">class</span><span> Application {&#160;&#160; </span></span>4.  <span>&#160;&#160;&#160; </span><span class=\"keyword\">public</span><span>&#160;</span><span class=\"keyword\">static</span><span>&#160;</span><span class=\"keyword\">void</span><span> main(String[] args) {&#160;&#160; </span></span>5.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; IInfoAdapter infoAdapter = </span><span class=\"keyword\">new</span><span> InfoAdapter();&#160;&#160; </span></span>6.  <span>&#160;&#160;&#160;&#160;&#160;&#160;&#160; System.out.println(infoAdapter.getInfo());&#160;&#160; </span>7.  <span>&#160;&#160;&#160; }&#160;&#160; </span>8.  <span>}&#160;&#160; </span>           </div>         </td>       </tr>     </tbody></table> \n\n最开始的时候我在想：如果设计之初就设计一个IInfo接口，那么什么麻烦都没有。但是设计总是会有纰漏的，适配器模式就是一个“补缺”的工具，用来解决接口不相容的问题。\n\n适配器的优点：\n\n**1、 ****关联不同的类**\n\n只要你愿意，你就可以让任何两个没有一点关系的类一起运行，只要适配器写得好。\n\n**2、 ****提高了复用度**\n\n原有的代码还能在原来的系统中用，新增的功能也很好的使用到了旧代码，很好的提高了代码复用度。\n\n**3、 ****非常灵活**\n\n适配器可以任意添加删除，对系统没有任何影响。","slug":"design-pattern-adapter","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg624p009wsb8f8y611mia"},{"title":"趣味数据结构 - SkipLists","id":"460","date":"2012-03-09T13:13:11.000Z","_content":"\n**1****、简介**\n\n给一串有序的数据，如何存储可以增删查改快速方便、扩容简单、实现也简单呢？用数组吧，实现简单，二分法也老快了，但是删除就很麻烦了，且扩容也需要开辟新的空间。用链表吧，新增删除都很快，但是查找就得遍历了。用平衡树（AVL、红黑树）吧，新增删除扩容都很方便，但是实现起来非常麻烦。\n  <!--more-->\n\n说完上面的，来推荐一个有趣的数据结构，可方便实现上面几个要求，那就是SkipLists（跳表）。我们先来看看SkipList作者William Pugh对它的定义吧：\n  > _Skip lists are a data structure that can be used in place of balanced trees. Skip lists use probabilistic balancing rather than strictly enforced balancing and as a result the algorithms for insertion and deletion in skip lists are much simpler and significantly faster than equivalent algorithms for balanced trees.(1990)_  \n\nSkipLists设计出来就是用来取代平衡树的，SkipList依靠随机的思想，从某种程序上实现了平衡，且插入与删除都比较简单。\n\n**2****、SkipLists思想**\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb4.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image4.png) 我们先来看看上面的有序链表（例子Copy自文献），需要查找一个节点，我们得获得头节点，再依次遍历下去，时间复杂度为O(n)。\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb5.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image5.png) 如果有上面这种结构，每间隔一个节点添加一个额外指针指向下下个节点。那么每次查找先查下下节点，大于继续查找，小于的话，查找下个节点。这样的话，时间复杂度就降到了O(n/2)。\n\n这基本上就是跳表的核心思想，即通过“空间来换取时间”的一个算法，通过在每个节点中增加了向前的指针，从而提升查找的效率。\n\n**3****、构造过程**\n\n1）给定一个有序的链表；\n\n2）选择链表最上层的最大、最小节点，然后从其它节点中按照一定算法随机选出一些节点，将这些节点组成有序链表。新链表称之为第一层，原链表称之为下一层；\n\n3）为刚选出的每个节点添加一个指针域，这个指针指向下一层中相应的节点。Top指针指向首层首节点；\n\n4）重复2、3步，直到不能选选择出除最大最小节点之外的节点。\n\n如下图：\n\n[![clip_image006](http://www.hongweiyi.com/wp-content/uploads/2012/03/clip_image006_thumb.jpg \"clip_image006\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/clip_image006.jpg)\n\n**4****、结构特征**\n\n1）一个SkipList应由多个层组成（Level）；\n\n2）SkipList的最底层包含所有的节点；\n\n3）每一层都是一个有序链表；\n\n4）如果节点X出现在第i层，那么所有&lt;i的层都含有X；\n\n5）Top指向最高层的首节点；\n\n6）第i层的节点通过down指针指向下一层相应的节点；\n\n7）每一层均有全局最大最小值。\n\n**5****、其它**\n\n**1****）随机算法**\n\n调用一个随机函数，该函数返回节点会撑到第几层，伪代码如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>randomLevel()\n\n&#160;&#160;&#160; lvl := 1\n\n_&#160;&#160;&#160; -- random_() _that returns a random value in _[0...1)\n\n**&#160;&#160;&#160; while **random() &lt; p **and **lvl &lt; MaxLevel **do**\n\n&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; lvl := lvl + 1\n\n**&#160;&#160;&#160; return **lvl\n         </td>       </tr>     </tbody></table> </p>  \n\n一般来说，p为0.5，那么能撑到第i的概率为0.5^i。\n\n**2****）查找**\n\nSkipLists查找从Top节点开始，如二分查找一样，大于下一节点就继续，小于则跳到下一层。直到找到节点或者到NULL为止。时间复杂度O(logn)。\n\n**3****）插入**\n\n插入也用上面的查找，但是每下一层均要记录转下的那个节点，将其存入update中。待找到插入的位置之后，需要在所有下层插入节点，根据update节点更新。\n\n同时，插入一个元素也需要调用随机算法，判断是否需要更新链表。使用的随机算法和构造时的算法是一致的。时间复杂度O(logn)。\n\n**4****）删除**\n\n删除找到之后，就直接删除了，没什么特别的地方。时间复杂度O(logn)。\n  > 参考资料：\n> \n> William Pugh：[Skip lists: a probabilistic alternative to balanced trees](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.85.9211&amp;rep=rep1&amp;type=pdf)\n> \n> 跳表：[www.cnblogs.com/xuqiang/archive/2011/05/22/2053516.html](http://www.cnblogs.com/xuqiang/archive/2011/05/22/2053516.html)","source":"_posts/data-structure-skiplists.md","raw":"title: 趣味数据结构 - SkipLists\ntags:\n  - 数据结构\nid: 460\ncategories:\n  - 技术分享\ndate: 2012-03-09 21:13:11\n---\n\n**1****、简介**\n\n给一串有序的数据，如何存储可以增删查改快速方便、扩容简单、实现也简单呢？用数组吧，实现简单，二分法也老快了，但是删除就很麻烦了，且扩容也需要开辟新的空间。用链表吧，新增删除都很快，但是查找就得遍历了。用平衡树（AVL、红黑树）吧，新增删除扩容都很方便，但是实现起来非常麻烦。\n  <!--more-->\n\n说完上面的，来推荐一个有趣的数据结构，可方便实现上面几个要求，那就是SkipLists（跳表）。我们先来看看SkipList作者William Pugh对它的定义吧：\n  > _Skip lists are a data structure that can be used in place of balanced trees. Skip lists use probabilistic balancing rather than strictly enforced balancing and as a result the algorithms for insertion and deletion in skip lists are much simpler and significantly faster than equivalent algorithms for balanced trees.(1990)_  \n\nSkipLists设计出来就是用来取代平衡树的，SkipList依靠随机的思想，从某种程序上实现了平衡，且插入与删除都比较简单。\n\n**2****、SkipLists思想**\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb4.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image4.png) 我们先来看看上面的有序链表（例子Copy自文献），需要查找一个节点，我们得获得头节点，再依次遍历下去，时间复杂度为O(n)。\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb5.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image5.png) 如果有上面这种结构，每间隔一个节点添加一个额外指针指向下下个节点。那么每次查找先查下下节点，大于继续查找，小于的话，查找下个节点。这样的话，时间复杂度就降到了O(n/2)。\n\n这基本上就是跳表的核心思想，即通过“空间来换取时间”的一个算法，通过在每个节点中增加了向前的指针，从而提升查找的效率。\n\n**3****、构造过程**\n\n1）给定一个有序的链表；\n\n2）选择链表最上层的最大、最小节点，然后从其它节点中按照一定算法随机选出一些节点，将这些节点组成有序链表。新链表称之为第一层，原链表称之为下一层；\n\n3）为刚选出的每个节点添加一个指针域，这个指针指向下一层中相应的节点。Top指针指向首层首节点；\n\n4）重复2、3步，直到不能选选择出除最大最小节点之外的节点。\n\n如下图：\n\n[![clip_image006](http://www.hongweiyi.com/wp-content/uploads/2012/03/clip_image006_thumb.jpg \"clip_image006\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/clip_image006.jpg)\n\n**4****、结构特征**\n\n1）一个SkipList应由多个层组成（Level）；\n\n2）SkipList的最底层包含所有的节点；\n\n3）每一层都是一个有序链表；\n\n4）如果节点X出现在第i层，那么所有&lt;i的层都含有X；\n\n5）Top指向最高层的首节点；\n\n6）第i层的节点通过down指针指向下一层相应的节点；\n\n7）每一层均有全局最大最小值。\n\n**5****、其它**\n\n**1****）随机算法**\n\n调用一个随机函数，该函数返回节点会撑到第几层，伪代码如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>randomLevel()\n\n&#160;&#160;&#160; lvl := 1\n\n_&#160;&#160;&#160; -- random_() _that returns a random value in _[0...1)\n\n**&#160;&#160;&#160; while **random() &lt; p **and **lvl &lt; MaxLevel **do**\n\n&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; lvl := lvl + 1\n\n**&#160;&#160;&#160; return **lvl\n         </td>       </tr>     </tbody></table> </p>  \n\n一般来说，p为0.5，那么能撑到第i的概率为0.5^i。\n\n**2****）查找**\n\nSkipLists查找从Top节点开始，如二分查找一样，大于下一节点就继续，小于则跳到下一层。直到找到节点或者到NULL为止。时间复杂度O(logn)。\n\n**3****）插入**\n\n插入也用上面的查找，但是每下一层均要记录转下的那个节点，将其存入update中。待找到插入的位置之后，需要在所有下层插入节点，根据update节点更新。\n\n同时，插入一个元素也需要调用随机算法，判断是否需要更新链表。使用的随机算法和构造时的算法是一致的。时间复杂度O(logn)。\n\n**4****）删除**\n\n删除找到之后，就直接删除了，没什么特别的地方。时间复杂度O(logn)。\n  > 参考资料：\n> \n> William Pugh：[Skip lists: a probabilistic alternative to balanced trees](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.85.9211&amp;rep=rep1&amp;type=pdf)\n> \n> 跳表：[www.cnblogs.com/xuqiang/archive/2011/05/22/2053516.html](http://www.cnblogs.com/xuqiang/archive/2011/05/22/2053516.html)","slug":"data-structure-skiplists","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg624r009zsb8fyfy9qnd2"},{"title":"趣味数据结构 - 并查集","id":"477","date":"2012-03-16T14:45:30.000Z","_content":"\n**1****、简介**\n\n在某些应用中，会将n个不同的元素分成一组不相交的集合（disjoint）。不相交的集合有两个重要的操作，即找到给定的元素所属的集合（find）和合并两个集合（union）。为了更好的支持这两种操作，就出现了并查集（Disjoint-Set or Union-find set）。\n  <!--more-->\n\n并查集保持了一组不相交的动态集合，每个集合通过一个代表来识别，代表即集合中的某个成员。哪个成员被选中无所谓iwom关心的是如果寻找某一动态集合的代表两次，并且在两次寻找之间不修改集合，两次得到的答案应该是一样的。\n\n**2****、基本操作**\n\n它主要涉及两个基本操作，分别为：\n\n**Union-Set(x, y)：**合并两个不相交集合\n\n**Find-Set(x)：**判断两个元素是否属于同一个集合\n\n还需要另外一个基本操作，即：\n\n**Make-Set(x)：**新建一个集合，唯一的成员也是代表就是x\n\n**3****、实现方法**\n\n现有不相交集合：{1, 3, 7}，{4}，{2, 5, 9, 10}，{6, 8}\n\n**1）用编号最小的元素标记所在集合**\n\n{**1**, 3, 7}，{**4**}，{**2**, 5, 9, 10}，{**6**, 8}\n\n**2）定义一个数组set[1...n]，其中set[i]表示元素i所在集合**\n\n[![clip_image002](http://www.hongweiyi.com/wp-content/uploads/2012/03/clip_image002_thumb.jpg \"clip_image002\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/clip_image002.jpg)\n\n**3）find操作**    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>find(x):\n\n&#160;&#160;&#160;&#160; return set[x];\n         </td>       </tr>     </tbody></table> </p>  \n\n**4）Union操作**    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>union(x, y):\n\n&#160;&#160;&#160; for k in [0, n): // 遍历所有集合，更新其中一个集合的代表\n\n&#160;&#160;&#160;&#160;&#160;&#160;&#160; if (set[k] == find(a)):\n\n&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; set[k] := find(b);\n         </td>       </tr>     </tbody></table> </p>  \n\n**4****、实现分析**\n\n上面实现很简单，find操作只需要返回其代表即可，时间复杂为O(1)。但是Union操作则需要修改其中一个集合所有的代表，同时由于是用的数组存的，元素为数组的索引，必须要遍历所有元素才可以修改，时间复杂为O(n)。要优化操作，就必须优化数据结构。\n\n&#160;\n\n**5****、优化**\n\n**1）链表**\n\n每个集合建立一个链表，有头尾指针，头结点为代表。所有结点都添加了指向代表的指针。\n\n很容易知道，find操作时间复杂度为O(1)，合并只需要将较小的集合添加到另一个集合的后尾，再更新代表即可，时间复杂度也为O(n)，与数组相比，在时间上优化了一点点。\n\n**2）有根树**\n\n并查集目前最好的实现是用有根树，即建立一个森林，每棵树是一个集合，树根元素就是代表，每个结点存储指向其父亲结点的指针（而不是指向子结点的指针）。\n\n可执行三种不相交集合操作：\n\na. Make-Set：创建一颗仅包含一个结点的树；\n\nb. Find-Set：查找可以描述为找两个元素各自的根，判断其是否相等。实现中需要沿着父结点指针一直找下去，直到找到树根为止。（时间复杂度O(n)）\n\nc. Union-Set：并集可以描述为把一棵树接到另一个棵树的根结点上，并更新某颗树的代表。（时间复杂度O(n)）\n\n[![clip_image003](http://www.hongweiyi.com/wp-content/uploads/2012/03/clip_image003_thumb.jpg \"clip_image003\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/clip_image003.jpg)\n\n其实这个与链表来说，性能没有本质上的提高。合并也需要更新结点代表，且如果树构造的时候，构造了一颗线性链的树，查找复杂度也提高了。对其进行优化，有两种策略：\n\n**a. ****按秩合并（union by rank）**\n\n秩（Rank）就是一颗树的结点数，即使包含较少结点的树根指向包含较多结点的树根。\n\n**b. ****路径压缩**\n\n**[![clip_image005](http://www.hongweiyi.com/wp-content/uploads/2012/03/clip_image005_thumb.jpg \"clip_image005\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/clip_image005.jpg)**\n\n如上图，使查找路径上的每个结点都直接指向根结点。简单而有效。\n\n&#160;\n\n**6****、小结**\n\n在实现中，并查集均是使用有根树结合按秩合并和路径压缩来实现。按秩合并提高了Union-Set操作效率，而路径压缩提高了Find-Set操作效率。\n\n空间复杂度为O(N)，建立一个集合的时间复杂度为O(1)， N次合并M查找的时间复杂度为O(M Alpha(N))，这里Alpha是Ackerman函数的某个反函数，在很大的范围内（人类目前观测到的宇宙范围估算有10的80次方个原子，这小于前面所说的范围）这个函数的值可以看成是不大于4的，所以并查集的操作可以看作是线性的。具体证明得参加&lt;算法导论&gt;。\n\n并查集常作为另一种复杂的数据结构或者算法的存储结构。常见的应用有：求无向图的连通分量个数、最近公共祖先（LCA）、最小生成树等。\n\n&#160;\n  > 参考资料：\n> \n> &lt;算法导论&gt;，第二十二章\n> \n> 董的博客：[数据结构之并查集](http://dongxicheng.org/structure/union-find-set/)","source":"_posts/data-structure-disjoint-set.md","raw":"title: 趣味数据结构 - 并查集\ntags:\n  - 数据结构\nid: 477\ncategories:\n  - 技术分享\ndate: 2012-03-16 22:45:30\n---\n\n**1****、简介**\n\n在某些应用中，会将n个不同的元素分成一组不相交的集合（disjoint）。不相交的集合有两个重要的操作，即找到给定的元素所属的集合（find）和合并两个集合（union）。为了更好的支持这两种操作，就出现了并查集（Disjoint-Set or Union-find set）。\n  <!--more-->\n\n并查集保持了一组不相交的动态集合，每个集合通过一个代表来识别，代表即集合中的某个成员。哪个成员被选中无所谓iwom关心的是如果寻找某一动态集合的代表两次，并且在两次寻找之间不修改集合，两次得到的答案应该是一样的。\n\n**2****、基本操作**\n\n它主要涉及两个基本操作，分别为：\n\n**Union-Set(x, y)：**合并两个不相交集合\n\n**Find-Set(x)：**判断两个元素是否属于同一个集合\n\n还需要另外一个基本操作，即：\n\n**Make-Set(x)：**新建一个集合，唯一的成员也是代表就是x\n\n**3****、实现方法**\n\n现有不相交集合：{1, 3, 7}，{4}，{2, 5, 9, 10}，{6, 8}\n\n**1）用编号最小的元素标记所在集合**\n\n{**1**, 3, 7}，{**4**}，{**2**, 5, 9, 10}，{**6**, 8}\n\n**2）定义一个数组set[1...n]，其中set[i]表示元素i所在集合**\n\n[![clip_image002](http://www.hongweiyi.com/wp-content/uploads/2012/03/clip_image002_thumb.jpg \"clip_image002\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/clip_image002.jpg)\n\n**3）find操作**    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>find(x):\n\n&#160;&#160;&#160;&#160; return set[x];\n         </td>       </tr>     </tbody></table> </p>  \n\n**4）Union操作**    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>union(x, y):\n\n&#160;&#160;&#160; for k in [0, n): // 遍历所有集合，更新其中一个集合的代表\n\n&#160;&#160;&#160;&#160;&#160;&#160;&#160; if (set[k] == find(a)):\n\n&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; set[k] := find(b);\n         </td>       </tr>     </tbody></table> </p>  \n\n**4****、实现分析**\n\n上面实现很简单，find操作只需要返回其代表即可，时间复杂为O(1)。但是Union操作则需要修改其中一个集合所有的代表，同时由于是用的数组存的，元素为数组的索引，必须要遍历所有元素才可以修改，时间复杂为O(n)。要优化操作，就必须优化数据结构。\n\n&#160;\n\n**5****、优化**\n\n**1）链表**\n\n每个集合建立一个链表，有头尾指针，头结点为代表。所有结点都添加了指向代表的指针。\n\n很容易知道，find操作时间复杂度为O(1)，合并只需要将较小的集合添加到另一个集合的后尾，再更新代表即可，时间复杂度也为O(n)，与数组相比，在时间上优化了一点点。\n\n**2）有根树**\n\n并查集目前最好的实现是用有根树，即建立一个森林，每棵树是一个集合，树根元素就是代表，每个结点存储指向其父亲结点的指针（而不是指向子结点的指针）。\n\n可执行三种不相交集合操作：\n\na. Make-Set：创建一颗仅包含一个结点的树；\n\nb. Find-Set：查找可以描述为找两个元素各自的根，判断其是否相等。实现中需要沿着父结点指针一直找下去，直到找到树根为止。（时间复杂度O(n)）\n\nc. Union-Set：并集可以描述为把一棵树接到另一个棵树的根结点上，并更新某颗树的代表。（时间复杂度O(n)）\n\n[![clip_image003](http://www.hongweiyi.com/wp-content/uploads/2012/03/clip_image003_thumb.jpg \"clip_image003\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/clip_image003.jpg)\n\n其实这个与链表来说，性能没有本质上的提高。合并也需要更新结点代表，且如果树构造的时候，构造了一颗线性链的树，查找复杂度也提高了。对其进行优化，有两种策略：\n\n**a. ****按秩合并（union by rank）**\n\n秩（Rank）就是一颗树的结点数，即使包含较少结点的树根指向包含较多结点的树根。\n\n**b. ****路径压缩**\n\n**[![clip_image005](http://www.hongweiyi.com/wp-content/uploads/2012/03/clip_image005_thumb.jpg \"clip_image005\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/clip_image005.jpg)**\n\n如上图，使查找路径上的每个结点都直接指向根结点。简单而有效。\n\n&#160;\n\n**6****、小结**\n\n在实现中，并查集均是使用有根树结合按秩合并和路径压缩来实现。按秩合并提高了Union-Set操作效率，而路径压缩提高了Find-Set操作效率。\n\n空间复杂度为O(N)，建立一个集合的时间复杂度为O(1)， N次合并M查找的时间复杂度为O(M Alpha(N))，这里Alpha是Ackerman函数的某个反函数，在很大的范围内（人类目前观测到的宇宙范围估算有10的80次方个原子，这小于前面所说的范围）这个函数的值可以看成是不大于4的，所以并查集的操作可以看作是线性的。具体证明得参加&lt;算法导论&gt;。\n\n并查集常作为另一种复杂的数据结构或者算法的存储结构。常见的应用有：求无向图的连通分量个数、最近公共祖先（LCA）、最小生成树等。\n\n&#160;\n  > 参考资料：\n> \n> &lt;算法导论&gt;，第二十二章\n> \n> 董的博客：[数据结构之并查集](http://dongxicheng.org/structure/union-find-set/)","slug":"data-structure-disjoint-set","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg624s00a2sb8fkgylrzax"},{"title":"趣味数据结构 - BitMap","id":"422","date":"2012-03-05T13:37:49.000Z","_content":"\n**1****、什么是Bit-Map**\n\nBit-Map被译为位图，和人讨论的时候，常常会与.BMP搞混，这个Map我觉得翻译成映射更为合适，Bit-Map也算是Hash的一直极致运用吧。Bit-Map会用Bit来标记某个元素对应的value，如何标记的呢，见下例：\n  <!--more-->\n\n我们现在有(1,2,5,8,10)数组，常规来说是这样声明的：\n\nint[] array = {1, 2, 5, 8, 10}\n\n上面这样声明会占用4×5个字节，即20个字节，少量数据可能没有什么特别大的感觉，如果数组长度为10,000,000，这样的方式就会占用4G的内存。\n\n如果用Bit-Map的话，可以这样来组织：\n\nbyte[] bytes = new bytes[2];\n\nbytes[0] = 01100100; // 就直接写二进制了\n\nbytes[1] = 10100000;\n\n**2****、Bit-Map建立**\n\n有了上面的例子之后，不知道对Bit-Map是否有了一个感性的认识。下面说下Bit-Map的建立过程。\n\n**1****）开辟定长数组**\n\nBit-Map会声明一个定长的byte/int数组，之后将数组内元素的所有Bit位均置为0，如下图：\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb2.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image2.png) \n\n**2****）遍历数据，并插入Bit-Map**\n\n上例来说，就会遍历array{1, 2, 5, 8, 10}，并将所有的元素均插入Bit-Map中。Bit-Map是Hash的极致，那么key即为array[i]/8，value即在byte中的位置array[i]%8。而实际中为了效率，hash函数可能会有些出入。如下：   <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>Byte: MASK = 0X07; SHIFT = 3; Integer: MASK = 0X1F; SHIFT = 5; \n\n// i&gt;&gt; SHIFT =&gt; i/8; i &amp; MASK =&gt; i%8\n\nset(i): array[i&gt;&gt;SHITF] |= (1 &lt;&lt; (i &amp; MASK);\n\n// return 0: not exist\n\nisExist(i) : return array[i&gt;&gt;SHIFT] &amp; (1 &lt;&lt; (i &amp; MASK);\n         </td>       </tr>     </tbody></table> </p>  \n\n遍历插入之后的数据应该是这样的：\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb3.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image3.png) \n\n**3****、Bit-Map应用**\n\n建立了Bit-Map之后，就可以方便的使用了。一般来说Bit-Map可作为数据的查找、去重、排序等操作。\n\n如上面提及的10,000,000个数据存储问题，用Integer存储，耗费4G内存。改成Bit-Map，耗费125MB内存。但是实际中，可能由于数据中最大最小值相差太大，如{1,2 99999}，只有三个数，但是最大最小相差悬殊，该方法就不适用了。\n\n查找和去重都好理解，至于排序，有点类似桶排序，每个byte都是一个桶。至于应用实例，自个用的少，copy别人的吧。\n\n**1)****已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。**\n\n8位最多99 999 999，大概需要99m个bit，大概10几m字节的内存即可。可以理解为从0-99 999 999的数字，每个数字对应一个Bit位，所以只需要99M个Bit==1.2MBytes，这样，就用了小小的1.2M左右的内存表示了所有的8位数的电话。\n\n**2)2.5****亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。**\n\n将bit-map扩展一下，用2bit表示一个数即可：0表示未出现；1表示出现一次；2表示出现2次及以上，即重复，在遍历这些数的时候，如果对应位置的值是0，则将其置为1；如果是1，将其置为2；如果是2，则保持不变。或者我们不用2bit来进行表示，我们用两个bit-map即可模拟实现这个2bit-map，都是一样的道理。\n  > 参考资料：\n> \n> 码农：[海量数据处理专题（四）——Bit-map](http://blog.redfox66.com/post/2010/09/26/mass-data-4-bitmap.aspx)","source":"_posts/data-structure-bitmap.md","raw":"title: 趣味数据结构 - BitMap\ntags:\n  - 数据结构\nid: 422\ncategories:\n  - 技术分享\ndate: 2012-03-05 21:37:49\n---\n\n**1****、什么是Bit-Map**\n\nBit-Map被译为位图，和人讨论的时候，常常会与.BMP搞混，这个Map我觉得翻译成映射更为合适，Bit-Map也算是Hash的一直极致运用吧。Bit-Map会用Bit来标记某个元素对应的value，如何标记的呢，见下例：\n  <!--more-->\n\n我们现在有(1,2,5,8,10)数组，常规来说是这样声明的：\n\nint[] array = {1, 2, 5, 8, 10}\n\n上面这样声明会占用4×5个字节，即20个字节，少量数据可能没有什么特别大的感觉，如果数组长度为10,000,000，这样的方式就会占用4G的内存。\n\n如果用Bit-Map的话，可以这样来组织：\n\nbyte[] bytes = new bytes[2];\n\nbytes[0] = 01100100; // 就直接写二进制了\n\nbytes[1] = 10100000;\n\n**2****、Bit-Map建立**\n\n有了上面的例子之后，不知道对Bit-Map是否有了一个感性的认识。下面说下Bit-Map的建立过程。\n\n**1****）开辟定长数组**\n\nBit-Map会声明一个定长的byte/int数组，之后将数组内元素的所有Bit位均置为0，如下图：\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb2.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image2.png) \n\n**2****）遍历数据，并插入Bit-Map**\n\n上例来说，就会遍历array{1, 2, 5, 8, 10}，并将所有的元素均插入Bit-Map中。Bit-Map是Hash的极致，那么key即为array[i]/8，value即在byte中的位置array[i]%8。而实际中为了效率，hash函数可能会有些出入。如下：   <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>Byte: MASK = 0X07; SHIFT = 3; Integer: MASK = 0X1F; SHIFT = 5; \n\n// i&gt;&gt; SHIFT =&gt; i/8; i &amp; MASK =&gt; i%8\n\nset(i): array[i&gt;&gt;SHITF] |= (1 &lt;&lt; (i &amp; MASK);\n\n// return 0: not exist\n\nisExist(i) : return array[i&gt;&gt;SHIFT] &amp; (1 &lt;&lt; (i &amp; MASK);\n         </td>       </tr>     </tbody></table> </p>  \n\n遍历插入之后的数据应该是这样的：\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/03/image_thumb3.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/03/image3.png) \n\n**3****、Bit-Map应用**\n\n建立了Bit-Map之后，就可以方便的使用了。一般来说Bit-Map可作为数据的查找、去重、排序等操作。\n\n如上面提及的10,000,000个数据存储问题，用Integer存储，耗费4G内存。改成Bit-Map，耗费125MB内存。但是实际中，可能由于数据中最大最小值相差太大，如{1,2 99999}，只有三个数，但是最大最小相差悬殊，该方法就不适用了。\n\n查找和去重都好理解，至于排序，有点类似桶排序，每个byte都是一个桶。至于应用实例，自个用的少，copy别人的吧。\n\n**1)****已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。**\n\n8位最多99 999 999，大概需要99m个bit，大概10几m字节的内存即可。可以理解为从0-99 999 999的数字，每个数字对应一个Bit位，所以只需要99M个Bit==1.2MBytes，这样，就用了小小的1.2M左右的内存表示了所有的8位数的电话。\n\n**2)2.5****亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。**\n\n将bit-map扩展一下，用2bit表示一个数即可：0表示未出现；1表示出现一次；2表示出现2次及以上，即重复，在遍历这些数的时候，如果对应位置的值是0，则将其置为1；如果是1，将其置为2；如果是2，则保持不变。或者我们不用2bit来进行表示，我们用两个bit-map即可模拟实现这个2bit-map，都是一样的道理。\n  > 参考资料：\n> \n> 码农：[海量数据处理专题（四）——Bit-map](http://blog.redfox66.com/post/2010/09/26/mass-data-4-bitmap.aspx)","slug":"data-structure-bitmap","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg624t00a5sb8ftj47qkb1"},{"title":"CSS 最佳实践","date":"2015-08-29T16:03:00.000Z","_content":"\n## 善用 伪元素(Pseudo-elements)\n\n### 常用伪元素\n\n* `:before`\n* `:after`\n* `:first-child`\n* `:last-child`\n\n### 实例\n\n* 插入类似列表符号：[JsFiddle](https://jsfiddle.net/pg4kpc3k/)\n\n* 插入 clearfix：[JsFiddle](https://jsfiddle.net/hy4av6eu/)\n\n* first-child & last-child 常用在 ul li 中，用以针对头尾设置不同的样式 \n\n\n## 善用属性选择器\n\n有了属性选择器可以设计很多自己的组件，比如按钮分组、进度条之类的。\n\n* [进度条实现 - JsFiddle](https://jsfiddle.net/j94nvngo/)\n\n\n## 待续...","source":"_posts/css-practice.md","raw":"title: CSS 最佳实践\ndate: 2015-08-30 00:03:00\ncategories: 最佳实践\ntags: [CSS, Frontend]\n---\n\n## 善用 伪元素(Pseudo-elements)\n\n### 常用伪元素\n\n* `:before`\n* `:after`\n* `:first-child`\n* `:last-child`\n\n### 实例\n\n* 插入类似列表符号：[JsFiddle](https://jsfiddle.net/pg4kpc3k/)\n\n* 插入 clearfix：[JsFiddle](https://jsfiddle.net/hy4av6eu/)\n\n* first-child & last-child 常用在 ul li 中，用以针对头尾设置不同的样式 \n\n\n## 善用属性选择器\n\n有了属性选择器可以设计很多自己的组件，比如按钮分组、进度条之类的。\n\n* [进度条实现 - JsFiddle](https://jsfiddle.net/j94nvngo/)\n\n\n## 待续...","slug":"css-practice","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg624v00a8sb8fpk0c459w"},{"title":"在Eclipse中配置Solr源码","id":"735","date":"2013-03-19T16:06:01.000Z","_content":"\n**1.** 下载solr的src包，并解压\n\n\t&nbsp;\n\n\t**2.** 解压后，在解压后的根目录执行ant eclipse，即生成eclipse需要的项目文件\n\n\t打开eclipse，File &gt; Import &gt; Existing Projects into Workspace\n\n\t选择刚才解压后的根目录，这时候java build path等都已经设置好了。\n\n<!--more-->\n\n\t&nbsp;\n\n\t**3.** Open Type(Ctrl+Shift+T)找到StartSolrJetty 这个类，修改main方法里面的setPort参数为默认的8983，以及ContextPath,War\n\n> War为&rdquo;solr/webapp/web/&rdquo;\n\n\t最后的代码应该是这样的：\n\n[code lang=\"java\"]\nServer server = new Server();\nSocketConnector connector = new SocketConnector();\n// Set some timeout options to make debugging easier.\nconnector.setMaxIdleTime(1000 * 60 * 60);\nconnector.setSoLingerTime(-1);\nconnector.setPort(8983); // HWY: MODI\nserver.setConnectors(new Connector[] { connector });\nWebAppContext bb = new WebAppContext();\nbb.setServer(server);\nbb.setContextPath(&quot;/solr&quot;); // HWY: MODI\nbb.setWar(&quot;solr/webapp/web&quot;); // HWY: MODI [/code]\n\n\t&nbsp;\n\n\t**4.** 设置solr.solr.home，并run\n\n\t在run configure中Arguments &gt; VM arguments中写入\n\n> -Dsolr.solr.home=your/path/of/example/solr\n\n\t也可以在代码中修改，\n\n> System.setProperty(&quot;solr.solr.home&quot;, &quot;your/path/of/example/solr&quot;);\n\n\t使用solr自带的一个example作为sold配置的根目录，也可以设置其他的solr配置目录。点击run即可运行Solr，debug也可以用。\n\n\t&nbsp;\n\n\t5\\. 浏览器输入[http://localhost:8983/solr](http://localhost:8983/solr)查看Solr Admin。\n\n\t&nbsp;\n\n> **参考资料：**[http://t.cn/zYduXSq](http://www.zwsun.com/solr_in_eclipse_2012_06_10_post)\r> \n> \n> \t\t**BTW： **lucene官网下载镜像地址版本不全，可用这个地址：[http://t.cn/zYDUP9j](http://archive.apache.org/dist/lucene/)","source":"_posts/configurate-solr-src-in-eclipse.md","raw":"title: 在Eclipse中配置Solr源码\ntags:\n  - Eclipse\n  - java\n  - Solr\nid: 735\ncategories:\n  - 技术分享\ndate: 2013-03-20 00:06:01\n---\n\n**1.** 下载solr的src包，并解压\n\n\t&nbsp;\n\n\t**2.** 解压后，在解压后的根目录执行ant eclipse，即生成eclipse需要的项目文件\n\n\t打开eclipse，File &gt; Import &gt; Existing Projects into Workspace\n\n\t选择刚才解压后的根目录，这时候java build path等都已经设置好了。\n\n<!--more-->\n\n\t&nbsp;\n\n\t**3.** Open Type(Ctrl+Shift+T)找到StartSolrJetty 这个类，修改main方法里面的setPort参数为默认的8983，以及ContextPath,War\n\n> War为&rdquo;solr/webapp/web/&rdquo;\n\n\t最后的代码应该是这样的：\n\n[code lang=\"java\"]\nServer server = new Server();\nSocketConnector connector = new SocketConnector();\n// Set some timeout options to make debugging easier.\nconnector.setMaxIdleTime(1000 * 60 * 60);\nconnector.setSoLingerTime(-1);\nconnector.setPort(8983); // HWY: MODI\nserver.setConnectors(new Connector[] { connector });\nWebAppContext bb = new WebAppContext();\nbb.setServer(server);\nbb.setContextPath(&quot;/solr&quot;); // HWY: MODI\nbb.setWar(&quot;solr/webapp/web&quot;); // HWY: MODI [/code]\n\n\t&nbsp;\n\n\t**4.** 设置solr.solr.home，并run\n\n\t在run configure中Arguments &gt; VM arguments中写入\n\n> -Dsolr.solr.home=your/path/of/example/solr\n\n\t也可以在代码中修改，\n\n> System.setProperty(&quot;solr.solr.home&quot;, &quot;your/path/of/example/solr&quot;);\n\n\t使用solr自带的一个example作为sold配置的根目录，也可以设置其他的solr配置目录。点击run即可运行Solr，debug也可以用。\n\n\t&nbsp;\n\n\t5\\. 浏览器输入[http://localhost:8983/solr](http://localhost:8983/solr)查看Solr Admin。\n\n\t&nbsp;\n\n> **参考资料：**[http://t.cn/zYduXSq](http://www.zwsun.com/solr_in_eclipse_2012_06_10_post)\r> \n> \n> \t\t**BTW： **lucene官网下载镜像地址版本不全，可用这个地址：[http://t.cn/zYDUP9j](http://archive.apache.org/dist/lucene/)","slug":"configurate-solr-src-in-eclipse","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg624y00aesb8fsbk5tmgp"},{"title":"买本本需要考虑什么？","id":"83","date":"2011-02-12T14:12:10.000Z","_content":"\n本人大学期间在电脑城做过一两年的兼职销售，卖台式机兼推荐本本。对大众买电脑的心理有一点点见解：\n> 首先，价格巨便宜还要搭上配置巨好；\r> \n> \n> 其次，别人有的我也要有，他们i3，我就要i5！他们320G，我要500G！他们512M显卡，我要1G的！\r> \n> \n> 再者，要是知名品牌，宏碁不行，做工不行，华硕不行，华而不实硕大无比；\r> \n> \n> 再者就针对女生了，要漂亮的，白色的，超薄的，轻的，但要便宜。\n哪有那么好的事情，物美价廉的事基本不存在！不过在一定价位内，选到适合自己的机型还是可以的。来说说我建议的方式吧：\n\n<!--more-->**1、定位自己能承受的价位**\n\n什么价位就是什么价位的配置，不要准备个3K，就想要买i系列、独显。不过呢，也没必要把电脑想象得老贵老贵，现在电脑都是白菜价，6500大洋基本的普通机型就可以拿到最高配置了，我那三四年前的8K的老机器，现在顶多卖个2500。如果价格定位（6500）再往上，就可以考虑Thinkpad、索尼、苹果了，不过性价比就没那么高了，毕竟这些大佬卖的是做工、品牌和品位。\n\n**2、明确电脑的用途**\n\n很多女同学要我帮忙参考电脑，我问：“你买了干嘛？”她答：“上网、聊QQ、看PPS、顺带还要p图。”我回：“去电脑城看中哪台漂亮拿走就得了，硬盘大点，其他都不用考虑了。”她再回：“别这样啊，我要双核独显啦！”我勒个去，要求那么高？说实在的，以上四个功能，基本上网本都能解决了，硬盘大点多装点电影，拿Photoshop做借口的我也见多了，推荐10台要做“ps”的机器，基本都沦为了上网本。\n\n所以要为自己量身选机，一般要求、不打3D游戏的，4K以下的本本基本全都能搞定，带不带显卡都可以。不要定位那么高，拿个5K-6K的要求去买个“上网本”？如果要打中型3D游戏的，5K出头也勉强可以了。超大型3D游戏的，6K+，或者考虑戴尔的Alienware系列（这个很贵！！！）。顺带提醒一句，魔兽世界我高中外面512M内存的网吧电脑就可以带动了，别说它是大型3D游戏。\n\n**3、对电脑的第一印象和手感很重要**\n\n看完1、2条之后，定位好价位和用途，其它的需要考虑得也差不多了。不做专业用途，也用不出区别来。只需要看看电脑外观和做工了，多余的钱整点小配件，自己用得心里舒服。\n\n最后再说说怎么砍价吧：**多听少说、货比三家**。\n\n不懂电脑就不要说话，站那里听商家忽悠。被忽悠完之后，问好价格看好中意的机型，就说要再参考参考，如果商家立马就降价了，得，不用在这家看了，老板太不诚实了！他说好，你就再转转，到了别的店面，直接报出自己中意的机型，要老板报个**实价**。按照之前的模型，多问几家，选出最低价，再减去100-200基本就差不多了。\n\n这个时候就可以**自信**点，再走进一家，要老板报实价，老板看到自信的人加明确的机型，内心防线被打破，报出实价，根据价格高低，你可以选择走或者说你问到的价比这个低（这个价可以是你心里的价格，不用问到）。多问几家，基本能到满意的价格。\n\n剩下就是**赠品**了，不要奢望送太多的赠品，赠品其实都是自己买的。基本的就是鼠标、包（尽量要原装，但是有时候比较难）、键盘膜（屏膜难有好货）、清洁套装。其他还有什么，能要的都可以要过来，什么乱七八糟的鼠标垫、电脑锁等。\n\n**P.S.: 以上经验只是个人看法，如觉有冒犯之处，敬请谅解。有想深入了解探讨的，请留言……^_^**","source":"_posts/buying-laptop.md","raw":"title: 买本本需要考虑什么？\ntags:\n  - 生活\nid: 83\ncategories:\n  - 生活分享\ndate: 2011-02-12 22:12:10\n---\n\n本人大学期间在电脑城做过一两年的兼职销售，卖台式机兼推荐本本。对大众买电脑的心理有一点点见解：\n> 首先，价格巨便宜还要搭上配置巨好；\r> \n> \n> 其次，别人有的我也要有，他们i3，我就要i5！他们320G，我要500G！他们512M显卡，我要1G的！\r> \n> \n> 再者，要是知名品牌，宏碁不行，做工不行，华硕不行，华而不实硕大无比；\r> \n> \n> 再者就针对女生了，要漂亮的，白色的，超薄的，轻的，但要便宜。\n哪有那么好的事情，物美价廉的事基本不存在！不过在一定价位内，选到适合自己的机型还是可以的。来说说我建议的方式吧：\n\n<!--more-->**1、定位自己能承受的价位**\n\n什么价位就是什么价位的配置，不要准备个3K，就想要买i系列、独显。不过呢，也没必要把电脑想象得老贵老贵，现在电脑都是白菜价，6500大洋基本的普通机型就可以拿到最高配置了，我那三四年前的8K的老机器，现在顶多卖个2500。如果价格定位（6500）再往上，就可以考虑Thinkpad、索尼、苹果了，不过性价比就没那么高了，毕竟这些大佬卖的是做工、品牌和品位。\n\n**2、明确电脑的用途**\n\n很多女同学要我帮忙参考电脑，我问：“你买了干嘛？”她答：“上网、聊QQ、看PPS、顺带还要p图。”我回：“去电脑城看中哪台漂亮拿走就得了，硬盘大点，其他都不用考虑了。”她再回：“别这样啊，我要双核独显啦！”我勒个去，要求那么高？说实在的，以上四个功能，基本上网本都能解决了，硬盘大点多装点电影，拿Photoshop做借口的我也见多了，推荐10台要做“ps”的机器，基本都沦为了上网本。\n\n所以要为自己量身选机，一般要求、不打3D游戏的，4K以下的本本基本全都能搞定，带不带显卡都可以。不要定位那么高，拿个5K-6K的要求去买个“上网本”？如果要打中型3D游戏的，5K出头也勉强可以了。超大型3D游戏的，6K+，或者考虑戴尔的Alienware系列（这个很贵！！！）。顺带提醒一句，魔兽世界我高中外面512M内存的网吧电脑就可以带动了，别说它是大型3D游戏。\n\n**3、对电脑的第一印象和手感很重要**\n\n看完1、2条之后，定位好价位和用途，其它的需要考虑得也差不多了。不做专业用途，也用不出区别来。只需要看看电脑外观和做工了，多余的钱整点小配件，自己用得心里舒服。\n\n最后再说说怎么砍价吧：**多听少说、货比三家**。\n\n不懂电脑就不要说话，站那里听商家忽悠。被忽悠完之后，问好价格看好中意的机型，就说要再参考参考，如果商家立马就降价了，得，不用在这家看了，老板太不诚实了！他说好，你就再转转，到了别的店面，直接报出自己中意的机型，要老板报个**实价**。按照之前的模型，多问几家，选出最低价，再减去100-200基本就差不多了。\n\n这个时候就可以**自信**点，再走进一家，要老板报实价，老板看到自信的人加明确的机型，内心防线被打破，报出实价，根据价格高低，你可以选择走或者说你问到的价比这个低（这个价可以是你心里的价格，不用问到）。多问几家，基本能到满意的价格。\n\n剩下就是**赠品**了，不要奢望送太多的赠品，赠品其实都是自己买的。基本的就是鼠标、包（尽量要原装，但是有时候比较难）、键盘膜（屏膜难有好货）、清洁套装。其他还有什么，能要的都可以要过来，什么乱七八糟的鼠标垫、电脑锁等。\n\n**P.S.: 以上经验只是个人看法，如觉有冒犯之处，敬请谅解。有想深入了解探讨的，请留言……^_^**","slug":"buying-laptop","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg624z00ajsb8fy320fyu8"},{"title":"Apache Solr —— Facet Pivot实现与低版本移植","date":"2013-03-27T15:12:00.000Z","_content":"\n### 1、前言\n\nSolr升级到4.0后便有了一个新功能，就是facet.pivot，关于pivot的介绍可以看上一篇文章：[《Apache Solr – Facet介绍》](http://hongweiyi.com/2013/03/apache-solr-facet-introduction/) 这篇主要讲述Pivot的内部实现机制，以及如何将这个功能移植到低版本的Solr中来。\n\n<!--more-->\n\n### 2、Pivot实现机制\n\n> `http://...?q=*:*&facet=true&&facet.field=province&facet.field=city&facet.pivot=province,city&wt=json`\n\n#### 2.1 获得所有pivots参数列表\n\n> e.g.: [\"province,city\", …]\n\n#### 2.2 将pivots交给PivotFacetHelper处理\n\n``` java\n// FacetComponent.java -> process\n// e.g.: [\"province,city\"]\nString[] pivots = params.getParams(FacetParams.FACET_PIVOT);\nif (pivots != null && pivots.length > 0) {\n\tPivotFacetHelper pivotHelper = new PivotFacetHelper(rb.req,\n\t\t\t\t\t\trb.getResults().docSet, params, rb);\n\t// process each pivots individually\n\tNamedList v = pivotHelper.process(pivots);\n\tif (v != null) {\n\t\tcounts.add(PIVOT_KEY, v);\n\t}\n}\n```\n\n#### 2.3 解析pivot，获得每个field –> pivot: field subField fnames\n\n``` Java\n// PivotFacetHelper.java -> process\nfor (String pivot : pivots) {\n\t// …\n\n\tString[] fields = pivot.split(\",\");\n\n\tif (fields.length < 2) {\n\t    throw new SolrException(ErrorCode.BAD_REQUEST,\n\t\t\t\"Pivot Facet needs at least two fields: \" + pivot);\n\t}\n\n\tString field = fields[0];\n\tString subField = fields[1];\n\n\t// the rest of fields\n\tDeque<String> fnames = new LinkedList<String>();\n\tfor (int i = fields.length - 1; i > 1; i--) {\n\t\tfnames.push(fields[i]);\n\t}\n\t// …\n}\n```\n\n#### 2.4 获得第一级field的facets\n\n``` java\n// PivotFacetHelper.java -> process\n// e.g.: field: province\n//        superFacets : [\"Jiangsu\", 4, \"Hunan\", 3, \"Guangdong\", 2, \"Beijing\", 1, \"Zhejiang\", 1]\nNamedList<Integer> superFacets = this.getTermCounts(field);\n```\n\n#### 2.5 递归调用pivotResult = doPivot(superFacets, field, subField, fnames, docs)\n\n``` java\n        // …\n        // super.key usually == pivot unless local-param 'key' used\n        pivotResponse.add(key,\n        doPivots(superFacets, field, subField, fnames, base));\n\t}\n\treturn pivotResponse;\n}\n\n// PivotFacetHelper.java -> doPivots\nprotected List<NamedList<Object>> doPivots(NamedList<Integer> superFacets, String field, String subField, Deque<String> fnames, DocSet docs) throws IOException {\n\n\t// …\n\t// 遍历该级所有facet，获得该facet下所有下一级facet数据…\n    // [\"Jiangsu\", \"Hunan\", \"Guangdong\", \"Beijing\", \"Zhejiang\"]\n\tfor (Map.Entry<String, Integer> kv : superFacets) {\n\t\t// Only sub-facet if parent facet has positive count - still may not\n\t\t// be any values for the sub-field though\n\t\tif (kv.getValue() >= minMatch) {\n\n\t\t\t// …\n\t\t\t// pivot就是该级facet，添加它相关数据（field、value、count）\n\t\t\tSimpleOrderedMap<Object> pivot = new SimpleOrderedMap<Object>();\n\t\t\tpivot.add(\"field\", field);\n\t\t\tif (null == fieldValue) {\n\t\t\t\tpivot.add(\"value\", null);\n\t\t\t} else {\n\t\t\t    // termval：当前facets、field下，所包含的值\n                // e.g.: “Jiangsu”\n\t\t\t\ttermval = new BytesRef();\n\t\t\t\tftype.readableToIndexed(fieldValue, termval);\n\t\t\t\tpivot.add(\"value\", ftype.toObject(sfield, termval));\n\t\t\t}\n\t\t\tpivot.add(\"count\", kv.getValue());\n\n\t\t\t// subField为空，这一级facet的这个pivot递归遍历完毕\n\t\t\tif (subField == null) {\n\t\t\t\tvalues.add(pivot);\n\t\t\t// subField不为空，继续递归遍历\n\t\t\t} else {\n\t\t\t    // subset: 当前facet下，包含field:value的文档子集\n\t\t\t    // field:value -> “province”:“Jiangsu”\n\t\t\t\tDocSet subset = null;\n\n\t\t\t\tif (null == termval) {\n\t\t\t\t\tDocSet hasVal = searcher.getDocSet(new TermRangeQuery(\n\t\t\t\t\t\t\tfield, null, null, false, false));\n\t\t\t\t\tsubset = docs.andNot(hasVal);\n\t\t\t\t} else {\n\t\t\t\t\tString term = new String(new String(termval.bytes,\n\t\t\t\t\t\t\ttermval.offset, termval.length));\n\n\t\t\t\t\tQuery query = new TermQuery(new Term(field, term));\n\t\t\t\t\tsubset = searcher.getDocSet(query, docs);\n\t\t\t\t}\n\t\t\t\tsuper.docs = subset;// used by getTermCounts()\n\n                 // nl: 获得当前docs下，下一级field的facets。\n                 // nl我理解为next level\n                 // e.g.: subField: “city”\n                 //         nl: [“Suzhou”, 3, “Nanjing”, 1]\n\t\t\t\tNamedList<Integer> nl = this.getTermCounts(subField);\n\t\t\t\tif (nl.size() >= minMatch) {\n                     // 继续下一层迭代\n\t\t\t\t\tpivot.add(\t\"pivot\",doPivots(nl, subField, nextField, fnames, subset));\n\t\t\t\t\tvalues.add(pivot); // only add response if there are\n\t\t\t\t\t\t\t\t\t\t\t// some counts\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t\t// put the field back on the list\n\tfnames.push(nextField);\n\treturn values;\n}\n```\n\n> 新版添加新机制方式可以参考，并不是在源码基础上大刀阔斧的改。而是添加了一个新类，只需原有获取facet流程逻辑上，添加少数几行代码即可，这也算是模块化思想么？\n\n### 3、移植Pivot功能到低级版本\n\n> 这里是从solr4.0移植到solr3.5\n\n移植步骤倒也还方便，主要是添加PivotFacetHelper类，剩下的就是一步一步修复红叉叉了。\n\n``` java\nIndex: core/src/java/org/apache/solr/handler/component/FacetComponent.java\n===================================================================\n--- core/src/java/org/apache/solr/handler/component/FacetComponent.java\t(Version unknown old)\n+++ core/src/java/org/apache/solr/handler/component/FacetComponent.java\t(Version unknown new)\n\n46a47,48\n> \tstatic final String PIVOT_KEY = \"facet_pivot\";\n>\n66c68,79\n<\n---\n> \t\t\tNamedList<Object> counts = f.getFacetCounts();\n> \t\t\t// e.g.: [\"province,city\"]\n> \t\t\tString[] pivots = params.getParams(FacetParams.FACET_PIVOT);\n> \t\t\tif (pivots != null && pivots.length > 0) {\n> \t\t\t\tPivotFacetHelper pivotHelper = new PivotFacetHelper(rb.req,\n> \t\t\t\t\t\trb.getResults().docSet, params, rb);\n> \t\t\t\t// process each pivots individually\n> \t\t\t\tNamedList v = pivotHelper.process(pivots);\n> \t\t\t\tif (v != null) {\n> \t\t\t\t\tcounts.add(PIVOT_KEY, v);\n> \t\t\t\t}\n> \t\t\t}\n68c81\n< \t\t\trb.rsp.add(\"facet_counts\", f.getFacetCounts());\n---\n> \t\t\trb.rsp.add(\"facet_counts\", counts);\n```\n\n``` java\nIndex: solrj/src/java/org/apache/solr/common/params/FacetParams.java\n===================================================================\n--- solrj/src/java/org/apache/solr/common/params/FacetParams.java\t(Version unknown old)\n+++ solrj/src/java/org/apache/solr/common/params/FacetParams.java\t(Version unknown new)\n\n92a93,98\n> \t/**\n> \t * Comma separated list of fields to pivot\n> \t *\n> \t * example: author,type (for types by author / types within author)\n> \t */\n> \tpublic static final String FACET_PIVOT = FACET + \".pivot\";\n94a101,106\n> \t * Minimum number of docs that need to match to be included in the sublist\n> \t *\n> \t * default value is 1\n> \t */\n> \tpublic static final String FACET_PIVOT_MINCOUNT = FACET_PIVOT + \".mincount\";\n> \t/**\n```\n\n``` java\nIndex: core/src/java/org/apache/solr/request/SimpleFacets.java\n===================================================================\n--- core/src/java/org/apache/solr/request/SimpleFacets.java\t(Version unknown old)\n+++ core/src/java/org/apache/solr/request/SimpleFacets.java\t(Version unknown new)\n\n74,76c74,77\n< \tString facetValue; // the field to or query to facet on (minus local params)\n< \tDocSet base; // the base docset for this particular facet\n< \tString key; // what name should the results be stored under\n---\n> \tprotected String facetValue; // the field to or query to facet on (minus\n> \t\t\t\t\t\t\t\t\t// local params)\n> \tprotected DocSet base; // the base docset for this particular facet\n> \tprotected String key; // what name should the results be stored under\n92,93c93,94\n< \tvoid parseParams(String type, String param) throws ParseException,\n< \t\t\tIOException {\n---\n> \tprotected void parseParams(String type, String param)\n> \t\t\tthrows ParseException, IOException {\n```\n\n```\nIndex: core/src/java/org/apache/solr/schema/FieldType.java\n===================================================================\n--- core/src/java/org/apache/solr/schema/FieldType.java\t(Version unknown old)\n+++ core/src/java/org/apache/solr/schema/FieldType.java\t(Version unknown new)\n394a399,411\n> \tpublic Object toObject(SchemaField sf, BytesRef term) {\n> \t\tfinal CharsRef ref = new CharsRef(term.length);\n> \t\tindexedToReadable(term, ref);\n> \t\tfinal Fieldable f =  createField(sf, ref.toString(), 1.0f);\n> \t\treturn toObject(f);\n> \t}\n>\n> \t/** Given an indexed term, append the human readable representation */\n> \tpublic CharsRef indexedToReadable(BytesRef input, CharsRef output) {\n> \t\tUnicodeUtil.UTF8toUTF16(input, output);\n> \t\treturn output;\n> \t}\n>\n418a436,441\n> \t/** Given the readable value, return the term value that will match it. */\n> \tpublic void readableToIndexed(CharSequence val, BytesRef result) {\n> \t\tfinal String internal = readableToIndexed(val.toString());\n> \t\tUnicodeUtil.UTF16toUTF8(internal, 0, internal.length(), result);\n> \t}\n>\n```\n\n```\nIndex: core/src/java/org/apache/solr/handler/component/PivotFacetHelper.java\n===================================================================\n--- core/src/java/org/apache/solr/handler/component/PivotFacetHelper.java\t(Version unknown old)\n+++ core/src/java/org/apache/solr/handler/component/PivotFacetHelper.java\t(Version unknown new)\n\n144c152,155\n<        Query query = new TermQuery(new Term(field, termval));\n---\n>        String term = new String(new String(termval.bytes,\n>                       termval.offset, termval.length));\n>\n>        Query query = new TermQuery(new Term(field, term));\n147,148c158,159\n<        super.docs = subset;// used by getTermCounts()\n<\n---\n>        super.base = subset;// used by getTermCounts()\n>\n```\n\n> 没弄过patch，上面的就将就着看吧。\n\n> **WARNING**:\n>\n> 3.x中，SimpleFacet组件中有两个成员，docs/base。在4.x中，这两个成员改名为docsOrig/docs。名字倒是清晰了，就是移植的时候没注意倒是挺麻烦的。\n\n> **WARNING**:\n>\n> BytesRef这个类，在4.x中改动比较大，而且Term也原生支持BytesRef。为了偷懒，就直接将BytesRef.bytes转换成了String。\n\n> **WARNING**:\n>\n>  上面还有一些小类，没有写上，有红叉叉自己改改应该问题不大。</blockquote>\n","source":"_posts/apache-solr-facet-pivot-implementation-tranplant.md","raw":"title: Apache Solr —— Facet Pivot实现与低版本移植\ndate: 2013-03-27 23:12:00\ncategories: 技术分享\ntags: Solr\n---\n\n### 1、前言\n\nSolr升级到4.0后便有了一个新功能，就是facet.pivot，关于pivot的介绍可以看上一篇文章：[《Apache Solr – Facet介绍》](http://hongweiyi.com/2013/03/apache-solr-facet-introduction/) 这篇主要讲述Pivot的内部实现机制，以及如何将这个功能移植到低版本的Solr中来。\n\n<!--more-->\n\n### 2、Pivot实现机制\n\n> `http://...?q=*:*&facet=true&&facet.field=province&facet.field=city&facet.pivot=province,city&wt=json`\n\n#### 2.1 获得所有pivots参数列表\n\n> e.g.: [\"province,city\", …]\n\n#### 2.2 将pivots交给PivotFacetHelper处理\n\n``` java\n// FacetComponent.java -> process\n// e.g.: [\"province,city\"]\nString[] pivots = params.getParams(FacetParams.FACET_PIVOT);\nif (pivots != null && pivots.length > 0) {\n\tPivotFacetHelper pivotHelper = new PivotFacetHelper(rb.req,\n\t\t\t\t\t\trb.getResults().docSet, params, rb);\n\t// process each pivots individually\n\tNamedList v = pivotHelper.process(pivots);\n\tif (v != null) {\n\t\tcounts.add(PIVOT_KEY, v);\n\t}\n}\n```\n\n#### 2.3 解析pivot，获得每个field –> pivot: field subField fnames\n\n``` Java\n// PivotFacetHelper.java -> process\nfor (String pivot : pivots) {\n\t// …\n\n\tString[] fields = pivot.split(\",\");\n\n\tif (fields.length < 2) {\n\t    throw new SolrException(ErrorCode.BAD_REQUEST,\n\t\t\t\"Pivot Facet needs at least two fields: \" + pivot);\n\t}\n\n\tString field = fields[0];\n\tString subField = fields[1];\n\n\t// the rest of fields\n\tDeque<String> fnames = new LinkedList<String>();\n\tfor (int i = fields.length - 1; i > 1; i--) {\n\t\tfnames.push(fields[i]);\n\t}\n\t// …\n}\n```\n\n#### 2.4 获得第一级field的facets\n\n``` java\n// PivotFacetHelper.java -> process\n// e.g.: field: province\n//        superFacets : [\"Jiangsu\", 4, \"Hunan\", 3, \"Guangdong\", 2, \"Beijing\", 1, \"Zhejiang\", 1]\nNamedList<Integer> superFacets = this.getTermCounts(field);\n```\n\n#### 2.5 递归调用pivotResult = doPivot(superFacets, field, subField, fnames, docs)\n\n``` java\n        // …\n        // super.key usually == pivot unless local-param 'key' used\n        pivotResponse.add(key,\n        doPivots(superFacets, field, subField, fnames, base));\n\t}\n\treturn pivotResponse;\n}\n\n// PivotFacetHelper.java -> doPivots\nprotected List<NamedList<Object>> doPivots(NamedList<Integer> superFacets, String field, String subField, Deque<String> fnames, DocSet docs) throws IOException {\n\n\t// …\n\t// 遍历该级所有facet，获得该facet下所有下一级facet数据…\n    // [\"Jiangsu\", \"Hunan\", \"Guangdong\", \"Beijing\", \"Zhejiang\"]\n\tfor (Map.Entry<String, Integer> kv : superFacets) {\n\t\t// Only sub-facet if parent facet has positive count - still may not\n\t\t// be any values for the sub-field though\n\t\tif (kv.getValue() >= minMatch) {\n\n\t\t\t// …\n\t\t\t// pivot就是该级facet，添加它相关数据（field、value、count）\n\t\t\tSimpleOrderedMap<Object> pivot = new SimpleOrderedMap<Object>();\n\t\t\tpivot.add(\"field\", field);\n\t\t\tif (null == fieldValue) {\n\t\t\t\tpivot.add(\"value\", null);\n\t\t\t} else {\n\t\t\t    // termval：当前facets、field下，所包含的值\n                // e.g.: “Jiangsu”\n\t\t\t\ttermval = new BytesRef();\n\t\t\t\tftype.readableToIndexed(fieldValue, termval);\n\t\t\t\tpivot.add(\"value\", ftype.toObject(sfield, termval));\n\t\t\t}\n\t\t\tpivot.add(\"count\", kv.getValue());\n\n\t\t\t// subField为空，这一级facet的这个pivot递归遍历完毕\n\t\t\tif (subField == null) {\n\t\t\t\tvalues.add(pivot);\n\t\t\t// subField不为空，继续递归遍历\n\t\t\t} else {\n\t\t\t    // subset: 当前facet下，包含field:value的文档子集\n\t\t\t    // field:value -> “province”:“Jiangsu”\n\t\t\t\tDocSet subset = null;\n\n\t\t\t\tif (null == termval) {\n\t\t\t\t\tDocSet hasVal = searcher.getDocSet(new TermRangeQuery(\n\t\t\t\t\t\t\tfield, null, null, false, false));\n\t\t\t\t\tsubset = docs.andNot(hasVal);\n\t\t\t\t} else {\n\t\t\t\t\tString term = new String(new String(termval.bytes,\n\t\t\t\t\t\t\ttermval.offset, termval.length));\n\n\t\t\t\t\tQuery query = new TermQuery(new Term(field, term));\n\t\t\t\t\tsubset = searcher.getDocSet(query, docs);\n\t\t\t\t}\n\t\t\t\tsuper.docs = subset;// used by getTermCounts()\n\n                 // nl: 获得当前docs下，下一级field的facets。\n                 // nl我理解为next level\n                 // e.g.: subField: “city”\n                 //         nl: [“Suzhou”, 3, “Nanjing”, 1]\n\t\t\t\tNamedList<Integer> nl = this.getTermCounts(subField);\n\t\t\t\tif (nl.size() >= minMatch) {\n                     // 继续下一层迭代\n\t\t\t\t\tpivot.add(\t\"pivot\",doPivots(nl, subField, nextField, fnames, subset));\n\t\t\t\t\tvalues.add(pivot); // only add response if there are\n\t\t\t\t\t\t\t\t\t\t\t// some counts\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t\t// put the field back on the list\n\tfnames.push(nextField);\n\treturn values;\n}\n```\n\n> 新版添加新机制方式可以参考，并不是在源码基础上大刀阔斧的改。而是添加了一个新类，只需原有获取facet流程逻辑上，添加少数几行代码即可，这也算是模块化思想么？\n\n### 3、移植Pivot功能到低级版本\n\n> 这里是从solr4.0移植到solr3.5\n\n移植步骤倒也还方便，主要是添加PivotFacetHelper类，剩下的就是一步一步修复红叉叉了。\n\n``` java\nIndex: core/src/java/org/apache/solr/handler/component/FacetComponent.java\n===================================================================\n--- core/src/java/org/apache/solr/handler/component/FacetComponent.java\t(Version unknown old)\n+++ core/src/java/org/apache/solr/handler/component/FacetComponent.java\t(Version unknown new)\n\n46a47,48\n> \tstatic final String PIVOT_KEY = \"facet_pivot\";\n>\n66c68,79\n<\n---\n> \t\t\tNamedList<Object> counts = f.getFacetCounts();\n> \t\t\t// e.g.: [\"province,city\"]\n> \t\t\tString[] pivots = params.getParams(FacetParams.FACET_PIVOT);\n> \t\t\tif (pivots != null && pivots.length > 0) {\n> \t\t\t\tPivotFacetHelper pivotHelper = new PivotFacetHelper(rb.req,\n> \t\t\t\t\t\trb.getResults().docSet, params, rb);\n> \t\t\t\t// process each pivots individually\n> \t\t\t\tNamedList v = pivotHelper.process(pivots);\n> \t\t\t\tif (v != null) {\n> \t\t\t\t\tcounts.add(PIVOT_KEY, v);\n> \t\t\t\t}\n> \t\t\t}\n68c81\n< \t\t\trb.rsp.add(\"facet_counts\", f.getFacetCounts());\n---\n> \t\t\trb.rsp.add(\"facet_counts\", counts);\n```\n\n``` java\nIndex: solrj/src/java/org/apache/solr/common/params/FacetParams.java\n===================================================================\n--- solrj/src/java/org/apache/solr/common/params/FacetParams.java\t(Version unknown old)\n+++ solrj/src/java/org/apache/solr/common/params/FacetParams.java\t(Version unknown new)\n\n92a93,98\n> \t/**\n> \t * Comma separated list of fields to pivot\n> \t *\n> \t * example: author,type (for types by author / types within author)\n> \t */\n> \tpublic static final String FACET_PIVOT = FACET + \".pivot\";\n94a101,106\n> \t * Minimum number of docs that need to match to be included in the sublist\n> \t *\n> \t * default value is 1\n> \t */\n> \tpublic static final String FACET_PIVOT_MINCOUNT = FACET_PIVOT + \".mincount\";\n> \t/**\n```\n\n``` java\nIndex: core/src/java/org/apache/solr/request/SimpleFacets.java\n===================================================================\n--- core/src/java/org/apache/solr/request/SimpleFacets.java\t(Version unknown old)\n+++ core/src/java/org/apache/solr/request/SimpleFacets.java\t(Version unknown new)\n\n74,76c74,77\n< \tString facetValue; // the field to or query to facet on (minus local params)\n< \tDocSet base; // the base docset for this particular facet\n< \tString key; // what name should the results be stored under\n---\n> \tprotected String facetValue; // the field to or query to facet on (minus\n> \t\t\t\t\t\t\t\t\t// local params)\n> \tprotected DocSet base; // the base docset for this particular facet\n> \tprotected String key; // what name should the results be stored under\n92,93c93,94\n< \tvoid parseParams(String type, String param) throws ParseException,\n< \t\t\tIOException {\n---\n> \tprotected void parseParams(String type, String param)\n> \t\t\tthrows ParseException, IOException {\n```\n\n```\nIndex: core/src/java/org/apache/solr/schema/FieldType.java\n===================================================================\n--- core/src/java/org/apache/solr/schema/FieldType.java\t(Version unknown old)\n+++ core/src/java/org/apache/solr/schema/FieldType.java\t(Version unknown new)\n394a399,411\n> \tpublic Object toObject(SchemaField sf, BytesRef term) {\n> \t\tfinal CharsRef ref = new CharsRef(term.length);\n> \t\tindexedToReadable(term, ref);\n> \t\tfinal Fieldable f =  createField(sf, ref.toString(), 1.0f);\n> \t\treturn toObject(f);\n> \t}\n>\n> \t/** Given an indexed term, append the human readable representation */\n> \tpublic CharsRef indexedToReadable(BytesRef input, CharsRef output) {\n> \t\tUnicodeUtil.UTF8toUTF16(input, output);\n> \t\treturn output;\n> \t}\n>\n418a436,441\n> \t/** Given the readable value, return the term value that will match it. */\n> \tpublic void readableToIndexed(CharSequence val, BytesRef result) {\n> \t\tfinal String internal = readableToIndexed(val.toString());\n> \t\tUnicodeUtil.UTF16toUTF8(internal, 0, internal.length(), result);\n> \t}\n>\n```\n\n```\nIndex: core/src/java/org/apache/solr/handler/component/PivotFacetHelper.java\n===================================================================\n--- core/src/java/org/apache/solr/handler/component/PivotFacetHelper.java\t(Version unknown old)\n+++ core/src/java/org/apache/solr/handler/component/PivotFacetHelper.java\t(Version unknown new)\n\n144c152,155\n<        Query query = new TermQuery(new Term(field, termval));\n---\n>        String term = new String(new String(termval.bytes,\n>                       termval.offset, termval.length));\n>\n>        Query query = new TermQuery(new Term(field, term));\n147,148c158,159\n<        super.docs = subset;// used by getTermCounts()\n<\n---\n>        super.base = subset;// used by getTermCounts()\n>\n```\n\n> 没弄过patch，上面的就将就着看吧。\n\n> **WARNING**:\n>\n> 3.x中，SimpleFacet组件中有两个成员，docs/base。在4.x中，这两个成员改名为docsOrig/docs。名字倒是清晰了，就是移植的时候没注意倒是挺麻烦的。\n\n> **WARNING**:\n>\n> BytesRef这个类，在4.x中改动比较大，而且Term也原生支持BytesRef。为了偷懒，就直接将BytesRef.bytes转换成了String。\n\n> **WARNING**:\n>\n>  上面还有一些小类，没有写上，有红叉叉自己改改应该问题不大。</blockquote>\n","slug":"apache-solr-facet-pivot-implementation-tranplant","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg625100amsb8fomtinzpn"},{"title":"Apache Solr —— Facet介绍","date":"2013-03-23T06:31:00.000Z","_content":"\n### 1、什么是Faceted Search\n\n`Facet['fæsɪt]`很难翻译，只能靠例子来理解了。Solr作者Yonik Seeley也给出更为直接的名字：导航（Guided Navigation）、参数化查询（Paramatic Search）。\n\n<!--more-->\n\n<center><div style=\"width: 80%;\">![facet-1](/images/facet-1.png)</div></center>\n\n上面是比较直接的Faceted Search例子，品牌、产品特征、卖家，均是Facet。而Apple、Lenovo等品牌，就是Facet values或者说Constraints，而Facet values所带的统计值就是Facet count/Constraint count。\n\n### 2、Facet使用\n> q = 超级本\nfacet = true\nfacet.field = 产品特性\nfacet.field = 品牌\nfacet.field = 卖家\n> `http://.../select?q=超级本&facet=true&wt=json&facet.field=品牌&facet.field=产品特性&facet.field=卖家`\n\n```\n\"facet_counts\": {\n\"facet_fields\": {\n  \"品牌\": [\n    \"Apple\", 4,\n    \"Lenovo\", 39\n      …]\n  \"产品特性\": [\n    \"显卡\", 42,\n    \"酷睿\", 38\n      …]\n\n  …}}\n```\n\n也可以提交查询条件，设置fq(filter query)。\n\n> q = 电脑\nfacet = true\nfq = 价格:[8000 TO \\*]\nfacet.mincount = 1 // fq将不符合的字段过滤后，会显示count为0\nfacet.field = 产品特性\nfacet.field = 品牌\nfacet.field = 卖家</blockquote>\n> `http://.../select?q=超级本&facet=true&wt=json&fq=价格:[8000 TO *]&facet.mincount=1&facet.field=品牌&facet.field=产品特性&facet.field=卖家\n\n``` json\n\"facet_counts\": {\n\"facet_fields\": {\n  \"品牌\": [\n    \"Apple\", 4,\n    \"Lenovo\", 10\n      …]\n  \"产品特性\": [\n    \"显卡\", 11,\n    \"酷睿\", 20\n      …]\n\n  …}}\n```\n\n如果用户选择了Apple这个分类，查询条件中需要添加另外一个fq查询条件，并移除Apple所在的facet.field。\n\n> `http://.../select?q=超级本&facet=true&wt=json&fq=价格:[8000 TO *]&fq=品牌:Apple&facet.mincount=1 &facet.field=产品特性&facet.field=卖家`\n\n### 3、Facet参数\n\n* **facet.prefix**: 限制constaints的前缀\n* **facet.mincount=0**: 限制constants count的最小返回值，默认为0\n* **facet.sort=count**: 排序的方式，根据count或者index\n* **facet.offset=0**: 表示在当前排序情况下的偏移，可以做分页\n* **facet.limit=100**: constraints返回的数目\n* **facet.missing=false**: 是否返回没有值的field\n* **facet.date**: Deprecated, use facet.range\n* **facet.query**: 指定一个查询字符串作为Facet Constraint\n\n```\nfacet.query = rank:[* TO 20]\nfacet.query = rank:[21 TO *]\n```\n\n``` xml\n  <result numFound=\"27\" ... />\n  ...\n  <lst name=\"facet_counts\">\n  <lst name=\"facet_queries\">\n    <int name=\"rank:[* TO 20]\">2</int>\n    <int name=\"rank:[21 TO *]\">15</int>\n  </lst>\n ...\n```\n\n* **facet.range:\n\n`http://.../select?&facet=true&facet.range=price&facet.range.start=5000&facet.range.end=8000&facet.range.gap=1000`\n\n``` json\n \"facet_counts\":{\n  \"facet_ranges\":{\n    \"price\":{\n      \"counts”:[\n        \"5000.0”,5,\n        \"6000.0”,2,\n        \"7000.0”,3,],\n      \"gap\":1000.0,\n      \"start\":5000.0,\n      \"end\":8000.0}}}}\n```\n\n> **WARNING:**\n>\n> range范围是左闭右开，`[start, end)`\n\n* **facet.pivot**\n\n这个是Solr 4.0的新特性，pivot和facet一样难理解，还是用例子来讲吧。\n\n> **Syntax:** facet.pivot=field1,field2,field3...\n> **e.g.:** facet.pivot=comment_user, grade\n\n|   |#docs|#docs grade:好|#docs 等级:中|#docs 等级:差|\n|---|----|--------------|------------|-----------|\n|comment_user:1|10|8|1|1|\n|comment_user:2|20|18|2|0|\n|comment_user:3|15|12|2|1|\n|comment_user:4|18|15|2|1|\n\n```\n  \"facet_counts\":{\n  \"facet_pivot\":{\n   \"comment_user, grade \":[{\n     \"field\":\"comment_user\",\n     \"value\":\"1\",\n     \"count\":10,\n     \"pivot\":[{\n       \"field\":\"grade\",\n       \"value\":\"好\",\n       \"count\":8}, {\n       \"field\":\"grade\",\n       \"value\":\"中\",\n       \"count\":1}, {\n       \"field\":\"grade\",\n       \"value\":\"差\",\n       \"count\":1}]\n     }, {\n       \"field\":\" comment_user \",\n       \"value\":\"2\",\n       \"count\":20,\n       \"pivot\":[{\n       ...\n```\n\n没有pivot机制的话，要做到上面那点可能需要多次查询：\n> `http://...q=comment&fq=grade:好&facet=true&facet.field=comment_user`\n> `http://...q=comment&fq=grade:中&facet=true&facet.field=comment_user`\n> `http://...q=comment&fq=grade:差&facet=true&facet.field=comment_user`\n\n> Facet.pivot - Computes a Matrix of Constraint Counts across multiple Facet Fields. by Yonik Seeley.\n上面那个解释很不错，只能理解不能翻译。\n\n> 参考资料：\n> * [The Many Facets of Apache Solr](http://2011.lucene-eurocon.org/attachments/0002/8835/Seeley_Eurocon_SolrFacets_1_.pdf)\n> * [SimpleFacetParameters Wiki](http://wiki.apache.org/solr/SimpleFacetParameters)\n","source":"_posts/apache-solr-facet-introduction.md","raw":"title: Apache Solr —— Facet介绍\ndate: 2013-03-23 14:31:00\ncategories: 技术分享\ntags: Solr\n---\n\n### 1、什么是Faceted Search\n\n`Facet['fæsɪt]`很难翻译，只能靠例子来理解了。Solr作者Yonik Seeley也给出更为直接的名字：导航（Guided Navigation）、参数化查询（Paramatic Search）。\n\n<!--more-->\n\n<center><div style=\"width: 80%;\">![facet-1](/images/facet-1.png)</div></center>\n\n上面是比较直接的Faceted Search例子，品牌、产品特征、卖家，均是Facet。而Apple、Lenovo等品牌，就是Facet values或者说Constraints，而Facet values所带的统计值就是Facet count/Constraint count。\n\n### 2、Facet使用\n> q = 超级本\nfacet = true\nfacet.field = 产品特性\nfacet.field = 品牌\nfacet.field = 卖家\n> `http://.../select?q=超级本&facet=true&wt=json&facet.field=品牌&facet.field=产品特性&facet.field=卖家`\n\n```\n\"facet_counts\": {\n\"facet_fields\": {\n  \"品牌\": [\n    \"Apple\", 4,\n    \"Lenovo\", 39\n      …]\n  \"产品特性\": [\n    \"显卡\", 42,\n    \"酷睿\", 38\n      …]\n\n  …}}\n```\n\n也可以提交查询条件，设置fq(filter query)。\n\n> q = 电脑\nfacet = true\nfq = 价格:[8000 TO \\*]\nfacet.mincount = 1 // fq将不符合的字段过滤后，会显示count为0\nfacet.field = 产品特性\nfacet.field = 品牌\nfacet.field = 卖家</blockquote>\n> `http://.../select?q=超级本&facet=true&wt=json&fq=价格:[8000 TO *]&facet.mincount=1&facet.field=品牌&facet.field=产品特性&facet.field=卖家\n\n``` json\n\"facet_counts\": {\n\"facet_fields\": {\n  \"品牌\": [\n    \"Apple\", 4,\n    \"Lenovo\", 10\n      …]\n  \"产品特性\": [\n    \"显卡\", 11,\n    \"酷睿\", 20\n      …]\n\n  …}}\n```\n\n如果用户选择了Apple这个分类，查询条件中需要添加另外一个fq查询条件，并移除Apple所在的facet.field。\n\n> `http://.../select?q=超级本&facet=true&wt=json&fq=价格:[8000 TO *]&fq=品牌:Apple&facet.mincount=1 &facet.field=产品特性&facet.field=卖家`\n\n### 3、Facet参数\n\n* **facet.prefix**: 限制constaints的前缀\n* **facet.mincount=0**: 限制constants count的最小返回值，默认为0\n* **facet.sort=count**: 排序的方式，根据count或者index\n* **facet.offset=0**: 表示在当前排序情况下的偏移，可以做分页\n* **facet.limit=100**: constraints返回的数目\n* **facet.missing=false**: 是否返回没有值的field\n* **facet.date**: Deprecated, use facet.range\n* **facet.query**: 指定一个查询字符串作为Facet Constraint\n\n```\nfacet.query = rank:[* TO 20]\nfacet.query = rank:[21 TO *]\n```\n\n``` xml\n  <result numFound=\"27\" ... />\n  ...\n  <lst name=\"facet_counts\">\n  <lst name=\"facet_queries\">\n    <int name=\"rank:[* TO 20]\">2</int>\n    <int name=\"rank:[21 TO *]\">15</int>\n  </lst>\n ...\n```\n\n* **facet.range:\n\n`http://.../select?&facet=true&facet.range=price&facet.range.start=5000&facet.range.end=8000&facet.range.gap=1000`\n\n``` json\n \"facet_counts\":{\n  \"facet_ranges\":{\n    \"price\":{\n      \"counts”:[\n        \"5000.0”,5,\n        \"6000.0”,2,\n        \"7000.0”,3,],\n      \"gap\":1000.0,\n      \"start\":5000.0,\n      \"end\":8000.0}}}}\n```\n\n> **WARNING:**\n>\n> range范围是左闭右开，`[start, end)`\n\n* **facet.pivot**\n\n这个是Solr 4.0的新特性，pivot和facet一样难理解，还是用例子来讲吧。\n\n> **Syntax:** facet.pivot=field1,field2,field3...\n> **e.g.:** facet.pivot=comment_user, grade\n\n|   |#docs|#docs grade:好|#docs 等级:中|#docs 等级:差|\n|---|----|--------------|------------|-----------|\n|comment_user:1|10|8|1|1|\n|comment_user:2|20|18|2|0|\n|comment_user:3|15|12|2|1|\n|comment_user:4|18|15|2|1|\n\n```\n  \"facet_counts\":{\n  \"facet_pivot\":{\n   \"comment_user, grade \":[{\n     \"field\":\"comment_user\",\n     \"value\":\"1\",\n     \"count\":10,\n     \"pivot\":[{\n       \"field\":\"grade\",\n       \"value\":\"好\",\n       \"count\":8}, {\n       \"field\":\"grade\",\n       \"value\":\"中\",\n       \"count\":1}, {\n       \"field\":\"grade\",\n       \"value\":\"差\",\n       \"count\":1}]\n     }, {\n       \"field\":\" comment_user \",\n       \"value\":\"2\",\n       \"count\":20,\n       \"pivot\":[{\n       ...\n```\n\n没有pivot机制的话，要做到上面那点可能需要多次查询：\n> `http://...q=comment&fq=grade:好&facet=true&facet.field=comment_user`\n> `http://...q=comment&fq=grade:中&facet=true&facet.field=comment_user`\n> `http://...q=comment&fq=grade:差&facet=true&facet.field=comment_user`\n\n> Facet.pivot - Computes a Matrix of Constraint Counts across multiple Facet Fields. by Yonik Seeley.\n上面那个解释很不错，只能理解不能翻译。\n\n> 参考资料：\n> * [The Many Facets of Apache Solr](http://2011.lucene-eurocon.org/attachments/0002/8835/Seeley_Eurocon_SolrFacets_1_.pdf)\n> * [SimpleFacetParameters Wiki](http://wiki.apache.org/solr/SimpleFacetParameters)\n","slug":"apache-solr-facet-introduction","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg625200apsb8f0fxuit4h"},{"title":"Apache Solr —— DistributedSearch","date":"2013-04-08T10:04:00.000Z","_content":"\n### 1、前言\n\n当索引太大以致单台服务器的磁盘无法承受了，当一个简单的查询实在要耗费过多的时间，可以考虑使用Solr的分布式索引机制，或者配置一台多核机制（multicore）。当Solr配置了这样的机制，实质上就是将大索引分成了多个小索引分布在了不同服务器上，或者将请求发到多核，充分利用服务器CPU资源。\n\nSolr会将请求请求分发不同shards（理解为地址）上，并合并所有请求结果并返回给客户端。那么，这个分布式查询内部是怎么实现的呢？\n\n<!--more-->\n\n### 2、机制解析\n\n一个SearchComponent如果作为Distributed SearchComponent，需要重写以下四个方法：\n\n* distributedProcess()\n* modifyRequest()\n* handleResponses()\n* finishStage()\n\n同时，Distributed Search主要有4个主要阶段：\n\n* **Start**(ResponseBuilder.STAGE_START)\n* **Query Parse**(ResponseBuilder.STAGE_PARSE_QUERY)\n* **Execute Query**(ResponseBuilder.STAGE_EXECUTE_QUERY)\n* **Get Fields**(ResponseBuilder.STAGE_GET_FIELDS)</blockquote>\n* **Done**(ResponseBuilder.STAGE_DONE)。\n\n在SearchHandler中，基本的**分布式查询算法**如下：\n\n#### 1. 如果不在STAGE_DONE的阶段，循环以下流程；\n#### 2. 发起分布式处理的组件会不断查询是否需要进行分布式处理。如果有的话（distributedProcess），返回4个阶段中一个状态并创建一个 ShardRequest并将它添加到一个队列（rb.outgoing)中；\n\n> Components可以指定一些purpose字段，可以定制一些特殊的请求处理。如下：\n\n``` java\npublic void handleResponses(ResponseBuilder rb, ShardRequest sreq) {\n  if (!rb.doFacets )\n     return;\n\n  if ((sreq.purpose & ShardRequest.PURPOSE_GET_FACETS) != 0) {\n     countFacets(rb, sreq);\n  } else if ((sreq.purpose & ShardRequest.PURPOSE_REFINE_FACETS ) != 0) {\n     refineFacets(rb, sreq);\n  }\n}\n```\n\n> modifyRequest()是用来精简shard请求的，该方法都是加在了ResponseBuilder.addRequest()中，实例可以参考FacetComponent.modifyRequest。\n\n``` java\npublic void addRequest(SearchComponent me, ShardRequest sreq) {\n  outgoing.add(sreq);\n  if ((sreq.purpose & ShardRequest.PURPOSE_PRIVATE)==0) {\n   // if this isn't a private request, let other components modify it.\n   for (SearchComponent component : components) {\n      if (component != me) {\n        component.modifyRequest( this, me, sreq);\n      }\n    }\n  }\n}\n```\n\n#### 3. 取出队列（rb.outgoing)中所有 ShardRequest，并根据其配置将请求发到相应的 Shards；\n#### 4. 如果队列为空，则等待接收到响应，并处理（handleResponse)；\n\n> 你可以合并文档id神马的。QueryComponent.handleResponse\n\n#### 5. 进入下一轮循环之前，先调用finishStage()\n\n> 进行该轮的收尾工作，比如说将为null的doc从responseDocs中移除。\n\n``` java\n// SearchHandler.handleRequestBody()\nif (rb.shards == null) {\n  // a normal non-distributed request\n  // ...\n} else {\n  // a distributed request\n\n  HttpCommComponent comm = new HttpCommComponent();\n\n  if (rb.outgoing == null ) {\n    rb.outgoing = new LinkedList<ShardRequest>();\n  }\n  rb.finished = new ArrayList<ShardRequest>();\n\n  int nextStage = 0;\n  do {\n    rb.stage = nextStage;\n    nextStage = ResponseBuilder.STAGE_DONE;\n\n    // call all components\n    for( SearchComponent c : components ) {\n      // the next stage is the minimum of what all components report\n      nextStage = Math.min(nextStage, c.distributedProcess(rb));\n    }\n\n\n    // check the outgoing queue and send requests\n    while (rb.outgoing.size() > 0) {\n\n      // submit all current request tasks at once\n      while (rb.outgoing.size() > 0) {\n        ShardRequest sreq = rb.outgoing.remove(0);\n        sreq.actualShards = sreq.shards ;\n        if (sreq.actualShards ==ShardRequest.ALL_SHARDS) {\n          sreq.actualShards = rb.shards ;\n        }\n        sreq.responses = new ArrayList<ShardResponse>();\n\n        // TODO: map from shard to address[]\n        for (String shard : sreq.actualShards ) {\n          ModifiableSolrParams params = new ModifiableSolrParams(sreq.params );\n          params.remove(ShardParams.SHARDS);      // not a top-level request\n          params.remove( \"indent\");\n          params.remove(CommonParams.HEADER_ECHO_PARAMS);\n          params.set(ShardParams.IS_SHARD, true );  // a sub (shard) request\n          String shardHandler = req.getParams().get(ShardParams.SHARDS_QT );\n          if (shardHandler == null) {\n            params.remove(CommonParams.QT);\n          } else {\n            params.set(CommonParams.QT, shardHandler);\n          }\n          // You can see CommonsHttpSolrServer.request.\n          comm.submit(sreq, shard, params);\n        }\n      }\n\n\n      // now wait for replies, but if anyone puts more requests on\n      // the outgoing queue, send them out immediately (by exiting\n      // this loop)\n      while (rb.outgoing.size() == 0) {\n        ShardResponse srsp = comm.takeCompletedOrError();\n        if (srsp == null) break;  // no more requests to wait for\n\n        // Was there an exception?  If so, abort everything and\n        // rethrow\n        if (srsp.getException() != null) {\n          comm.cancelAll();\n          if (srsp.getException() instanceof SolrException) {\n            throw (SolrException)srsp.getException();\n          } else {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, srsp.getException());\n          }\n        }\n\n        rb.finished.add(srsp.getShardRequest());\n\n        // let the components see the responses to the request\n        for(SearchComponent c : components ) {\n          c.handleResponses(rb, srsp.getShardRequest());\n        }\n      }\n    }\n\n    for(SearchComponent c : components) {\n        c.finishStage(rb);\n     }\n\n    // we are done when the next stage is MAX_VALUE\n    // BTW ResponseBuilder.STAGE_DONE == Integer.MAX_VALUE\n  } while (nextStage != Integer.MAX_VALUE);\n}\n```\n\n### 3、其他\n\n有意思的是，我从Solr 3.5的reference中看到一句这样的话：\n\n> It is up to you to get all your documents indexed on each shard of your server farm. Solr does not include out-of-the-box support for distributed indexing, but your method can be as simple as a round robin technique. Just index each document to the next server in the circle.\n\n> Solr本身并不自带分布式的一些机制，索引如何分块还是靠自己写逻辑（如：轮询、hash取模等）。难怪我测试multicore的时候，shards的地址参数还得自己写，这一阶段对于用户来说不是透明的，所谓的分布式查询，也就是每个查询都要访问多台服务器，之后将多台服务器的结果和合并起来，这样看来，对每台服务器的压力来说感觉都是一样的诶（虽然可以不同业务分响应的小集群）。\n\n不知从哪个版本（好像是4.0）推出了Solr Cloud，官方这样介绍的：\n\n> SolrCloud is the name of a set of new distributed capabilities in Solr. Passing parameters to enable these capabilities will enable you to set up a highly available, fault tolerant cluster of Solr servers. Use SolrCloud when you want high scale, fault tolerant, distributed indexing and search capabilities.\n\n似乎这样才算是分布式解决方案，嗯，以后再深入看看Solr Cloud Architecture。\n\n> 参考资料：\n* [SolrCloud](http://wiki.apache.org/solr/SolrCloud)\n* [DistributedSearchComponent](http://wiki.apache.org/solr/WritingDistributedSearchComponents)\n","source":"_posts/apache-solr-distributed-search.md","raw":"title: Apache Solr —— DistributedSearch\ndate: 2013-04-08 18:04:00\ncategories: 技术分享\ntags: Solr\n---\n\n### 1、前言\n\n当索引太大以致单台服务器的磁盘无法承受了，当一个简单的查询实在要耗费过多的时间，可以考虑使用Solr的分布式索引机制，或者配置一台多核机制（multicore）。当Solr配置了这样的机制，实质上就是将大索引分成了多个小索引分布在了不同服务器上，或者将请求发到多核，充分利用服务器CPU资源。\n\nSolr会将请求请求分发不同shards（理解为地址）上，并合并所有请求结果并返回给客户端。那么，这个分布式查询内部是怎么实现的呢？\n\n<!--more-->\n\n### 2、机制解析\n\n一个SearchComponent如果作为Distributed SearchComponent，需要重写以下四个方法：\n\n* distributedProcess()\n* modifyRequest()\n* handleResponses()\n* finishStage()\n\n同时，Distributed Search主要有4个主要阶段：\n\n* **Start**(ResponseBuilder.STAGE_START)\n* **Query Parse**(ResponseBuilder.STAGE_PARSE_QUERY)\n* **Execute Query**(ResponseBuilder.STAGE_EXECUTE_QUERY)\n* **Get Fields**(ResponseBuilder.STAGE_GET_FIELDS)</blockquote>\n* **Done**(ResponseBuilder.STAGE_DONE)。\n\n在SearchHandler中，基本的**分布式查询算法**如下：\n\n#### 1. 如果不在STAGE_DONE的阶段，循环以下流程；\n#### 2. 发起分布式处理的组件会不断查询是否需要进行分布式处理。如果有的话（distributedProcess），返回4个阶段中一个状态并创建一个 ShardRequest并将它添加到一个队列（rb.outgoing)中；\n\n> Components可以指定一些purpose字段，可以定制一些特殊的请求处理。如下：\n\n``` java\npublic void handleResponses(ResponseBuilder rb, ShardRequest sreq) {\n  if (!rb.doFacets )\n     return;\n\n  if ((sreq.purpose & ShardRequest.PURPOSE_GET_FACETS) != 0) {\n     countFacets(rb, sreq);\n  } else if ((sreq.purpose & ShardRequest.PURPOSE_REFINE_FACETS ) != 0) {\n     refineFacets(rb, sreq);\n  }\n}\n```\n\n> modifyRequest()是用来精简shard请求的，该方法都是加在了ResponseBuilder.addRequest()中，实例可以参考FacetComponent.modifyRequest。\n\n``` java\npublic void addRequest(SearchComponent me, ShardRequest sreq) {\n  outgoing.add(sreq);\n  if ((sreq.purpose & ShardRequest.PURPOSE_PRIVATE)==0) {\n   // if this isn't a private request, let other components modify it.\n   for (SearchComponent component : components) {\n      if (component != me) {\n        component.modifyRequest( this, me, sreq);\n      }\n    }\n  }\n}\n```\n\n#### 3. 取出队列（rb.outgoing)中所有 ShardRequest，并根据其配置将请求发到相应的 Shards；\n#### 4. 如果队列为空，则等待接收到响应，并处理（handleResponse)；\n\n> 你可以合并文档id神马的。QueryComponent.handleResponse\n\n#### 5. 进入下一轮循环之前，先调用finishStage()\n\n> 进行该轮的收尾工作，比如说将为null的doc从responseDocs中移除。\n\n``` java\n// SearchHandler.handleRequestBody()\nif (rb.shards == null) {\n  // a normal non-distributed request\n  // ...\n} else {\n  // a distributed request\n\n  HttpCommComponent comm = new HttpCommComponent();\n\n  if (rb.outgoing == null ) {\n    rb.outgoing = new LinkedList<ShardRequest>();\n  }\n  rb.finished = new ArrayList<ShardRequest>();\n\n  int nextStage = 0;\n  do {\n    rb.stage = nextStage;\n    nextStage = ResponseBuilder.STAGE_DONE;\n\n    // call all components\n    for( SearchComponent c : components ) {\n      // the next stage is the minimum of what all components report\n      nextStage = Math.min(nextStage, c.distributedProcess(rb));\n    }\n\n\n    // check the outgoing queue and send requests\n    while (rb.outgoing.size() > 0) {\n\n      // submit all current request tasks at once\n      while (rb.outgoing.size() > 0) {\n        ShardRequest sreq = rb.outgoing.remove(0);\n        sreq.actualShards = sreq.shards ;\n        if (sreq.actualShards ==ShardRequest.ALL_SHARDS) {\n          sreq.actualShards = rb.shards ;\n        }\n        sreq.responses = new ArrayList<ShardResponse>();\n\n        // TODO: map from shard to address[]\n        for (String shard : sreq.actualShards ) {\n          ModifiableSolrParams params = new ModifiableSolrParams(sreq.params );\n          params.remove(ShardParams.SHARDS);      // not a top-level request\n          params.remove( \"indent\");\n          params.remove(CommonParams.HEADER_ECHO_PARAMS);\n          params.set(ShardParams.IS_SHARD, true );  // a sub (shard) request\n          String shardHandler = req.getParams().get(ShardParams.SHARDS_QT );\n          if (shardHandler == null) {\n            params.remove(CommonParams.QT);\n          } else {\n            params.set(CommonParams.QT, shardHandler);\n          }\n          // You can see CommonsHttpSolrServer.request.\n          comm.submit(sreq, shard, params);\n        }\n      }\n\n\n      // now wait for replies, but if anyone puts more requests on\n      // the outgoing queue, send them out immediately (by exiting\n      // this loop)\n      while (rb.outgoing.size() == 0) {\n        ShardResponse srsp = comm.takeCompletedOrError();\n        if (srsp == null) break;  // no more requests to wait for\n\n        // Was there an exception?  If so, abort everything and\n        // rethrow\n        if (srsp.getException() != null) {\n          comm.cancelAll();\n          if (srsp.getException() instanceof SolrException) {\n            throw (SolrException)srsp.getException();\n          } else {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, srsp.getException());\n          }\n        }\n\n        rb.finished.add(srsp.getShardRequest());\n\n        // let the components see the responses to the request\n        for(SearchComponent c : components ) {\n          c.handleResponses(rb, srsp.getShardRequest());\n        }\n      }\n    }\n\n    for(SearchComponent c : components) {\n        c.finishStage(rb);\n     }\n\n    // we are done when the next stage is MAX_VALUE\n    // BTW ResponseBuilder.STAGE_DONE == Integer.MAX_VALUE\n  } while (nextStage != Integer.MAX_VALUE);\n}\n```\n\n### 3、其他\n\n有意思的是，我从Solr 3.5的reference中看到一句这样的话：\n\n> It is up to you to get all your documents indexed on each shard of your server farm. Solr does not include out-of-the-box support for distributed indexing, but your method can be as simple as a round robin technique. Just index each document to the next server in the circle.\n\n> Solr本身并不自带分布式的一些机制，索引如何分块还是靠自己写逻辑（如：轮询、hash取模等）。难怪我测试multicore的时候，shards的地址参数还得自己写，这一阶段对于用户来说不是透明的，所谓的分布式查询，也就是每个查询都要访问多台服务器，之后将多台服务器的结果和合并起来，这样看来，对每台服务器的压力来说感觉都是一样的诶（虽然可以不同业务分响应的小集群）。\n\n不知从哪个版本（好像是4.0）推出了Solr Cloud，官方这样介绍的：\n\n> SolrCloud is the name of a set of new distributed capabilities in Solr. Passing parameters to enable these capabilities will enable you to set up a highly available, fault tolerant cluster of Solr servers. Use SolrCloud when you want high scale, fault tolerant, distributed indexing and search capabilities.\n\n似乎这样才算是分布式解决方案，嗯，以后再深入看看Solr Cloud Architecture。\n\n> 参考资料：\n* [SolrCloud](http://wiki.apache.org/solr/SolrCloud)\n* [DistributedSearchComponent](http://wiki.apache.org/solr/WritingDistributedSearchComponents)\n","slug":"apache-solr-distributed-search","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg625400assb8f7r6f78qd"},{"title":"Apache Solr —— 常用数据结构（二）","date":"2013-04-08T10:04:00.000Z","_content":"\n### 1、前言\n\n继上篇[《Apache Solr – 常用数据结构（一）》](http://hongweiyi.com/2013/04/apache-solr-data-structrue-part-1/)介绍了NamedList和DocSet之后，这篇主要介绍ResponseBuilder和Query。\n\n<!--more-->\n\n### 2、ResponseBuilder\n\n每个组件（ QueryComponent、FacetComponent、MoreLikeThisComponent、HighlightComponent、 DebugComponent等)的操作都是围绕着 ResponseBuilder的实例来进行的，因为这个实例包含了全部的请求以及响应的信息。\n\nResponseBuilder是在SearchHandler的handleRequestBody方法中创建的，主要包含两个成员，SolrQueryRequest和SolrQueryResponse。还有一个components成员，用来装各种SearchComponent，但是好像这个成员并无太大的用武之地。推测作者设计ResponseBuilder类的原因应该是为了降低组件与组件之间的耦合度，让代码逻辑更为清晰。\n\n各种Components的prepare阶段主要是丰满了rb对象，将request成员中各种参数一一取出，赋值给rb。并在process方法中将结果写入response成员。\n\n如FacetComponent的prepare方法：\n\n``` java\npublic void prepare(ResponseBuilder rb) throws IOException {\n  if (rb.req .getParams().getBool(FacetParams.FACET, false)) {\n    rb.setNeedDocSet( true);\n    rb. doFacets = true ;\n  }\n}\n```\n\n\n### 3、Query\n\nLucene提供了多种多样的Query的实现，大多数都在org.apache.lucene.search包下面，这些Query结合起来可以实现非常复杂的查询。Query类有MatchAllDocsQuery、BooleanQuery、TermQuery等，系统通过QueryParser就会将查询解析为一个Query。如\"*:*\"就会解析成MatchAllDocsQuery，\"queryStr1 OR queryStr2\"就会解析成一个BooleanQuery等。\n\nQuery是大多数场景的开始，如果没有Query的话，系统就无法查询文档更别说进行打分（Score）。Query是Scorer的催化剂，并且负责创建和协调它，而Weight则提供了一个Query的中间形态，任何Searcher的依赖状态都必须存放在Weight对象中，而不是Query对象，所以大多数Query的实现类都需要提供一个Weight的实现。\n\nQuery的深入剖析好像是需要对Solr、Lucene有一个专家级的理解了，初学者的我就不多言了。\n\n可参考文档：\n\n* [Apache Lucene - Scoring](http://lucene.apache.org/core/3_6_2/scoring.html)\n* [Package - org.apache.lucene.search - query](http://lucene.apache.org/core/3_6_2/api/core/org/apache/lucene/search/package-summary.html#query)\n* [Lucene打分机制和Similarity模块](http://my.oschina.net/BreathL/blog/51498)\n\n### 4、结尾\n\n以上包括上一篇博文我都只能粗略的理解一些，并不能深入详细的理解及运用，需要在后期的学习及实践的过程中继续深入了。\n","source":"_posts/apache-solr-data-structrue-part-2.md","raw":"title: Apache Solr —— 常用数据结构（二）\ndate: 2013-04-08 18:04:00\ncategories: 技术分享\ntags: Solr, 数据结构\n---\n\n### 1、前言\n\n继上篇[《Apache Solr – 常用数据结构（一）》](http://hongweiyi.com/2013/04/apache-solr-data-structrue-part-1/)介绍了NamedList和DocSet之后，这篇主要介绍ResponseBuilder和Query。\n\n<!--more-->\n\n### 2、ResponseBuilder\n\n每个组件（ QueryComponent、FacetComponent、MoreLikeThisComponent、HighlightComponent、 DebugComponent等)的操作都是围绕着 ResponseBuilder的实例来进行的，因为这个实例包含了全部的请求以及响应的信息。\n\nResponseBuilder是在SearchHandler的handleRequestBody方法中创建的，主要包含两个成员，SolrQueryRequest和SolrQueryResponse。还有一个components成员，用来装各种SearchComponent，但是好像这个成员并无太大的用武之地。推测作者设计ResponseBuilder类的原因应该是为了降低组件与组件之间的耦合度，让代码逻辑更为清晰。\n\n各种Components的prepare阶段主要是丰满了rb对象，将request成员中各种参数一一取出，赋值给rb。并在process方法中将结果写入response成员。\n\n如FacetComponent的prepare方法：\n\n``` java\npublic void prepare(ResponseBuilder rb) throws IOException {\n  if (rb.req .getParams().getBool(FacetParams.FACET, false)) {\n    rb.setNeedDocSet( true);\n    rb. doFacets = true ;\n  }\n}\n```\n\n\n### 3、Query\n\nLucene提供了多种多样的Query的实现，大多数都在org.apache.lucene.search包下面，这些Query结合起来可以实现非常复杂的查询。Query类有MatchAllDocsQuery、BooleanQuery、TermQuery等，系统通过QueryParser就会将查询解析为一个Query。如\"*:*\"就会解析成MatchAllDocsQuery，\"queryStr1 OR queryStr2\"就会解析成一个BooleanQuery等。\n\nQuery是大多数场景的开始，如果没有Query的话，系统就无法查询文档更别说进行打分（Score）。Query是Scorer的催化剂，并且负责创建和协调它，而Weight则提供了一个Query的中间形态，任何Searcher的依赖状态都必须存放在Weight对象中，而不是Query对象，所以大多数Query的实现类都需要提供一个Weight的实现。\n\nQuery的深入剖析好像是需要对Solr、Lucene有一个专家级的理解了，初学者的我就不多言了。\n\n可参考文档：\n\n* [Apache Lucene - Scoring](http://lucene.apache.org/core/3_6_2/scoring.html)\n* [Package - org.apache.lucene.search - query](http://lucene.apache.org/core/3_6_2/api/core/org/apache/lucene/search/package-summary.html#query)\n* [Lucene打分机制和Similarity模块](http://my.oschina.net/BreathL/blog/51498)\n\n### 4、结尾\n\n以上包括上一篇博文我都只能粗略的理解一些，并不能深入详细的理解及运用，需要在后期的学习及实践的过程中继续深入了。\n","slug":"apache-solr-data-structrue-part-2","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg625600avsb8fjjtw08gd"},{"title":"Apache Solr —— 常用数据结构（一）","date":"2013-04-08T10:04:00.000Z","_content":"\n### 1、前言\n\n这一段时间看Solr源码，主要的心思都是放在了整体框架运行流程，或者称之为“算法”。这些流程中间会穿插很多有意思的接口/类，NamedList、DocSet、DocIdSet、Query、Document、FieldType、ResponseBuilder等，这些接口/类看似简单，但是里面又有各种不同的实现，在翻源码的时候，确实会让人有些招架不过来，所以就准备写这篇博文让自己梳理梳理Solr的常用“数据结构”，有了算法和数据结构才能对Solr有一个完整的理解。\n\n<!--more-->\n\n### 2、NamedList\n\n一个简单的键值对列表，与Map不同的是：\n\n* 键名可以重复；\n* 保持数据的插入顺序；\n* 元素可以通过下标访问；\n* 键与值均可为null。\n\n内部实现其实也挺简单，内部容器采用的是ArrayList。list中的内部数据格式为：\n\n* [key1, value1, key2, value2, key3, value3,...]\n\n键与值通过线性排列组合在一起，访问下标则为：\n\n* key = list.get(idx << 1);\n* value = list.get((idx << 1) +1);\n\n如需要通过键查询的话，则是遍历list中的所有元素，时间复杂为O(N)。因为设计该类主要是用来实现有序的键值对序列，通过键查询的需求较少。如果需要经常查询的话，可以用SimpleOrderedMap或者直接用Map。\n\n需要说明的是，我并没有看出SimpleOrderedMap有啥名堂，内部实现只是实现了几个构造函数（全部调用super()），和一个clone()。并无其他逻辑。\n\nNamedList主要用来保存各种结果或者参数，变量名常见于res、params、terms。\n\n### 3、DocSet\n\n<center><div style=\"width: 80%;\">![DocSet](/images/sofa-DocSet.png)</div></center>\n\n这DocSet、DocList接口是DocSet数据结构的基础，一般来说DocSet就是用来保存DocId的集合，提供了一些集合的逻辑运算，如：union、intersection、addNot等。\n\n* DocSet是一个无序的Lucene Document Id的集合。\n* DocList是一个有序的Lucene Document Id的列表，这里的有序（ordered）应该不是指的排序（sorted），而是docs是顺序有关的，不可随意打乱，因为这个顺序关联一个可选的scores成员。\n\n在DocSet基础上，Solr提供了一个抽象类DocSetBase，DocSet系列中所有的派生类均继承了该方法。该抽象类实现了一些方法，这些方法主要是提供给无该方法实现的子类。如DocSlice，该类就没有实现union方法。\n\nDocSlice就是DocList的实现，好像没有啥特别的地方。由于实现DocList的原因，DocSlice也不建议被修改，它提供了一个subset的方法，可获得其子集。\n\nHashDocSet用的Hash表方法存的docIds，在数据比较少的时候好像比较省内存（但是除了测试代码之外，Solr内部没看到有实际逻辑代码使用了该类- -）\n\nSortedIntDocSet是排序的DocSet，在构造SortedIntDocSet的时候，就已经传入了一个排序好的docs。\n\nBitDocSet是用的位图存放docIds，集合的逻辑运算实现用的lucene的OpenBitSet，这个类也是Solr用的最多的DocSet了。位图的一些知识可以参考我的博文：[《趣味数据结构 - Bitmap》](http://hongweiyi.com/2012/03/data-structure-bitmap/)\n\n> BTW：还有一个DocIdSet，我就觉得稀奇了！DocSet也是放Document Id的，DocIdSet也是放Document Id的。而DocIdSet不直接提供存放Id的容器，只提供了一个迭代器的功能，这样的设计暂时没有弄明白是为什么，先放着吧。\n\n### 4、结尾\n\n今天就只分析NamedList和DocSet了，剩下的等清明小长假后再分析吧，下午出去旅游一下了……\n","source":"_posts/apache-solr-data-structrue-part-1.md","raw":"title: Apache Solr —— 常用数据结构（一）\ndate: 2013-04-08 18:04:00\ncategories: 技术分享\ntags: Solr, 数据结构\n---\n\n### 1、前言\n\n这一段时间看Solr源码，主要的心思都是放在了整体框架运行流程，或者称之为“算法”。这些流程中间会穿插很多有意思的接口/类，NamedList、DocSet、DocIdSet、Query、Document、FieldType、ResponseBuilder等，这些接口/类看似简单，但是里面又有各种不同的实现，在翻源码的时候，确实会让人有些招架不过来，所以就准备写这篇博文让自己梳理梳理Solr的常用“数据结构”，有了算法和数据结构才能对Solr有一个完整的理解。\n\n<!--more-->\n\n### 2、NamedList\n\n一个简单的键值对列表，与Map不同的是：\n\n* 键名可以重复；\n* 保持数据的插入顺序；\n* 元素可以通过下标访问；\n* 键与值均可为null。\n\n内部实现其实也挺简单，内部容器采用的是ArrayList。list中的内部数据格式为：\n\n* [key1, value1, key2, value2, key3, value3,...]\n\n键与值通过线性排列组合在一起，访问下标则为：\n\n* key = list.get(idx << 1);\n* value = list.get((idx << 1) +1);\n\n如需要通过键查询的话，则是遍历list中的所有元素，时间复杂为O(N)。因为设计该类主要是用来实现有序的键值对序列，通过键查询的需求较少。如果需要经常查询的话，可以用SimpleOrderedMap或者直接用Map。\n\n需要说明的是，我并没有看出SimpleOrderedMap有啥名堂，内部实现只是实现了几个构造函数（全部调用super()），和一个clone()。并无其他逻辑。\n\nNamedList主要用来保存各种结果或者参数，变量名常见于res、params、terms。\n\n### 3、DocSet\n\n<center><div style=\"width: 80%;\">![DocSet](/images/sofa-DocSet.png)</div></center>\n\n这DocSet、DocList接口是DocSet数据结构的基础，一般来说DocSet就是用来保存DocId的集合，提供了一些集合的逻辑运算，如：union、intersection、addNot等。\n\n* DocSet是一个无序的Lucene Document Id的集合。\n* DocList是一个有序的Lucene Document Id的列表，这里的有序（ordered）应该不是指的排序（sorted），而是docs是顺序有关的，不可随意打乱，因为这个顺序关联一个可选的scores成员。\n\n在DocSet基础上，Solr提供了一个抽象类DocSetBase，DocSet系列中所有的派生类均继承了该方法。该抽象类实现了一些方法，这些方法主要是提供给无该方法实现的子类。如DocSlice，该类就没有实现union方法。\n\nDocSlice就是DocList的实现，好像没有啥特别的地方。由于实现DocList的原因，DocSlice也不建议被修改，它提供了一个subset的方法，可获得其子集。\n\nHashDocSet用的Hash表方法存的docIds，在数据比较少的时候好像比较省内存（但是除了测试代码之外，Solr内部没看到有实际逻辑代码使用了该类- -）\n\nSortedIntDocSet是排序的DocSet，在构造SortedIntDocSet的时候，就已经传入了一个排序好的docs。\n\nBitDocSet是用的位图存放docIds，集合的逻辑运算实现用的lucene的OpenBitSet，这个类也是Solr用的最多的DocSet了。位图的一些知识可以参考我的博文：[《趣味数据结构 - Bitmap》](http://hongweiyi.com/2012/03/data-structure-bitmap/)\n\n> BTW：还有一个DocIdSet，我就觉得稀奇了！DocSet也是放Document Id的，DocIdSet也是放Document Id的。而DocIdSet不直接提供存放Id的容器，只提供了一个迭代器的功能，这样的设计暂时没有弄明白是为什么，先放着吧。\n\n### 4、结尾\n\n今天就只分析NamedList和DocSet了，剩下的等清明小长假后再分析吧，下午出去旅游一下了……\n","slug":"apache-solr-data-structrue-part-1","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg625800azsb8fp6nr0ky5"},{"title":"Apache Hadoop YARN - 背景及概述","id":"578","date":"2012-09-06T14:41:59.000Z","_content":"\n虽然yahoo!关于YARN作为下一代（Next-gen）MapReduce框架的文章（[点这里](http://developer.yahoo.com/blogs/hadoop/posts/2011/02/mapreduce-nextgen/)）去年就看过了，但是那个看到是“下一代”，竟然以为只是一个设想，没想到早就发布了版本，导致对于Hadoop的认识还停留在0.20×版本上，真是罪过罪过。由于最近比较忙，闲暇时间扫了扫国内外博客，发现0.23、1.×，以及最近发布的2.×，hadoop的变化非常之大。比如说HDFS Federation（联邦）支持多NameNode并存，也有HA的BackupNode，想多了解的可以看[这里](http://ai-longyu.iteye.com/blog/1566619)以及[官方文档](http://hadoop.apache.org/common/docs/r0.23.0/hadoop-yarn/hadoop-yarn-site/Federation.html)。最大的莫过于计算框架了，MapReduce进入了2.0时代，MR2.0或者叫YARN（其实YARN和MapReduce没什么关系了），这篇博客就简要的说说Apache Hadoop MapReduce的前世今生吧。主要是翻译了这篇博客：[地址](http://hortonworks.com/blog/apache-hadoop-yarn-background-and-an-overview/)，也加上了自己的一些见解，后续再继续添加对YARN的认识。\n<!--more-->\n\n**Apache Hadoop MapReduce**\n\nApache Hadoop MapReduce是一个Google MapReduce编程模型的开源版本，由Apache基金会维护。现在，已经有人花了超过6年的时间在Hadoop上。但是，基本上MapReduce基本上可以分为三个主要部分：\n  > 1\\. **MapReduce API：**提供给终端用户（程序猿）开发MR程序的接口；\n> \n> 2\\. **MapReduce 框架：**MR各个过程（phrase）的实现，如：map phrase、reduce phrase、sort/shuffle/merge phrase等；\n> \n> 3\\. **MapReduce 系统：**运行用户MR程序的后端基础设施，用以管理资源、调度任务等。  \n\n将MR分成以上三个概念非常的重要，特别是对终端用户，他们可以完全专注于MR逻辑代码的编写，只需要通过API既可，由MR系统来解决资源管理、容错、调度的问题，而不需要用户考虑后端框架和系统的细节。\n\n现在工业界大部分还是用的0.23之前的版本（至少我待的公司还是0.20.2），老版本的MapReduce系统是简易的Master-Slaves结构，具体名字叫JobTracker-TaskTracker。\n\nJobTracker负责资源的管理（结点资源、计算资源等）以及任务生命周期管理（任务调度、进度查看、容错等）。而TaskTracker职责非常简单，开启/销毁任务，向JobTracker汇报任务状态。\n\n旧版的架构其实挺清晰的，不过也有很多不足的地方，业界一直嚷着要给MR一次大整修（Overhaul），JobTracker的可靠性是一直被诟病的一点（虽然我没见它挂过，但是风险一直存在着），但是除了JobTracker的单点问题，其它的问题也需要一一列出来。\n\n**不支持其它编程模型**\n\nMapReduce对大多数应用（尤其是大数据统计分析）来说，都非常合适。但是有的时候，可能现实生活也有其它的编程模型，如图算法([Google Pregel](http://www.csdn.net/article/2012-08-20/2808870)/[Apache Giapah](http://giraph.apache.org/))或者是迭代式模型([MPI](http://en.wikipedia.org/wiki/Message_Passing_Interface))。当企业的所有数据在放在了HDFS上，有多种处理数据的方式就很重要了。\n\n而且，MR本质上是面向批处理的，并不支持实时或接近实时的处理请求，但是业界也希望Hadoop能支持实时计算。（我也一直希望可以支持实时计算，但是有时候觉得有点贪心，专注做一项不就好了么？但是好像人的贪欲是无穷的）\n\n有了以上的需求，为了降低了管理者使用成本，减少数据在HDFS和其它存储设备的迁移，Hadoop开发组织重新投入了Hadoop设计。\n\n**低可扩展性**\n\n摩尔定律一直在生效，也让商用服务器的性能一直提高，以下就是一台商用服务器在不同时间的配置：\n\n2009 - 8 cores, 16GB of RAM, 4*1TB disk\n\n2012 - 16+ cores, 48-96GB of RAM, 12*2TB or 12*3TB of disk\n\n按照上面的配置，大约2-3年，服务器的配置就可以翻翻。而现在的Hadoop集群就只能支持10,000个节点和200,000个核。Hadoop软件需要赶上硬件的速度是非常重要的。顺带说句，我们公司的计算型服务器就是16cores 64GB of RAM。\n\n**服务器的低利用率**\n\n在现在的系统中，JobTracker将管理集群视为很多的Map/Reduce槽（slot），然而在MR用运行的时候，大多数时候都是reduce槽在等待map槽完成（map 100% reduce 0%）。如果能优化这个的话，服务器就可以得到最大的利用。\n\n**使用的灵活性**\n\n在现实生产环境中，Hadoop常常被部署成一个共享的、多用户的系统。这样就会导致一种情况，完全Hadoop软件可能会影响到整个部门。用户希望能够控制hadoop软件栈升级，因此，允许多版本的MapReduce框架并存对Hadoop来说就是很重要的了。\n\n**Apache Hadoop YARN**\n\nYARN的基本思想是将JobTracker的两个主要职责给解耦：资源管理和任务管理（监控/调度），YARN将其分成了两个部分：全局的ResourceManager(RM)和给每个应用分配的ApplicationMaster(AM)。ResourceManager和它每个节点的slave——NodeManager(NM)，形成了一个全新的、用以管理应用的分布式系统。\n\nRM是系统资源的终极管理者，而AM则是一个特定应用框架的实体（每次提交任务的时候，需要编写相应的应用框架，现在只支持MapReduce），需要与RM索要应用资源，和NM一起执行和监控任务。\n\nRM中有调度器，而调度器内嵌有策略可插拔的插件，主要负责将集群中得资源分配给多个队列和应用。当前MapReduce的调度器，如Capacity Scheduler和Fair Scheduler，均可作为该插件。但是调度器的职责仅限于调度任务，并不保证任务的容错性。\n\nNodeManager有点类似于TaskTracker，它负责启动应用程序Container（类似于JVM），并监控container的资源（CPU、内存、磁盘、网络等），并将信息上报给ResouceManager。需要注意的是，调度器就是根据应用程序的Container进行调度的。\n\nApplicationMaster负责向调度器请求合适的container，并监控container的状态以及任务进程。\n\n下图是YARN的架构图：\n\n[![YARNArch](http://www.hongweiyi.com/wp-content/uploads/2012/09/YARNArch_thumb.png \"YARNArch\")](http://www.hongweiyi.com/wp-content/uploads/2012/09/YARNArch.png)\n\n新YARN系统比较重要的一条就是复用了原有的MapReduce框架，而并不需要大的改动，这对现有的MR应用以及用户来说，是非常重要的，具体是怎么复用的，以后再细说。\n\n接下来，Hadoop开发者会深入架构细节，继续提高系统的可扩展性，并让其支持更多的数据处理框架（graph, MPI）并提高集群可用性。\n\n以Hortonworks' Arun Murthy（YARN开发者）的一段话做结尾吧：\n  > “People are not going to be comfortable buying a $5 million Hadoop cluster just to do MapReduce and a $2 million cluster to do something else. If you can allow them to run both apps in the same cluster, its not only easier for you in terms of a CapEx perspective … it’s also easier from an operational perspective because you don’t have to have two separate sets of people managing your clusters or two sets of tools for managing your clusters.”","source":"_posts/apache-hadoop-yarn-background-and-an-overview.md","raw":"title: Apache Hadoop YARN - 背景及概述\ntags:\n  - Hadoop\n  - MapReduce\n  - YARN\nid: 578\ncategories:\n  - 技术分享\ndate: 2012-09-06 22:41:59\n---\n\n虽然yahoo!关于YARN作为下一代（Next-gen）MapReduce框架的文章（[点这里](http://developer.yahoo.com/blogs/hadoop/posts/2011/02/mapreduce-nextgen/)）去年就看过了，但是那个看到是“下一代”，竟然以为只是一个设想，没想到早就发布了版本，导致对于Hadoop的认识还停留在0.20×版本上，真是罪过罪过。由于最近比较忙，闲暇时间扫了扫国内外博客，发现0.23、1.×，以及最近发布的2.×，hadoop的变化非常之大。比如说HDFS Federation（联邦）支持多NameNode并存，也有HA的BackupNode，想多了解的可以看[这里](http://ai-longyu.iteye.com/blog/1566619)以及[官方文档](http://hadoop.apache.org/common/docs/r0.23.0/hadoop-yarn/hadoop-yarn-site/Federation.html)。最大的莫过于计算框架了，MapReduce进入了2.0时代，MR2.0或者叫YARN（其实YARN和MapReduce没什么关系了），这篇博客就简要的说说Apache Hadoop MapReduce的前世今生吧。主要是翻译了这篇博客：[地址](http://hortonworks.com/blog/apache-hadoop-yarn-background-and-an-overview/)，也加上了自己的一些见解，后续再继续添加对YARN的认识。\n<!--more-->\n\n**Apache Hadoop MapReduce**\n\nApache Hadoop MapReduce是一个Google MapReduce编程模型的开源版本，由Apache基金会维护。现在，已经有人花了超过6年的时间在Hadoop上。但是，基本上MapReduce基本上可以分为三个主要部分：\n  > 1\\. **MapReduce API：**提供给终端用户（程序猿）开发MR程序的接口；\n> \n> 2\\. **MapReduce 框架：**MR各个过程（phrase）的实现，如：map phrase、reduce phrase、sort/shuffle/merge phrase等；\n> \n> 3\\. **MapReduce 系统：**运行用户MR程序的后端基础设施，用以管理资源、调度任务等。  \n\n将MR分成以上三个概念非常的重要，特别是对终端用户，他们可以完全专注于MR逻辑代码的编写，只需要通过API既可，由MR系统来解决资源管理、容错、调度的问题，而不需要用户考虑后端框架和系统的细节。\n\n现在工业界大部分还是用的0.23之前的版本（至少我待的公司还是0.20.2），老版本的MapReduce系统是简易的Master-Slaves结构，具体名字叫JobTracker-TaskTracker。\n\nJobTracker负责资源的管理（结点资源、计算资源等）以及任务生命周期管理（任务调度、进度查看、容错等）。而TaskTracker职责非常简单，开启/销毁任务，向JobTracker汇报任务状态。\n\n旧版的架构其实挺清晰的，不过也有很多不足的地方，业界一直嚷着要给MR一次大整修（Overhaul），JobTracker的可靠性是一直被诟病的一点（虽然我没见它挂过，但是风险一直存在着），但是除了JobTracker的单点问题，其它的问题也需要一一列出来。\n\n**不支持其它编程模型**\n\nMapReduce对大多数应用（尤其是大数据统计分析）来说，都非常合适。但是有的时候，可能现实生活也有其它的编程模型，如图算法([Google Pregel](http://www.csdn.net/article/2012-08-20/2808870)/[Apache Giapah](http://giraph.apache.org/))或者是迭代式模型([MPI](http://en.wikipedia.org/wiki/Message_Passing_Interface))。当企业的所有数据在放在了HDFS上，有多种处理数据的方式就很重要了。\n\n而且，MR本质上是面向批处理的，并不支持实时或接近实时的处理请求，但是业界也希望Hadoop能支持实时计算。（我也一直希望可以支持实时计算，但是有时候觉得有点贪心，专注做一项不就好了么？但是好像人的贪欲是无穷的）\n\n有了以上的需求，为了降低了管理者使用成本，减少数据在HDFS和其它存储设备的迁移，Hadoop开发组织重新投入了Hadoop设计。\n\n**低可扩展性**\n\n摩尔定律一直在生效，也让商用服务器的性能一直提高，以下就是一台商用服务器在不同时间的配置：\n\n2009 - 8 cores, 16GB of RAM, 4*1TB disk\n\n2012 - 16+ cores, 48-96GB of RAM, 12*2TB or 12*3TB of disk\n\n按照上面的配置，大约2-3年，服务器的配置就可以翻翻。而现在的Hadoop集群就只能支持10,000个节点和200,000个核。Hadoop软件需要赶上硬件的速度是非常重要的。顺带说句，我们公司的计算型服务器就是16cores 64GB of RAM。\n\n**服务器的低利用率**\n\n在现在的系统中，JobTracker将管理集群视为很多的Map/Reduce槽（slot），然而在MR用运行的时候，大多数时候都是reduce槽在等待map槽完成（map 100% reduce 0%）。如果能优化这个的话，服务器就可以得到最大的利用。\n\n**使用的灵活性**\n\n在现实生产环境中，Hadoop常常被部署成一个共享的、多用户的系统。这样就会导致一种情况，完全Hadoop软件可能会影响到整个部门。用户希望能够控制hadoop软件栈升级，因此，允许多版本的MapReduce框架并存对Hadoop来说就是很重要的了。\n\n**Apache Hadoop YARN**\n\nYARN的基本思想是将JobTracker的两个主要职责给解耦：资源管理和任务管理（监控/调度），YARN将其分成了两个部分：全局的ResourceManager(RM)和给每个应用分配的ApplicationMaster(AM)。ResourceManager和它每个节点的slave——NodeManager(NM)，形成了一个全新的、用以管理应用的分布式系统。\n\nRM是系统资源的终极管理者，而AM则是一个特定应用框架的实体（每次提交任务的时候，需要编写相应的应用框架，现在只支持MapReduce），需要与RM索要应用资源，和NM一起执行和监控任务。\n\nRM中有调度器，而调度器内嵌有策略可插拔的插件，主要负责将集群中得资源分配给多个队列和应用。当前MapReduce的调度器，如Capacity Scheduler和Fair Scheduler，均可作为该插件。但是调度器的职责仅限于调度任务，并不保证任务的容错性。\n\nNodeManager有点类似于TaskTracker，它负责启动应用程序Container（类似于JVM），并监控container的资源（CPU、内存、磁盘、网络等），并将信息上报给ResouceManager。需要注意的是，调度器就是根据应用程序的Container进行调度的。\n\nApplicationMaster负责向调度器请求合适的container，并监控container的状态以及任务进程。\n\n下图是YARN的架构图：\n\n[![YARNArch](http://www.hongweiyi.com/wp-content/uploads/2012/09/YARNArch_thumb.png \"YARNArch\")](http://www.hongweiyi.com/wp-content/uploads/2012/09/YARNArch.png)\n\n新YARN系统比较重要的一条就是复用了原有的MapReduce框架，而并不需要大的改动，这对现有的MR应用以及用户来说，是非常重要的，具体是怎么复用的，以后再细说。\n\n接下来，Hadoop开发者会深入架构细节，继续提高系统的可扩展性，并让其支持更多的数据处理框架（graph, MPI）并提高集群可用性。\n\n以Hortonworks' Arun Murthy（YARN开发者）的一段话做结尾吧：\n  > “People are not going to be comfortable buying a $5 million Hadoop cluster just to do MapReduce and a $2 million cluster to do something else. If you can allow them to run both apps in the same cluster, its not only easier for you in terms of a CapEx perspective … it’s also easier from an operational perspective because you don’t have to have two separate sets of people managing your clusters or two sets of tools for managing your clusters.”","slug":"apache-hadoop-yarn-background-and-an-overview","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg625900b2sb8f1quxtx2h"},{"title":"Android UI学习笔记","id":"145","date":"2011-07-21T10:57:24.000Z","_content":"\n**1\\. UI****设计**\n\n自学Android也有一段时间了，自我感觉良好。于是乎反编译了一些UI界面不错的APK学习一下。为了做对比，反编译了一个中文应用一个英文应用，不知是师出同门，还是业界标准，这两个APK的UI资源文件格式惊人的相似，现将res结构贴出来：\n\n[![](http://www.hongweiyi.com/wp-content/uploads/2011/07/Android-Res1.png \"Android Res2\")](http://www.hongweiyi.com/wp-content/uploads/2011/07/Android-Res1.png)\n\n<!--more-->这与我们在书本、网络、视频教程看到不一样的是，它将类型一致的常量分离出来，如colors、dimens。同时，它也将样式（styles）给分离出来，主窗体中只留下了界面组件的结构，如同写html+css一样……\n\n将colors、dimens、styles给分离出来的好处显而易见，它能使UI设计的结构更为清晰，组织更为方便。现在给一个例子，让我们更为理性的了解一下这种模式的好处……\n> &lt;!-- layout/main.xml 定义一个TextView --&gt;\r> \n> \n> &lt;TextView style=_\"@style/StyleTest\"_ /&gt;\r> \n> \n> &lt;!-- values/styles.xml 定义一个_StyleTest_ --&gt;\r> \n> \n> &lt;resources&gt;\r> \n> \n> &lt;style name=_\"StyleTest\"_&gt;\r> \n> \n> &lt;item name=_\"android:id\"_&gt;@+id/text&lt;/item&gt;\r> \n> \n> &lt;item name=_\"android:textSize\"_&gt;@dimen/text_medium&lt;/item&gt;\r> \n> \n> &lt;item name=_\"android:textStyle\"_&gt;bold&lt;/item&gt;\r> \n> \n> &lt;item name=_\"android:textColor\"_&gt;@color/title_text&lt;/item&gt;\r> \n> \n> &lt;item name=_\"android:ellipsize\"_&gt;end&lt;/item&gt;\r> \n> \n> &lt;item name=_\"android:gravity\"_&gt;center_vertical&lt;/item&gt;\r> \n> \n> &lt;item name=_\"android:layout_width\"_&gt;@dimen/text_width&lt;/item&gt;\r> \n> \n> &lt;item name=_\"android:layout_height\"_&gt;fill_parent&lt;/item&gt;\r> \n> \n> &lt;item name=_\"android:singleLine\"_&gt;true&lt;/item&gt;\r> \n> \n> &lt;/style&gt;\r> \n> \n> &lt;/resources&gt;\r> \n> \n> &lt;!-- values/dimens.xml 定义一个text_medium text_width --&gt;\r> \n> \n> &lt;resources&gt;\r> \n> \n> &lt;dimen name=_\"text_medium\"_&gt;14.0dip&lt;/dimen&gt;\r> \n> \n> &lt;dimen name=_\"text_width\"_&gt;40.0dip&lt;/dimen&gt;\r> \n> \n> &lt;/resources&gt;\r> \n> \n> &lt;!-- values/colors.xml 定义一个text_color --&gt;\r> \n> \n> &lt;resources&gt;\r> \n> \n> &lt;color name=_\"text_color\"_&gt;#000&lt;/color&gt;\r> \n> \n> &lt;/resources&gt;\n将相同类型的常量分离出来后，方便开发者统一组织与管理，如统一将字号变大，统一将字体颜色修改等……将样式分离出来的好处，相信做过web开发的朋友应该能很好的理解，开发者将应用UI整体结构打好之后，剩下的工作就是一个一个给其赋属性（style）了，同时还可以方便的替换多种样式。\n\n需要强调的一点就是，android的UI设计也支持include，这个也是今天才知道的，格式如下：\n\n&lt;include layout=_\"@layout/title_bar\" _/&gt;\n\n**2\\. ****监听器模式**\n\n在学习的时候，大部分教程写UI事件监听器都是一个这样的方式，先findViewByID(ID)；再setOnXXXListener(new OnXXXListener({ methods}))。个人不是很喜欢这样的方式，繁琐而且代码不清晰，于是乎便建立了很多很多的XXXListener.java类，管理起来更累。周爱名前辈写的《大道至简》中说到：“是懒人造就了方法。”于是乎我就在组件属性中发现了一个很熟悉的名词：OnClick，让我很是开心。这个和javaScript类似，开发者只需要在相应的Activity中加上相应的方法即可。如：\n> &lt;!-- layout/XXX.xml 定义一个Button --&gt;\r> \n> \n> &lt;Button …\r> \n> \n> android:onClick=_\"onButtonClicked\"_\r> \n> \n> …/&gt;\r> \n> \n> // Button点击事件\r> \n> \n> public void onButtonClicked(View view){\r> \n> \n> …\r> \n> \n> }\n是不是简单得多？方便得多？清晰得多？\n\n**3\\. ****其它问题**\n\n**3.1 Tab****修改样式**\n\n不管哪种语言，Tab组件一定是最麻烦的！比如我在xml中定义它的时候，需要一个TabHost，一个TabWidget，一个FrameLayout，这还不算什么，最令人觉得怪异的是，它都没有定义字体的属性，无奈只能通过代码修改，但代码的修改方式同样很诡异……\n> **public** **void** setTabStyle(TabHost **tabHost**) {\r> \n> \n> // 还得向上转型，将TabWidget转成View才能修改！！！\r> \n> \n> ** for**(**int** **i** = 0; **i**&lt; **tabHost**.getTabWidget().getChildCount();**i**++){\r> \n> \n> View **view** = **tabHost**.getTabWidget().getChildTabViewAt(**i**);\r> \n> \n> ** view**.setXXX();\r> \n> \n> // 标题栏\r> \n> \n> TextView **tv** = (TextView) **view**.findViewById(android.R.id._title_);\r> \n> \n> ** tv**.setXXX();\r> \n> \n> }\r> \n> \n> }\n不知是自己功力不够，还是本来就是这么麻烦，现在只能认了……不知你有没有好的方法？\n\n**3.2 DatePickerDialog**\n\n我用DatePickerDialog时，返回的月份（monthOfYear）是从0开始算起，查了一下SDK，它的解释是：monthOfYear The month that was set (0-11) for compatibility with Calendar. 以后用得注意一下……","source":"_posts/android-ui.md","raw":"title: Android UI学习笔记\ntags:\n  - Android\nid: 145\ncategories:\n  - 技术分享\ndate: 2011-07-21 18:57:24\n---\n\n**1\\. UI****设计**\n\n自学Android也有一段时间了，自我感觉良好。于是乎反编译了一些UI界面不错的APK学习一下。为了做对比，反编译了一个中文应用一个英文应用，不知是师出同门，还是业界标准，这两个APK的UI资源文件格式惊人的相似，现将res结构贴出来：\n\n[![](http://www.hongweiyi.com/wp-content/uploads/2011/07/Android-Res1.png \"Android Res2\")](http://www.hongweiyi.com/wp-content/uploads/2011/07/Android-Res1.png)\n\n<!--more-->这与我们在书本、网络、视频教程看到不一样的是，它将类型一致的常量分离出来，如colors、dimens。同时，它也将样式（styles）给分离出来，主窗体中只留下了界面组件的结构，如同写html+css一样……\n\n将colors、dimens、styles给分离出来的好处显而易见，它能使UI设计的结构更为清晰，组织更为方便。现在给一个例子，让我们更为理性的了解一下这种模式的好处……\n> &lt;!-- layout/main.xml 定义一个TextView --&gt;\r> \n> \n> &lt;TextView style=_\"@style/StyleTest\"_ /&gt;\r> \n> \n> &lt;!-- values/styles.xml 定义一个_StyleTest_ --&gt;\r> \n> \n> &lt;resources&gt;\r> \n> \n> &lt;style name=_\"StyleTest\"_&gt;\r> \n> \n> &lt;item name=_\"android:id\"_&gt;@+id/text&lt;/item&gt;\r> \n> \n> &lt;item name=_\"android:textSize\"_&gt;@dimen/text_medium&lt;/item&gt;\r> \n> \n> &lt;item name=_\"android:textStyle\"_&gt;bold&lt;/item&gt;\r> \n> \n> &lt;item name=_\"android:textColor\"_&gt;@color/title_text&lt;/item&gt;\r> \n> \n> &lt;item name=_\"android:ellipsize\"_&gt;end&lt;/item&gt;\r> \n> \n> &lt;item name=_\"android:gravity\"_&gt;center_vertical&lt;/item&gt;\r> \n> \n> &lt;item name=_\"android:layout_width\"_&gt;@dimen/text_width&lt;/item&gt;\r> \n> \n> &lt;item name=_\"android:layout_height\"_&gt;fill_parent&lt;/item&gt;\r> \n> \n> &lt;item name=_\"android:singleLine\"_&gt;true&lt;/item&gt;\r> \n> \n> &lt;/style&gt;\r> \n> \n> &lt;/resources&gt;\r> \n> \n> &lt;!-- values/dimens.xml 定义一个text_medium text_width --&gt;\r> \n> \n> &lt;resources&gt;\r> \n> \n> &lt;dimen name=_\"text_medium\"_&gt;14.0dip&lt;/dimen&gt;\r> \n> \n> &lt;dimen name=_\"text_width\"_&gt;40.0dip&lt;/dimen&gt;\r> \n> \n> &lt;/resources&gt;\r> \n> \n> &lt;!-- values/colors.xml 定义一个text_color --&gt;\r> \n> \n> &lt;resources&gt;\r> \n> \n> &lt;color name=_\"text_color\"_&gt;#000&lt;/color&gt;\r> \n> \n> &lt;/resources&gt;\n将相同类型的常量分离出来后，方便开发者统一组织与管理，如统一将字号变大，统一将字体颜色修改等……将样式分离出来的好处，相信做过web开发的朋友应该能很好的理解，开发者将应用UI整体结构打好之后，剩下的工作就是一个一个给其赋属性（style）了，同时还可以方便的替换多种样式。\n\n需要强调的一点就是，android的UI设计也支持include，这个也是今天才知道的，格式如下：\n\n&lt;include layout=_\"@layout/title_bar\" _/&gt;\n\n**2\\. ****监听器模式**\n\n在学习的时候，大部分教程写UI事件监听器都是一个这样的方式，先findViewByID(ID)；再setOnXXXListener(new OnXXXListener({ methods}))。个人不是很喜欢这样的方式，繁琐而且代码不清晰，于是乎便建立了很多很多的XXXListener.java类，管理起来更累。周爱名前辈写的《大道至简》中说到：“是懒人造就了方法。”于是乎我就在组件属性中发现了一个很熟悉的名词：OnClick，让我很是开心。这个和javaScript类似，开发者只需要在相应的Activity中加上相应的方法即可。如：\n> &lt;!-- layout/XXX.xml 定义一个Button --&gt;\r> \n> \n> &lt;Button …\r> \n> \n> android:onClick=_\"onButtonClicked\"_\r> \n> \n> …/&gt;\r> \n> \n> // Button点击事件\r> \n> \n> public void onButtonClicked(View view){\r> \n> \n> …\r> \n> \n> }\n是不是简单得多？方便得多？清晰得多？\n\n**3\\. ****其它问题**\n\n**3.1 Tab****修改样式**\n\n不管哪种语言，Tab组件一定是最麻烦的！比如我在xml中定义它的时候，需要一个TabHost，一个TabWidget，一个FrameLayout，这还不算什么，最令人觉得怪异的是，它都没有定义字体的属性，无奈只能通过代码修改，但代码的修改方式同样很诡异……\n> **public** **void** setTabStyle(TabHost **tabHost**) {\r> \n> \n> // 还得向上转型，将TabWidget转成View才能修改！！！\r> \n> \n> ** for**(**int** **i** = 0; **i**&lt; **tabHost**.getTabWidget().getChildCount();**i**++){\r> \n> \n> View **view** = **tabHost**.getTabWidget().getChildTabViewAt(**i**);\r> \n> \n> ** view**.setXXX();\r> \n> \n> // 标题栏\r> \n> \n> TextView **tv** = (TextView) **view**.findViewById(android.R.id._title_);\r> \n> \n> ** tv**.setXXX();\r> \n> \n> }\r> \n> \n> }\n不知是自己功力不够，还是本来就是这么麻烦，现在只能认了……不知你有没有好的方法？\n\n**3.2 DatePickerDialog**\n\n我用DatePickerDialog时，返回的月份（monthOfYear）是从0开始算起，查了一下SDK，它的解释是：monthOfYear The month that was set (0-11) for compatibility with Calendar. 以后用得注意一下……","slug":"android-ui","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg625b00b8sb8f93zvfmtb"},{"title":"算法设计 - 回溯法到搜索浅谈","id":"331","date":"2012-02-21T16:56:00.000Z","_content":"\n**一、定义说明**\n\n\t回溯法是一个即带有系统性又带有跳跃性的搜索算法，它在问题的解空间树中，按深度优先搜索策略，从根结点出发搜索解空间树。算法搜索至解空间树的任一结点时，先判断该结点是否包含问题的解。如果肯定不包含，则跳过对该结点为根的子树的搜索，逐层向其祖先结点回溯；否则，进入该子树，继续按深度优先策略搜索。\n\n\t<!--more-->\n\n\t回溯法是设计递归过程的一种重要方法，它的求解过程实质上是一个先序遍历一颗&ldquo;状态树&rdquo;的过程，只是这一棵树不是遍历前预先建立的，而是隐含在遍历过程中。\n\n\t**二、简单示例**\n\n\t经典回溯的例子是求n个元素的幂集，幂集简单点说就是n个元素的全组合再加上空集，它的解空间树（状态树）如下：\n\n\t[![clip_image002](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image002_thumb2.jpg \"clip_image002\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0022.jpg)\n\n\t上面的树是一颗满二叉树，树中每个结点的状态都是求解过程中可能出现的状态（即解）。递归过程可以简单理解为对n个元素的0、1取舍，伪代码如下：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"568\">\n\n\t\t\t\t\tdef powerset(i : int):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; if i &gt; n Then: print\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; else:\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 取第i个元素（1）; powerset(i+1);\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 舍第i个元素（0）; powerset(i+1);\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t&nbsp;\n\n\t**三、问题说明**\n\n\t很多问题用回溯法求解时，描述过程的树不是一颗满二叉树，这类问题在求解之前需要确定问题的约束函数：&ldquo;约束函数是根据题意定出的，通过描述合法解的一般特征用于去除不合法的解（剪支），从而避免继续搜索出这个不合法解的剩余部分。因此，约束函数是对于任何状态空间树上的节点都有效、等价的。&rdquo;\n\n\t以四皇后问题为例，剪支后的状态树如下：\n\n\t[![clip_image004](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image004_thumb1.jpg \"clip_image004\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0041.jpg)\n\n\t伪代码如下：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"568\">\n\n\t\t\t\t\tdef trial(i : int):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; if i&gt;n Then: print\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; else:\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for j in [0, n):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 在(i, j)处放置棋子;\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if 布局合法 Then: trail(i+1);\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 拿走(i, j)处的棋子\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t&nbsp;\n\n\t**4、浅谈搜索**\n\n\t上面所说的回溯法在&lt;算法导论&gt;中没有提到，觉着有些奇怪，但是仔细一想，好像又不那么奇怪。毕竟，回溯法是一种建立查找树、遍历树的递归应用算法，这些基础的知识在&lt;算法导论&gt;中均有详细解释，书中没单独辟章说明也不足为奇了。\n\n\t和友人[@烟雨华年](http://weibo.com/liangke723)讨论这个的时候，他提到：&ldquo;将整个搜索状态树中的每一个结点看作一种状态，搜索一般是求一种状态到指定状态有没有可行的变化，或者最佳的变化。&rdquo;个人觉得这句概括得还是挺到位的，大部分搜索都是检索从初始状态（状态树的根）到某个状态的变化，而可行的变化即验证是否存在解，最佳的变化即求最优解。\n\n\t说到这里又不得不说搜索两种最基本的方式，深度优先搜索（DFS）和广度优先搜索（BFS），网络上都是简单的描述一些，并没对它们的运用有一个很好的解释，那么这两种方式如何更好的运用呢？\n\n\t简单点说，就是验证最优解用DFS，搜索最优解&amp;&amp;解空间小用BFS。\n\n\t1）DFS有着内存需要相对较少的优点，可以利用栈在有限的空间内遍历所有的解，如前面提到的回溯法；\n\n\t2）BFS类似于树的分层遍历，有限空间的情况下无法使用。但是由于它分层的特性，可以保证当前搜索到的解都是最优解，可以不用完全遍历完解空间的情况下，找到最优解。如最短路径算法。\n\n\t网上还有一个有趣的说法：&ldquo;一个行不通就用另外一个！&rdquo;哈哈，想图省事的话，找一些模拟数据来跑一圈，是驴是马很快就可以见分晓啦！\n\n\t**五、结束语**\n\n\t搜索，算法中最重要的一个环节，以上仅是对它的粗浅认识，对其理解还有待进一步的深入&hellip;&hellip;","source":"_posts/algorithm-search.md","raw":"title: 算法设计 - 回溯法到搜索浅谈\ntags:\n  - 算法\nid: 331\ncategories:\n  - 技术分享\ndate: 2012-02-22 00:56:00\n---\n\n**一、定义说明**\n\n\t回溯法是一个即带有系统性又带有跳跃性的搜索算法，它在问题的解空间树中，按深度优先搜索策略，从根结点出发搜索解空间树。算法搜索至解空间树的任一结点时，先判断该结点是否包含问题的解。如果肯定不包含，则跳过对该结点为根的子树的搜索，逐层向其祖先结点回溯；否则，进入该子树，继续按深度优先策略搜索。\n\n\t<!--more-->\n\n\t回溯法是设计递归过程的一种重要方法，它的求解过程实质上是一个先序遍历一颗&ldquo;状态树&rdquo;的过程，只是这一棵树不是遍历前预先建立的，而是隐含在遍历过程中。\n\n\t**二、简单示例**\n\n\t经典回溯的例子是求n个元素的幂集，幂集简单点说就是n个元素的全组合再加上空集，它的解空间树（状态树）如下：\n\n\t[![clip_image002](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image002_thumb2.jpg \"clip_image002\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0022.jpg)\n\n\t上面的树是一颗满二叉树，树中每个结点的状态都是求解过程中可能出现的状态（即解）。递归过程可以简单理解为对n个元素的0、1取舍，伪代码如下：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"568\">\n\n\t\t\t\t\tdef powerset(i : int):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; if i &gt; n Then: print\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; else:\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 取第i个元素（1）; powerset(i+1);\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 舍第i个元素（0）; powerset(i+1);\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t&nbsp;\n\n\t**三、问题说明**\n\n\t很多问题用回溯法求解时，描述过程的树不是一颗满二叉树，这类问题在求解之前需要确定问题的约束函数：&ldquo;约束函数是根据题意定出的，通过描述合法解的一般特征用于去除不合法的解（剪支），从而避免继续搜索出这个不合法解的剩余部分。因此，约束函数是对于任何状态空间树上的节点都有效、等价的。&rdquo;\n\n\t以四皇后问题为例，剪支后的状态树如下：\n\n\t[![clip_image004](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image004_thumb1.jpg \"clip_image004\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0041.jpg)\n\n\t伪代码如下：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"568\">\n\n\t\t\t\t\tdef trial(i : int):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; if i&gt;n Then: print\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; else:\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for j in [0, n):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 在(i, j)处放置棋子;\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if 布局合法 Then: trail(i+1);\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 拿走(i, j)处的棋子\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t&nbsp;\n\n\t**4、浅谈搜索**\n\n\t上面所说的回溯法在&lt;算法导论&gt;中没有提到，觉着有些奇怪，但是仔细一想，好像又不那么奇怪。毕竟，回溯法是一种建立查找树、遍历树的递归应用算法，这些基础的知识在&lt;算法导论&gt;中均有详细解释，书中没单独辟章说明也不足为奇了。\n\n\t和友人[@烟雨华年](http://weibo.com/liangke723)讨论这个的时候，他提到：&ldquo;将整个搜索状态树中的每一个结点看作一种状态，搜索一般是求一种状态到指定状态有没有可行的变化，或者最佳的变化。&rdquo;个人觉得这句概括得还是挺到位的，大部分搜索都是检索从初始状态（状态树的根）到某个状态的变化，而可行的变化即验证是否存在解，最佳的变化即求最优解。\n\n\t说到这里又不得不说搜索两种最基本的方式，深度优先搜索（DFS）和广度优先搜索（BFS），网络上都是简单的描述一些，并没对它们的运用有一个很好的解释，那么这两种方式如何更好的运用呢？\n\n\t简单点说，就是验证最优解用DFS，搜索最优解&amp;&amp;解空间小用BFS。\n\n\t1）DFS有着内存需要相对较少的优点，可以利用栈在有限的空间内遍历所有的解，如前面提到的回溯法；\n\n\t2）BFS类似于树的分层遍历，有限空间的情况下无法使用。但是由于它分层的特性，可以保证当前搜索到的解都是最优解，可以不用完全遍历完解空间的情况下，找到最优解。如最短路径算法。\n\n\t网上还有一个有趣的说法：&ldquo;一个行不通就用另外一个！&rdquo;哈哈，想图省事的话，找一些模拟数据来跑一圈，是驴是马很快就可以见分晓啦！\n\n\t**五、结束语**\n\n\t搜索，算法中最重要的一个环节，以上仅是对它的粗浅认识，对其理解还有待进一步的深入&hellip;&hellip;","slug":"algorithm-search","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg625d00bcsb8f0edbvbst"},{"title":"算法设计 - 概率初探","id":"320","date":"2012-02-16T04:36:40.000Z","_content":"\n**一、问题描述**\n\n有n个元素，需要随机选择m个，且要保证每个元素被选的概率相同。\n\n <!--more-->  \n\n**二、解决思路**\n\n**1****）解法一**\n\n拿这题问朋友的时候，很多人都是说：“一个m长度的for循环，取m次random。”\n\n这个方法看似可以，简单方便，代码也一目了然：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\" width=\"561\"><tbody>       <tr>         <td valign=\"top\" width=\"559\">           <p>// random() -&gt; (0,1)\n\nfor i in [0, m):\n\n&#160;&#160;&#160; results[i] = data[random()*(n-1)] \n         </td>       </tr>     </tbody></table> </p>  \n\n但是，这段代码有什么问题吗？结果集中会不会出现重复的结果呢？既然是随机的，那肯定就有可能重复，如何消重就得看解法二了。\n\n**2****）解法二**\n\n要消重的话，就需要将已经选择的元素剔出，不进入下一次迭代过程。这个就和中国古代的“抓阄”是一个概念了，用高中知识解释就是“古典概率模型”——在有限多个基本结果、每个结果出现的可能性相同的条件下，先选与后选概率相同。\n\n将已经选择的元素剔出看似很方便，直接删除即可。但是数据集采用数组形式存储，删除的时间复杂度为线性，有人又说可以改成链表，但是链表存储查找又是线性时间了。那么我们能做的就是不删除元素，只是改变一下它的位置：将已选择的元素移到数组末尾。如下图：\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/02/image_thumb1.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/image1.png) \n\n代码如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\" width=\"561\"><tbody>       <tr>         <td valign=\"top\" width=\"559\">           <p>// random() -&gt; (0,1)\n\ntmp := n-1;\n\nfor i in [0, m):\n\n&#160;&#160;&#160; swap(data, random()*tmp, tmp);\n\n&#160;&#160;&#160; tmp--;\n         </td>       </tr>     </tbody></table> </p>  \n\n题外话：以上问题源自实际编码中，同时在&lt;编程珠玑 II&gt;中也有提到，不过书中所提到是现实生活问题：N个地区，随机选择M个做样本。书中提到了一个很有趣的解法：“将N个地区名字打印出来，剪成均等的字条，放入纸篓摇乱，抓取M条。”作者称之为haha!算法，的确，看到这个算法我也哈哈大笑了很久。有时候，我们如果打破我们的概念壁垒，换一种思维思考问题，是一种解法更是一种乐趣。\n\n**三、问题升级**\n\n问题一升级，就到了Google的经典面试题了：给你一个长度为N的链表。N很大，但你不知道N有多大。你的任务是从这N个元素中随机取出k个元素。你只能遍历这个链表一次。你的算法必须保证取出的元素恰好有k个，且它们是完全随机的（出现概率均等）？\n\n**四、升级问题解法**\n\n不知道N的长度，就不满足古典概型的有限个基本问题的要求。如题目没要求只能遍历一遍，可否求出长度再转换成古典概型呢？怕也不行，如果数据是动态增加的，两次遍历依然无法解决问题。\n\n那么问题就转换成蓄水池抽样（Reservoir Sampling）问题了。算法描述如下：\n\n1）先选择前k个元素，放入结果集中；\n\n2）从k+1开始，取[1, k+1]的random，如果得到的随机数小于k，就替换掉结果集中的相应元素；\n\n3）重复第2步，直到迭代完毕。\n\n伪代码：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>// random() -&gt; (0,1)\n\nfor i in [0, n):\n\n&#160;&#160;&#160; if i &lt; k then: // 将前k个元素放入结果集中\n\n&#160;&#160;&#160;&#160;&#160;&#160;&#160; results[i] := data[i];\n\n&#160;&#160;&#160; else:\n\n&#160;&#160;&#160;&#160;&#160;&#160;&#160; tmp := random() * i;\n\n&#160;&#160;&#160;&#160;&#160;&#160;&#160; if tmp &lt; k then:\n\n&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; swap(results, tmp, data, i); // 交换结果集与数据集的元素\n         </td>       </tr>     </tbody></table> </p>  \n\n**证明1：**\n\n1）前k个被选中的概率均为1；\n\n2）第k+1个元素被选中概率为k/k+1，结果集中的元素没被剔出的概率为： 1-p， p = （k / k+1）×（1 / k）。k / k+1为第k+1被选中的概率，1 / k为不幸被剔出的概率。综上，结果集中元素没被剔出的概率也为k / k+1；\n\n3）归纳法，即可证明。\n\n**证明2：**\n\n同样也可以这样证明，元素a被选中的概率为：\n\n被选中的概率×（后面元素没被选中 + 后面元素被选中 × 没被替换的概率）\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/02/image_thumb2.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/image2.png) \n\n证明2简明扼要啊！\n\n**五、总结**\n\n其实没啥好总结的，上面所提到仅仅只是概率运用的很小一部分。对概率理解还是得从古典概率模型出发，一般情况下，书上将概率算法大致分为四类：数值概率算法、蒙特卡罗（Monte Carlo）算法、拉斯维加斯（Las Vegas）算法和舍伍德（Sherwood）算法，我也没想通上面的是属于上面四种的哪一种，或许哪种都不是，算法嘛，思想在即可，不必纠结于概念。\n\n顺便说句：两天前，一次不经意的防泼溅测试，我的小黑本不幸挂了。两天后的今天，换了主板的小黑又原地复活啦！！！哈哈……","source":"_posts/algorithm-probability.md","raw":"title: 算法设计 - 概率初探\ntags:\n  - 算法\nid: 320\ncategories:\n  - 技术分享\ndate: 2012-02-16 12:36:40\n---\n\n**一、问题描述**\n\n有n个元素，需要随机选择m个，且要保证每个元素被选的概率相同。\n\n <!--more-->  \n\n**二、解决思路**\n\n**1****）解法一**\n\n拿这题问朋友的时候，很多人都是说：“一个m长度的for循环，取m次random。”\n\n这个方法看似可以，简单方便，代码也一目了然：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\" width=\"561\"><tbody>       <tr>         <td valign=\"top\" width=\"559\">           <p>// random() -&gt; (0,1)\n\nfor i in [0, m):\n\n&#160;&#160;&#160; results[i] = data[random()*(n-1)] \n         </td>       </tr>     </tbody></table> </p>  \n\n但是，这段代码有什么问题吗？结果集中会不会出现重复的结果呢？既然是随机的，那肯定就有可能重复，如何消重就得看解法二了。\n\n**2****）解法二**\n\n要消重的话，就需要将已经选择的元素剔出，不进入下一次迭代过程。这个就和中国古代的“抓阄”是一个概念了，用高中知识解释就是“古典概率模型”——在有限多个基本结果、每个结果出现的可能性相同的条件下，先选与后选概率相同。\n\n将已经选择的元素剔出看似很方便，直接删除即可。但是数据集采用数组形式存储，删除的时间复杂度为线性，有人又说可以改成链表，但是链表存储查找又是线性时间了。那么我们能做的就是不删除元素，只是改变一下它的位置：将已选择的元素移到数组末尾。如下图：\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/02/image_thumb1.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/image1.png) \n\n代码如下：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\" width=\"561\"><tbody>       <tr>         <td valign=\"top\" width=\"559\">           <p>// random() -&gt; (0,1)\n\ntmp := n-1;\n\nfor i in [0, m):\n\n&#160;&#160;&#160; swap(data, random()*tmp, tmp);\n\n&#160;&#160;&#160; tmp--;\n         </td>       </tr>     </tbody></table> </p>  \n\n题外话：以上问题源自实际编码中，同时在&lt;编程珠玑 II&gt;中也有提到，不过书中所提到是现实生活问题：N个地区，随机选择M个做样本。书中提到了一个很有趣的解法：“将N个地区名字打印出来，剪成均等的字条，放入纸篓摇乱，抓取M条。”作者称之为haha!算法，的确，看到这个算法我也哈哈大笑了很久。有时候，我们如果打破我们的概念壁垒，换一种思维思考问题，是一种解法更是一种乐趣。\n\n**三、问题升级**\n\n问题一升级，就到了Google的经典面试题了：给你一个长度为N的链表。N很大，但你不知道N有多大。你的任务是从这N个元素中随机取出k个元素。你只能遍历这个链表一次。你的算法必须保证取出的元素恰好有k个，且它们是完全随机的（出现概率均等）？\n\n**四、升级问题解法**\n\n不知道N的长度，就不满足古典概型的有限个基本问题的要求。如题目没要求只能遍历一遍，可否求出长度再转换成古典概型呢？怕也不行，如果数据是动态增加的，两次遍历依然无法解决问题。\n\n那么问题就转换成蓄水池抽样（Reservoir Sampling）问题了。算法描述如下：\n\n1）先选择前k个元素，放入结果集中；\n\n2）从k+1开始，取[1, k+1]的random，如果得到的随机数小于k，就替换掉结果集中的相应元素；\n\n3）重复第2步，直到迭代完毕。\n\n伪代码：    <table border=\"1\" cellspacing=\"0\" cellpadding=\"0\"><tbody>       <tr>         <td valign=\"top\" width=\"568\">           <p>// random() -&gt; (0,1)\n\nfor i in [0, n):\n\n&#160;&#160;&#160; if i &lt; k then: // 将前k个元素放入结果集中\n\n&#160;&#160;&#160;&#160;&#160;&#160;&#160; results[i] := data[i];\n\n&#160;&#160;&#160; else:\n\n&#160;&#160;&#160;&#160;&#160;&#160;&#160; tmp := random() * i;\n\n&#160;&#160;&#160;&#160;&#160;&#160;&#160; if tmp &lt; k then:\n\n&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; swap(results, tmp, data, i); // 交换结果集与数据集的元素\n         </td>       </tr>     </tbody></table> </p>  \n\n**证明1：**\n\n1）前k个被选中的概率均为1；\n\n2）第k+1个元素被选中概率为k/k+1，结果集中的元素没被剔出的概率为： 1-p， p = （k / k+1）×（1 / k）。k / k+1为第k+1被选中的概率，1 / k为不幸被剔出的概率。综上，结果集中元素没被剔出的概率也为k / k+1；\n\n3）归纳法，即可证明。\n\n**证明2：**\n\n同样也可以这样证明，元素a被选中的概率为：\n\n被选中的概率×（后面元素没被选中 + 后面元素被选中 × 没被替换的概率）\n\n[![image](http://www.hongweiyi.com/wp-content/uploads/2012/02/image_thumb2.png \"image\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/image2.png) \n\n证明2简明扼要啊！\n\n**五、总结**\n\n其实没啥好总结的，上面所提到仅仅只是概率运用的很小一部分。对概率理解还是得从古典概率模型出发，一般情况下，书上将概率算法大致分为四类：数值概率算法、蒙特卡罗（Monte Carlo）算法、拉斯维加斯（Las Vegas）算法和舍伍德（Sherwood）算法，我也没想通上面的是属于上面四种的哪一种，或许哪种都不是，算法嘛，思想在即可，不必纠结于概念。\n\n顺便说句：两天前，一次不经意的防泼溅测试，我的小黑本不幸挂了。两天后的今天，换了主板的小黑又原地复活啦！！！哈哈……","slug":"algorithm-probability","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg625e00bfsb8fkoprwipm"},{"title":"算法设计 - 动态规划","id":"317","date":"2012-02-14T12:13:50.000Z","_content":"\n**一、定义说明**\n\n\t动态规划（Dynamic Programming）是通过组合子问题的解而解决整个问题的。分治法算是是将问题划分成一些独立的子问题，递归地求解各子问题，递归地求解个子问题，然后合并子问题的解而得到原问题的解。而动态规划与此不同，它是用于子问题不是独立的情况，就是各子问题包含公共的子的子问题。\n\n<!--more-->\n\n\t动态规划常用于求最优解问题，此类问题可能有很多可行解，每个解都有一个值，而我们希望找到一个最优（最大、最小）值的解。需要注意，这样的问题可能有多个最优解，但是我们只求解&ldquo;一个&rdquo;。\n\n\t动态规划算法的设计分为如下4个步骤：\n\n\t1）描述最优解的结构；\n\n\t2）递归定义最优解的值；\n\n\t3）按自底向上的方式计算最优解的值；\n\n\t4）由计算出的结果构造一个最优解。\n\n\t**二、简单示例**\n\n\t斐波那契（Fibonacci）数列。相信所有大学生都对这个名字不会陌生，大计基（大学计算机基础）课上老师会给大家一个这样的公式：\n\n> f(n) = f(n-2) + f(n-1);&nbsp;&nbsp;f(0) =0,&nbsp;f(1) = 1\n\n\t同时，老师就会给一个递归的解，几行代码了事。期末或国家计算机考试的时候，写出递归解就算过关了。但对于我们程序猿来说，可不是这么回事了，递归算f(20)都算不出来。\n\n\t不知道拿Fibonacci说事合理不合理，因为Fibonacci数列不存在最优不最优，我们姑且算求得答案算最优解吧。\n\n\t动态规划有两个要素：**最优子结构与重叠子问题**。\n\n\t最优子结构要素：如果问题的最优解所包含的子问题的解也是最优的，我们就称该问题具有最优子结构要素。\n\n\t子问题重叠要素：子问题重叠要素是指在用递归算法自顶向下对问题进行求解时，每次产生的子问题并不总是新问题，有些子问题会被重复计算多次。\n\n\tFibonacci数列满足最优子结构，那子问题重叠呢？f(n-1)、f(n-2)均要用到f(n-3)的解，但是每次都要重复计算一次，所以也满足子问题重叠性质。\n\n\t已经描述了Fibonacci的最优解结构，公式也就是其递归解，现在需要做的就是自底向上计算最优解了，伪代码如下：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"568\">\n\n\t\t\t\t\tf[] := new bigint[n];\n\n\t\t\t\t\tf[0] := f[1] := 1;\n\n\t\t\t\t\tfor i in [2, n):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp; f[i] := f[i-1] + f[i-2];\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t构造出的最优解就是上述代码中的f(n)了。动态规划利用了子问题的重叠性质，对每一个子问题只计算一次，然后将其计算结果保存在一个表格中，当再次需要计算已经计算过的子问题时，只是在表格中简单地查看一下结果，从而获得较高的效率。\n\n\t**三、经典例子**\n\n\t接下来汇总一些经典的动态规划问题，但是只给出状态转移方程（递归解）和伪代码。\n\n\t**1）01背包问题**\n\n\t有N件物品和一个容量为W的背包。第i件物品的重量是w[i]，价值是v[i]。求解将哪些物品装入背包可使这些物品的重量总和不超过背包容量，且价值总和最大。为啥叫01背包呢，因为每个物体就一件，放就是1不放就是0。\n\n\t子问题为V[i][w]，定义为：前i件物品恰放入一个容量为w的背包可以获得的最大价值。\n\n\t状态转移方程：\n\n\tV[i][w] = MAX{V[i-1][w], V[i-1][w-w[i]]+v[i]}\n\n\t其中，V[i-1][w]代表第i件物品没有加入到背包中（为0），V[i-1][w-w[i]]+v[i]表示第i件物品加入了（为1），在01中取最大值。\n\n\t伪代码：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"568\">\n\n\t\t\t\t\tV[][] := new int[n][W]\n\n\t\t\t\t\tfor i in [1, n):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; for w in (W, w[i-1]]: // 保证w-w[i-1]不越界\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; V[i][w] := MAX{V[i-1][w], V[i-1][w-w[i]]+v[i]}\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t上面的时间复杂度为O(n*W)，空间复杂度也为O(n*W)。我们可以压缩一下空间，因为我们只需要袋子装满没有，装满后的价值是多少，设V[w]：在w重量下，袋子中物品的最大价值。\n\n\t状态转移方程：\n\n> V [w] = MAX{V[w], V[w-w[i]]+v[i]}\n\n\t伪代码：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"568\">\n\n\t\t\t\t\tV[]:= new int [W+1]\n\n\t\t\t\t\tfor i in [0, n):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; for w in [W, w[i]-1]: // 保证w-w[i-1]不越界\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; V[w] := MAX{V[w], V[w-w[i]]+v[i]}\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**2）最长公共子序列（Longest Common Sequence）**\n\n\t求两数组相同的最长子序列，子序列可以不连续的。状态转移方程：\n\n\t[![clip_image002](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image002_thumb1.jpg \"clip_image002\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0021.jpg)\n\n\tc[i][j]表示在字符串x的i位前与字符串y的j位前最长公共子序列。很容易理解，如果一个x[i]、y[j]相等，c[i-1][j-1]加1，不等的话，c[i][j]等于c[i-1][j]、c[i][j-1]中较大的数。\n\n\t伪代码：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"568\">\n\n\t\t\t\t\tc[][] := new int[len(x)][len(y)]\n\n\t\t\t\t\tfor i in [0, len(x)):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; for j in [0, len(y));\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if i==0 || j==0 then:\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; c[i][j] :=0;\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; else if x[i] == y[j] then:\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; c[i-1][j-1] += 1;\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; else:\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; c[i][j]:= MAX{c[i][j-1], c[i-1][j]};\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**3）最长递增子序列（Longest Increase Sequence）**\n\n\t求一个一维数组（N个元素）中最长递增子序列的长度。状态转移方程：\n\n> LIS[i+1] = MAX{1, LIS[k] +1}, array[i+1] > array[k], for k in [0, i]\n\n\t伪代码：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"568\">\n\n\t\t\t\t\tL[] :=new int[len(array)];\n\n\t\t\t\t\tfor i in [0, len(array)):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; L[i] := 1 // 初始默认为1\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; for j in [0, j):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if array[i] > array[j] &amp;&amp; L[j] +1 > L[i]:\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; L[i] = L[j] +1;\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**四、小结**\n\n\t以上整理自&lt;**算法导论**&gt;、&lt;**编程之美**&gt;，要掌握动态规划主要是理解两个要素：最优子结构和重叠子问题。要懂得找到一个好的&ldquo;表格&rdquo;来装子问题，将大问题逐步简化，直到得到状态转移方程。&ldquo;表格&rdquo;即子问题最优解，如背包问题：V[w]为背包重量为w的时候最大价值；LCS问题：c[i][j]为x[0, i]、y[0, j]的最大子序列；LIS问题：L[i]为array[0, i]的最大递增序列。\n\n\t但要完全掌握动态规划仅靠以上几道经典问题是不够的，需要不断思考、分析、实践，才可逐渐掌握这一算法分析设计方法。以上经典问题的解答也是经典的，还有许多需要优化以及修改的地方，但不写在博客里了，有兴趣的可以参考相关书籍，也欢迎留言讨论。","source":"_posts/algorithm-dynammic-programming.md","raw":"title: 算法设计 - 动态规划\ntags:\n  - 算法\nid: 317\ncategories:\n  - 技术分享\ndate: 2012-02-14 20:13:50\n---\n\n**一、定义说明**\n\n\t动态规划（Dynamic Programming）是通过组合子问题的解而解决整个问题的。分治法算是是将问题划分成一些独立的子问题，递归地求解各子问题，递归地求解个子问题，然后合并子问题的解而得到原问题的解。而动态规划与此不同，它是用于子问题不是独立的情况，就是各子问题包含公共的子的子问题。\n\n<!--more-->\n\n\t动态规划常用于求最优解问题，此类问题可能有很多可行解，每个解都有一个值，而我们希望找到一个最优（最大、最小）值的解。需要注意，这样的问题可能有多个最优解，但是我们只求解&ldquo;一个&rdquo;。\n\n\t动态规划算法的设计分为如下4个步骤：\n\n\t1）描述最优解的结构；\n\n\t2）递归定义最优解的值；\n\n\t3）按自底向上的方式计算最优解的值；\n\n\t4）由计算出的结果构造一个最优解。\n\n\t**二、简单示例**\n\n\t斐波那契（Fibonacci）数列。相信所有大学生都对这个名字不会陌生，大计基（大学计算机基础）课上老师会给大家一个这样的公式：\n\n> f(n) = f(n-2) + f(n-1);&nbsp;&nbsp;f(0) =0,&nbsp;f(1) = 1\n\n\t同时，老师就会给一个递归的解，几行代码了事。期末或国家计算机考试的时候，写出递归解就算过关了。但对于我们程序猿来说，可不是这么回事了，递归算f(20)都算不出来。\n\n\t不知道拿Fibonacci说事合理不合理，因为Fibonacci数列不存在最优不最优，我们姑且算求得答案算最优解吧。\n\n\t动态规划有两个要素：**最优子结构与重叠子问题**。\n\n\t最优子结构要素：如果问题的最优解所包含的子问题的解也是最优的，我们就称该问题具有最优子结构要素。\n\n\t子问题重叠要素：子问题重叠要素是指在用递归算法自顶向下对问题进行求解时，每次产生的子问题并不总是新问题，有些子问题会被重复计算多次。\n\n\tFibonacci数列满足最优子结构，那子问题重叠呢？f(n-1)、f(n-2)均要用到f(n-3)的解，但是每次都要重复计算一次，所以也满足子问题重叠性质。\n\n\t已经描述了Fibonacci的最优解结构，公式也就是其递归解，现在需要做的就是自底向上计算最优解了，伪代码如下：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"568\">\n\n\t\t\t\t\tf[] := new bigint[n];\n\n\t\t\t\t\tf[0] := f[1] := 1;\n\n\t\t\t\t\tfor i in [2, n):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp; f[i] := f[i-1] + f[i-2];\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t构造出的最优解就是上述代码中的f(n)了。动态规划利用了子问题的重叠性质，对每一个子问题只计算一次，然后将其计算结果保存在一个表格中，当再次需要计算已经计算过的子问题时，只是在表格中简单地查看一下结果，从而获得较高的效率。\n\n\t**三、经典例子**\n\n\t接下来汇总一些经典的动态规划问题，但是只给出状态转移方程（递归解）和伪代码。\n\n\t**1）01背包问题**\n\n\t有N件物品和一个容量为W的背包。第i件物品的重量是w[i]，价值是v[i]。求解将哪些物品装入背包可使这些物品的重量总和不超过背包容量，且价值总和最大。为啥叫01背包呢，因为每个物体就一件，放就是1不放就是0。\n\n\t子问题为V[i][w]，定义为：前i件物品恰放入一个容量为w的背包可以获得的最大价值。\n\n\t状态转移方程：\n\n\tV[i][w] = MAX{V[i-1][w], V[i-1][w-w[i]]+v[i]}\n\n\t其中，V[i-1][w]代表第i件物品没有加入到背包中（为0），V[i-1][w-w[i]]+v[i]表示第i件物品加入了（为1），在01中取最大值。\n\n\t伪代码：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"568\">\n\n\t\t\t\t\tV[][] := new int[n][W]\n\n\t\t\t\t\tfor i in [1, n):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; for w in (W, w[i-1]]: // 保证w-w[i-1]不越界\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; V[i][w] := MAX{V[i-1][w], V[i-1][w-w[i]]+v[i]}\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t上面的时间复杂度为O(n*W)，空间复杂度也为O(n*W)。我们可以压缩一下空间，因为我们只需要袋子装满没有，装满后的价值是多少，设V[w]：在w重量下，袋子中物品的最大价值。\n\n\t状态转移方程：\n\n> V [w] = MAX{V[w], V[w-w[i]]+v[i]}\n\n\t伪代码：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"568\">\n\n\t\t\t\t\tV[]:= new int [W+1]\n\n\t\t\t\t\tfor i in [0, n):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; for w in [W, w[i]-1]: // 保证w-w[i-1]不越界\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; V[w] := MAX{V[w], V[w-w[i]]+v[i]}\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**2）最长公共子序列（Longest Common Sequence）**\n\n\t求两数组相同的最长子序列，子序列可以不连续的。状态转移方程：\n\n\t[![clip_image002](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image002_thumb1.jpg \"clip_image002\")](http://www.hongweiyi.com/wp-content/uploads/2012/02/clip_image0021.jpg)\n\n\tc[i][j]表示在字符串x的i位前与字符串y的j位前最长公共子序列。很容易理解，如果一个x[i]、y[j]相等，c[i-1][j-1]加1，不等的话，c[i][j]等于c[i-1][j]、c[i][j-1]中较大的数。\n\n\t伪代码：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"568\">\n\n\t\t\t\t\tc[][] := new int[len(x)][len(y)]\n\n\t\t\t\t\tfor i in [0, len(x)):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; for j in [0, len(y));\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if i==0 || j==0 then:\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; c[i][j] :=0;\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; else if x[i] == y[j] then:\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; c[i-1][j-1] += 1;\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; else:\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; c[i][j]:= MAX{c[i][j-1], c[i-1][j]};\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**3）最长递增子序列（Longest Increase Sequence）**\n\n\t求一个一维数组（N个元素）中最长递增子序列的长度。状态转移方程：\n\n> LIS[i+1] = MAX{1, LIS[k] +1}, array[i+1] > array[k], for k in [0, i]\n\n\t伪代码：\n\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"0\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td valign=\"top\" width=\"568\">\n\n\t\t\t\t\tL[] :=new int[len(array)];\n\n\t\t\t\t\tfor i in [0, len(array)):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; L[i] := 1 // 初始默认为1\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp; for j in [0, j):\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if array[i] > array[j] &amp;&amp; L[j] +1 > L[i]:\n\n\t\t\t\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; L[i] = L[j] +1;\n\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\t**四、小结**\n\n\t以上整理自&lt;**算法导论**&gt;、&lt;**编程之美**&gt;，要掌握动态规划主要是理解两个要素：最优子结构和重叠子问题。要懂得找到一个好的&ldquo;表格&rdquo;来装子问题，将大问题逐步简化，直到得到状态转移方程。&ldquo;表格&rdquo;即子问题最优解，如背包问题：V[w]为背包重量为w的时候最大价值；LCS问题：c[i][j]为x[0, i]、y[0, j]的最大子序列；LIS问题：L[i]为array[0, i]的最大递增序列。\n\n\t但要完全掌握动态规划仅靠以上几道经典问题是不够的，需要不断思考、分析、实践，才可逐渐掌握这一算法分析设计方法。以上经典问题的解答也是经典的，还有许多需要优化以及修改的地方，但不写在博客里了，有兴趣的可以参考相关书籍，也欢迎留言讨论。","slug":"algorithm-dynammic-programming","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg625f00bisb8fbapd2hdh"},{"title":"README","date":"2015-08-28T12:32:00.000Z","_content":"\n\n# 建站\n\n使用 [hexo](https://hexo.io/zh-cn/)，快速开始如下：\n\n```\n$ npm install hexo-cli -g\n$ hexo init blog\n$ cd blog\n$ npm install\n$ hexo server\n```\n\n\n# 主题\n\n使用了 [NexT](http://theme-next.iissnan.com/)，快速开始如下：\n\n```\n$ cd your-hexo-site\n$ git clone https://github.com/iissnan/hexo-theme-next themes/next\n```\n\n\n由于墙的存在，建议直接到项目的 [github 主页](https://github.com/iissnan/hexo-theme-next) 直接下载 zip 包。\n\n\n# 部署到 github pages\n\n安装 git 部署插件即可，参考: [部署](https://hexo.io/zh-cn/docs/deployment.html)\n\n* 安装插件\n\n\n```\n$ npm install hexo-deployer-git --save\n```\n\n* 在 `_config.yml` 中修改 deploy 内容\n\n```\ndeploy:\n  type: git\n  repo: https://github.com/hongweiyi/hongweiyi.github.io.git\n```\n\n* 部署\n\n```\n$ hexo deploy\n```\n","source":"_posts/README.md","raw":"title: README\ndate: 2015-08-28 20:32:00\n---\n\n\n# 建站\n\n使用 [hexo](https://hexo.io/zh-cn/)，快速开始如下：\n\n```\n$ npm install hexo-cli -g\n$ hexo init blog\n$ cd blog\n$ npm install\n$ hexo server\n```\n\n\n# 主题\n\n使用了 [NexT](http://theme-next.iissnan.com/)，快速开始如下：\n\n```\n$ cd your-hexo-site\n$ git clone https://github.com/iissnan/hexo-theme-next themes/next\n```\n\n\n由于墙的存在，建议直接到项目的 [github 主页](https://github.com/iissnan/hexo-theme-next) 直接下载 zip 包。\n\n\n# 部署到 github pages\n\n安装 git 部署插件即可，参考: [部署](https://hexo.io/zh-cn/docs/deployment.html)\n\n* 安装插件\n\n\n```\n$ npm install hexo-deployer-git --save\n```\n\n* 在 `_config.yml` 中修改 deploy 内容\n\n```\ndeploy:\n  type: git\n  repo: https://github.com/hongweiyi/hongweiyi.github.io.git\n```\n\n* 部署\n\n```\n$ hexo deploy\n```\n","slug":"README","published":1,"updated":"2015-12-29T13:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg625h00blsb8fjakv6ncr"},{"title":"2013学习计划","id":"623","date":"2013-01-03T15:20:47.000Z","_content":"\n2012年也过去了，去年这个博客基本坚持了至少一个月一篇博文，但是12月学习的知识实在是太零散了（文本分类、自然语言处理、分布式系统、流处理系统、并发编程，甚至还看了一小会儿汇编），同时自己理解也过于肤浅，今年找个时间再整理出来吧。BTW：13年也是我一个发力之年啊，3月份会去一个新的地方发展，主要的应该关注在分布式系统和实时计算上，到时候的心得应该会比现在更多。\n\n<!--more-->\n\n好吧，列列我的学习清单吧：\n\n1）**分布式相关**：solr、hbase的深入理解与应用，hadoop就继续翻源码吧；\n\n2）**流处理相关**：主要是storm，虽然storm看了一些，也写了一些小topologies，但是没有实战过；\n\n3）**实时处理相关**：Dremel打头阵了，Google论文一出，业内一片欢声一片哀声，欢的是有此神功我等有救了，哀的是欲练神功必先自宫！现有的HDFS要上Dremel这类应用，不大刀阔斧的改可能难见成效；\n\n4）**计算机基础知识**：算法与数据结构深入、Linux内核了解、I/O机制深入、并发编程深入……这些知识都是上面的基础，也是IT人士的内功心法，我这半路科班人士，就得更加的深入学习了；\n\n5）**机器学习与数据挖掘**：文本分类、LDA、信息论。这快一年的实习，与这个有一定的接触，虽然主要兴趣不在于此，但是觉得这门学科博大精深，特别是看了东犇基于LDA的小实验结果，效果惊人，不继续了解了解有可能会遗憾终生啊。\n\n&nbsp;\n\n看了上面的学习计划，好像我挺大挺贪的，但是只要不半途而废的话，还是可以理解到某些方向的精髓滴。突然又想到了一条，最近朋友的mac air放我这了，体验非常非常好，所以再加上一条：\n\n6）**mac os深入了解**：不过这条前提是买mac本，T_T。\n\n最后，望14年一切安好，ICC与CC也安好。","source":"_posts/2013-learning-plan.md","raw":"title: 2013学习计划\ntags:\n  - 生活\nid: 623\ncategories:\n  - 生活分享\ndate: 2013-01-03 23:20:47\n---\n\n2012年也过去了，去年这个博客基本坚持了至少一个月一篇博文，但是12月学习的知识实在是太零散了（文本分类、自然语言处理、分布式系统、流处理系统、并发编程，甚至还看了一小会儿汇编），同时自己理解也过于肤浅，今年找个时间再整理出来吧。BTW：13年也是我一个发力之年啊，3月份会去一个新的地方发展，主要的应该关注在分布式系统和实时计算上，到时候的心得应该会比现在更多。\n\n<!--more-->\n\n好吧，列列我的学习清单吧：\n\n1）**分布式相关**：solr、hbase的深入理解与应用，hadoop就继续翻源码吧；\n\n2）**流处理相关**：主要是storm，虽然storm看了一些，也写了一些小topologies，但是没有实战过；\n\n3）**实时处理相关**：Dremel打头阵了，Google论文一出，业内一片欢声一片哀声，欢的是有此神功我等有救了，哀的是欲练神功必先自宫！现有的HDFS要上Dremel这类应用，不大刀阔斧的改可能难见成效；\n\n4）**计算机基础知识**：算法与数据结构深入、Linux内核了解、I/O机制深入、并发编程深入……这些知识都是上面的基础，也是IT人士的内功心法，我这半路科班人士，就得更加的深入学习了；\n\n5）**机器学习与数据挖掘**：文本分类、LDA、信息论。这快一年的实习，与这个有一定的接触，虽然主要兴趣不在于此，但是觉得这门学科博大精深，特别是看了东犇基于LDA的小实验结果，效果惊人，不继续了解了解有可能会遗憾终生啊。\n\n&nbsp;\n\n看了上面的学习计划，好像我挺大挺贪的，但是只要不半途而废的话，还是可以理解到某些方向的精髓滴。突然又想到了一条，最近朋友的mac air放我这了，体验非常非常好，所以再加上一条：\n\n6）**mac os深入了解**：不过这条前提是买mac本，T_T。\n\n最后，望14年一切安好，ICC与CC也安好。","slug":"2013-learning-plan","published":1,"updated":"2015-12-29T13:31:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciirg625i00bmsb8fjmu9hdpm"}],"PostAsset":[],"PostCategory":[{"post_id":"ciirg620d0001sb8fc9nebivq","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg620h0005sb8feh7egbnv"},{"post_id":"ciirg620i0006sb8fu116ik6u","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg620j0007sb8f7q8kffge"},{"post_id":"ciirg620l000asb8fofw0pm2c","category_id":"ciirg620m000bsb8fkm4sf9k6","_id":"ciirg620n000esb8f25su0snt"},{"post_id":"ciirg620o000hsb8fdkgqpsgk","category_id":"ciirg620m000bsb8fkm4sf9k6","_id":"ciirg620o000isb8fts87sh90"},{"post_id":"ciirg620q000nsb8fup05cm9a","category_id":"ciirg620m000bsb8fkm4sf9k6","_id":"ciirg620r000osb8fd1sll519"},{"post_id":"ciirg620t000rsb8f0ulnpyru","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg620t000ssb8fvs2xcac1"},{"post_id":"ciirg620v000vsb8ft22vrm2a","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg620v000wsb8fmiyivw7h"},{"post_id":"ciirg620w000zsb8fj4kdfeh0","category_id":"ciirg620m000bsb8fkm4sf9k6","_id":"ciirg620x0010sb8fikdx8kmw"},{"post_id":"ciirg620y0013sb8fkcydi3hs","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg620z0014sb8fbomffemk"},{"post_id":"ciirg62100017sb8fg6wrqajc","category_id":"ciirg620m000bsb8fkm4sf9k6","_id":"ciirg62110018sb8ftyc339vz"},{"post_id":"ciirg6212001dsb8ffouz1ish","category_id":"ciirg6212001esb8fp344f5y9","_id":"ciirg6213001hsb8fwybya4zm"},{"post_id":"ciirg6213001isb8fmo597y2n","category_id":"ciirg6214001jsb8fgfjd266m","_id":"ciirg6215001msb8fygx3gkmq"},{"post_id":"ciirg6215001psb8fk39q4xa3","category_id":"ciirg620m000bsb8fkm4sf9k6","_id":"ciirg6216001qsb8f6mksu73i"},{"post_id":"ciirg6218001usb8f1tkoxsrp","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg6218001vsb8fvl94z2zq"},{"post_id":"ciirg621a0021sb8fkst4112j","category_id":"ciirg620m000bsb8fkm4sf9k6","_id":"ciirg621b0022sb8fza0xlrks"},{"post_id":"ciirg621c0027sb8fewtedb9i","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg621d0028sb8f96zn8ywg"},{"post_id":"ciirg621e002dsb8f47ka4ywp","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg621e002esb8fprc05a0p"},{"post_id":"ciirg621f002hsb8fhgqxcz3e","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg621g002isb8fsqv2x9dq"},{"post_id":"ciirg621h002ksb8fq5nlr8x6","category_id":"ciirg620m000bsb8fkm4sf9k6","_id":"ciirg621h002lsb8fe7au964d"},{"post_id":"ciirg621j002osb8ff1bosx26","category_id":"ciirg6214001jsb8fgfjd266m","_id":"ciirg621k002psb8fq216r9sp"},{"post_id":"ciirg621l002vsb8fgozjki59","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg621m002wsb8fl8w2nqdk"},{"post_id":"ciirg621n0030sb8flqq1w280","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg621o0031sb8frhfu9j6v"},{"post_id":"ciirg621p0034sb8fwobft8w3","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg621q0035sb8f5ki9dv2r"},{"post_id":"ciirg621r003asb8fia88xgop","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg621s003bsb8fi5hqcqr2"},{"post_id":"ciirg621t003fsb8fckoq1sqh","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg621t003gsb8feq4bzhnr"},{"post_id":"ciirg621u003msb8f24kw3s4n","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg621v003nsb8flq1uc89o"},{"post_id":"ciirg621z003tsb8fkbvyuo63","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg6220003usb8febm3he1r"},{"post_id":"ciirg6223003xsb8fcen68f4q","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg6223003ysb8f5375e4hr"},{"post_id":"ciirg62240040sb8frxp017s4","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg62240041sb8f43zaojb5"},{"post_id":"ciirg62250043sb8fu5kruni6","category_id":"ciirg620m000bsb8fkm4sf9k6","_id":"ciirg62260044sb8fn8ievcyz"},{"post_id":"ciirg62270046sb8fzbkuwllm","category_id":"ciirg620m000bsb8fkm4sf9k6","_id":"ciirg62280047sb8frmnfvmgz"},{"post_id":"ciirg622b004esb8fryz8m4x3","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg622c004fsb8fetl809ex"},{"post_id":"ciirg622e004ksb8fy6qfb57u","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg622f004lsb8fsjvmey4s"},{"post_id":"ciirg622h004psb8fm9udo4dh","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg622h004qsb8fh98qp7h3"},{"post_id":"ciirg622j004tsb8f9lmz1p8i","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg622k004usb8ftpbvep66"},{"post_id":"ciirg622l004zsb8fn9vq0ke5","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg622m0050sb8fda0qcfcu"},{"post_id":"ciirg622n0053sb8fc6aqce3h","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg622o0054sb8f9v1md0hn"},{"post_id":"ciirg622p0057sb8fd2majmpk","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg622q0058sb8f8czzy0l7"},{"post_id":"ciirg622r005dsb8fg3pzkwkv","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg622r005esb8fn09p30g9"},{"post_id":"ciirg622s005hsb8fpcni6h4n","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg622t005isb8f2d7gajrc"},{"post_id":"ciirg622u005lsb8fua2jrmej","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg622v005msb8fazwbe1nc"},{"post_id":"ciirg622w005psb8frln26qp5","category_id":"ciirg620m000bsb8fkm4sf9k6","_id":"ciirg622w005qsb8fvc14jy93"},{"post_id":"ciirg622x005tsb8fno1na3yx","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg622y005usb8fi1p0uj3a"},{"post_id":"ciirg622z005wsb8fm2aami3p","category_id":"ciirg6214001jsb8fgfjd266m","_id":"ciirg6230005xsb8fkoubvlfx"},{"post_id":"ciirg62310060sb8fenovhnnj","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg62320061sb8fyj73qpqu"},{"post_id":"ciirg62320063sb8fbj698zwi","category_id":"ciirg6214001jsb8fgfjd266m","_id":"ciirg62330064sb8fiyxuojiv"},{"post_id":"ciirg62340066sb8f1f55dv0n","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg62350067sb8fgnmy7qfb"},{"post_id":"ciirg62350069sb8fw77h4cbp","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg6236006asb8fik4jovxo"},{"post_id":"ciirg6237006dsb8fi0763m4z","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg6237006esb8fdrc1x65h"},{"post_id":"ciirg6238006jsb8fpf1y2gws","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg6239006ksb8fau3d7yk7"},{"post_id":"ciirg623a006nsb8fu2bi5dhs","category_id":"ciirg6212001esb8fp344f5y9","_id":"ciirg623a006osb8fjqqrpckz"},{"post_id":"ciirg623b006rsb8f6l9brp4n","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg623c006ssb8ft481gb9p"},{"post_id":"ciirg623d006vsb8fwxucqwl2","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg623e006wsb8f8125xufq"},{"post_id":"ciirg623f006ysb8fcmqm2fr2","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg623f006zsb8fojdonejg"},{"post_id":"ciirg623g0074sb8f021yhjoc","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg623h0075sb8fdu28saev"},{"post_id":"ciirg623i0079sb8fnzgje88k","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg623j007asb8fm2fxypvi"},{"post_id":"ciirg623k007esb8f7ggt3fom","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg623l007fsb8fzhh06k4y"},{"post_id":"ciirg623p007isb8f5uodzpij","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg623p007jsb8fm1u0p2g1"},{"post_id":"ciirg623q007msb8f3y9e9qh8","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg623r007nsb8fqxytp7pi"},{"post_id":"ciirg623r007psb8fxi147iu8","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg623s007qsb8fm24lir7d"},{"post_id":"ciirg623t007ssb8fyghfif6h","category_id":"ciirg620m000bsb8fkm4sf9k6","_id":"ciirg623t007tsb8fpfpl3cu8"},{"post_id":"ciirg623u007wsb8fb145hlx7","category_id":"ciirg6214001jsb8fgfjd266m","_id":"ciirg623v007xsb8f6ofxiotl"},{"post_id":"ciirg623v0080sb8fve7w65dn","category_id":"ciirg6212001esb8fp344f5y9","_id":"ciirg623w0081sb8f6rynm9su"},{"post_id":"ciirg623x0084sb8f3nfkrqoc","category_id":"ciirg620m000bsb8fkm4sf9k6","_id":"ciirg623y0085sb8f974cypg7"},{"post_id":"ciirg623y0088sb8f9zxg4am1","category_id":"ciirg620m000bsb8fkm4sf9k6","_id":"ciirg623z0089sb8fx7b6ky6s"},{"post_id":"ciirg6241008csb8f15ct5jre","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg6242008dsb8fs4lca782"},{"post_id":"ciirg6243008hsb8fta1bt7k9","category_id":"ciirg6243008isb8fq4wzlvb6","_id":"ciirg6244008lsb8fy1yzwo7f"},{"post_id":"ciirg6247008qsb8fmkuz8kqu","category_id":"ciirg6214001jsb8fgfjd266m","_id":"ciirg6248008rsb8ftoe4ac5f"},{"post_id":"ciirg6249008vsb8ftjncozzm","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg624a008ysb8f2cwz3lfj"},{"post_id":"ciirg6249008vsb8ftjncozzm","category_id":"ciirg6249008wsb8f0ydfqs54","_id":"ciirg624a008zsb8f5j5q0mer"},{"post_id":"ciirg624b0090sb8fgn7hmnzm","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg624c0091sb8f8zi4ra82"},{"post_id":"ciirg624c0094sb8fswg0jbic","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg624d0095sb8f6wt1r4ue"},{"post_id":"ciirg624e0098sb8fozf07zx5","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg624e0099sb8ftmwridbo"},{"post_id":"ciirg624f009bsb8fu6r73978","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg624g009csb8f4ize1nfo"},{"post_id":"ciirg624h009esb8f5h4jcnon","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg624i009fsb8fg9au743q"},{"post_id":"ciirg624j009hsb8fkbe0qon7","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg624j009isb8fixq0mimy"},{"post_id":"ciirg624k009ksb8fhdbgg0za","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg624l009lsb8fd09pq4ts"},{"post_id":"ciirg624l009nsb8fayiwbpg6","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg624m009osb8fpkxqsg0a"},{"post_id":"ciirg624n009qsb8fgrc69ec1","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg624n009rsb8f4yibtwn8"},{"post_id":"ciirg624o009tsb8f05k3y3ne","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg624p009usb8fxstnoo0m"},{"post_id":"ciirg624p009wsb8f8y611mia","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg624q009xsb8fzs0cs4in"},{"post_id":"ciirg624r009zsb8fyfy9qnd2","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg624r00a0sb8fzzs1evvx"},{"post_id":"ciirg624s00a2sb8fkgylrzax","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg624t00a3sb8fvsogmln2"},{"post_id":"ciirg624t00a5sb8ftj47qkb1","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg624u00a6sb8f97wbdx9u"},{"post_id":"ciirg624v00a8sb8fpk0c459w","category_id":"ciirg6214001jsb8fgfjd266m","_id":"ciirg624w00a9sb8fs8ra69ke"},{"post_id":"ciirg624y00aesb8fsbk5tmgp","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg624y00afsb8fe6s6fwpv"},{"post_id":"ciirg624z00ajsb8fy320fyu8","category_id":"ciirg620m000bsb8fkm4sf9k6","_id":"ciirg625000aksb8f11yzk4u8"},{"post_id":"ciirg625100amsb8fomtinzpn","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg625100ansb8f6ldkcmr1"},{"post_id":"ciirg625200apsb8f0fxuit4h","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg625300aqsb8fvhctsgpl"},{"post_id":"ciirg625400assb8f7r6f78qd","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg625500atsb8fsm9jmuld"},{"post_id":"ciirg625600avsb8fjjtw08gd","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg625700awsb8f2ij3cbgj"},{"post_id":"ciirg625800azsb8fp6nr0ky5","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg625900b0sb8ff9eryvxn"},{"post_id":"ciirg625900b2sb8f1quxtx2h","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg625a00b3sb8fuhpnfpad"},{"post_id":"ciirg625b00b8sb8f93zvfmtb","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg625c00b9sb8fiq0p7t1a"},{"post_id":"ciirg625d00bcsb8f0edbvbst","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg625d00bdsb8fqo9mbahi"},{"post_id":"ciirg625e00bfsb8fkoprwipm","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg625f00bgsb8f835mof77"},{"post_id":"ciirg625f00bisb8fbapd2hdh","category_id":"ciirg620g0002sb8fbby8sg93","_id":"ciirg625g00bjsb8f97udy1fm"},{"post_id":"ciirg625i00bmsb8fjmu9hdpm","category_id":"ciirg620m000bsb8fkm4sf9k6","_id":"ciirg625j00bnsb8fzdgk1clr"}],"PostTag":[{"post_id":"ciirg620d0001sb8fc9nebivq","tag_id":"ciirg620g0003sb8fqnkobn6l","_id":"ciirg620h0004sb8f2j6ybu1b"},{"post_id":"ciirg620i0006sb8fu116ik6u","tag_id":"ciirg620j0008sb8fcej531ut","_id":"ciirg620j0009sb8fektapo74"},{"post_id":"ciirg620l000asb8fofw0pm2c","tag_id":"ciirg620m000csb8fv7idho0w","_id":"ciirg620n000fsb8fjlss8p1f"},{"post_id":"ciirg620l000asb8fofw0pm2c","tag_id":"ciirg620m000dsb8fc7xbgnve","_id":"ciirg620n000gsb8f5zzzb82g"},{"post_id":"ciirg620o000hsb8fdkgqpsgk","tag_id":"ciirg620o000jsb8fr67fcpk3","_id":"ciirg620p000lsb8fjyyqxgh5"},{"post_id":"ciirg620o000hsb8fdkgqpsgk","tag_id":"ciirg620p000ksb8fmbj2hnkd","_id":"ciirg620p000msb8fg7kaugvc"},{"post_id":"ciirg620q000nsb8fup05cm9a","tag_id":"ciirg620r000psb8ft97zbfd8","_id":"ciirg620r000qsb8figika1q5"},{"post_id":"ciirg620t000rsb8f0ulnpyru","tag_id":"ciirg620t000tsb8fokjp9qz2","_id":"ciirg620t000usb8fqm3gyp3j"},{"post_id":"ciirg620v000vsb8ft22vrm2a","tag_id":"ciirg620v000xsb8fv8iehob8","_id":"ciirg620v000ysb8ffexu674c"},{"post_id":"ciirg620w000zsb8fj4kdfeh0","tag_id":"ciirg620x0011sb8fgvnmth0u","_id":"ciirg620x0012sb8fz6unl34s"},{"post_id":"ciirg620y0013sb8fkcydi3hs","tag_id":"ciirg620z0015sb8ftt6zkyhl","_id":"ciirg620z0016sb8fxi1nhgky"},{"post_id":"ciirg62100017sb8fg6wrqajc","tag_id":"ciirg62110019sb8f3b3ljm9e","_id":"ciirg6211001bsb8fopo5oyqy"},{"post_id":"ciirg62100017sb8fg6wrqajc","tag_id":"ciirg6211001asb8ffv5lc1za","_id":"ciirg6211001csb8fed6y1psx"},{"post_id":"ciirg6212001dsb8ffouz1ish","tag_id":"ciirg6212001fsb8f0kxx42mx","_id":"ciirg6212001gsb8ffrfdb2oi"},{"post_id":"ciirg6213001isb8fmo597y2n","tag_id":"ciirg6214001ksb8f3x2jq7g6","_id":"ciirg6215001nsb8f0mhb8tdv"},{"post_id":"ciirg6213001isb8fmo597y2n","tag_id":"ciirg6215001lsb8f8nnl1r3y","_id":"ciirg6215001osb8fuk3a0dhg"},{"post_id":"ciirg6215001psb8fk39q4xa3","tag_id":"ciirg6216001rsb8flhtf2d4s","_id":"ciirg6216001ssb8fdyqa1vyx"},{"post_id":"ciirg6215001psb8fk39q4xa3","tag_id":"ciirg620r000psb8ft97zbfd8","_id":"ciirg6216001tsb8fg70ap8dx"},{"post_id":"ciirg6218001usb8f1tkoxsrp","tag_id":"ciirg620t000tsb8fokjp9qz2","_id":"ciirg6219001ysb8fbghmpvqc"},{"post_id":"ciirg6218001usb8f1tkoxsrp","tag_id":"ciirg6219001wsb8fta0gpu8n","_id":"ciirg6219001zsb8f5yepsgfl"},{"post_id":"ciirg6218001usb8f1tkoxsrp","tag_id":"ciirg6219001xsb8fz1lzll39","_id":"ciirg62190020sb8fnf4o9d2d"},{"post_id":"ciirg621a0021sb8fkst4112j","tag_id":"ciirg621b0023sb8fby7stplw","_id":"ciirg621b0024sb8f5oqfh3xu"},{"post_id":"ciirg621a0021sb8fkst4112j","tag_id":"ciirg6211001asb8ffv5lc1za","_id":"ciirg621b0025sb8fjxrac2bk"},{"post_id":"ciirg621a0021sb8fkst4112j","tag_id":"ciirg620r000psb8ft97zbfd8","_id":"ciirg621b0026sb8faln8b2c5"},{"post_id":"ciirg621c0027sb8fewtedb9i","tag_id":"ciirg621d0029sb8fntb0q0wa","_id":"ciirg621d002bsb8f2jp2xaja"},{"post_id":"ciirg621c0027sb8fewtedb9i","tag_id":"ciirg621d002asb8fjny6hacz","_id":"ciirg621d002csb8f0lm48ub5"},{"post_id":"ciirg621e002dsb8f47ka4ywp","tag_id":"ciirg621e002fsb8faw75aatq","_id":"ciirg621f002gsb8fn4asdb07"},{"post_id":"ciirg621f002hsb8fhgqxcz3e","tag_id":"ciirg621e002fsb8faw75aatq","_id":"ciirg621g002jsb8fxkifpmvm"},{"post_id":"ciirg621h002ksb8fq5nlr8x6","tag_id":"ciirg62110019sb8f3b3ljm9e","_id":"ciirg621h002msb8fhzswk1q2"},{"post_id":"ciirg621h002ksb8fq5nlr8x6","tag_id":"ciirg6211001asb8ffv5lc1za","_id":"ciirg621i002nsb8fiwdib76l"},{"post_id":"ciirg621j002osb8ff1bosx26","tag_id":"ciirg6214001ksb8f3x2jq7g6","_id":"ciirg621k002ssb8fk6dyvxy4"},{"post_id":"ciirg621j002osb8ff1bosx26","tag_id":"ciirg621k002qsb8fgax3jowx","_id":"ciirg621k002tsb8flf9v1hdf"},{"post_id":"ciirg621j002osb8ff1bosx26","tag_id":"ciirg621k002rsb8fhh7h6610","_id":"ciirg621k002usb8fd2fb7pkg"},{"post_id":"ciirg621l002vsb8fgozjki59","tag_id":"ciirg621m002xsb8freipxmyd","_id":"ciirg621m002ysb8fh2fxiczk"},{"post_id":"ciirg621l002vsb8fgozjki59","tag_id":"ciirg621k002qsb8fgax3jowx","_id":"ciirg621m002zsb8f4ubluxif"},{"post_id":"ciirg621n0030sb8flqq1w280","tag_id":"ciirg621o0032sb8fz3izaal3","_id":"ciirg621o0033sb8frgdb6g6y"},{"post_id":"ciirg621p0034sb8fwobft8w3","tag_id":"ciirg621d002asb8fjny6hacz","_id":"ciirg621q0037sb8fi8h9ujtg"},{"post_id":"ciirg621p0034sb8fwobft8w3","tag_id":"ciirg621o0032sb8fz3izaal3","_id":"ciirg621r0038sb8fcczp3s74"},{"post_id":"ciirg621p0034sb8fwobft8w3","tag_id":"ciirg621q0036sb8fefqfzzlg","_id":"ciirg621r0039sb8fl76i7a8r"},{"post_id":"ciirg621r003asb8fia88xgop","tag_id":"ciirg621d002asb8fjny6hacz","_id":"ciirg621s003csb8fu52pi9hv"},{"post_id":"ciirg621r003asb8fia88xgop","tag_id":"ciirg621o0032sb8fz3izaal3","_id":"ciirg621s003dsb8fiel5aas8"},{"post_id":"ciirg621r003asb8fia88xgop","tag_id":"ciirg621q0036sb8fefqfzzlg","_id":"ciirg621s003esb8fmpdcku0q"},{"post_id":"ciirg621t003fsb8fckoq1sqh","tag_id":"ciirg6214001ksb8f3x2jq7g6","_id":"ciirg621u003jsb8fo05wl6vw"},{"post_id":"ciirg621t003fsb8fckoq1sqh","tag_id":"ciirg621t003hsb8f4ldc3pdr","_id":"ciirg621u003ksb8fvgc6w440"},{"post_id":"ciirg621t003fsb8fckoq1sqh","tag_id":"ciirg621u003isb8fnnc3eoaf","_id":"ciirg621u003lsb8fjaph7bi4"},{"post_id":"ciirg621u003msb8f24kw3s4n","tag_id":"ciirg6214001ksb8f3x2jq7g6","_id":"ciirg621w003psb8fnecn8ul2"},{"post_id":"ciirg621u003msb8f24kw3s4n","tag_id":"ciirg621t003hsb8f4ldc3pdr","_id":"ciirg621w003qsb8femen2avl"},{"post_id":"ciirg621u003msb8f24kw3s4n","tag_id":"ciirg621u003isb8fnnc3eoaf","_id":"ciirg621w003rsb8fm9j8tw5m"},{"post_id":"ciirg621u003msb8f24kw3s4n","tag_id":"ciirg621w003osb8f3ezc4h8a","_id":"ciirg621w003ssb8frfad7dbf"},{"post_id":"ciirg621z003tsb8fkbvyuo63","tag_id":"ciirg621u003isb8fnnc3eoaf","_id":"ciirg6220003vsb8f8lwf0x7k"},{"post_id":"ciirg621z003tsb8fkbvyuo63","tag_id":"ciirg621w003osb8f3ezc4h8a","_id":"ciirg6220003wsb8fa50sssn1"},{"post_id":"ciirg6223003xsb8fcen68f4q","tag_id":"ciirg621u003isb8fnnc3eoaf","_id":"ciirg6223003zsb8fhn5bpekr"},{"post_id":"ciirg62240040sb8frxp017s4","tag_id":"ciirg621u003isb8fnnc3eoaf","_id":"ciirg62240042sb8f9ohxfz0r"},{"post_id":"ciirg62250043sb8fu5kruni6","tag_id":"ciirg620x0011sb8fgvnmth0u","_id":"ciirg62260045sb8far59rdv3"},{"post_id":"ciirg62270046sb8fzbkuwllm","tag_id":"ciirg62280048sb8fxnppdpo8","_id":"ciirg6229004bsb8frgzlzws6"},{"post_id":"ciirg62270046sb8fzbkuwllm","tag_id":"ciirg62280049sb8f0f7dm5s4","_id":"ciirg6229004csb8fgg2bdxhy"},{"post_id":"ciirg62270046sb8fzbkuwllm","tag_id":"ciirg6229004asb8ftcgmwvc8","_id":"ciirg6229004dsb8fvh9u0d9o"},{"post_id":"ciirg622b004esb8fryz8m4x3","tag_id":"ciirg622c004gsb8fzy1qftf1","_id":"ciirg622d004isb8fwupv39dc"},{"post_id":"ciirg622b004esb8fryz8m4x3","tag_id":"ciirg622d004hsb8fprifglr2","_id":"ciirg622d004jsb8fsmk1jwpr"},{"post_id":"ciirg622e004ksb8fy6qfb57u","tag_id":"ciirg621m002xsb8freipxmyd","_id":"ciirg622f004nsb8f7inmmchs"},{"post_id":"ciirg622e004ksb8fy6qfb57u","tag_id":"ciirg622f004msb8f7kvfp75z","_id":"ciirg622f004osb8fj3wof652"},{"post_id":"ciirg622h004psb8fm9udo4dh","tag_id":"ciirg621m002xsb8freipxmyd","_id":"ciirg622i004rsb8f8duulrwx"},{"post_id":"ciirg622h004psb8fm9udo4dh","tag_id":"ciirg622f004msb8f7kvfp75z","_id":"ciirg622i004ssb8fa5ap7omn"},{"post_id":"ciirg622j004tsb8f9lmz1p8i","tag_id":"ciirg622k004vsb8fbw9s558a","_id":"ciirg622k004xsb8fhlcl6kzw"},{"post_id":"ciirg622j004tsb8f9lmz1p8i","tag_id":"ciirg622k004wsb8f4z1elrwv","_id":"ciirg622k004ysb8fikcz3lue"},{"post_id":"ciirg622l004zsb8fn9vq0ke5","tag_id":"ciirg622k004vsb8fbw9s558a","_id":"ciirg622m0051sb8ffhistjyx"},{"post_id":"ciirg622l004zsb8fn9vq0ke5","tag_id":"ciirg622k004wsb8f4z1elrwv","_id":"ciirg622m0052sb8f3ct92qdr"},{"post_id":"ciirg622n0053sb8fc6aqce3h","tag_id":"ciirg622k004vsb8fbw9s558a","_id":"ciirg622o0055sb8f0v606fkj"},{"post_id":"ciirg622n0053sb8fc6aqce3h","tag_id":"ciirg622k004wsb8f4z1elrwv","_id":"ciirg622o0056sb8fh5fjegkx"},{"post_id":"ciirg622p0057sb8fd2majmpk","tag_id":"ciirg622q0059sb8f9tfnnyex","_id":"ciirg622q005bsb8f2tcgh3ih"},{"post_id":"ciirg622p0057sb8fd2majmpk","tag_id":"ciirg622q005asb8fiyh8ysh5","_id":"ciirg622q005csb8f5wvjk0fz"},{"post_id":"ciirg622r005dsb8fg3pzkwkv","tag_id":"ciirg622q0059sb8f9tfnnyex","_id":"ciirg622s005fsb8ftvnc2665"},{"post_id":"ciirg622r005dsb8fg3pzkwkv","tag_id":"ciirg622q005asb8fiyh8ysh5","_id":"ciirg622s005gsb8f55rb3pmp"},{"post_id":"ciirg622s005hsb8fpcni6h4n","tag_id":"ciirg622q0059sb8f9tfnnyex","_id":"ciirg622t005jsb8ftajf4ixz"},{"post_id":"ciirg622s005hsb8fpcni6h4n","tag_id":"ciirg622q005asb8fiyh8ysh5","_id":"ciirg622t005ksb8frccj39q7"},{"post_id":"ciirg622u005lsb8fua2jrmej","tag_id":"ciirg622q0059sb8f9tfnnyex","_id":"ciirg622v005nsb8f3tvzpxbi"},{"post_id":"ciirg622u005lsb8fua2jrmej","tag_id":"ciirg622q005asb8fiyh8ysh5","_id":"ciirg622v005osb8fmdcoyrlw"},{"post_id":"ciirg622w005psb8frln26qp5","tag_id":"ciirg620o000jsb8fr67fcpk3","_id":"ciirg622w005rsb8fxenel7l2"},{"post_id":"ciirg622w005psb8frln26qp5","tag_id":"ciirg620p000ksb8fmbj2hnkd","_id":"ciirg622w005ssb8fcueoigvi"},{"post_id":"ciirg622x005tsb8fno1na3yx","tag_id":"ciirg621k002qsb8fgax3jowx","_id":"ciirg622y005vsb8f5xlz96sr"},{"post_id":"ciirg622z005wsb8fm2aami3p","tag_id":"ciirg6230005ysb8fypiqk7vm","_id":"ciirg6230005zsb8fe51stz0x"},{"post_id":"ciirg62310060sb8fenovhnnj","tag_id":"ciirg621m002xsb8freipxmyd","_id":"ciirg62320062sb8f90ck1gu4"},{"post_id":"ciirg62320063sb8fbj698zwi","tag_id":"ciirg6214001ksb8f3x2jq7g6","_id":"ciirg62330065sb8fl99xemr8"},{"post_id":"ciirg62340066sb8f1f55dv0n","tag_id":"ciirg621m002xsb8freipxmyd","_id":"ciirg62350068sb8f299h6tk8"},{"post_id":"ciirg62350069sb8fw77h4cbp","tag_id":"ciirg622k004vsb8fbw9s558a","_id":"ciirg6236006bsb8fosj2d0vi"},{"post_id":"ciirg62350069sb8fw77h4cbp","tag_id":"ciirg622k004wsb8f4z1elrwv","_id":"ciirg6236006csb8fy6eda6vc"},{"post_id":"ciirg6237006dsb8fi0763m4z","tag_id":"ciirg622k004vsb8fbw9s558a","_id":"ciirg6238006gsb8fzjzs3zzg"},{"post_id":"ciirg6237006dsb8fi0763m4z","tag_id":"ciirg6238006fsb8fks4ogclw","_id":"ciirg6238006hsb8fhhh6bqij"},{"post_id":"ciirg6237006dsb8fi0763m4z","tag_id":"ciirg622k004wsb8f4z1elrwv","_id":"ciirg6238006isb8fzblun7t8"},{"post_id":"ciirg6238006jsb8fpf1y2gws","tag_id":"ciirg622k004vsb8fbw9s558a","_id":"ciirg6239006lsb8fw5ev75nf"},{"post_id":"ciirg6238006jsb8fpf1y2gws","tag_id":"ciirg622k004wsb8f4z1elrwv","_id":"ciirg6239006msb8fhjklj6wp"},{"post_id":"ciirg623a006nsb8fu2bi5dhs","tag_id":"ciirg623a006psb8frqi6r0st","_id":"ciirg623b006qsb8flmx9qsr8"},{"post_id":"ciirg623b006rsb8f6l9brp4n","tag_id":"ciirg623c006tsb8fidhw2pe2","_id":"ciirg623d006usb8f3f9gdel2"},{"post_id":"ciirg623d006vsb8fwxucqwl2","tag_id":"ciirg622k004vsb8fbw9s558a","_id":"ciirg623e006xsb8fmitrefcl"},{"post_id":"ciirg623f006ysb8fcmqm2fr2","tag_id":"ciirg622k004vsb8fbw9s558a","_id":"ciirg623g0071sb8fsqby00sz"},{"post_id":"ciirg623f006ysb8fcmqm2fr2","tag_id":"ciirg623f0070sb8f7oq2oz44","_id":"ciirg623g0072sb8fb0ccympj"},{"post_id":"ciirg623f006ysb8fcmqm2fr2","tag_id":"ciirg622k004wsb8f4z1elrwv","_id":"ciirg623g0073sb8ft4okx40f"},{"post_id":"ciirg623g0074sb8f021yhjoc","tag_id":"ciirg622k004vsb8fbw9s558a","_id":"ciirg623h0076sb8f0odqb883"},{"post_id":"ciirg623g0074sb8f021yhjoc","tag_id":"ciirg623f0070sb8f7oq2oz44","_id":"ciirg623h0077sb8f5btzqxhf"},{"post_id":"ciirg623g0074sb8f021yhjoc","tag_id":"ciirg622k004wsb8f4z1elrwv","_id":"ciirg623h0078sb8f6lytlk7k"},{"post_id":"ciirg623i0079sb8fnzgje88k","tag_id":"ciirg622k004vsb8fbw9s558a","_id":"ciirg623k007csb8fa5wgnfo6"},{"post_id":"ciirg623i0079sb8fnzgje88k","tag_id":"ciirg623j007bsb8fvnl246eh","_id":"ciirg623k007dsb8ftxslgybp"},{"post_id":"ciirg623k007esb8f7ggt3fom","tag_id":"ciirg622k004vsb8fbw9s558a","_id":"ciirg623o007gsb8fvgpxfaqb"},{"post_id":"ciirg623k007esb8f7ggt3fom","tag_id":"ciirg623j007bsb8fvnl246eh","_id":"ciirg623o007hsb8frvc5cv02"},{"post_id":"ciirg623p007isb8f5uodzpij","tag_id":"ciirg622k004vsb8fbw9s558a","_id":"ciirg623q007ksb8ftklit729"},{"post_id":"ciirg623p007isb8f5uodzpij","tag_id":"ciirg623j007bsb8fvnl246eh","_id":"ciirg623q007lsb8fpmv1e12s"},{"post_id":"ciirg623q007msb8f3y9e9qh8","tag_id":"ciirg622k004vsb8fbw9s558a","_id":"ciirg623r007osb8f5z09lbpf"},{"post_id":"ciirg623r007psb8fxi147iu8","tag_id":"ciirg622k004vsb8fbw9s558a","_id":"ciirg623s007rsb8fsburppdn"},{"post_id":"ciirg623t007ssb8fyghfif6h","tag_id":"ciirg623t007usb8fgn1ep5zp","_id":"ciirg623t007vsb8fmakhcc7i"},{"post_id":"ciirg623u007wsb8fb145hlx7","tag_id":"ciirg623v007ysb8fhk51qd8z","_id":"ciirg623v007zsb8f4044zrrn"},{"post_id":"ciirg623v0080sb8fve7w65dn","tag_id":"ciirg623w0082sb8fgrgje94l","_id":"ciirg623w0083sb8ftpkr775s"},{"post_id":"ciirg623x0084sb8f3nfkrqoc","tag_id":"ciirg620x0011sb8fgvnmth0u","_id":"ciirg623y0086sb8ftwb7fqqy"},{"post_id":"ciirg623x0084sb8f3nfkrqoc","tag_id":"ciirg620r000psb8ft97zbfd8","_id":"ciirg623y0087sb8f3i5hoz1c"},{"post_id":"ciirg623y0088sb8f9zxg4am1","tag_id":"ciirg623z008asb8frvr8e8ww","_id":"ciirg6240008bsb8fkcwtw421"},{"post_id":"ciirg6241008csb8f15ct5jre","tag_id":"ciirg6242008esb8f3kwxr7lr","_id":"ciirg6242008fsb8f6u493qow"},{"post_id":"ciirg6241008csb8f15ct5jre","tag_id":"ciirg621m002xsb8freipxmyd","_id":"ciirg6242008gsb8f59nyt66n"},{"post_id":"ciirg6243008hsb8fta1bt7k9","tag_id":"ciirg6244008jsb8f61nvp1jt","_id":"ciirg6244008nsb8fwz15nqvw"},{"post_id":"ciirg6243008hsb8fta1bt7k9","tag_id":"ciirg6244008ksb8fxvwjwhkb","_id":"ciirg6245008osb8fh2e031zl"},{"post_id":"ciirg6243008hsb8fta1bt7k9","tag_id":"ciirg6244008msb8fhqk0j0ip","_id":"ciirg6245008psb8f6m1yd637"},{"post_id":"ciirg6247008qsb8fmkuz8kqu","tag_id":"ciirg6244008jsb8f61nvp1jt","_id":"ciirg6248008tsb8f0rsk86wo"},{"post_id":"ciirg6247008qsb8fmkuz8kqu","tag_id":"ciirg6248008ssb8f4c0vvuz2","_id":"ciirg6248008usb8fzo33wjeq"},{"post_id":"ciirg6249008vsb8ftjncozzm","tag_id":"ciirg6211001asb8ffv5lc1za","_id":"ciirg624a008xsb8fdnldw2t2"},{"post_id":"ciirg624b0090sb8fgn7hmnzm","tag_id":"ciirg624c0092sb8f7z4bwasu","_id":"ciirg624c0093sb8fiyyxayqh"},{"post_id":"ciirg624c0094sb8fswg0jbic","tag_id":"ciirg624d0096sb8fe0udssau","_id":"ciirg624d0097sb8fsqgobwa3"},{"post_id":"ciirg624e0098sb8fozf07zx5","tag_id":"ciirg624d0096sb8fe0udssau","_id":"ciirg624f009asb8f90vsfncx"},{"post_id":"ciirg624f009bsb8fu6r73978","tag_id":"ciirg624d0096sb8fe0udssau","_id":"ciirg624g009dsb8f4tngvkpb"},{"post_id":"ciirg624h009esb8f5h4jcnon","tag_id":"ciirg624d0096sb8fe0udssau","_id":"ciirg624i009gsb8foonn79sa"},{"post_id":"ciirg624j009hsb8fkbe0qon7","tag_id":"ciirg624d0096sb8fe0udssau","_id":"ciirg624k009jsb8fcvga6oeu"},{"post_id":"ciirg624k009ksb8fhdbgg0za","tag_id":"ciirg624d0096sb8fe0udssau","_id":"ciirg624l009msb8fqm70jypb"},{"post_id":"ciirg624l009nsb8fayiwbpg6","tag_id":"ciirg624d0096sb8fe0udssau","_id":"ciirg624m009psb8f84z5ar2s"},{"post_id":"ciirg624n009qsb8fgrc69ec1","tag_id":"ciirg624d0096sb8fe0udssau","_id":"ciirg624o009ssb8fqk4sb27l"},{"post_id":"ciirg624o009tsb8f05k3y3ne","tag_id":"ciirg624d0096sb8fe0udssau","_id":"ciirg624p009vsb8fkvvx0l3f"},{"post_id":"ciirg624p009wsb8f8y611mia","tag_id":"ciirg624d0096sb8fe0udssau","_id":"ciirg624q009ysb8fb3nq3aw4"},{"post_id":"ciirg624r009zsb8fyfy9qnd2","tag_id":"ciirg6219001xsb8fz1lzll39","_id":"ciirg624s00a1sb8fredewwnv"},{"post_id":"ciirg624s00a2sb8fkgylrzax","tag_id":"ciirg6219001xsb8fz1lzll39","_id":"ciirg624t00a4sb8fhmw2v8nj"},{"post_id":"ciirg624t00a5sb8ftj47qkb1","tag_id":"ciirg6219001xsb8fz1lzll39","_id":"ciirg624u00a7sb8fojhgd6uv"},{"post_id":"ciirg624v00a8sb8fpk0c459w","tag_id":"ciirg624w00aasb8fnao5ecc9","_id":"ciirg624w00acsb8fhdkmojqe"},{"post_id":"ciirg624v00a8sb8fpk0c459w","tag_id":"ciirg624w00absb8fo7vlmox0","_id":"ciirg624x00adsb8f0n5e2cwx"},{"post_id":"ciirg624y00aesb8fsbk5tmgp","tag_id":"ciirg6242008esb8f3kwxr7lr","_id":"ciirg624z00agsb8fj1jq1vhf"},{"post_id":"ciirg624y00aesb8fsbk5tmgp","tag_id":"ciirg621m002xsb8freipxmyd","_id":"ciirg624z00ahsb8fa9ugz9o6"},{"post_id":"ciirg624y00aesb8fsbk5tmgp","tag_id":"ciirg620z0015sb8ftt6zkyhl","_id":"ciirg624z00aisb8fv6zxja76"},{"post_id":"ciirg624z00ajsb8fy320fyu8","tag_id":"ciirg620r000psb8ft97zbfd8","_id":"ciirg625000alsb8f8llc10db"},{"post_id":"ciirg625100amsb8fomtinzpn","tag_id":"ciirg620z0015sb8ftt6zkyhl","_id":"ciirg625100aosb8f7s4lhxtz"},{"post_id":"ciirg625200apsb8f0fxuit4h","tag_id":"ciirg620z0015sb8ftt6zkyhl","_id":"ciirg625300arsb8fw2yveseb"},{"post_id":"ciirg625400assb8f7r6f78qd","tag_id":"ciirg620z0015sb8ftt6zkyhl","_id":"ciirg625600ausb8f4crscdro"},{"post_id":"ciirg625600avsb8fjjtw08gd","tag_id":"ciirg625700axsb8fa1prz4x5","_id":"ciirg625700aysb8ft2ovewh4"},{"post_id":"ciirg625800azsb8fp6nr0ky5","tag_id":"ciirg625700axsb8fa1prz4x5","_id":"ciirg625900b1sb8fudhvizol"},{"post_id":"ciirg625900b2sb8f1quxtx2h","tag_id":"ciirg622k004vsb8fbw9s558a","_id":"ciirg625a00b5sb8fibfpeue2"},{"post_id":"ciirg625900b2sb8f1quxtx2h","tag_id":"ciirg622k004wsb8f4z1elrwv","_id":"ciirg625b00b6sb8fi4705m2x"},{"post_id":"ciirg625900b2sb8f1quxtx2h","tag_id":"ciirg625a00b4sb8fzbfktfq4","_id":"ciirg625b00b7sb8fvt6rkbnp"},{"post_id":"ciirg625b00b8sb8f93zvfmtb","tag_id":"ciirg625c00basb8fgqxkyqb4","_id":"ciirg625c00bbsb8fe20a07xz"},{"post_id":"ciirg625d00bcsb8f0edbvbst","tag_id":"ciirg621d002asb8fjny6hacz","_id":"ciirg625d00besb8f9w1sal9w"},{"post_id":"ciirg625e00bfsb8fkoprwipm","tag_id":"ciirg621d002asb8fjny6hacz","_id":"ciirg625f00bhsb8fkzv6uk5z"},{"post_id":"ciirg625f00bisb8fbapd2hdh","tag_id":"ciirg621d002asb8fjny6hacz","_id":"ciirg625g00bksb8fplngnhat"},{"post_id":"ciirg625i00bmsb8fjmu9hdpm","tag_id":"ciirg620r000psb8ft97zbfd8","_id":"ciirg625j00bosb8fnaph7yd1"}],"Tag":[{"name":"ZooKeeper","_id":"ciirg620g0003sb8fqnkobn6l"},{"name":"双11","_id":"ciirg620j0008sb8fcej531ut"},{"name":"微博","_id":"ciirg620m000csb8fv7idho0w"},{"name":"数据分析","_id":"ciirg620m000dsb8fc7xbgnve"},{"name":"歌词","_id":"ciirg620o000jsb8fr67fcpk3"},{"name":"音乐","_id":"ciirg620p000ksb8fmbj2hnkd"},{"name":"生活","_id":"ciirg620r000psb8ft97zbfd8"},{"name":"NoSQL","_id":"ciirg620t000tsb8fokjp9qz2"},{"name":"系统架构","_id":"ciirg620v000xsb8fv8iehob8"},{"name":"价值观","_id":"ciirg620x0011sb8fgvnmth0u"},{"name":"Solr","_id":"ciirg620z0015sb8ftt6zkyhl"},{"name":"摄影","_id":"ciirg62110019sb8f3b3ljm9e"},{"name":"数码","_id":"ciirg6211001asb8ffv5lc1za"},{"name":"REWORK, 37signals, 书摘, 生活","_id":"ciirg6212001fsb8f0kxx42mx"},{"name":"Java","_id":"ciirg6214001ksb8f3x2jq7g6"},{"name":"Network","_id":"ciirg6215001lsb8f8nnl1r3y"},{"name":"果壳网","_id":"ciirg6216001rsb8flhtf2d4s"},{"name":"Redis","_id":"ciirg6219001wsb8fta0gpu8n"},{"name":"数据结构","_id":"ciirg6219001xsb8fz1lzll39"},{"name":"SSD","_id":"ciirg621b0023sb8fby7stplw"},{"name":"电影","_id":"ciirg621d0029sb8fntb0q0wa"},{"name":"算法","_id":"ciirg621d002asb8fjny6hacz"},{"name":"Python","_id":"ciirg621e002fsb8faw75aatq"},{"name":"JVM","_id":"ciirg621k002qsb8fgax3jowx"},{"name":"OOM Killer","_id":"ciirg621k002rsb8fhh7h6610"},{"name":"java","_id":"ciirg621m002xsb8freipxmyd"},{"name":"自然语言处理","_id":"ciirg621o0032sb8fz3izaal3"},{"name":"语义","_id":"ciirg621q0036sb8fefqfzzlg"},{"name":"Mina","_id":"ciirg621t003hsb8f4ldc3pdr"},{"name":"Netty","_id":"ciirg621u003isb8fnnc3eoaf"},{"name":"线程模型","_id":"ciirg621w003osb8f3ezc4h8a"},{"name":"Apple","_id":"ciirg62280048sb8fxnppdpo8"},{"name":"Macbook","_id":"ciirg62280049sb8f0f7dm5s4"},{"name":"RBMP","_id":"ciirg6229004asb8ftcgmwvc8"},{"name":"group by","_id":"ciirg622c004gsb8fzy1qftf1"},{"name":"SQL","_id":"ciirg622d004hsb8fprifglr2"},{"name":"Maven","_id":"ciirg622f004msb8f7kvfp75z"},{"name":"Hadoop","_id":"ciirg622k004vsb8fbw9s558a"},{"name":"MapReduce","_id":"ciirg622k004wsb8f4z1elrwv"},{"name":"Linux","_id":"ciirg622q0059sb8f9tfnnyex"},{"name":"Shell","_id":"ciirg622q005asb8fiyh8ysh5"},{"name":"Java, 源码","_id":"ciirg6230005ysb8fypiqk7vm"},{"name":"Haloop","_id":"ciirg6238006fsb8fks4ogclw"},{"name":"Remote, 书摘, 生活","_id":"ciirg623a006psb8frqi6r0st"},{"name":"SAE","_id":"ciirg623c006tsb8fidhw2pe2"},{"name":"Hadoop Pipes","_id":"ciirg623f0070sb8f7oq2oz44"},{"name":"RPC","_id":"ciirg623j007bsb8fvnl246eh"},{"name":"Google","_id":"ciirg623t007usb8fgn1ep5zp"},{"name":"GIT","_id":"ciirg623v007ysb8fhk51qd8z"},{"name":"价值观, 生活","_id":"ciirg623w0082sb8fgrgje94l"},{"name":"英语","_id":"ciirg623z008asb8frvr8e8ww"},{"name":"Eclipse","_id":"ciirg6242008esb8f3kwxr7lr"},{"name":"Docker","_id":"ciirg6244008jsb8f61nvp1jt"},{"name":"Docker plugins","_id":"ciirg6244008ksb8fxvwjwhkb"},{"name":"Docker volume","_id":"ciirg6244008msb8fhqk0j0ip"},{"name":"Docker Compose","_id":"ciirg6248008ssb8f4c0vvuz2"},{"name":"分布式","_id":"ciirg624c0092sb8f7z4bwasu"},{"name":"设计模式","_id":"ciirg624d0096sb8fe0udssau"},{"name":"CSS","_id":"ciirg624w00aasb8fnao5ecc9"},{"name":"Frontend","_id":"ciirg624w00absb8fo7vlmox0"},{"name":"Solr, 数据结构","_id":"ciirg625700axsb8fa1prz4x5"},{"name":"YARN","_id":"ciirg625a00b4sb8fzbfktfq4"},{"name":"Android","_id":"ciirg625c00basb8fgqxkyqb4"}]}}